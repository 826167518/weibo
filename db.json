{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/spff/source/apple-touch-icon.png","path":"apple-touch-icon.png","modified":1,"renderable":1},{"_id":"themes/spff/source/css/loading-style.css","path":"css/loading-style.css","modified":1,"renderable":1},{"_id":"themes/spff/source/css/showshare.css","path":"css/showshare.css","modified":1,"renderable":1},{"_id":"themes/spff/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/spff/source/img/coderwall.png","path":"img/coderwall.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/delicious.png","path":"img/delicious.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/douban.png","path":"img/douban.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/facebook.png","path":"img/facebook.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/favicon.png","path":"img/favicon.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/github.png","path":"img/github.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/google.png","path":"img/google.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/head.jpg","path":"img/head.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/img/img-err.png","path":"img/img-err.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/img-loading.png","path":"img/img-loading.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/linkedin.png","path":"img/linkedin.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/mail.png","path":"img/mail.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/pinboard.png","path":"img/pinboard.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/pinterest.png","path":"img/pinterest.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/qq.png","path":"img/qq.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/rss.png","path":"img/rss.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/scrollbar_arrow.png","path":"img/scrollbar_arrow.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/stackoverflow.png","path":"img/stackoverflow.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/twitter.png","path":"img/twitter.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/wechat.png","path":"img/wechat.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/weibo.png","path":"img/weibo.png","modified":1,"renderable":1},{"_id":"themes/spff/source/img/zhihu.png","path":"img/zhihu.png","modified":1,"renderable":1},{"_id":"themes/spff/source/js/TweenMax.js","path":"js/TweenMax.js","modified":1,"renderable":1},{"_id":"themes/spff/source/js/clipboard.min.js","path":"js/clipboard.min.js","modified":1,"renderable":1},{"_id":"themes/spff/source/js/instagram.js","path":"js/instagram.js","modified":1,"renderable":1},{"_id":"themes/spff/source/js/jquery.lazyload.js","path":"js/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/spff/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"themes/spff/source/js/mobile.js","path":"js/mobile.js","modified":1,"renderable":1},{"_id":"themes/spff/source/js/pace.js","path":"js/pace.js","modified":1,"renderable":1},{"_id":"themes/spff/source/js/pc.js","path":"js/pc.js","modified":1,"renderable":1},{"_id":"themes/spff/source/js/plugins.js","path":"js/plugins.js","modified":1,"renderable":1},{"_id":"themes/spff/source/img/head1.jpg","path":"img/head1.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/js/TweenMax.min.js","path":"js/TweenMax.min.js","modified":1,"renderable":1},{"_id":"themes/spff/source/js/embed.js","path":"js/embed.js","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-1.jpg","path":"background/bg-1.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-109.jpg","path":"background/bg-109.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-11.jpg","path":"background/bg-11.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-20.jpg","path":"background/bg-20.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-17.jpg","path":"background/bg-17.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-3.jpg","path":"background/bg-3.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg.jpg","path":"background/bg.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/css/pace/pace-theme-flash.css","path":"css/pace/pace-theme-flash.css","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/spff/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/spff/source/font-awesome/css/font-awesome.css","path":"font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/spff/source/font-awesome/css/font-awesome.min.css","path":"font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/spff/source/js/404/jquery.parallaxify-0.0.2.min.js","path":"js/404/jquery.parallaxify-0.0.2.min.js","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-15.jpg","path":"background/bg-15.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-23.jpg","path":"background/bg-23.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-7.jpg","path":"background/bg-7.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/font-awesome/fonts/FontAwesome.otf","path":"font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/spff/source/font-awesome/fonts/fontawesome-webfont.eot","path":"font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/spff/source/font-awesome/fonts/fontawesome-webfont.woff","path":"font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/spff/source/font-awesome/fonts/fontawesome-webfont.woff2","path":"font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/spff/source/js/404/jquery-2.0.3.min.js","path":"js/404/jquery-2.0.3.min.js","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-14.jpg","path":"background/bg-14.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-9.jpg","path":"background/bg-9.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/font-awesome/fonts/fontawesome-webfont.ttf","path":"font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-19.jpg","path":"background/bg-19.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-21.jpg","path":"background/bg-21.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-22.jpg","path":"background/bg-22.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-24.jpg","path":"background/bg-24.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-4.jpg","path":"background/bg-4.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-8.jpg","path":"background/bg-8.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-6.jpg","path":"background/bg-6.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-12.jpg","path":"background/bg-12.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-10.jpg","path":"background/bg-10.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-18.jpg","path":"background/bg-18.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/img/bg.jpg","path":"img/bg.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-111.jpg","path":"background/bg-111.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-13.jpg","path":"background/bg-13.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-16.jpg","path":"background/bg-16.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/font-awesome/fonts/fontawesome-webfont.svg","path":"font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-2.jpg","path":"background/bg-2.jpg","modified":1,"renderable":1},{"_id":"themes/spff/source/background/bg-5.jpg","path":"background/bg-5.jpg","modified":1,"renderable":1}],"Cache":[{"_id":"themes/spff/README.md","hash":"d549f7441186cf124996ea878934c8934f70412a","modified":1560845221136},{"_id":"themes/spff/_config.yml","hash":"f12788d94eeca5ede4f05e3d17393c3efae1766e","modified":1560845221136},{"_id":"themes/spff/package.json","hash":"00357ef6f24eb049074da81809e98f973f528cca","modified":1560845221141},{"_id":"source/_posts/Glances.md","hash":"11ae2c75b87c2f6b089337f8cc79debefd1ac0a1","modified":1560845221112},{"_id":"source/_posts/Kubernetes如何使用kube-dns实现服务发现.md","hash":"bc366b2597f56410cd81befcb60ebb44655b9a91","modified":1560845221113},{"_id":"source/_posts/Python(基础数据类型)详解.md","hash":"292864063295d36f374403fed9375db226f6b48b","modified":1560845221113},{"_id":"source/_posts/Traefik-kubernetes 初试.md","hash":"7018d464cc5ac77d6fe5b7aef1662e7e2eb3aa5f","modified":1561688098289},{"_id":"source/_posts/git.md","hash":"c336930ef5d27d2d5a9423de5a8f3d34f81ac8fa","modified":1560845221113},{"_id":"source/_posts/gitlab安装.md","hash":"e535f9868f066679b209c292da2a859ea15724d6","modified":1560845221113},{"_id":"source/_posts/git使用说明.md","hash":"7d227ed75a4f58d4908518009f5ed52ccab8f11f","modified":1560845221113},{"_id":"source/_posts/hello-world.md","hash":"9c2c98cb11fe73371a33d84d3ae7054f7458f3a0","modified":1560845221114},{"_id":"source/_posts/hexo.md","hash":"7905a70fd43ef7b142c4dd98f54dc2276f79e4dd","modified":1560845221114},{"_id":"source/_posts/htop使用说明.md","hash":"f0ba4e4a21e5b207d65bd5c571a65639d62b8d3b","modified":1560845221114},{"_id":"source/_posts/jira和confluence迁移记录.md","hash":"efcfef323bc13d15a569a6572af0085e61ec06eb","modified":1569319009931},{"_id":"source/_posts/keepalive+nginx实现高可用.md","hash":"99d6fb7643ffd8c054c9b5afd6b02818b3113035","modified":1560845221114},{"_id":"source/_posts/linux traceroute 命令详解.md","hash":"4b552f2b9faeee26b682c6e92f936788d0dc314c","modified":1560845221114},{"_id":"source/_posts/linux_traceroute_命令详解.md","hash":"e10a5882633e271771d6ea61e38140a290a96751","modified":1560845221114},{"_id":"source/_posts/linux_下同步工具inotify_+_rsync_使用详解.md","hash":"a66cc3848bdd9f9800b82109769c152bbb00e17c","modified":1560845221114},{"_id":"source/_posts/linux_命令rsync+crontab实现自动同步.md","hash":"ebed5e251b1119351c7e0f2e0fdc8dc9f6bab27e","modified":1560845221115},{"_id":"source/_posts/linux—SSH1.md","hash":"f979d0c14ce0b607605e6584c6eb9b53899a864c","modified":1560845221115},{"_id":"source/_posts/linux—SSH（二）Rsync备份.md","hash":"f56d6cba193e25a75fc6aa589f39b9bb387a56c8","modified":1560845221115},{"_id":"source/_posts/linux开机启动顺序.md","hash":"c99e22bf0d67d9e04780b82ea7f8f12da8cd937a","modified":1560845221115},{"_id":"source/_posts/lsyncd实时同步.md","hash":"baa255c1c8464f56b88df8dec361b2a66360759e","modified":1560845221116},{"_id":"source/_posts/lsyncd实现文件目录同步简要说明.md","hash":"88babaca91577eea8e7dde38938e0a9cf631b0f7","modified":1560845221116},{"_id":"source/_posts/mtr命令详解.md","hash":"ae39f1636bb45371a99ae09df8b269f6256ac2d7","modified":1560845221116},{"_id":"source/_posts/mysql主从配置文件内容.md","hash":"32a9ce3c9514d159bd6d8ee59e1ae817d45c69ec","modified":1560845221116},{"_id":"source/_posts/mysql使用binlog日志恢复.md","hash":"2b86f6d670d7af71db33b76f35f54bd392a0257f","modified":1560845221116},{"_id":"source/_posts/open-falcon安装.md","hash":"f9b0f08eea8b4ccee0285a1f360ba4a82861cacf","modified":1560845221117},{"_id":"source/_posts/tcpdump抓包命令详解.md","hash":"8e9ba3428ccb4ad5138b9daec44e6b7a66967317","modified":1560845221117},{"_id":"source/_posts/tcpdump：理论、自动抓包及业务架构树的生成.md","hash":"f51f30d4ef45606495bb2808ab475083fa272654","modified":1560845221117},{"_id":"source/_posts/tsung说明文档.md","hash":"376d9759aa6da4d77c46de61e3b38e8ba79fe564","modified":1560845221117},{"_id":"source/_posts/yum仓库搭建之RPM包制作.md","hash":"53e73739f7814fa0a4081bb4c55ccb206fa6dc7e","modified":1560845221118},{"_id":"source/_posts/zabbix2.6安装.md","hash":"fe917e7440943a1e3695d8beac3b3dbe13820612","modified":1560845221118},{"_id":"source/_posts/搭建WordPress.md","hash":"ee59a8e271499a6451da997747f953695e006598","modified":1560845221118},{"_id":"source/_posts/用Kibana和logstash快速搭建实时日志查询、收集与分析系统.md","hash":"8a63d84454e69f239a55d2e189b369681c46bc6b","modified":1560845221118},{"_id":"source/categories/index.md","hash":"249f810f68960834eab25186193af8dd88aa5c26","modified":1560845221118},{"_id":"source/tags/index.md","hash":"10e6fd48019caef04285e242116935d721b42188","modified":1560845221118},{"_id":"themes/spff/languages/de.yml","hash":"ecb13af8af81ccc033ae7494cb2f94f84f6466ad","modified":1560845221137},{"_id":"themes/spff/languages/default.yml","hash":"9e59cd11b290be84909612beb12d0f93ce737f53","modified":1560845221137},{"_id":"themes/spff/languages/en.yml","hash":"8fa0a7482188ca56fd3cf19c4a87320f85a76846","modified":1560845221137},{"_id":"themes/spff/languages/fr-FR.yml","hash":"12cfa96dc412ecb6f8bf4de2690575929464906e","modified":1560845221137},{"_id":"themes/spff/languages/pt-BR","hash":"922b6d836cc690742b2d55a725e3886c5d0cbb75","modified":1560845221137},{"_id":"themes/spff/languages/ru.yml","hash":"9997425292031ee8a58a93346ac6d3f38f18e566","modified":1560845221137},{"_id":"themes/spff/languages/zh-Hans.yml","hash":"0d7e8da60fd5e5db217e1733ac273ae00fd752ea","modified":1560845221137},{"_id":"themes/spff/languages/zh-hk.yml","hash":"606dfb34d3fec1d7895a654ff7a5a1de0c6a5c55","modified":1560845221137},{"_id":"themes/spff/languages/zh-tw.yml","hash":"9e4034870b57d2bb3063c91f8d206a6c4d7b3789","modified":1560845221137},{"_id":"themes/spff/languages/zh.yml","hash":"0d7e8da60fd5e5db217e1733ac273ae00fd752ea","modified":1560845221137},{"_id":"themes/spff/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1560845221141},{"_id":"themes/spff/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1560845221141},{"_id":"themes/spff/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1560845221141},{"_id":"themes/spff/layout/layout.ejs","hash":"4a5566f704f3246f5ef77badddf18d2e16750328","modified":1560845221141},{"_id":"themes/spff/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1560845221141},{"_id":"themes/spff/layout/plugins.swig","hash":"f809b5e62e968a80921c56e5d7658325b48b7263","modified":1560845221141},{"_id":"themes/spff/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1560845221141},{"_id":"themes/spff/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1560845221141},{"_id":"themes/spff/source/apple-touch-icon.png","hash":"c36a373c7830d61d1ce092bd5a88d0e9b54212fd","modified":1560845221142},{"_id":"themes/spff/layout/_partial/after-footer.ejs","hash":"54e262b6025026b3125868826c64527c3b8a4ca5","modified":1560845221138},{"_id":"themes/spff/layout/_partial/archive-post.ejs","hash":"8af583c5f60c69ffdc97bee4e8fdac1ba34ebecd","modified":1560845221138},{"_id":"themes/spff/layout/_partial/archive.ejs","hash":"a6e94061ac55b9eb55275f87b608d62f6ea35659","modified":1560845221138},{"_id":"themes/spff/layout/_partial/article.ejs","hash":"13f788f96eec6cad9c29a6f373b88c164b279856","modified":1560845221138},{"_id":"themes/spff/layout/_partial/background.ejs","hash":"e566c3804a25e4c76f025db511dbaa0d008757e2","modified":1560845221138},{"_id":"themes/spff/layout/_partial/bodybackground.ejs","hash":"931700a928b84577cc33dfff68a009188885f6c0","modified":1560845221138},{"_id":"themes/spff/layout/_partial/case.swig","hash":"a2a7ec0e4c203e49fd32335c60c3b9851ed6e4a5","modified":1560845221138},{"_id":"themes/spff/layout/_partial/footer.ejs","hash":"2a2509580a686dcdf247a336f87988c72514266b","modified":1560845221139},{"_id":"themes/spff/layout/_partial/head.ejs","hash":"8670e539351a3d248c299905e700d05e0a9b0f9a","modified":1560845221139},{"_id":"themes/spff/layout/_partial/header.ejs","hash":"6387a93dad7c3d778eb91e3821852fbf6813880c","modified":1560845221139},{"_id":"themes/spff/layout/_partial/hide-labels.ejs","hash":"e981795db4954ba5cc9d6844a6a2799bffdc0af3","modified":1560845221139},{"_id":"themes/spff/layout/_partial/left-col.ejs","hash":"cfcc6ed9ad918cf7c30bfeb746171440991b2e15","modified":1560845221139},{"_id":"themes/spff/layout/_partial/mathjax.ejs","hash":"cdfd21f079933f3a275bc4088e1ca5e6068e75b4","modified":1560845221139},{"_id":"themes/spff/layout/_partial/mobile-nav.ejs","hash":"1ddd03edfb88867eff99bc0060466ea7cca3825c","modified":1560845221139},{"_id":"themes/spff/layout/_partial/page.ejs","hash":"55ffdcc87b5fa50afdc370f439c0e812e307cbff","modified":1560845221139},{"_id":"themes/spff/layout/_partial/plugin.swig","hash":"17b6c6945e4b1b41dbb10d851f85ca10100c28ea","modified":1560845221139},{"_id":"themes/spff/layout/_partial/scrolling-button.ejs","hash":"b3a28974f37375796687e6100b48c3da6f662640","modified":1560845221140},{"_id":"themes/spff/layout/_partial/theme.swig","hash":"5a279ad8f6c6b7c104cce495faa563d8b7a7c74a","modified":1560845221140},{"_id":"themes/spff/layout/_partial/work.swig","hash":"6bdb6ec45f6179875e5a33bfdc7568a3831638fd","modified":1560845221141},{"_id":"themes/spff/layout/_partial/toc.ejs","hash":"84bbda825793de643d5a40190fab2160af1e75e3","modified":1560845221140},{"_id":"themes/spff/layout/_partial/post-nav-button.ejs","hash":"89b0b0bc70dcebfae064e2e7355177cd8f9e526b","modified":1560845221139},{"_id":"themes/spff/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1560845221215},{"_id":"themes/spff/source/css/_variables.styl","hash":"47b0536f118d75fc9705c437faf89fd5a93b3615","modified":1560845221219},{"_id":"themes/spff/source/css/loading-style.css","hash":"1f67362d809e85edc9f122db7bc3711af1ed1d8b","modified":1560845221219},{"_id":"themes/spff/source/css/showshare.css","hash":"3efc4afd0d136fb5dec993e9cd9ce85b9d1cf589","modified":1560845221220},{"_id":"themes/spff/source/css/style.styl","hash":"998204af28e814cbb5a70f7534f1a67c23d5103d","modified":1560845221220},{"_id":"themes/spff/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1560845221220},{"_id":"themes/spff/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1560845221220},{"_id":"themes/spff/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1560845221221},{"_id":"themes/spff/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1560845221221},{"_id":"themes/spff/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1560845221221},{"_id":"themes/spff/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1560845221221},{"_id":"themes/spff/source/fancybox/jquery.fancybox.css","hash":"b6aa6692c2e5f8bd74d96827b78570f0c5683c20","modified":1560845221222},{"_id":"themes/spff/source/fancybox/jquery.fancybox.js","hash":"a82597493d75ea989ca586e09173cff332efe41e","modified":1560845221222},{"_id":"themes/spff/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1560845221223},{"_id":"themes/spff/source/img/coderwall.png","hash":"fa84676c4d654e040e51fd34bfcd9f9348cd5331","modified":1560845221234},{"_id":"themes/spff/source/img/delicious.png","hash":"9553a5f5189e4a953e04a58a49dbfa74b86b73dd","modified":1560845221235},{"_id":"themes/spff/source/img/douban.png","hash":"e2ade003ffadd5826ee66ec23901c2d6e8607e4e","modified":1560845221235},{"_id":"themes/spff/source/img/facebook.png","hash":"d19ad7a0903daf26817afd8753cd97e0cc714f54","modified":1560845221235},{"_id":"themes/spff/source/img/favicon.png","hash":"5b4e9c94ff3396db5b074b69c1aa5bb909aba825","modified":1560845221235},{"_id":"themes/spff/source/img/github.png","hash":"b84d03b32fa388dcbf149296ebd16dce6223d48d","modified":1560845221235},{"_id":"themes/spff/source/img/google.png","hash":"61a21fec7346fa3400b747ac9a201cf3d5bc013d","modified":1560845221236},{"_id":"themes/spff/source/img/head.jpg","hash":"f96ad10fc77afd93821e72ac7fc3783e115cac42","modified":1560845221236},{"_id":"themes/spff/source/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1560845221237},{"_id":"themes/spff/source/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1560845221237},{"_id":"themes/spff/source/img/linkedin.png","hash":"e203138fb53c257cb214e97f4e30091b9c568d2c","modified":1560845221237},{"_id":"themes/spff/source/img/mail.png","hash":"fca8199cc77fdbd700a45bf56d091c82f4a67fe7","modified":1560845221237},{"_id":"themes/spff/source/img/pinboard.png","hash":"0891fbb6d092fa012bf936019923383d84c6aeb0","modified":1560845221237},{"_id":"themes/spff/source/img/pinterest.png","hash":"9c72917f8779c083157c6ce7a5d62ed4874f0630","modified":1560845221237},{"_id":"themes/spff/source/img/qq.png","hash":"fd741764c5528fe371f053beac99839a97900eef","modified":1560845221238},{"_id":"themes/spff/source/img/rss.png","hash":"430fd47340e75214c081abd05cd7410cf7c71b86","modified":1560845221238},{"_id":"themes/spff/source/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1560845221238},{"_id":"themes/spff/source/img/stackoverflow.png","hash":"da5dfe9043055c95e479d49c78cd3b020de608f2","modified":1560845221238},{"_id":"themes/spff/source/img/twitter.png","hash":"14dbb8e62d056525253bc0de13acd1723da7a934","modified":1560845221238},{"_id":"themes/spff/source/img/wechat.png","hash":"7ca41b6e32ca4dac419225261ab4fee5a88f73a9","modified":1560845221238},{"_id":"themes/spff/source/img/weibo.png","hash":"280dae3fd38086158b4a1b57edb94c06b1a5014b","modified":1560845221238},{"_id":"themes/spff/source/img/zhihu.png","hash":"a6d6ef65e9ac82e613a311810391ebb90d9b1c1d","modified":1560845221238},{"_id":"themes/spff/source/js/TweenMax.js","hash":"0ba64564a4fde4085fa3971dd53b7d64a41751e1","modified":1560845221240},{"_id":"themes/spff/source/js/clipboard.min.js","hash":"c13b4bb8fee46447284590d2afc0efca0ea3cb7b","modified":1560845221242},{"_id":"themes/spff/source/js/instagram.js","hash":"f19adbcc0dac33536bc6660598059048ec901882","modified":1560845221243},{"_id":"themes/spff/source/js/jquery.lazyload.js","hash":"c11a2e7b330d16d06feabd0a8477099adf9d6799","modified":1560845221243},{"_id":"themes/spff/source/js/main.js","hash":"153b4796d6c22f3bfaa28a4f8a361d4685286c6f","modified":1560845221244},{"_id":"themes/spff/source/js/mobile.js","hash":"d3847e5bcaf39108931724ecb02770c62b10889f","modified":1560845221244},{"_id":"themes/spff/source/js/pace.js","hash":"b49c10cd65d9488f7338e3c778e55ac6628650f3","modified":1560845221244},{"_id":"themes/spff/source/js/pc.js","hash":"ab375af6e3bcd054b1e87e1a8dcd3d7d25c2db40","modified":1560845221244},{"_id":"themes/spff/source/js/plugins.js","hash":"c1cf96b2d852b5803228a34d99014b005623bc06","modified":1560845221244},{"_id":"themes/spff/source/img/head1.jpg","hash":"80c0999acfc1173183d3dd243b4b90d077ab97cb","modified":1560845221237},{"_id":"themes/spff/source/js/TweenMax.min.js","hash":"eaa4e4a08400da3f22dedda706ba56cdce5b0b7a","modified":1560845221242},{"_id":"themes/spff/source/js/embed.js","hash":"8d2d4a812ab639bc02fdd8749d3a39f6b9406c54","modified":1560845221243},{"_id":"themes/spff/layout/_partial/analytics/baidu-analytics.ejs","hash":"b21500b87d79a0068e3ca0408b4e125e3e749d01","modified":1560845221138},{"_id":"themes/spff/layout/_partial/analytics/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1560845221138},{"_id":"themes/spff/layout/_partial/comments/disqus.ejs","hash":"7792a79ab85ef28551cc2a793735973b1d5521a7","modified":1560845221138},{"_id":"themes/spff/layout/_partial/comments/duoshuo.ejs","hash":"8d90eb435739eae6f0282c67899ba768b1d9cc7c","modified":1560845221138},{"_id":"themes/spff/layout/_partial/comments/youyan.ejs","hash":"a6853b59ee60e775de1ed90b242084f83774d195","modified":1560845221138},{"_id":"themes/spff/layout/_partial/post/TipTitle.ejs","hash":"65b0956edca84e0bc0eb616ec236309822d5f803","modified":1560845221139},{"_id":"themes/spff/layout/_partial/post/category.ejs","hash":"265bb12f7cfa5e0bcbb74fdd409ba13a6d9d2e22","modified":1560845221140},{"_id":"themes/spff/layout/_partial/post/date.ejs","hash":"1cfcf2e06ab9b1c6dcd44f41825dfe98d400c7ea","modified":1560845221140},{"_id":"themes/spff/layout/_partial/post/loading.ejs","hash":"52a576a8afee08d33c6f69a61c496e1820132e91","modified":1560845221140},{"_id":"themes/spff/layout/_partial/post/nav.ejs","hash":"d22cfc20d9a94a33b7e790c0fc4cb11136cb3059","modified":1560845221140},{"_id":"themes/spff/layout/_partial/post/swiftype.ejs","hash":"76374e601d911e1279e1944d2a6b7eb3391c7c7c","modified":1560845221140},{"_id":"themes/spff/layout/_partial/post/tag.ejs","hash":"9dad471e27de9e066666f3082137eccaede2e67b","modified":1560845221140},{"_id":"themes/spff/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1560845221140},{"_id":"themes/spff/layout/_partial/share/baidu-share.ejs","hash":"21fbd6dbdcc631c61194ea04fc19b298133b0e2f","modified":1560845221140},{"_id":"themes/spff/layout/_partial/share/share.ejs","hash":"62467610ba6df9b63350d163e806be774dcf5a00","modified":1560845221140},{"_id":"themes/spff/layout/_partial/share/showshare.ejs","hash":"410b809eb6c50bacfd9e1e573f1e0251841bc79d","modified":1560845221140},{"_id":"themes/spff/source/background/bg-1.jpg","hash":"f0617756387d74f99afe0087c7b93a32f3c7096b","modified":1560845221143},{"_id":"themes/spff/source/background/bg-109.jpg","hash":"6171c1e921c8cc9bdcd7276cf7f0bee5295f4672","modified":1560845221148},{"_id":"themes/spff/source/background/bg-11.jpg","hash":"d69a0447e91f62977b144737f08620d77037c76a","modified":1560845221150},{"_id":"themes/spff/source/background/bg-20.jpg","hash":"9d428ac435198b2a0107102a2e9ae71e53afe364","modified":1560845221180},{"_id":"themes/spff/source/background/bg-17.jpg","hash":"6ab5e470059e8ccb0c8bc6786abfb5db7e9a1826","modified":1560845221169},{"_id":"themes/spff/source/background/bg-3.jpg","hash":"f1347eddd07bdae93ab6bebad8627eddc5baeb44","modified":1560845221192},{"_id":"themes/spff/source/background/bg.jpg","hash":"f0617756387d74f99afe0087c7b93a32f3c7096b","modified":1560845221215},{"_id":"themes/spff/source/css/_partial/archive.styl","hash":"a8bc2e2458bcc51fa68122274a41f5e4e52a8ebd","modified":1560845221216},{"_id":"themes/spff/source/css/_partial/article.styl","hash":"8a7383c57181800add514705455d09f40975b758","modified":1560845221216},{"_id":"themes/spff/source/css/_partial/baidushare.styl","hash":"fe36e3d8933b1b0b674aaf16e50dbf6090099912","modified":1560845221216},{"_id":"themes/spff/source/css/_partial/footer.styl","hash":"cbf916a5338e69e05d0815c53aeb818d636b6d99","modified":1560845221217},{"_id":"themes/spff/source/css/_partial/header.styl","hash":"85ab11e082f4dd86dde72bed653d57ec5381f30c","modified":1560845221217},{"_id":"themes/spff/source/css/_partial/highlight.styl","hash":"f317abc2669a5b71c0f6661fdade86c630453fd0","modified":1560845221217},{"_id":"themes/spff/source/css/_partial/instagram.styl","hash":"db9cc156c7df27f7f54b0e7ff34b5949f55f99eb","modified":1560845221217},{"_id":"themes/spff/source/css/_partial/main.styl","hash":"667567c3ea25cd4acbaab98867a92fefd098fcc1","modified":1560845221218},{"_id":"themes/spff/source/css/_partial/mains.styl","hash":"530f74b0c32eb9554032004217b29d1df42161af","modified":1560845221218},{"_id":"themes/spff/source/css/_partial/mobile-slider.styl","hash":"3bf9f2359f68c700e21618ad6262db81038c3d96","modified":1560845221218},{"_id":"themes/spff/source/css/_partial/mobile.styl","hash":"53b1a06e08df81427505cbc76cc8eb02bea54356","modified":1560845221218},{"_id":"themes/spff/source/css/_partial/page.styl","hash":"46b9c91428c1e1f42cc8a1010f600f70fb8edc82","modified":1560845221218},{"_id":"themes/spff/source/css/_partial/plugins.styl","hash":"629ae10dfc053dbfc074966f0bf7f0115acf65e2","modified":1560845221219},{"_id":"themes/spff/source/css/_partial/scroll.styl","hash":"1932774d30b8706919342f9cf36ea2d99987ce14","modified":1560845221219},{"_id":"themes/spff/source/css/_partial/share.styl","hash":"2dde7c9ea40c71fce3dbd8d5e2bcc8d9682141b8","modified":1560845221219},{"_id":"themes/spff/source/css/_partial/tagcloud.styl","hash":"91e6553775ca931a1b3db1ab11c4cf227df68c21","modified":1560845221219},{"_id":"themes/spff/source/css/_partial/wheelmenu.styl","hash":"74630c56944e27bef53ef0c0e391611a2eec2ed0","modified":1560845221219},{"_id":"themes/spff/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1560845221219},{"_id":"themes/spff/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1560845221219},{"_id":"themes/spff/source/css/pace/pace-theme-flash.css","hash":"508bce8b59a1fbc1f1443a7c4ab3b026e5517dab","modified":1560845221220},{"_id":"themes/spff/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1560845221221},{"_id":"themes/spff/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1560845221221},{"_id":"themes/spff/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1560845221221},{"_id":"themes/spff/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1560845221222},{"_id":"themes/spff/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1560845221222},{"_id":"themes/spff/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1560845221222},{"_id":"themes/spff/source/font-awesome/css/font-awesome.css","hash":"b488600451227b445414796e9b8550e7c1bd6d29","modified":1560845221223},{"_id":"themes/spff/source/font-awesome/css/font-awesome.min.css","hash":"12d6861075de8e293265ff6ff03b1f3adcb44c76","modified":1560845221224},{"_id":"themes/spff/source/js/404/jquery.parallaxify-0.0.2.min.js","hash":"b97e2dfcb210b76f7bdd6e1800b26128bf4fad99","modified":1560845221240},{"_id":"themes/spff/source/background/bg-15.jpg","hash":"ce5760578eb814fe951c56200e81c6f47b6468d4","modified":1560845221164},{"_id":"themes/spff/source/background/bg-23.jpg","hash":"050937d649be2c02ef8a66a0ffe7d320b236d1b0","modified":1560845221187},{"_id":"themes/spff/source/background/bg-7.jpg","hash":"acbe0946a47ba16b79f062dbee14c4c9ff9a48da","modified":1560845221203},{"_id":"themes/spff/source/font-awesome/fonts/FontAwesome.otf","hash":"42c179eef588854b5ec151bcf6a3f58aa8b79b11","modified":1560845221226},{"_id":"themes/spff/source/font-awesome/fonts/fontawesome-webfont.eot","hash":"986eed8dca049714e43eeebcb3932741a4bec76d","modified":1560845221227},{"_id":"themes/spff/source/font-awesome/fonts/fontawesome-webfont.woff","hash":"4a313eb93b959cc4154c684b915b0a31ddb68d84","modified":1560845221231},{"_id":"themes/spff/source/font-awesome/fonts/fontawesome-webfont.woff2","hash":"638c652d623280a58144f93e7b552c66d1667a11","modified":1560845221231},{"_id":"themes/spff/source/js/404/jquery-2.0.3.min.js","hash":"fbf9c77d0c4e3c34a485980c1e5316b6212160c8","modified":1560845221240},{"_id":"themes/spff/source/background/bg-14.jpg","hash":"2fd6ede2bc9de2d26d910ea4e45d28b2350881eb","modified":1560845221162},{"_id":"themes/spff/source/background/bg-9.jpg","hash":"df731da0fe0de9a05d99d017e747252c990f972d","modified":1560845221213},{"_id":"themes/spff/source/css/_partial/customise/blockquote.styl","hash":"83179f1d0e12b025cd433a6071b2826c2b4168cc","modified":1560845221216},{"_id":"themes/spff/source/css/_partial/customise/code-block.styl","hash":"ebf7ca8598d93235479460ea7d1be97d44224b05","modified":1560845221216},{"_id":"themes/spff/source/css/_partial/customise/inline-code.styl","hash":"1f15986381f7b7b0953ba30733e473b12ea46800","modified":1560845221217},{"_id":"themes/spff/source/css/_partial/post/youyan.styl","hash":"ac2869e2e0fb3a1ee0df4b0c0a233a2b1923ea20","modified":1560845221219},{"_id":"themes/spff/source/font-awesome/fonts/fontawesome-webfont.ttf","hash":"6484f1af6b485d5096b71b344e67f4164c33dd1f","modified":1560845221230},{"_id":"themes/spff/source/background/bg-19.jpg","hash":"d77504412d28432643fc61ed9fd9f7c57096bdd9","modified":1560845221174},{"_id":"themes/spff/source/background/bg-21.jpg","hash":"7c4c6cd5d75115093fa29bba7372fa198f04b0f1","modified":1560845221182},{"_id":"themes/spff/source/background/bg-22.jpg","hash":"7a055391fa4188d9c22fdc1d34a10b26e2f0826d","modified":1560845221184},{"_id":"themes/spff/source/background/bg-24.jpg","hash":"796fa5262d7714e8ce9496a2d03864429cfc5b45","modified":1560845221190},{"_id":"themes/spff/source/background/bg-4.jpg","hash":"da47f889e02241c8b095f852fb7efd89c114599d","modified":1560845221194},{"_id":"themes/spff/source/background/bg-8.jpg","hash":"dbecc189e28d00fa23e397eb512e039c2ff03c87","modified":1560845221205},{"_id":"themes/spff/source/background/bg-6.jpg","hash":"1a4f4c8875b2c56e7992000979a7fca7856eec35","modified":1560845221201},{"_id":"themes/spff/source/background/bg-12.jpg","hash":"2e0815591309863d8130881681cde32ec4bfebf1","modified":1560845221155},{"_id":"themes/spff/source/background/bg-10.jpg","hash":"dfb23c1c3cf8a3dcb8dc0ea10cf06501c151a2a2","modified":1560845221147},{"_id":"themes/spff/source/background/bg-18.jpg","hash":"4d61dc41a781a9c1d37c9e5e413ac0d8a9538f6a","modified":1560845221171},{"_id":"themes/spff/source/img/bg.jpg","hash":"1bcba3c6348e2190a42bff762800bf846cf9239c","modified":1560845221234},{"_id":"themes/spff/source/background/bg-111.jpg","hash":"e1631b47fede8da6c03582ceed648668547c4f09","modified":1560845221153},{"_id":"themes/spff/source/background/bg-13.jpg","hash":"d7237c6014e28c90f53287f48f718d0759af104b","modified":1560845221159},{"_id":"themes/spff/source/background/bg-16.jpg","hash":"d1a34d0c4b69262169b543922e4aeb4dae997ad8","modified":1560845221167},{"_id":"themes/spff/source/font-awesome/fonts/fontawesome-webfont.svg","hash":"b06b5c8f67fd632cdc62a33b62ae4f74194131b3","modified":1560845221229},{"_id":"themes/spff/source/background/bg-2.jpg","hash":"40a6db13e9c461f80e2c4efee7fb63bbd594e751","modified":1560845221178},{"_id":"themes/spff/source/background/bg-5.jpg","hash":"2d5da2a209732cce0abf2ca234c0bef0516b65ff","modified":1560845221198},{"_id":"public/atom.xml","hash":"b910947433a17b1bc69c1b3aa38c9c65d4e58ca8","modified":1668651929246},{"_id":"public/categories/index.html","hash":"6ed0d567ae71137bb5d9888b0ef04fd5c79bc99a","modified":1668651931695},{"_id":"public/archives/page/4/index.html","hash":"457382b3931da7ea97c9c0619392b9e92b73169d","modified":1668651931696},{"_id":"public/archives/2014/index.html","hash":"5b7ad36668366535cdf7d7fbb73700f7e6981908","modified":1668651931696},{"_id":"public/archives/2014/09/index.html","hash":"3d9cea47816a1c4d512cfd217681d0ea25350819","modified":1668651931696},{"_id":"public/archives/2016/10/index.html","hash":"cdcc4eb745c06cf2e81d36bde3a07159a84e4daa","modified":1668651931696},{"_id":"public/archives/2017/page/2/index.html","hash":"162fc2ee0a67709879dedd3940d9be9c92df7b96","modified":1668651931696},{"_id":"public/archives/2017/01/index.html","hash":"f2a9ddd484ad1e565a26d22861b4db091096305e","modified":1668651931696},{"_id":"public/archives/2017/02/index.html","hash":"dc01a36532c59a366995f0b5981771c8e7a44331","modified":1668651931697},{"_id":"public/archives/2017/03/index.html","hash":"c217c7d083f3a7c8af7bb0224db509bf6792240e","modified":1668651931697},{"_id":"public/archives/2017/06/index.html","hash":"8ec7f06722c1dde348a89ef94d5f62936dbc5891","modified":1668651931697},{"_id":"public/archives/2017/07/index.html","hash":"6c0393911e83afe1b31dfba35c7eda25f88c339b","modified":1668651931697},{"_id":"public/archives/2017/08/index.html","hash":"4b33c1736881df79ca6087fbbd1f8cea8b7b43bc","modified":1668651931697},{"_id":"public/archives/2018/index.html","hash":"5724637248300c12b6fe6305fc1a2be424b1c7e9","modified":1668651931698},{"_id":"public/archives/2018/04/index.html","hash":"04faf27f47ce5c2e0e03bab4a92742c6500d6811","modified":1668651931698},{"_id":"public/archives/2018/11/index.html","hash":"5b2fd123839134e9043288f95cf28292d76ef60a","modified":1668651931698},{"_id":"public/archives/2019/index.html","hash":"295125346f3fb8f3d1f3dee9640f06503aa57ca1","modified":1668651931698},{"_id":"public/archives/2019/06/index.html","hash":"efb5f907251770c3076dd3714fbffc08c173bcda","modified":1668651931698},{"_id":"public/archives/2019/09/index.html","hash":"1eb29211209d0184367fde0ffeb25d7711f3c322","modified":1668651931698},{"_id":"public/categories/Glances/index.html","hash":"c58a6e1e5a84f01d938b039e9f997fc7c900f2ef","modified":1668651931699},{"_id":"public/categories/k8s/index.html","hash":"dc6fd4ed91946b62e31e07b1a0c6c6bcffc10891","modified":1668651931699},{"_id":"public/categories/python/index.html","hash":"da32932e3c910759c93f23e0ed89e3f1fc6bd39f","modified":1668651931699},{"_id":"public/categories/ingress/index.html","hash":"0a84ecf55c68098584c0f932316366eab8b3ff44","modified":1668651931699},{"_id":"public/categories/jira/index.html","hash":"6e9fb660c9251400aba13d2cc62ae2970cca84ef","modified":1668651931699},{"_id":"public/categories/nginx/index.html","hash":"8907d1f8c614fef483e994301aa43c6d14fa0b1f","modified":1668651931699},{"_id":"public/categories/rsync/index.html","hash":"c8226ed036dcd90bbd25395e98e239d39c789eb3","modified":1668651931699},{"_id":"public/categories/lsync/index.html","hash":"ddd345c3d6491d0c803a01d42b63c61ffbddf00e","modified":1668651931700},{"_id":"public/categories/mtr/index.html","hash":"473e8dd3363a73b7bc77c89177a070fb7ce292a4","modified":1668651931700},{"_id":"public/categories/mysql/index.html","hash":"4fa911cd7cd694c22ff100fc06fa02f5f485050b","modified":1668651931700},{"_id":"public/categories/open-falcon/index.html","hash":"ef13938f997359361580b7f5492221bc83c87aca","modified":1668651931700},{"_id":"public/categories/tsung/index.html","hash":"5e7ca9caa1c5b4c7f0658d32e96ddee54d209e04","modified":1668651931700},{"_id":"public/categories/rpm/index.html","hash":"cc6d907998e7c91689582d986eafd5809b939661","modified":1668651931700},{"_id":"public/categories/zabbix/index.html","hash":"942d8eacf4a1522859a4ed6431d2e17ff856f957","modified":1668651931701},{"_id":"public/categories/woedpress/index.html","hash":"5246dfaef22b4486d1c2ac932dba0a7876ef9cc3","modified":1668651931701},{"_id":"public/categories/elk/index.html","hash":"109e204dbf5c412770908c26a24262fb91b1c20e","modified":1668651931701},{"_id":"public/tags/Glances/index.html","hash":"f1fb1d0ddce7c336cecda9151096e7f4a6f37e89","modified":1668651931701},{"_id":"public/tags/k8s/index.html","hash":"78b709485e56ffb59bb209e44d380849a6b5e13f","modified":1668651931701},{"_id":"public/tags/python/index.html","hash":"6aa9046e14abd420a78c436dc81fa95364f79923","modified":1668651931701},{"_id":"public/tags/ingress/index.html","hash":"2ca52474b323945a70032f776be6b927d4ecea4c","modified":1668651931702},{"_id":"public/tags/linux/index.html","hash":"989a7b3b9f6f68a781f629ece06312f1f24000e9","modified":1668651931702},{"_id":"public/tags/jira/index.html","hash":"02048c5a17f98b1dbc6628f4eea802f541846a06","modified":1668651931702},{"_id":"public/tags/nginx/index.html","hash":"d4d2376a76c935c890cd6da71e1150b49ecf9b3b","modified":1668651931702},{"_id":"public/tags/traceroute/index.html","hash":"31684171db004b6993606ed4c4fd5dbad544f78e","modified":1668651931702},{"_id":"public/tags/rsync/index.html","hash":"b6a3dc7ac363d4167789524604016e830857ce1e","modified":1668651931702},{"_id":"public/tags/ssh/index.html","hash":"f5aaf34bd98b613e2daed65c48495f1bb542c40a","modified":1668651931703},{"_id":"public/tags/lsync/index.html","hash":"b911d1f00665710377281dbfd56ca02140941d02","modified":1668651931703},{"_id":"public/tags/mtr/index.html","hash":"2781f8cf7462759a5e9ff2fc34c2f638fce4414c","modified":1668651931703},{"_id":"public/tags/mysql/index.html","hash":"344da12e09e8a3a4757488bdc03a2f37f5d50857","modified":1668651931703},{"_id":"public/tags/open-falcon/index.html","hash":"13eaa3d73a3f3a4ba0bc41b7ede46616170b5cea","modified":1668651931703},{"_id":"public/tags/tcpdum/index.html","hash":"39e606b3f7f272097366e9ba435fe4846d75763f","modified":1668651931703},{"_id":"public/tags/tcpdump/index.html","hash":"5d33826110877c157947ac490c247d666ddaebbd","modified":1668651931704},{"_id":"public/tags/tsung/index.html","hash":"9fcaf4fded336541a9cbacb3ee7a590748ce4af0","modified":1668651931704},{"_id":"public/tags/rpm/index.html","hash":"64dcb13b260ac88ab6dae2e268e317c3dafd91db","modified":1668651931704},{"_id":"public/tags/zabbix/index.html","hash":"a74432b755c00aab41a5eee52cc3247084728415","modified":1668651931704},{"_id":"public/tags/wordpress/index.html","hash":"dc280c6002895a298202b48696818bd6c4785d35","modified":1668651931704},{"_id":"public/tags/elk/index.html","hash":"26e4e04600022a939c773675f2321764710b43ee","modified":1668651931704},{"_id":"public/tags/index.html","hash":"9aa27256431171822e06d5007f6fe8235f9fe7d7","modified":1668651931704},{"_id":"public/2019/09/24/jira和confluence迁移记录/index.html","hash":"28480d167345ba7a449fc6760d7dfecdf42f07b6","modified":1668651931705},{"_id":"public/2019/06/27/Traefik-kubernetes 初试/index.html","hash":"cd05b62185d66f7c6e99ebed9d2471de263ec365","modified":1668651931705},{"_id":"public/2018/11/07/mysql使用binlog日志恢复/index.html","hash":"2aeac819f6258ed64fe37a98302f03a3c727580c","modified":1668651931705},{"_id":"public/2018/04/10/Kubernetes如何使用kube-dns实现服务发现/index.html","hash":"7db1e87af80b6277eef1808368e222d2ce8db7d3","modified":1668651931705},{"_id":"public/2017/09/22/lsyncd实现文件目录同步简要说明/index.html","hash":"186cbd16ee6e67fb87bcd6553a912992ab145168","modified":1668651931705},{"_id":"public/2017/09/13/linux_下同步工具inotify_+_rsync_使用详解/index.html","hash":"bda6871cdeb81733f49a911c30ba86b9de516f01","modified":1668651931706},{"_id":"public/2017/09/13/lsyncd实时同步/index.html","hash":"edec1f8506b3146ec039b30623c2aae63ff827a6","modified":1668651931706},{"_id":"public/2017/09/08/gitlab安装/index.html","hash":"b51b249c0bc746f35bba2350761f37cb23b61bc3","modified":1668651931706},{"_id":"public/2017/08/31/open-falcon安装/index.html","hash":"a947798f75ef92e5f4600c223b45657f347112d1","modified":1668651931706},{"_id":"public/2017/07/05/Python(基础数据类型)详解/index.html","hash":"07fb4b7b77f17b52367e99f56d379c0e517c4330","modified":1668651931706},{"_id":"public/2017/06/28/linux开机启动顺序/index.html","hash":"56c53f0a94008d4467c4abf4446aecf462f3fbdc","modified":1668651931706},{"_id":"public/2017/06/16/git使用说明/index.html","hash":"e8a7975b5a29b7fde48e2a2b50ca72a79d8003d0","modified":1668651931706},{"_id":"public/2017/03/03/用Kibana和logstash快速搭建实时日志查询、收集与分析系统/index.html","hash":"da761ff35a8829290650dbb2d57555cc0a41b215","modified":1668651931707},{"_id":"public/2017/03/02/tcpdump：理论、自动抓包及业务架构树的生成/index.html","hash":"1d86c139c0a1b78b9b6d907467052106bd1d2a24","modified":1668651931707},{"_id":"public/2017/02/28/Glances/index.html","hash":"4c830c8d5af451459faef340d6ca28e46202df19","modified":1668651931707},{"_id":"public/2017/01/08/tsung说明文档/index.html","hash":"a67589be853860e69175229f56d75621391f8053","modified":1668651931707},{"_id":"public/2016/11/05/yum仓库搭建之RPM包制作/index.html","hash":"4e732a08afe4e55739abecf33a9c74ea3d6d2bb9","modified":1668651931707},{"_id":"public/2016/11/03/linux traceroute 命令详解/index.html","hash":"edb1df49a2e5f81e7c95882957c1d7e7164ba1cc","modified":1668651931707},{"_id":"public/2016/11/03/mtr命令详解/index.html","hash":"fafe418ed1c0962426aefb8bc755c10fb90429ec","modified":1668651931707},{"_id":"public/2016/11/03/linux_traceroute_命令详解/index.html","hash":"e7eae6289d1e9171bb9173522e6d819c11b9e339","modified":1668651931708},{"_id":"public/2016/11/03/tcpdump抓包命令详解/index.html","hash":"e9b6258cb2b2e94d7236d38ebb90fff91a7a4f7a","modified":1668651931708},{"_id":"public/2016/10/05/linux_命令rsync+crontab实现自动同步/index.html","hash":"ad93bcdb4ce1784adcea040497891bf48eb9ada5","modified":1668651931708},{"_id":"public/2016/09/06/htop使用说明/index.html","hash":"25010e099f3595665377d8e1af304c716ed365b5","modified":1668651931708},{"_id":"public/2016/09/05/mysql主从配置文件内容/index.html","hash":"0fbd673cdcdb5b1b9179e6f01c708b907da949c7","modified":1668651931708},{"_id":"public/2016/09/02/搭建WordPress/index.html","hash":"47e12c7b0359ca3838963e3b37539011fc2d4754","modified":1668651931708},{"_id":"public/2016/09/02/linux—SSH1/index.html","hash":"fcdbd82d6d0617014514d970a9b603a485579505","modified":1668651931708},{"_id":"public/2016/09/02/git/index.html","hash":"095f5c8385a98b5d5c647478f6f34e853ce2592a","modified":1668651931709},{"_id":"public/2016/09/02/keepalive+nginx实现高可用/index.html","hash":"845e34956261db71ebe0daefe939a120e8a466f1","modified":1668651931709},{"_id":"public/2016/09/02/linux—SSH（二）Rsync备份/index.html","hash":"febc18237cb82b44d9dcfac46e5f3fc3b61aa28f","modified":1668651931709},{"_id":"public/2016/09/02/zabbix2.6安装/index.html","hash":"47f5867088bdcd77f56afa95f7c34bb1d152f980","modified":1668651931709},{"_id":"public/2016/09/02/hexo/index.html","hash":"0fe866ab154e5d9bf83699c3925504917aa2e604","modified":1668651931709},{"_id":"public/2014/09/02/hello-world/index.html","hash":"3e05c5e17a118a46a8ac25bc18e3c0d50a36886a","modified":1668651931710},{"_id":"public/archives/index.html","hash":"f9675cd0f18295da8c6888df4d784f55ccf9f7e8","modified":1668651931710},{"_id":"public/archives/page/2/index.html","hash":"123ace2a5b57ac0288fe6d6253c4ec97cbdd2643","modified":1668651931711},{"_id":"public/archives/page/3/index.html","hash":"3fdc7be9f31c832b4509c6457d8d08fd69215500","modified":1668651931711},{"_id":"public/archives/2016/index.html","hash":"e151e6b7a6bec46ef1d27e1bb6b237803810d3f2","modified":1668651931711},{"_id":"public/archives/2016/page/2/index.html","hash":"21e1826c19bfd084cc6b6f359b13723f0eaea31d","modified":1668651931711},{"_id":"public/archives/2016/09/index.html","hash":"6ec0c91461851c24f25bf40f370b8609abf988c0","modified":1668651931712},{"_id":"public/archives/2016/11/index.html","hash":"d0d7d617d1fca9a00e957b90a6b1269a255e9e6f","modified":1668651931712},{"_id":"public/archives/2017/index.html","hash":"228ba383d1755f55eb7946ec8b0c4db7585363c8","modified":1668651931712},{"_id":"public/archives/2017/09/index.html","hash":"4342383019376ce9bf57d53da8cf1afacd18358f","modified":1668651931712},{"_id":"public/categories/git/index.html","hash":"e39583f03308be2547b5507f8c0bdec90ad42b78","modified":1668651931712},{"_id":"public/categories/linux/index.html","hash":"c31dac1eb0c21ec7bb7c20233e3fde46092f8c5c","modified":1668651931712},{"_id":"public/index.html","hash":"c557ef4af1c9f82d01b0ae6a42762931d8e1a814","modified":1668651931713},{"_id":"public/page/2/index.html","hash":"124955b1c308c18d42bf0355a411aca1b1f59cc2","modified":1668651931713},{"_id":"public/page/3/index.html","hash":"bfa12adfa5adc45a6168f04c01bfa1408c55ef5c","modified":1668651931713},{"_id":"public/page/4/index.html","hash":"552c93ef902e505f64d8d838e37d25e5a08b3fe0","modified":1668651931713},{"_id":"public/tags/git/index.html","hash":"0d216c9698729366c69a9a5aa2044a3a2e728a4c","modified":1668651931713},{"_id":"public/apple-touch-icon.png","hash":"c36a373c7830d61d1ce092bd5a88d0e9b54212fd","modified":1668651931779},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1668651931779},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1668651931779},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1668651931780},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1668651931780},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1668651931780},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1668651931780},{"_id":"public/img/coderwall.png","hash":"fa84676c4d654e040e51fd34bfcd9f9348cd5331","modified":1668651931780},{"_id":"public/img/delicious.png","hash":"9553a5f5189e4a953e04a58a49dbfa74b86b73dd","modified":1668651931781},{"_id":"public/img/douban.png","hash":"e2ade003ffadd5826ee66ec23901c2d6e8607e4e","modified":1668651931781},{"_id":"public/img/facebook.png","hash":"d19ad7a0903daf26817afd8753cd97e0cc714f54","modified":1668651931781},{"_id":"public/img/favicon.png","hash":"5b4e9c94ff3396db5b074b69c1aa5bb909aba825","modified":1668651931781},{"_id":"public/img/github.png","hash":"b84d03b32fa388dcbf149296ebd16dce6223d48d","modified":1668651931781},{"_id":"public/img/google.png","hash":"61a21fec7346fa3400b747ac9a201cf3d5bc013d","modified":1668651931781},{"_id":"public/img/head.jpg","hash":"f96ad10fc77afd93821e72ac7fc3783e115cac42","modified":1668651931781},{"_id":"public/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1668651931781},{"_id":"public/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1668651931782},{"_id":"public/img/linkedin.png","hash":"e203138fb53c257cb214e97f4e30091b9c568d2c","modified":1668651931782},{"_id":"public/img/mail.png","hash":"fca8199cc77fdbd700a45bf56d091c82f4a67fe7","modified":1668651931782},{"_id":"public/img/pinboard.png","hash":"0891fbb6d092fa012bf936019923383d84c6aeb0","modified":1668651931782},{"_id":"public/img/pinterest.png","hash":"9c72917f8779c083157c6ce7a5d62ed4874f0630","modified":1668651931782},{"_id":"public/img/qq.png","hash":"fd741764c5528fe371f053beac99839a97900eef","modified":1668651931782},{"_id":"public/img/rss.png","hash":"430fd47340e75214c081abd05cd7410cf7c71b86","modified":1668651931782},{"_id":"public/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1668651931782},{"_id":"public/img/stackoverflow.png","hash":"da5dfe9043055c95e479d49c78cd3b020de608f2","modified":1668651931783},{"_id":"public/img/twitter.png","hash":"14dbb8e62d056525253bc0de13acd1723da7a934","modified":1668651931783},{"_id":"public/img/wechat.png","hash":"7ca41b6e32ca4dac419225261ab4fee5a88f73a9","modified":1668651931783},{"_id":"public/img/weibo.png","hash":"280dae3fd38086158b4a1b57edb94c06b1a5014b","modified":1668651931783},{"_id":"public/img/zhihu.png","hash":"a6d6ef65e9ac82e613a311810391ebb90d9b1c1d","modified":1668651931784},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1668651931784},{"_id":"public/img/head1.jpg","hash":"80c0999acfc1173183d3dd243b4b90d077ab97cb","modified":1668651934214},{"_id":"public/font-awesome/fonts/FontAwesome.otf","hash":"42c179eef588854b5ec151bcf6a3f58aa8b79b11","modified":1668651934225},{"_id":"public/font-awesome/fonts/fontawesome-webfont.eot","hash":"986eed8dca049714e43eeebcb3932741a4bec76d","modified":1668651934237},{"_id":"public/font-awesome/fonts/fontawesome-webfont.woff","hash":"4a313eb93b959cc4154c684b915b0a31ddb68d84","modified":1668651934237},{"_id":"public/font-awesome/fonts/fontawesome-webfont.woff2","hash":"638c652d623280a58144f93e7b552c66d1667a11","modified":1668651934238},{"_id":"public/css/loading-style.css","hash":"1f67362d809e85edc9f122db7bc3711af1ed1d8b","modified":1668651934278},{"_id":"public/css/showshare.css","hash":"3efc4afd0d136fb5dec993e9cd9ce85b9d1cf589","modified":1668651934278},{"_id":"public/fancybox/jquery.fancybox.css","hash":"b6aa6692c2e5f8bd74d96827b78570f0c5683c20","modified":1668651934278},{"_id":"public/js/TweenMax.js","hash":"0ba64564a4fde4085fa3971dd53b7d64a41751e1","modified":1668651934278},{"_id":"public/js/clipboard.min.js","hash":"c13b4bb8fee46447284590d2afc0efca0ea3cb7b","modified":1668651934279},{"_id":"public/js/instagram.js","hash":"f19adbcc0dac33536bc6660598059048ec901882","modified":1668651934279},{"_id":"public/js/jquery.lazyload.js","hash":"c11a2e7b330d16d06feabd0a8477099adf9d6799","modified":1668651934279},{"_id":"public/js/main.js","hash":"153b4796d6c22f3bfaa28a4f8a361d4685286c6f","modified":1668651934279},{"_id":"public/js/mobile.js","hash":"d3847e5bcaf39108931724ecb02770c62b10889f","modified":1668651934279},{"_id":"public/js/pc.js","hash":"ab375af6e3bcd054b1e87e1a8dcd3d7d25c2db40","modified":1668651934279},{"_id":"public/js/plugins.js","hash":"c1cf96b2d852b5803228a34d99014b005623bc06","modified":1668651934280},{"_id":"public/css/pace/pace-theme-flash.css","hash":"508bce8b59a1fbc1f1443a7c4ab3b026e5517dab","modified":1668651934280},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1668651934280},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1668651934280},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1668651934280},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1668651934280},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1668651934280},{"_id":"public/js/404/jquery.parallaxify-0.0.2.min.js","hash":"b97e2dfcb210b76f7bdd6e1800b26128bf4fad99","modified":1668651934281},{"_id":"public/css/style.css","hash":"7f7da82693557f8d599062bf927435a0d8bf7de5","modified":1668651934281},{"_id":"public/fancybox/jquery.fancybox.js","hash":"a82597493d75ea989ca586e09173cff332efe41e","modified":1668651934281},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1668651934281},{"_id":"public/js/pace.js","hash":"b49c10cd65d9488f7338e3c778e55ac6628650f3","modified":1668651934281},{"_id":"public/js/TweenMax.min.js","hash":"eaa4e4a08400da3f22dedda706ba56cdce5b0b7a","modified":1668651934281},{"_id":"public/js/embed.js","hash":"8d2d4a812ab639bc02fdd8749d3a39f6b9406c54","modified":1668651934282},{"_id":"public/font-awesome/css/font-awesome.css","hash":"b488600451227b445414796e9b8550e7c1bd6d29","modified":1668651934282},{"_id":"public/font-awesome/css/font-awesome.min.css","hash":"12d6861075de8e293265ff6ff03b1f3adcb44c76","modified":1668651934282},{"_id":"public/js/404/jquery-2.0.3.min.js","hash":"fbf9c77d0c4e3c34a485980c1e5316b6212160c8","modified":1668651934282},{"_id":"public/background/bg-1.jpg","hash":"f0617756387d74f99afe0087c7b93a32f3c7096b","modified":1668651934283},{"_id":"public/background/bg-109.jpg","hash":"6171c1e921c8cc9bdcd7276cf7f0bee5295f4672","modified":1668651934283},{"_id":"public/background/bg-11.jpg","hash":"d69a0447e91f62977b144737f08620d77037c76a","modified":1668651934283},{"_id":"public/background/bg-20.jpg","hash":"9d428ac435198b2a0107102a2e9ae71e53afe364","modified":1668651934284},{"_id":"public/background/bg-17.jpg","hash":"6ab5e470059e8ccb0c8bc6786abfb5db7e9a1826","modified":1668651934284},{"_id":"public/background/bg-3.jpg","hash":"f1347eddd07bdae93ab6bebad8627eddc5baeb44","modified":1668651934284},{"_id":"public/background/bg.jpg","hash":"f0617756387d74f99afe0087c7b93a32f3c7096b","modified":1668651934285},{"_id":"public/font-awesome/fonts/fontawesome-webfont.ttf","hash":"6484f1af6b485d5096b71b344e67f4164c33dd1f","modified":1668651934285},{"_id":"public/background/bg-15.jpg","hash":"ce5760578eb814fe951c56200e81c6f47b6468d4","modified":1668651934308},{"_id":"public/background/bg-23.jpg","hash":"050937d649be2c02ef8a66a0ffe7d320b236d1b0","modified":1668651934308},{"_id":"public/background/bg-7.jpg","hash":"acbe0946a47ba16b79f062dbee14c4c9ff9a48da","modified":1668651934309},{"_id":"public/background/bg-14.jpg","hash":"2fd6ede2bc9de2d26d910ea4e45d28b2350881eb","modified":1668651934321},{"_id":"public/background/bg-9.jpg","hash":"df731da0fe0de9a05d99d017e747252c990f972d","modified":1668651934321},{"_id":"public/background/bg-19.jpg","hash":"d77504412d28432643fc61ed9fd9f7c57096bdd9","modified":1668651934333},{"_id":"public/background/bg-21.jpg","hash":"7c4c6cd5d75115093fa29bba7372fa198f04b0f1","modified":1668651934333},{"_id":"public/background/bg-22.jpg","hash":"7a055391fa4188d9c22fdc1d34a10b26e2f0826d","modified":1668651934335},{"_id":"public/background/bg-24.jpg","hash":"796fa5262d7714e8ce9496a2d03864429cfc5b45","modified":1668651934336},{"_id":"public/background/bg-4.jpg","hash":"da47f889e02241c8b095f852fb7efd89c114599d","modified":1668651934337},{"_id":"public/background/bg-8.jpg","hash":"dbecc189e28d00fa23e397eb512e039c2ff03c87","modified":1668651934338},{"_id":"public/background/bg-6.jpg","hash":"1a4f4c8875b2c56e7992000979a7fca7856eec35","modified":1668651934339},{"_id":"public/font-awesome/fonts/fontawesome-webfont.svg","hash":"b06b5c8f67fd632cdc62a33b62ae4f74194131b3","modified":1668651934340},{"_id":"public/background/bg-12.jpg","hash":"2e0815591309863d8130881681cde32ec4bfebf1","modified":1668651934355},{"_id":"public/background/bg-10.jpg","hash":"dfb23c1c3cf8a3dcb8dc0ea10cf06501c151a2a2","modified":1668651934355},{"_id":"public/background/bg-18.jpg","hash":"4d61dc41a781a9c1d37c9e5e413ac0d8a9538f6a","modified":1668651934356},{"_id":"public/img/bg.jpg","hash":"1bcba3c6348e2190a42bff762800bf846cf9239c","modified":1668651934357},{"_id":"public/background/bg-111.jpg","hash":"e1631b47fede8da6c03582ceed648668547c4f09","modified":1668651934364},{"_id":"public/background/bg-13.jpg","hash":"d7237c6014e28c90f53287f48f718d0759af104b","modified":1668651934364},{"_id":"public/background/bg-16.jpg","hash":"d1a34d0c4b69262169b543922e4aeb4dae997ad8","modified":1668651934365},{"_id":"public/background/bg-2.jpg","hash":"40a6db13e9c461f80e2c4efee7fb63bbd594e751","modified":1668651934369},{"_id":"public/background/bg-5.jpg","hash":"2d5da2a209732cce0abf2ca234c0bef0516b65ff","modified":1668651934373}],"Category":[{"name":"Glances","_id":"clakg9shs0004hcb7c626nh29"},{"name":"k8s","_id":"clakg9sit0009hcb7d34xls7f"},{"name":"python","_id":"clakg9sjd000fhcb7bmc33hnm"},{"name":"ingress","_id":"clakg9sjn000lhcb7w8e75wun"},{"name":"git","_id":"clakg9sjy000rhcb7c6ezzdsx"},{"name":"linux","_id":"clakg9skx0019hcb7anu8ytug"},{"name":"jira","_id":"clakg9slh001ghcb7jaedd4qj"},{"name":"nginx","_id":"clakg9slt001nhcb74bpxm4u4"},{"name":"rsync","_id":"clakg9smh001zhcb75keax31e"},{"name":"lsync","_id":"clakg9sno002nhcb7yai4blkc"},{"name":"mtr","_id":"clakg9sns002vhcb71zpyd1cc"},{"name":"mysql","_id":"clakg9snv0030hcb79qfgtx2f"},{"name":"open-falcon","_id":"clakg9so00037hcb7gqh20amv"},{"name":"tsung","_id":"clakg9so2003chcb7u5292syo"},{"name":"rpm","_id":"clakg9so3003ghcb7sxa4ifa0"},{"name":"zabbix","_id":"clakg9so5003khcb7wd5hkaaz"},{"name":"woedpress","_id":"clakg9soa003ohcb77z7bvlft"},{"name":"elk","_id":"clakg9sog003shcb7i6j487er"}],"Data":[],"Page":[{"title":"categories","date":"2018-05-11T16:01:54.000Z","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2018-05-11 12:01:54\n---\n","updated":"2019-06-18T08:07:01.118Z","path":"categories/index.html","comments":1,"layout":"page","_id":"clakg9sh20001hcb7jmmzgb1r","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2018-05-11T15:46:11.000Z","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-05-11 11:46:11\n---\n","updated":"2019-06-18T08:07:01.118Z","path":"tags/index.html","comments":1,"layout":"page","_id":"clakg9sho0003hcb7nhsn6g76","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Glances","date":"2017-02-28T05:00:00.000Z","_content":"top 命令是 Linux 下的一个实时任务管理器， 同时也是用于在 GNU/Linux 发行版中寻找系统性能方面的瓶颈，并帮助我们作出正确操作的常用系统监视工具。 她有着一个极为简洁的界面，并自带少量的可以帮助我们快速了解系统性能的实用选项。\n<!--more-->\n但是，有些时候想要通过她寻找一个占用系统资源比较大的应用或进程可能会比较困难。 因为 top 命令本身并不会帮助我们高亮那些吃太多 CPU，内存，或者其他资源的程序。\n\n为了达到这个目标，这里我们将介绍一款超牛逼的系统监视程序 —— Glances。 她可以自动高亮利用最高系统资源的程序，并为 Linux/Unix 服务器提供尽可能多的信息。\n\n什么是 Glances？\nGlances 是一个由 Python 编写，使用 psutil 库来从系统抓取信息的基于 curses 开发的跨平台命令行系统监视工具。 通过 Glances，我们可以监视 CPU，平均负载，内存，网络流量，磁盘 I/O，其他处理器 和 文件系统 空间的利用情况。\n\nGlances 是一个用来监视 GNU/Linux 和 FreeBSD 操作系统的 GPL 授权的自由软件。\n\nGlances 同时也提供了很多实用的选项。 其中我们能够在配置文件见到的一项主要的功能就是设置关键值及相应的标签 （careful[小心], warning[警告] 和 critical[严重]）， 然后她会自动帮我们用不同颜色标出系统达到某个瓶颈的信息。\n\nGlances 主要功能\nCPU 信息 （用户的相关应用, 系统核心程序和空闲程序）\n总内存信息，包括了物理内存，交换空间和空闲内存等等\n之前的 1 分钟、5 分钟和 15 分钟平均的 CPU 负载\n网络链接的下行和上行速度\n处理器总数，以及其活动状态\n硬盘 I/O 相关（读写）速度详情\n当前挂载设备的磁盘使用情况\n高 CPU 和内存使用的进程名，和相关应用的位置\n在底部显示当前日期和时间\n将消耗最高系统资源的进程用红色标出\n下面是一个 Glances 的使用截图：\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214404gen07qvynyj3vjzn.jpeg)\n在 Linux/Unix 系统中安装 Glances\n虽然这个工具的发布比较晚，但你仍然可以在 Red Hat 系的系统中通过 EPEL 软件源安装。在终端用下面的命令安装：\n\n对于 RHEL/CentOS/Fedora 发行版  \n    # yum install -y glances  \n对于 Debian/Ubuntu/Linux Mint 发行版  \n    $ sudo apt-add-repository ppa:arnaud-hartmann/glances-stable    \n    $ sudo apt-get update  \n    $ sudo apt-get install glances  \n如何使用 Glances\n首先，你需要在终端中输入以下命令  \n    \n    # glances  \n![](https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214413hgrs2ozqwarrwypo.jpeg)\n\n按下 ‘q‘ （‘ESC‘ 和 ‘Ctrl-C‘ 也可以） 退出 Glances 终端。 这里是从 CentOS 6.5 截取的另一张截图：\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214419xaiwmtwwaawo2oya.jpeg)\nGlances 的默认刷新频率是 1 （秒），但是你可以通过在终端指定参数来手动定义其刷新频率  \n    # glances -t 2   \nGlances 中颜色的含义\nGlances 会用一下几种颜色来代表状态：\n\n绿色：OK（一切正常）\n蓝色：CAREFUL（需要注意）\n紫色：WARNING（警告）\n红色：CRITICAL（严重）\n阀值可以在配置文件中设置，一般阀值被默认设置为（careful=50、warning=70、critical=90）。\n\n我们可以按照自己的需求在配置文件（默认在 /etc/glances/glances.conf）中自定义。\n\nGlances 的选项\n除了很多命令行选项之外，Glances 还提供了更多的可在其运行时开关输出信息选项的快捷键，下面是一些例子：\n\na – 对进程自动排序  \nc – 按 CPU 百分比对进程排序   \nm – 按内存百分比对进程排序  \np – 按进程名字母顺序对进程排序  \ni – 按读写频率（I/O）对进程排序  \nd – 显示/隐藏磁盘 I/O 统计信息  \nf – 显示/隐藏文件系统统计信息  \nn – 显示/隐藏网络接口统计信息  \ns – 显示/隐藏传感器统计信息  \ny – 显示/隐藏硬盘温度统计信息  \nl – 显示/隐藏日志（log）  \nb – 切换网络 I/O 单位（Bytes/bits）  \nw – 删除警告日志   \nx – 删除警告和严重日志  \n1 – 切换全局 CPU 使用情况和每个 CPU 的使用情况  \nh – 显示/隐藏这个帮助画面  \nt – 以组合形式浏览网络 I/O  \nu – 以累计形式浏览网络 I/O  \nq – 退出（‘ESC‘ 和 ‘Ctrl&C‘ 也可以）  \n远程使用 Glances  \n你甚至也可以通过 Glances 来监视远程系统。 要在远程系统使用 ‘glances’，需要在服务器运行 ‘glances -s’（-s 启动服务器/客户端模式）命令。  \n    # glances -s\n \nDefine the password for the Glances server\nPassword: \nPassword (confirm): \nGlances server is running on 0.0.0.0:61209  \n注意：当你执行了‘glances’命令后，她会让你为 Glances 服务器设置密码。\n\n当你设置完毕，你将看到 “Glances server is running on 0.0.0.0:61209” （Glances 服务器正在 0.0.0.0 的 61209 端口运行）的消息。\n\n当 Glances 服务器启动后，到本地执行下面的命令来指定服务器IP地址或主机名以链接。\n\n注：这里的 ‘172.16.27.56’ 是我 Glances 服务器的 IP 地址。  \n    # glances -c -P 172.16.27.56    \n  下面是一些在使用服务器/客户端模式时必须知道的事情：  \n* 在服务器模式，你可以通过 `-B 地址` 来设置绑定地址，也可以通过 `-p 端口` 来绑定监听的 TCP 端口  \n* 在客户端模式，你可以通过同样的 `-p 端口` 来指定服务器端口  \n* 默认的绑定地址是 0.0.0.0，但这么做会监听所有网络接口的指定端口  \n* 在服务器/客户端模式下，限制的阀值将由服务器的设置决定  \n* 你也可以在命令行下用过 `-P 密码` 的方式来为服务器端设置一个密码  \n总结  \nGlances 对于大多用户而言是个在系统资源上提供过多信息的工具。但是如果你是一个想要仅从命令行就能快速获取系统整体状况的系统管理员，那这个工具绝对是你的必备利器。  \n请不要将 glances（本文中的工具）和 glance（一个 OpenStack 的工具）这两个包搞混了  \nUbuntu 官方 Extra 源中的 glances 因为 python 库移动的问题导致无法正常使用 但可以通过建立软链接的方式临时修复：sudo ln -s /usr/lib/python2.7/dist-packages/glances /usr/share/pyshared/glances\n","source":"_posts/Glances.md","raw":"---\ntitle: Glances\ndate: 2017-02-28\ntags: Glances\ncategories: Glances\n---\ntop 命令是 Linux 下的一个实时任务管理器， 同时也是用于在 GNU/Linux 发行版中寻找系统性能方面的瓶颈，并帮助我们作出正确操作的常用系统监视工具。 她有着一个极为简洁的界面，并自带少量的可以帮助我们快速了解系统性能的实用选项。\n<!--more-->\n但是，有些时候想要通过她寻找一个占用系统资源比较大的应用或进程可能会比较困难。 因为 top 命令本身并不会帮助我们高亮那些吃太多 CPU，内存，或者其他资源的程序。\n\n为了达到这个目标，这里我们将介绍一款超牛逼的系统监视程序 —— Glances。 她可以自动高亮利用最高系统资源的程序，并为 Linux/Unix 服务器提供尽可能多的信息。\n\n什么是 Glances？\nGlances 是一个由 Python 编写，使用 psutil 库来从系统抓取信息的基于 curses 开发的跨平台命令行系统监视工具。 通过 Glances，我们可以监视 CPU，平均负载，内存，网络流量，磁盘 I/O，其他处理器 和 文件系统 空间的利用情况。\n\nGlances 是一个用来监视 GNU/Linux 和 FreeBSD 操作系统的 GPL 授权的自由软件。\n\nGlances 同时也提供了很多实用的选项。 其中我们能够在配置文件见到的一项主要的功能就是设置关键值及相应的标签 （careful[小心], warning[警告] 和 critical[严重]）， 然后她会自动帮我们用不同颜色标出系统达到某个瓶颈的信息。\n\nGlances 主要功能\nCPU 信息 （用户的相关应用, 系统核心程序和空闲程序）\n总内存信息，包括了物理内存，交换空间和空闲内存等等\n之前的 1 分钟、5 分钟和 15 分钟平均的 CPU 负载\n网络链接的下行和上行速度\n处理器总数，以及其活动状态\n硬盘 I/O 相关（读写）速度详情\n当前挂载设备的磁盘使用情况\n高 CPU 和内存使用的进程名，和相关应用的位置\n在底部显示当前日期和时间\n将消耗最高系统资源的进程用红色标出\n下面是一个 Glances 的使用截图：\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214404gen07qvynyj3vjzn.jpeg)\n在 Linux/Unix 系统中安装 Glances\n虽然这个工具的发布比较晚，但你仍然可以在 Red Hat 系的系统中通过 EPEL 软件源安装。在终端用下面的命令安装：\n\n对于 RHEL/CentOS/Fedora 发行版  \n    # yum install -y glances  \n对于 Debian/Ubuntu/Linux Mint 发行版  \n    $ sudo apt-add-repository ppa:arnaud-hartmann/glances-stable    \n    $ sudo apt-get update  \n    $ sudo apt-get install glances  \n如何使用 Glances\n首先，你需要在终端中输入以下命令  \n    \n    # glances  \n![](https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214413hgrs2ozqwarrwypo.jpeg)\n\n按下 ‘q‘ （‘ESC‘ 和 ‘Ctrl-C‘ 也可以） 退出 Glances 终端。 这里是从 CentOS 6.5 截取的另一张截图：\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214419xaiwmtwwaawo2oya.jpeg)\nGlances 的默认刷新频率是 1 （秒），但是你可以通过在终端指定参数来手动定义其刷新频率  \n    # glances -t 2   \nGlances 中颜色的含义\nGlances 会用一下几种颜色来代表状态：\n\n绿色：OK（一切正常）\n蓝色：CAREFUL（需要注意）\n紫色：WARNING（警告）\n红色：CRITICAL（严重）\n阀值可以在配置文件中设置，一般阀值被默认设置为（careful=50、warning=70、critical=90）。\n\n我们可以按照自己的需求在配置文件（默认在 /etc/glances/glances.conf）中自定义。\n\nGlances 的选项\n除了很多命令行选项之外，Glances 还提供了更多的可在其运行时开关输出信息选项的快捷键，下面是一些例子：\n\na – 对进程自动排序  \nc – 按 CPU 百分比对进程排序   \nm – 按内存百分比对进程排序  \np – 按进程名字母顺序对进程排序  \ni – 按读写频率（I/O）对进程排序  \nd – 显示/隐藏磁盘 I/O 统计信息  \nf – 显示/隐藏文件系统统计信息  \nn – 显示/隐藏网络接口统计信息  \ns – 显示/隐藏传感器统计信息  \ny – 显示/隐藏硬盘温度统计信息  \nl – 显示/隐藏日志（log）  \nb – 切换网络 I/O 单位（Bytes/bits）  \nw – 删除警告日志   \nx – 删除警告和严重日志  \n1 – 切换全局 CPU 使用情况和每个 CPU 的使用情况  \nh – 显示/隐藏这个帮助画面  \nt – 以组合形式浏览网络 I/O  \nu – 以累计形式浏览网络 I/O  \nq – 退出（‘ESC‘ 和 ‘Ctrl&C‘ 也可以）  \n远程使用 Glances  \n你甚至也可以通过 Glances 来监视远程系统。 要在远程系统使用 ‘glances’，需要在服务器运行 ‘glances -s’（-s 启动服务器/客户端模式）命令。  \n    # glances -s\n \nDefine the password for the Glances server\nPassword: \nPassword (confirm): \nGlances server is running on 0.0.0.0:61209  \n注意：当你执行了‘glances’命令后，她会让你为 Glances 服务器设置密码。\n\n当你设置完毕，你将看到 “Glances server is running on 0.0.0.0:61209” （Glances 服务器正在 0.0.0.0 的 61209 端口运行）的消息。\n\n当 Glances 服务器启动后，到本地执行下面的命令来指定服务器IP地址或主机名以链接。\n\n注：这里的 ‘172.16.27.56’ 是我 Glances 服务器的 IP 地址。  \n    # glances -c -P 172.16.27.56    \n  下面是一些在使用服务器/客户端模式时必须知道的事情：  \n* 在服务器模式，你可以通过 `-B 地址` 来设置绑定地址，也可以通过 `-p 端口` 来绑定监听的 TCP 端口  \n* 在客户端模式，你可以通过同样的 `-p 端口` 来指定服务器端口  \n* 默认的绑定地址是 0.0.0.0，但这么做会监听所有网络接口的指定端口  \n* 在服务器/客户端模式下，限制的阀值将由服务器的设置决定  \n* 你也可以在命令行下用过 `-P 密码` 的方式来为服务器端设置一个密码  \n总结  \nGlances 对于大多用户而言是个在系统资源上提供过多信息的工具。但是如果你是一个想要仅从命令行就能快速获取系统整体状况的系统管理员，那这个工具绝对是你的必备利器。  \n请不要将 glances（本文中的工具）和 glance（一个 OpenStack 的工具）这两个包搞混了  \nUbuntu 官方 Extra 源中的 glances 因为 python 库移动的问题导致无法正常使用 但可以通过建立软链接的方式临时修复：sudo ln -s /usr/lib/python2.7/dist-packages/glances /usr/share/pyshared/glances\n","slug":"Glances","published":1,"updated":"2019-06-18T08:07:01.112Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sgl0000hcb7dfzse2v9","content":"<p>top 命令是 Linux 下的一个实时任务管理器， 同时也是用于在 GNU/Linux 发行版中寻找系统性能方面的瓶颈，并帮助我们作出正确操作的常用系统监视工具。 她有着一个极为简洁的界面，并自带少量的可以帮助我们快速了解系统性能的实用选项。<br><a id=\"more\"></a><br>但是，有些时候想要通过她寻找一个占用系统资源比较大的应用或进程可能会比较困难。 因为 top 命令本身并不会帮助我们高亮那些吃太多 CPU，内存，或者其他资源的程序。</p>\n<p>为了达到这个目标，这里我们将介绍一款超牛逼的系统监视程序 —— Glances。 她可以自动高亮利用最高系统资源的程序，并为 Linux/Unix 服务器提供尽可能多的信息。</p>\n<p>什么是 Glances？<br>Glances 是一个由 Python 编写，使用 psutil 库来从系统抓取信息的基于 curses 开发的跨平台命令行系统监视工具。 通过 Glances，我们可以监视 CPU，平均负载，内存，网络流量，磁盘 I/O，其他处理器 和 文件系统 空间的利用情况。</p>\n<p>Glances 是一个用来监视 GNU/Linux 和 FreeBSD 操作系统的 GPL 授权的自由软件。</p>\n<p>Glances 同时也提供了很多实用的选项。 其中我们能够在配置文件见到的一项主要的功能就是设置关键值及相应的标签 （careful[小心], warning[警告] 和 critical[严重]）， 然后她会自动帮我们用不同颜色标出系统达到某个瓶颈的信息。</p>\n<p>Glances 主要功能<br>CPU 信息 （用户的相关应用, 系统核心程序和空闲程序）<br>总内存信息，包括了物理内存，交换空间和空闲内存等等<br>之前的 1 分钟、5 分钟和 15 分钟平均的 CPU 负载<br>网络链接的下行和上行速度<br>处理器总数，以及其活动状态<br>硬盘 I/O 相关（读写）速度详情<br>当前挂载设备的磁盘使用情况<br>高 CPU 和内存使用的进程名，和相关应用的位置<br>在底部显示当前日期和时间<br>将消耗最高系统资源的进程用红色标出<br>下面是一个 Glances 的使用截图：<br><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214404gen07qvynyj3vjzn.jpeg\" alt=\"\"><br>在 Linux/Unix 系统中安装 Glances<br>虽然这个工具的发布比较晚，但你仍然可以在 Red Hat 系的系统中通过 EPEL 软件源安装。在终端用下面的命令安装：</p>\n<p>对于 RHEL/CentOS/Fedora 发行版  </p>\n<pre><code># yum install -y glances  \n</code></pre><p>对于 Debian/Ubuntu/Linux Mint 发行版<br>    $ sudo apt-add-repository ppa:arnaud-hartmann/glances-stable<br>    $ sudo apt-get update<br>    $ sudo apt-get install glances<br>如何使用 Glances<br>首先，你需要在终端中输入以下命令  </p>\n<pre><code># glances  \n</code></pre><p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214413hgrs2ozqwarrwypo.jpeg\" alt=\"\"></p>\n<p>按下 ‘q‘ （‘ESC‘ 和 ‘Ctrl-C‘ 也可以） 退出 Glances 终端。 这里是从 CentOS 6.5 截取的另一张截图：<br><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214419xaiwmtwwaawo2oya.jpeg\" alt=\"\"><br>Glances 的默认刷新频率是 1 （秒），但是你可以通过在终端指定参数来手动定义其刷新频率  </p>\n<pre><code># glances -t 2   \n</code></pre><p>Glances 中颜色的含义<br>Glances 会用一下几种颜色来代表状态：</p>\n<p>绿色：OK（一切正常）<br>蓝色：CAREFUL（需要注意）<br>紫色：WARNING（警告）<br>红色：CRITICAL（严重）<br>阀值可以在配置文件中设置，一般阀值被默认设置为（careful=50、warning=70、critical=90）。</p>\n<p>我们可以按照自己的需求在配置文件（默认在 /etc/glances/glances.conf）中自定义。</p>\n<p>Glances 的选项<br>除了很多命令行选项之外，Glances 还提供了更多的可在其运行时开关输出信息选项的快捷键，下面是一些例子：</p>\n<p>a – 对进程自动排序<br>c – 按 CPU 百分比对进程排序<br>m – 按内存百分比对进程排序<br>p – 按进程名字母顺序对进程排序<br>i – 按读写频率（I/O）对进程排序<br>d – 显示/隐藏磁盘 I/O 统计信息<br>f – 显示/隐藏文件系统统计信息<br>n – 显示/隐藏网络接口统计信息<br>s – 显示/隐藏传感器统计信息<br>y – 显示/隐藏硬盘温度统计信息<br>l – 显示/隐藏日志（log）<br>b – 切换网络 I/O 单位（Bytes/bits）<br>w – 删除警告日志<br>x – 删除警告和严重日志<br>1 – 切换全局 CPU 使用情况和每个 CPU 的使用情况<br>h – 显示/隐藏这个帮助画面<br>t – 以组合形式浏览网络 I/O<br>u – 以累计形式浏览网络 I/O<br>q – 退出（‘ESC‘ 和 ‘Ctrl&amp;C‘ 也可以）<br>远程使用 Glances<br>你甚至也可以通过 Glances 来监视远程系统。 要在远程系统使用 ‘glances’，需要在服务器运行 ‘glances -s’（-s 启动服务器/客户端模式）命令。  </p>\n<pre><code># glances -s\n</code></pre><p>Define the password for the Glances server<br>Password:<br>Password (confirm):<br>Glances server is running on 0.0.0.0:61209<br>注意：当你执行了‘glances’命令后，她会让你为 Glances 服务器设置密码。</p>\n<p>当你设置完毕，你将看到 “Glances server is running on 0.0.0.0:61209” （Glances 服务器正在 0.0.0.0 的 61209 端口运行）的消息。</p>\n<p>当 Glances 服务器启动后，到本地执行下面的命令来指定服务器IP地址或主机名以链接。</p>\n<p>注：这里的 ‘172.16.27.56’ 是我 Glances 服务器的 IP 地址。  </p>\n<pre><code># glances -c -P 172.16.27.56    \n</code></pre><p>  下面是一些在使用服务器/客户端模式时必须知道的事情：  </p>\n<ul>\n<li>在服务器模式，你可以通过 <code>-B 地址</code> 来设置绑定地址，也可以通过 <code>-p 端口</code> 来绑定监听的 TCP 端口  </li>\n<li>在客户端模式，你可以通过同样的 <code>-p 端口</code> 来指定服务器端口  </li>\n<li>默认的绑定地址是 0.0.0.0，但这么做会监听所有网络接口的指定端口  </li>\n<li>在服务器/客户端模式下，限制的阀值将由服务器的设置决定  </li>\n<li>你也可以在命令行下用过 <code>-P 密码</code> 的方式来为服务器端设置一个密码<br>总结<br>Glances 对于大多用户而言是个在系统资源上提供过多信息的工具。但是如果你是一个想要仅从命令行就能快速获取系统整体状况的系统管理员，那这个工具绝对是你的必备利器。<br>请不要将 glances（本文中的工具）和 glance（一个 OpenStack 的工具）这两个包搞混了<br>Ubuntu 官方 Extra 源中的 glances 因为 python 库移动的问题导致无法正常使用 但可以通过建立软链接的方式临时修复：sudo ln -s /usr/lib/python2.7/dist-packages/glances /usr/share/pyshared/glances</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>top 命令是 Linux 下的一个实时任务管理器， 同时也是用于在 GNU/Linux 发行版中寻找系统性能方面的瓶颈，并帮助我们作出正确操作的常用系统监视工具。 她有着一个极为简洁的界面，并自带少量的可以帮助我们快速了解系统性能的实用选项。<br>","more":"<br>但是，有些时候想要通过她寻找一个占用系统资源比较大的应用或进程可能会比较困难。 因为 top 命令本身并不会帮助我们高亮那些吃太多 CPU，内存，或者其他资源的程序。</p>\n<p>为了达到这个目标，这里我们将介绍一款超牛逼的系统监视程序 —— Glances。 她可以自动高亮利用最高系统资源的程序，并为 Linux/Unix 服务器提供尽可能多的信息。</p>\n<p>什么是 Glances？<br>Glances 是一个由 Python 编写，使用 psutil 库来从系统抓取信息的基于 curses 开发的跨平台命令行系统监视工具。 通过 Glances，我们可以监视 CPU，平均负载，内存，网络流量，磁盘 I/O，其他处理器 和 文件系统 空间的利用情况。</p>\n<p>Glances 是一个用来监视 GNU/Linux 和 FreeBSD 操作系统的 GPL 授权的自由软件。</p>\n<p>Glances 同时也提供了很多实用的选项。 其中我们能够在配置文件见到的一项主要的功能就是设置关键值及相应的标签 （careful[小心], warning[警告] 和 critical[严重]）， 然后她会自动帮我们用不同颜色标出系统达到某个瓶颈的信息。</p>\n<p>Glances 主要功能<br>CPU 信息 （用户的相关应用, 系统核心程序和空闲程序）<br>总内存信息，包括了物理内存，交换空间和空闲内存等等<br>之前的 1 分钟、5 分钟和 15 分钟平均的 CPU 负载<br>网络链接的下行和上行速度<br>处理器总数，以及其活动状态<br>硬盘 I/O 相关（读写）速度详情<br>当前挂载设备的磁盘使用情况<br>高 CPU 和内存使用的进程名，和相关应用的位置<br>在底部显示当前日期和时间<br>将消耗最高系统资源的进程用红色标出<br>下面是一个 Glances 的使用截图：<br><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214404gen07qvynyj3vjzn.jpeg\" alt=\"\"><br>在 Linux/Unix 系统中安装 Glances<br>虽然这个工具的发布比较晚，但你仍然可以在 Red Hat 系的系统中通过 EPEL 软件源安装。在终端用下面的命令安装：</p>\n<p>对于 RHEL/CentOS/Fedora 发行版  </p>\n<pre><code># yum install -y glances  \n</code></pre><p>对于 Debian/Ubuntu/Linux Mint 发行版<br>    $ sudo apt-add-repository ppa:arnaud-hartmann/glances-stable<br>    $ sudo apt-get update<br>    $ sudo apt-get install glances<br>如何使用 Glances<br>首先，你需要在终端中输入以下命令  </p>\n<pre><code># glances  \n</code></pre><p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214413hgrs2ozqwarrwypo.jpeg\" alt=\"\"></p>\n<p>按下 ‘q‘ （‘ESC‘ 和 ‘Ctrl-C‘ 也可以） 退出 Glances 终端。 这里是从 CentOS 6.5 截取的另一张截图：<br><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214419xaiwmtwwaawo2oya.jpeg\" alt=\"\"><br>Glances 的默认刷新频率是 1 （秒），但是你可以通过在终端指定参数来手动定义其刷新频率  </p>\n<pre><code># glances -t 2   \n</code></pre><p>Glances 中颜色的含义<br>Glances 会用一下几种颜色来代表状态：</p>\n<p>绿色：OK（一切正常）<br>蓝色：CAREFUL（需要注意）<br>紫色：WARNING（警告）<br>红色：CRITICAL（严重）<br>阀值可以在配置文件中设置，一般阀值被默认设置为（careful=50、warning=70、critical=90）。</p>\n<p>我们可以按照自己的需求在配置文件（默认在 /etc/glances/glances.conf）中自定义。</p>\n<p>Glances 的选项<br>除了很多命令行选项之外，Glances 还提供了更多的可在其运行时开关输出信息选项的快捷键，下面是一些例子：</p>\n<p>a – 对进程自动排序<br>c – 按 CPU 百分比对进程排序<br>m – 按内存百分比对进程排序<br>p – 按进程名字母顺序对进程排序<br>i – 按读写频率（I/O）对进程排序<br>d – 显示/隐藏磁盘 I/O 统计信息<br>f – 显示/隐藏文件系统统计信息<br>n – 显示/隐藏网络接口统计信息<br>s – 显示/隐藏传感器统计信息<br>y – 显示/隐藏硬盘温度统计信息<br>l – 显示/隐藏日志（log）<br>b – 切换网络 I/O 单位（Bytes/bits）<br>w – 删除警告日志<br>x – 删除警告和严重日志<br>1 – 切换全局 CPU 使用情况和每个 CPU 的使用情况<br>h – 显示/隐藏这个帮助画面<br>t – 以组合形式浏览网络 I/O<br>u – 以累计形式浏览网络 I/O<br>q – 退出（‘ESC‘ 和 ‘Ctrl&amp;C‘ 也可以）<br>远程使用 Glances<br>你甚至也可以通过 Glances 来监视远程系统。 要在远程系统使用 ‘glances’，需要在服务器运行 ‘glances -s’（-s 启动服务器/客户端模式）命令。  </p>\n<pre><code># glances -s\n</code></pre><p>Define the password for the Glances server<br>Password:<br>Password (confirm):<br>Glances server is running on 0.0.0.0:61209<br>注意：当你执行了‘glances’命令后，她会让你为 Glances 服务器设置密码。</p>\n<p>当你设置完毕，你将看到 “Glances server is running on 0.0.0.0:61209” （Glances 服务器正在 0.0.0.0 的 61209 端口运行）的消息。</p>\n<p>当 Glances 服务器启动后，到本地执行下面的命令来指定服务器IP地址或主机名以链接。</p>\n<p>注：这里的 ‘172.16.27.56’ 是我 Glances 服务器的 IP 地址。  </p>\n<pre><code># glances -c -P 172.16.27.56    \n</code></pre><p>  下面是一些在使用服务器/客户端模式时必须知道的事情：  </p>\n<ul>\n<li>在服务器模式，你可以通过 <code>-B 地址</code> 来设置绑定地址，也可以通过 <code>-p 端口</code> 来绑定监听的 TCP 端口  </li>\n<li>在客户端模式，你可以通过同样的 <code>-p 端口</code> 来指定服务器端口  </li>\n<li>默认的绑定地址是 0.0.0.0，但这么做会监听所有网络接口的指定端口  </li>\n<li>在服务器/客户端模式下，限制的阀值将由服务器的设置决定  </li>\n<li>你也可以在命令行下用过 <code>-P 密码</code> 的方式来为服务器端设置一个密码<br>总结<br>Glances 对于大多用户而言是个在系统资源上提供过多信息的工具。但是如果你是一个想要仅从命令行就能快速获取系统整体状况的系统管理员，那这个工具绝对是你的必备利器。<br>请不要将 glances（本文中的工具）和 glance（一个 OpenStack 的工具）这两个包搞混了<br>Ubuntu 官方 Extra 源中的 glances 因为 python 库移动的问题导致无法正常使用 但可以通过建立软链接的方式临时修复：sudo ln -s /usr/lib/python2.7/dist-packages/glances /usr/share/pyshared/glances</li>\n</ul>"},{"title":"Kubernetes如何使用kube-dns实现服务发现","date":"2018-04-10T04:00:00.000Z","_content":"# Kubernetes中如何发现服务\n<!--more-->\n##  发现Pod提供的服务\n首先使用nginx-deployment.yaml文件创建一个Nginx Deployment，文件内容如图所示：\n首先创建两个运行Nginx服务的Pod：\n![http://blog.tenxcloud.com/wp-content/uploads/2016/10/1.png](http://blog.tenxcloud.com/wp-content/uploads/2016/10/1.png)\n\n使用kubectl create -f nginx-deployment.yaml指令创建，这样便可以得到两个运行nginx服务的Pod。待Pod运行之后查看一下它们的IP，并在k8s集群内通过podIP和containerPort来访问Nginx服务：\n\n### 获取Pod IP：\n```\nkubectl get pod -o yaml -l run=myy-nginx|grep podIP\n```\n![http://blog.tenxcloud.com/wp-content/uploads/2016/10/2.png](http://blog.tenxcloud.com/wp-content/uploads/2016/10/2.png)\n\n### 在集群内访问Nginx服务：\n![http://blog.tenxcloud.com/wp-content/uploads/2016/10/3.png](http://blog.tenxcloud.com/wp-content/uploads/2016/10/3.png)\n\n看到这里相信很多人会有以下疑问：\n>1.  每次收到获取podIP太扯了，总不能每次都要手动改程序或者配置才能访问服务吧，要怎么提前知道podIP呢？\n>2.  Pod在运行中可能会重建，IP变了怎么解？\n>3.  如何在多个Pod中实现负载均衡嘞？\n\n这些问题使用k8s Service就可以解决。\n\n## 使用Service发现服务\n下面为两个Nginx Pod创建一个Service。使用nginx-service.yaml文件进行创建，文件内容如下：\n![http://blog.tenxcloud.com/wp-content/uploads/2016/10/4.png](http://blog.tenxcloud.com/wp-content/uploads/2016/10/4.png)\n创建之后，仍需要获取Service的Cluster-IP，再结合Port访问Nginx服务。\n\nService可以将pod  IP封装起来，即使Pod发生重建，依然可以通过Service来访问Pod提供的服务。此外，Service还解决了负载均衡的问题，大家可以多访问几次Service，然后通过kubectl logs 来查看两个Nginx Pod的访问日志来确认。\n\n### 获取IP：\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/5.png)\n\n### 在集群内访问Service：\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/6.png)\n\n虽然Service解决了Pod的服务发现和负载均衡问题，但存在着类似的问题：不提前知道Service的IP，还是需要改程序或配置啊。看到这里有没有感觉身体被掏空？\n\n接下来聊聊kube-dns是如何解决上面这个问题的。\n\n## 使用kube-dns发现服务\n\nkube-dns可以解决Service的发现问题，k8s将Service的名称当做域名注册到kube-dns中，通过Service的名称就可以访问其提供的服务。\n\n可能有人会问如果集群中没有部署kube-dns怎么办？没关系，实际上kube-dns插件只是运行在kube-system命名空间下的Pod，完全可以手动创建它。可以在k8s源码（v1.2）的cluster/addons/dns目录下找到两个模板（skydns-rc.yaml.in和skydns-svc.yaml.in）来创建，为大家准备的完整示例文件会在分享结束后提供获取方式，PPT中只截取了部分内容。\n\n通过skydns-rc.yaml文件创建kube-dns Pod，其中包含了四个containers，这里开始简单过一下文件的主要部分，稍后做详细介绍。\n\n第一部分可以看到kube-dns使用了RC来管理Pod，可以提供最基本的故障重启功能。\n\n创建kube-dns Pod，其中包含了4个containers\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/7.png)\n\n接下来是第一个容器  etcd  ，它的用途是保存DNS规则。\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/8.png)\n\n第二个容器  kube2sky ，作用是写入DNS规则。\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/9.png)\n\n第三个容器是  skydns ，提供DNS解析服务。\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/10.png)\n\n最后一个容器是  healthz ，提供健康检查功能。\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/11.png)\n\n有了Pod之后，还需要创建一个Service以便集群中的其他Pod访问DNS查询服务。通过skydns-svc.yaml创建Service，内容如下：\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/12.png)\n\n创建完kube-dns Pod和Service，并且Pod运行后，便可以访问kube-dns服务。\n\n下面创建一个Pod，并在该Pod中访问Nginx服务：\n\n创建之后等待kube-dns处于运行状态\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/13.png)\n\n再新建一个Pod，通过其访问Nginx服务\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/14.png)\n\n在curl-util Pod中通过Service名称访问my-nginx Service：\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/15.png)\n\n只要知道需要的服务名称就可以访问，使用kube-dns发现服务就是那么简单。\n\n虽然领略了使用kube-dns发现服务的便利性，但相信有很多人也是一头雾水：kube-dns到底怎么工作的？在集群中启用了kube-dns插件，怎么就能通过名称访问Service了呢？\n\n# kube-dns原理\n\n## Kube-dns组成\n\n之前已经了解到kube-dns是由四个容器组成的，它们扮演的角色可以通过下面这张图来理解。\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/kube-dns%E6%9E%B6%E6%9E%84.png)\n\n其中：\n\n●  SkyDNS是用于服务发现的开源框架，构建于etcd之上。作用是为k8s集群中的Pod提供DNS查询接口。项目托管于https://github.com/skynetservices/skydns\n\n●  etcd是一种开源的分布式key-value存储，其功能与ZooKeeper类似。在kube-dns中的作用为存储SkyDNS需要的各种数据，写入方为kube2sky，读取方为SkyDNS。项目托管于https://github.com/coreos/etcd。\n\n●   kube2sky是k8s实现的一个适配程序，它通过名为kubernetes的Service（通过kubectl get svc可以查看到该Service，由集群自动创建）调用k8s的list和watch API来监听k8s Service资源的变更，从而修改etcd中的SkyDNS记录。代码可以在k8s源码（v1.2）的cluster/addons/dns/kube2sky/目录中找到。\n\n●   exec-healthz是k8s提供的一种辅助容器，多用于side car模式中。它的原理是定期执行指定的Linux指令，从而判断当前Pod中关键容器的健康状态。在kube-dns中的作用就是通过nslookup指令检查DNS查询服务的健康状态，k8s livenessProbe通过访问exec-healthz提供的Http API了解健康状态，并在出现故障时重启容器。其源码位于https://github.com/kubernetes/contrib/tree/master/exec-healthz。\n\n●  从图中可以发现，Pod查询DNS是通过ServiceName.Namespace子域名来查询的，但在之前的示例中只用了Service名称，什么原理呢？其实当我们只使用Service名称时会默认Namespace为default，而上面示例中的my-nginx Service就是在default Namespace中，因此是可以正常运行的。关于这一点，后续再深入介绍。\n\n●  skydns-rc.yaml中可以发现livenessProbe是设置在kube2sky容器中的，其意图应该是希望通过重启kube2sky来重新写入DNS规则\n\n## 域名格式\n\n接下来了解一下kube-dns支持的域名格式，具体为：..svc.。\n\n其中cluster_domain可以使用kubelet的--cluster-domain=SomeDomain参数进行设置，同时也要保证kube2sky容器的启动参数中--domain参数设置了相同的值。通常设置为cluster.local。那么之前示例中的my-nginx Service对应的完整域名就是my-nginx.default.svc.cluster.local。看到这里，相信很多人会有疑问，既然完整域名是这样的，那为什么在Pod中只通过Service名称和Namespace就能访问Service呢？下面来解释其中原因。\n\n# 配置\n\n## 域名解析配置\n\n为了在Pod中调用其他Service，kubelet会自动在容器中创建域名解析配置（/etc/resolv.conf），内容为：\n\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/16.png)\n\n感兴趣的可以在网上查找一些resolv.conf的资料来了解具体的含义。之所以能够通过Service名称和Namespace就能访问Service，就是因为search配置的规则。在解析域名时会自动拼接成完整域名去查询DNS。\n\n刚才提到的kubelet --cluster-domain参数与search的具体配置是相对应的。而kube2sky容器的--domain参数影响的是写入到etcd中的域名，kube2sky会获取Service的名称和Namespace，并使用--domain参数拼接完整域名。这也就是让两个参数保持一致的原因。\n\n## NS 相关配置\n\nkube-dns可以让Pod发现其他Service，那Pod又是如何自动发现kube-dns的呢？在上一节中的/etc/resolv.conf中可以看到nameserver，这个配置就会告诉Pod去哪访问域名解析服务器。\n\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/17.png)\n\n相应的，可以在之前提到的skydns-svc.yaml中看到spec.clusterIP配置了相同的值。通常来说创建一个Service并不需要指定clusterIP，k8s会自动为其分配，但kube-dns比较特殊，需要指定clusterIP使其与/etc/resolv.conf中的nameserver保持一致。\n\n修改nameserver配置同样需要修改两个地方，一个是kubelet的--cluster-dns参数，另一个就是kube-dns Service的clusterIP。\n\n\n# 总结\n接下来重新梳理一下本文的主要内容：\n>●    在k8s集群中，服务是运行在Pod中的，Pod的发现和副本间负载均衡是我们面临的问题。\n>●    通过Service可以解决这两个问题，但访问Service也需要对应的IP，因此又引入了Service发现的问题。\n>●    得益于kube-dns插件，我们可以通过域名来访问集群内的Service，解决了Service发现的问题。\n>●    为了让Pod中的容器可以使用kube-dns来解析域名，k8s会修改容器的/etc/resolv.conf配置。\n\n有了以上机制的保证，就可以在Pod中通过Service名称和namespace非常方便地访问对应的服务了。\n\n","source":"_posts/Kubernetes如何使用kube-dns实现服务发现.md","raw":"---\ntitle: Kubernetes如何使用kube-dns实现服务发现\ndate: 2018-04-10\ntags: k8s\ncategories: k8s\n---\n# Kubernetes中如何发现服务\n<!--more-->\n##  发现Pod提供的服务\n首先使用nginx-deployment.yaml文件创建一个Nginx Deployment，文件内容如图所示：\n首先创建两个运行Nginx服务的Pod：\n![http://blog.tenxcloud.com/wp-content/uploads/2016/10/1.png](http://blog.tenxcloud.com/wp-content/uploads/2016/10/1.png)\n\n使用kubectl create -f nginx-deployment.yaml指令创建，这样便可以得到两个运行nginx服务的Pod。待Pod运行之后查看一下它们的IP，并在k8s集群内通过podIP和containerPort来访问Nginx服务：\n\n### 获取Pod IP：\n```\nkubectl get pod -o yaml -l run=myy-nginx|grep podIP\n```\n![http://blog.tenxcloud.com/wp-content/uploads/2016/10/2.png](http://blog.tenxcloud.com/wp-content/uploads/2016/10/2.png)\n\n### 在集群内访问Nginx服务：\n![http://blog.tenxcloud.com/wp-content/uploads/2016/10/3.png](http://blog.tenxcloud.com/wp-content/uploads/2016/10/3.png)\n\n看到这里相信很多人会有以下疑问：\n>1.  每次收到获取podIP太扯了，总不能每次都要手动改程序或者配置才能访问服务吧，要怎么提前知道podIP呢？\n>2.  Pod在运行中可能会重建，IP变了怎么解？\n>3.  如何在多个Pod中实现负载均衡嘞？\n\n这些问题使用k8s Service就可以解决。\n\n## 使用Service发现服务\n下面为两个Nginx Pod创建一个Service。使用nginx-service.yaml文件进行创建，文件内容如下：\n![http://blog.tenxcloud.com/wp-content/uploads/2016/10/4.png](http://blog.tenxcloud.com/wp-content/uploads/2016/10/4.png)\n创建之后，仍需要获取Service的Cluster-IP，再结合Port访问Nginx服务。\n\nService可以将pod  IP封装起来，即使Pod发生重建，依然可以通过Service来访问Pod提供的服务。此外，Service还解决了负载均衡的问题，大家可以多访问几次Service，然后通过kubectl logs 来查看两个Nginx Pod的访问日志来确认。\n\n### 获取IP：\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/5.png)\n\n### 在集群内访问Service：\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/6.png)\n\n虽然Service解决了Pod的服务发现和负载均衡问题，但存在着类似的问题：不提前知道Service的IP，还是需要改程序或配置啊。看到这里有没有感觉身体被掏空？\n\n接下来聊聊kube-dns是如何解决上面这个问题的。\n\n## 使用kube-dns发现服务\n\nkube-dns可以解决Service的发现问题，k8s将Service的名称当做域名注册到kube-dns中，通过Service的名称就可以访问其提供的服务。\n\n可能有人会问如果集群中没有部署kube-dns怎么办？没关系，实际上kube-dns插件只是运行在kube-system命名空间下的Pod，完全可以手动创建它。可以在k8s源码（v1.2）的cluster/addons/dns目录下找到两个模板（skydns-rc.yaml.in和skydns-svc.yaml.in）来创建，为大家准备的完整示例文件会在分享结束后提供获取方式，PPT中只截取了部分内容。\n\n通过skydns-rc.yaml文件创建kube-dns Pod，其中包含了四个containers，这里开始简单过一下文件的主要部分，稍后做详细介绍。\n\n第一部分可以看到kube-dns使用了RC来管理Pod，可以提供最基本的故障重启功能。\n\n创建kube-dns Pod，其中包含了4个containers\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/7.png)\n\n接下来是第一个容器  etcd  ，它的用途是保存DNS规则。\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/8.png)\n\n第二个容器  kube2sky ，作用是写入DNS规则。\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/9.png)\n\n第三个容器是  skydns ，提供DNS解析服务。\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/10.png)\n\n最后一个容器是  healthz ，提供健康检查功能。\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/11.png)\n\n有了Pod之后，还需要创建一个Service以便集群中的其他Pod访问DNS查询服务。通过skydns-svc.yaml创建Service，内容如下：\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/12.png)\n\n创建完kube-dns Pod和Service，并且Pod运行后，便可以访问kube-dns服务。\n\n下面创建一个Pod，并在该Pod中访问Nginx服务：\n\n创建之后等待kube-dns处于运行状态\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/13.png)\n\n再新建一个Pod，通过其访问Nginx服务\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/14.png)\n\n在curl-util Pod中通过Service名称访问my-nginx Service：\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/15.png)\n\n只要知道需要的服务名称就可以访问，使用kube-dns发现服务就是那么简单。\n\n虽然领略了使用kube-dns发现服务的便利性，但相信有很多人也是一头雾水：kube-dns到底怎么工作的？在集群中启用了kube-dns插件，怎么就能通过名称访问Service了呢？\n\n# kube-dns原理\n\n## Kube-dns组成\n\n之前已经了解到kube-dns是由四个容器组成的，它们扮演的角色可以通过下面这张图来理解。\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/kube-dns%E6%9E%B6%E6%9E%84.png)\n\n其中：\n\n●  SkyDNS是用于服务发现的开源框架，构建于etcd之上。作用是为k8s集群中的Pod提供DNS查询接口。项目托管于https://github.com/skynetservices/skydns\n\n●  etcd是一种开源的分布式key-value存储，其功能与ZooKeeper类似。在kube-dns中的作用为存储SkyDNS需要的各种数据，写入方为kube2sky，读取方为SkyDNS。项目托管于https://github.com/coreos/etcd。\n\n●   kube2sky是k8s实现的一个适配程序，它通过名为kubernetes的Service（通过kubectl get svc可以查看到该Service，由集群自动创建）调用k8s的list和watch API来监听k8s Service资源的变更，从而修改etcd中的SkyDNS记录。代码可以在k8s源码（v1.2）的cluster/addons/dns/kube2sky/目录中找到。\n\n●   exec-healthz是k8s提供的一种辅助容器，多用于side car模式中。它的原理是定期执行指定的Linux指令，从而判断当前Pod中关键容器的健康状态。在kube-dns中的作用就是通过nslookup指令检查DNS查询服务的健康状态，k8s livenessProbe通过访问exec-healthz提供的Http API了解健康状态，并在出现故障时重启容器。其源码位于https://github.com/kubernetes/contrib/tree/master/exec-healthz。\n\n●  从图中可以发现，Pod查询DNS是通过ServiceName.Namespace子域名来查询的，但在之前的示例中只用了Service名称，什么原理呢？其实当我们只使用Service名称时会默认Namespace为default，而上面示例中的my-nginx Service就是在default Namespace中，因此是可以正常运行的。关于这一点，后续再深入介绍。\n\n●  skydns-rc.yaml中可以发现livenessProbe是设置在kube2sky容器中的，其意图应该是希望通过重启kube2sky来重新写入DNS规则\n\n## 域名格式\n\n接下来了解一下kube-dns支持的域名格式，具体为：..svc.。\n\n其中cluster_domain可以使用kubelet的--cluster-domain=SomeDomain参数进行设置，同时也要保证kube2sky容器的启动参数中--domain参数设置了相同的值。通常设置为cluster.local。那么之前示例中的my-nginx Service对应的完整域名就是my-nginx.default.svc.cluster.local。看到这里，相信很多人会有疑问，既然完整域名是这样的，那为什么在Pod中只通过Service名称和Namespace就能访问Service呢？下面来解释其中原因。\n\n# 配置\n\n## 域名解析配置\n\n为了在Pod中调用其他Service，kubelet会自动在容器中创建域名解析配置（/etc/resolv.conf），内容为：\n\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/16.png)\n\n感兴趣的可以在网上查找一些resolv.conf的资料来了解具体的含义。之所以能够通过Service名称和Namespace就能访问Service，就是因为search配置的规则。在解析域名时会自动拼接成完整域名去查询DNS。\n\n刚才提到的kubelet --cluster-domain参数与search的具体配置是相对应的。而kube2sky容器的--domain参数影响的是写入到etcd中的域名，kube2sky会获取Service的名称和Namespace，并使用--domain参数拼接完整域名。这也就是让两个参数保持一致的原因。\n\n## NS 相关配置\n\nkube-dns可以让Pod发现其他Service，那Pod又是如何自动发现kube-dns的呢？在上一节中的/etc/resolv.conf中可以看到nameserver，这个配置就会告诉Pod去哪访问域名解析服务器。\n\n![](http://blog.tenxcloud.com/wp-content/uploads/2016/10/17.png)\n\n相应的，可以在之前提到的skydns-svc.yaml中看到spec.clusterIP配置了相同的值。通常来说创建一个Service并不需要指定clusterIP，k8s会自动为其分配，但kube-dns比较特殊，需要指定clusterIP使其与/etc/resolv.conf中的nameserver保持一致。\n\n修改nameserver配置同样需要修改两个地方，一个是kubelet的--cluster-dns参数，另一个就是kube-dns Service的clusterIP。\n\n\n# 总结\n接下来重新梳理一下本文的主要内容：\n>●    在k8s集群中，服务是运行在Pod中的，Pod的发现和副本间负载均衡是我们面临的问题。\n>●    通过Service可以解决这两个问题，但访问Service也需要对应的IP，因此又引入了Service发现的问题。\n>●    得益于kube-dns插件，我们可以通过域名来访问集群内的Service，解决了Service发现的问题。\n>●    为了让Pod中的容器可以使用kube-dns来解析域名，k8s会修改容器的/etc/resolv.conf配置。\n\n有了以上机制的保证，就可以在Pod中通过Service名称和namespace非常方便地访问对应的服务了。\n\n","slug":"Kubernetes如何使用kube-dns实现服务发现","published":1,"updated":"2019-06-18T08:07:01.113Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9shd0002hcb7aro7i2j4","content":"<h1 id=\"Kubernetes中如何发现服务\"><a href=\"#Kubernetes中如何发现服务\" class=\"headerlink\" title=\"Kubernetes中如何发现服务\"></a>Kubernetes中如何发现服务</h1><a id=\"more\"></a>\n<h2 id=\"发现Pod提供的服务\"><a href=\"#发现Pod提供的服务\" class=\"headerlink\" title=\"发现Pod提供的服务\"></a>发现Pod提供的服务</h2><p>首先使用nginx-deployment.yaml文件创建一个Nginx Deployment，文件内容如图所示：<br>首先创建两个运行Nginx服务的Pod：<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/1.png\" alt=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/1.png\"></p>\n<p>使用kubectl create -f nginx-deployment.yaml指令创建，这样便可以得到两个运行nginx服务的Pod。待Pod运行之后查看一下它们的IP，并在k8s集群内通过podIP和containerPort来访问Nginx服务：</p>\n<h3 id=\"获取Pod-IP：\"><a href=\"#获取Pod-IP：\" class=\"headerlink\" title=\"获取Pod IP：\"></a>获取Pod IP：</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get pod -o yaml -l run=myy-nginx|grep podIP</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/2.png\" alt=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/2.png\"></p>\n<h3 id=\"在集群内访问Nginx服务：\"><a href=\"#在集群内访问Nginx服务：\" class=\"headerlink\" title=\"在集群内访问Nginx服务：\"></a>在集群内访问Nginx服务：</h3><p><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/3.png\" alt=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/3.png\"></p>\n<p>看到这里相信很多人会有以下疑问：</p>\n<blockquote>\n<ol>\n<li>每次收到获取podIP太扯了，总不能每次都要手动改程序或者配置才能访问服务吧，要怎么提前知道podIP呢？</li>\n<li>Pod在运行中可能会重建，IP变了怎么解？</li>\n<li>如何在多个Pod中实现负载均衡嘞？</li>\n</ol>\n</blockquote>\n<p>这些问题使用k8s Service就可以解决。</p>\n<h2 id=\"使用Service发现服务\"><a href=\"#使用Service发现服务\" class=\"headerlink\" title=\"使用Service发现服务\"></a>使用Service发现服务</h2><p>下面为两个Nginx Pod创建一个Service。使用nginx-service.yaml文件进行创建，文件内容如下：<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/4.png\" alt=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/4.png\"><br>创建之后，仍需要获取Service的Cluster-IP，再结合Port访问Nginx服务。</p>\n<p>Service可以将pod  IP封装起来，即使Pod发生重建，依然可以通过Service来访问Pod提供的服务。此外，Service还解决了负载均衡的问题，大家可以多访问几次Service，然后通过kubectl logs 来查看两个Nginx Pod的访问日志来确认。</p>\n<h3 id=\"获取IP：\"><a href=\"#获取IP：\" class=\"headerlink\" title=\"获取IP：\"></a>获取IP：</h3><p><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/5.png\" alt=\"\"></p>\n<h3 id=\"在集群内访问Service：\"><a href=\"#在集群内访问Service：\" class=\"headerlink\" title=\"在集群内访问Service：\"></a>在集群内访问Service：</h3><p><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/6.png\" alt=\"\"></p>\n<p>虽然Service解决了Pod的服务发现和负载均衡问题，但存在着类似的问题：不提前知道Service的IP，还是需要改程序或配置啊。看到这里有没有感觉身体被掏空？</p>\n<p>接下来聊聊kube-dns是如何解决上面这个问题的。</p>\n<h2 id=\"使用kube-dns发现服务\"><a href=\"#使用kube-dns发现服务\" class=\"headerlink\" title=\"使用kube-dns发现服务\"></a>使用kube-dns发现服务</h2><p>kube-dns可以解决Service的发现问题，k8s将Service的名称当做域名注册到kube-dns中，通过Service的名称就可以访问其提供的服务。</p>\n<p>可能有人会问如果集群中没有部署kube-dns怎么办？没关系，实际上kube-dns插件只是运行在kube-system命名空间下的Pod，完全可以手动创建它。可以在k8s源码（v1.2）的cluster/addons/dns目录下找到两个模板（skydns-rc.yaml.in和skydns-svc.yaml.in）来创建，为大家准备的完整示例文件会在分享结束后提供获取方式，PPT中只截取了部分内容。</p>\n<p>通过skydns-rc.yaml文件创建kube-dns Pod，其中包含了四个containers，这里开始简单过一下文件的主要部分，稍后做详细介绍。</p>\n<p>第一部分可以看到kube-dns使用了RC来管理Pod，可以提供最基本的故障重启功能。</p>\n<p>创建kube-dns Pod，其中包含了4个containers<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/7.png\" alt=\"\"></p>\n<p>接下来是第一个容器  etcd  ，它的用途是保存DNS规则。<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/8.png\" alt=\"\"></p>\n<p>第二个容器  kube2sky ，作用是写入DNS规则。<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/9.png\" alt=\"\"></p>\n<p>第三个容器是  skydns ，提供DNS解析服务。<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/10.png\" alt=\"\"></p>\n<p>最后一个容器是  healthz ，提供健康检查功能。<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/11.png\" alt=\"\"></p>\n<p>有了Pod之后，还需要创建一个Service以便集群中的其他Pod访问DNS查询服务。通过skydns-svc.yaml创建Service，内容如下：<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/12.png\" alt=\"\"></p>\n<p>创建完kube-dns Pod和Service，并且Pod运行后，便可以访问kube-dns服务。</p>\n<p>下面创建一个Pod，并在该Pod中访问Nginx服务：</p>\n<p>创建之后等待kube-dns处于运行状态<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/13.png\" alt=\"\"></p>\n<p>再新建一个Pod，通过其访问Nginx服务<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/14.png\" alt=\"\"></p>\n<p>在curl-util Pod中通过Service名称访问my-nginx Service：<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/15.png\" alt=\"\"></p>\n<p>只要知道需要的服务名称就可以访问，使用kube-dns发现服务就是那么简单。</p>\n<p>虽然领略了使用kube-dns发现服务的便利性，但相信有很多人也是一头雾水：kube-dns到底怎么工作的？在集群中启用了kube-dns插件，怎么就能通过名称访问Service了呢？</p>\n<h1 id=\"kube-dns原理\"><a href=\"#kube-dns原理\" class=\"headerlink\" title=\"kube-dns原理\"></a>kube-dns原理</h1><h2 id=\"Kube-dns组成\"><a href=\"#Kube-dns组成\" class=\"headerlink\" title=\"Kube-dns组成\"></a>Kube-dns组成</h2><p>之前已经了解到kube-dns是由四个容器组成的，它们扮演的角色可以通过下面这张图来理解。<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/kube-dns%E6%9E%B6%E6%9E%84.png\" alt=\"\"></p>\n<p>其中：</p>\n<p>●  SkyDNS是用于服务发现的开源框架，构建于etcd之上。作用是为k8s集群中的Pod提供DNS查询接口。项目托管于<a href=\"https://github.com/skynetservices/skydns\" target=\"_blank\" rel=\"noopener\">https://github.com/skynetservices/skydns</a></p>\n<p>●  etcd是一种开源的分布式key-value存储，其功能与ZooKeeper类似。在kube-dns中的作用为存储SkyDNS需要的各种数据，写入方为kube2sky，读取方为SkyDNS。项目托管于<a href=\"https://github.com/coreos/etcd。\" target=\"_blank\" rel=\"noopener\">https://github.com/coreos/etcd。</a></p>\n<p>●   kube2sky是k8s实现的一个适配程序，它通过名为kubernetes的Service（通过kubectl get svc可以查看到该Service，由集群自动创建）调用k8s的list和watch API来监听k8s Service资源的变更，从而修改etcd中的SkyDNS记录。代码可以在k8s源码（v1.2）的cluster/addons/dns/kube2sky/目录中找到。</p>\n<p>●   exec-healthz是k8s提供的一种辅助容器，多用于side car模式中。它的原理是定期执行指定的Linux指令，从而判断当前Pod中关键容器的健康状态。在kube-dns中的作用就是通过nslookup指令检查DNS查询服务的健康状态，k8s livenessProbe通过访问exec-healthz提供的Http API了解健康状态，并在出现故障时重启容器。其源码位于<a href=\"https://github.com/kubernetes/contrib/tree/master/exec-healthz。\" target=\"_blank\" rel=\"noopener\">https://github.com/kubernetes/contrib/tree/master/exec-healthz。</a></p>\n<p>●  从图中可以发现，Pod查询DNS是通过ServiceName.Namespace子域名来查询的，但在之前的示例中只用了Service名称，什么原理呢？其实当我们只使用Service名称时会默认Namespace为default，而上面示例中的my-nginx Service就是在default Namespace中，因此是可以正常运行的。关于这一点，后续再深入介绍。</p>\n<p>●  skydns-rc.yaml中可以发现livenessProbe是设置在kube2sky容器中的，其意图应该是希望通过重启kube2sky来重新写入DNS规则</p>\n<h2 id=\"域名格式\"><a href=\"#域名格式\" class=\"headerlink\" title=\"域名格式\"></a>域名格式</h2><p>接下来了解一下kube-dns支持的域名格式，具体为：..svc.。</p>\n<p>其中cluster_domain可以使用kubelet的–cluster-domain=SomeDomain参数进行设置，同时也要保证kube2sky容器的启动参数中–domain参数设置了相同的值。通常设置为cluster.local。那么之前示例中的my-nginx Service对应的完整域名就是my-nginx.default.svc.cluster.local。看到这里，相信很多人会有疑问，既然完整域名是这样的，那为什么在Pod中只通过Service名称和Namespace就能访问Service呢？下面来解释其中原因。</p>\n<h1 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h1><h2 id=\"域名解析配置\"><a href=\"#域名解析配置\" class=\"headerlink\" title=\"域名解析配置\"></a>域名解析配置</h2><p>为了在Pod中调用其他Service，kubelet会自动在容器中创建域名解析配置（/etc/resolv.conf），内容为：</p>\n<p><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/16.png\" alt=\"\"></p>\n<p>感兴趣的可以在网上查找一些resolv.conf的资料来了解具体的含义。之所以能够通过Service名称和Namespace就能访问Service，就是因为search配置的规则。在解析域名时会自动拼接成完整域名去查询DNS。</p>\n<p>刚才提到的kubelet –cluster-domain参数与search的具体配置是相对应的。而kube2sky容器的–domain参数影响的是写入到etcd中的域名，kube2sky会获取Service的名称和Namespace，并使用–domain参数拼接完整域名。这也就是让两个参数保持一致的原因。</p>\n<h2 id=\"NS-相关配置\"><a href=\"#NS-相关配置\" class=\"headerlink\" title=\"NS 相关配置\"></a>NS 相关配置</h2><p>kube-dns可以让Pod发现其他Service，那Pod又是如何自动发现kube-dns的呢？在上一节中的/etc/resolv.conf中可以看到nameserver，这个配置就会告诉Pod去哪访问域名解析服务器。</p>\n<p><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/17.png\" alt=\"\"></p>\n<p>相应的，可以在之前提到的skydns-svc.yaml中看到spec.clusterIP配置了相同的值。通常来说创建一个Service并不需要指定clusterIP，k8s会自动为其分配，但kube-dns比较特殊，需要指定clusterIP使其与/etc/resolv.conf中的nameserver保持一致。</p>\n<p>修改nameserver配置同样需要修改两个地方，一个是kubelet的–cluster-dns参数，另一个就是kube-dns Service的clusterIP。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>接下来重新梳理一下本文的主要内容：</p>\n<blockquote>\n<p>●    在k8s集群中，服务是运行在Pod中的，Pod的发现和副本间负载均衡是我们面临的问题。<br>●    通过Service可以解决这两个问题，但访问Service也需要对应的IP，因此又引入了Service发现的问题。<br>●    得益于kube-dns插件，我们可以通过域名来访问集群内的Service，解决了Service发现的问题。<br>●    为了让Pod中的容器可以使用kube-dns来解析域名，k8s会修改容器的/etc/resolv.conf配置。</p>\n</blockquote>\n<p>有了以上机制的保证，就可以在Pod中通过Service名称和namespace非常方便地访问对应的服务了。</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"Kubernetes中如何发现服务\"><a href=\"#Kubernetes中如何发现服务\" class=\"headerlink\" title=\"Kubernetes中如何发现服务\"></a>Kubernetes中如何发现服务</h1>","more":"<h2 id=\"发现Pod提供的服务\"><a href=\"#发现Pod提供的服务\" class=\"headerlink\" title=\"发现Pod提供的服务\"></a>发现Pod提供的服务</h2><p>首先使用nginx-deployment.yaml文件创建一个Nginx Deployment，文件内容如图所示：<br>首先创建两个运行Nginx服务的Pod：<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/1.png\" alt=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/1.png\"></p>\n<p>使用kubectl create -f nginx-deployment.yaml指令创建，这样便可以得到两个运行nginx服务的Pod。待Pod运行之后查看一下它们的IP，并在k8s集群内通过podIP和containerPort来访问Nginx服务：</p>\n<h3 id=\"获取Pod-IP：\"><a href=\"#获取Pod-IP：\" class=\"headerlink\" title=\"获取Pod IP：\"></a>获取Pod IP：</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get pod -o yaml -l run=myy-nginx|grep podIP</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/2.png\" alt=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/2.png\"></p>\n<h3 id=\"在集群内访问Nginx服务：\"><a href=\"#在集群内访问Nginx服务：\" class=\"headerlink\" title=\"在集群内访问Nginx服务：\"></a>在集群内访问Nginx服务：</h3><p><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/3.png\" alt=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/3.png\"></p>\n<p>看到这里相信很多人会有以下疑问：</p>\n<blockquote>\n<ol>\n<li>每次收到获取podIP太扯了，总不能每次都要手动改程序或者配置才能访问服务吧，要怎么提前知道podIP呢？</li>\n<li>Pod在运行中可能会重建，IP变了怎么解？</li>\n<li>如何在多个Pod中实现负载均衡嘞？</li>\n</ol>\n</blockquote>\n<p>这些问题使用k8s Service就可以解决。</p>\n<h2 id=\"使用Service发现服务\"><a href=\"#使用Service发现服务\" class=\"headerlink\" title=\"使用Service发现服务\"></a>使用Service发现服务</h2><p>下面为两个Nginx Pod创建一个Service。使用nginx-service.yaml文件进行创建，文件内容如下：<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/4.png\" alt=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/4.png\"><br>创建之后，仍需要获取Service的Cluster-IP，再结合Port访问Nginx服务。</p>\n<p>Service可以将pod  IP封装起来，即使Pod发生重建，依然可以通过Service来访问Pod提供的服务。此外，Service还解决了负载均衡的问题，大家可以多访问几次Service，然后通过kubectl logs 来查看两个Nginx Pod的访问日志来确认。</p>\n<h3 id=\"获取IP：\"><a href=\"#获取IP：\" class=\"headerlink\" title=\"获取IP：\"></a>获取IP：</h3><p><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/5.png\" alt=\"\"></p>\n<h3 id=\"在集群内访问Service：\"><a href=\"#在集群内访问Service：\" class=\"headerlink\" title=\"在集群内访问Service：\"></a>在集群内访问Service：</h3><p><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/6.png\" alt=\"\"></p>\n<p>虽然Service解决了Pod的服务发现和负载均衡问题，但存在着类似的问题：不提前知道Service的IP，还是需要改程序或配置啊。看到这里有没有感觉身体被掏空？</p>\n<p>接下来聊聊kube-dns是如何解决上面这个问题的。</p>\n<h2 id=\"使用kube-dns发现服务\"><a href=\"#使用kube-dns发现服务\" class=\"headerlink\" title=\"使用kube-dns发现服务\"></a>使用kube-dns发现服务</h2><p>kube-dns可以解决Service的发现问题，k8s将Service的名称当做域名注册到kube-dns中，通过Service的名称就可以访问其提供的服务。</p>\n<p>可能有人会问如果集群中没有部署kube-dns怎么办？没关系，实际上kube-dns插件只是运行在kube-system命名空间下的Pod，完全可以手动创建它。可以在k8s源码（v1.2）的cluster/addons/dns目录下找到两个模板（skydns-rc.yaml.in和skydns-svc.yaml.in）来创建，为大家准备的完整示例文件会在分享结束后提供获取方式，PPT中只截取了部分内容。</p>\n<p>通过skydns-rc.yaml文件创建kube-dns Pod，其中包含了四个containers，这里开始简单过一下文件的主要部分，稍后做详细介绍。</p>\n<p>第一部分可以看到kube-dns使用了RC来管理Pod，可以提供最基本的故障重启功能。</p>\n<p>创建kube-dns Pod，其中包含了4个containers<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/7.png\" alt=\"\"></p>\n<p>接下来是第一个容器  etcd  ，它的用途是保存DNS规则。<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/8.png\" alt=\"\"></p>\n<p>第二个容器  kube2sky ，作用是写入DNS规则。<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/9.png\" alt=\"\"></p>\n<p>第三个容器是  skydns ，提供DNS解析服务。<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/10.png\" alt=\"\"></p>\n<p>最后一个容器是  healthz ，提供健康检查功能。<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/11.png\" alt=\"\"></p>\n<p>有了Pod之后，还需要创建一个Service以便集群中的其他Pod访问DNS查询服务。通过skydns-svc.yaml创建Service，内容如下：<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/12.png\" alt=\"\"></p>\n<p>创建完kube-dns Pod和Service，并且Pod运行后，便可以访问kube-dns服务。</p>\n<p>下面创建一个Pod，并在该Pod中访问Nginx服务：</p>\n<p>创建之后等待kube-dns处于运行状态<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/13.png\" alt=\"\"></p>\n<p>再新建一个Pod，通过其访问Nginx服务<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/14.png\" alt=\"\"></p>\n<p>在curl-util Pod中通过Service名称访问my-nginx Service：<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/15.png\" alt=\"\"></p>\n<p>只要知道需要的服务名称就可以访问，使用kube-dns发现服务就是那么简单。</p>\n<p>虽然领略了使用kube-dns发现服务的便利性，但相信有很多人也是一头雾水：kube-dns到底怎么工作的？在集群中启用了kube-dns插件，怎么就能通过名称访问Service了呢？</p>\n<h1 id=\"kube-dns原理\"><a href=\"#kube-dns原理\" class=\"headerlink\" title=\"kube-dns原理\"></a>kube-dns原理</h1><h2 id=\"Kube-dns组成\"><a href=\"#Kube-dns组成\" class=\"headerlink\" title=\"Kube-dns组成\"></a>Kube-dns组成</h2><p>之前已经了解到kube-dns是由四个容器组成的，它们扮演的角色可以通过下面这张图来理解。<br><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/kube-dns%E6%9E%B6%E6%9E%84.png\" alt=\"\"></p>\n<p>其中：</p>\n<p>●  SkyDNS是用于服务发现的开源框架，构建于etcd之上。作用是为k8s集群中的Pod提供DNS查询接口。项目托管于<a href=\"https://github.com/skynetservices/skydns\" target=\"_blank\" rel=\"noopener\">https://github.com/skynetservices/skydns</a></p>\n<p>●  etcd是一种开源的分布式key-value存储，其功能与ZooKeeper类似。在kube-dns中的作用为存储SkyDNS需要的各种数据，写入方为kube2sky，读取方为SkyDNS。项目托管于<a href=\"https://github.com/coreos/etcd。\" target=\"_blank\" rel=\"noopener\">https://github.com/coreos/etcd。</a></p>\n<p>●   kube2sky是k8s实现的一个适配程序，它通过名为kubernetes的Service（通过kubectl get svc可以查看到该Service，由集群自动创建）调用k8s的list和watch API来监听k8s Service资源的变更，从而修改etcd中的SkyDNS记录。代码可以在k8s源码（v1.2）的cluster/addons/dns/kube2sky/目录中找到。</p>\n<p>●   exec-healthz是k8s提供的一种辅助容器，多用于side car模式中。它的原理是定期执行指定的Linux指令，从而判断当前Pod中关键容器的健康状态。在kube-dns中的作用就是通过nslookup指令检查DNS查询服务的健康状态，k8s livenessProbe通过访问exec-healthz提供的Http API了解健康状态，并在出现故障时重启容器。其源码位于<a href=\"https://github.com/kubernetes/contrib/tree/master/exec-healthz。\" target=\"_blank\" rel=\"noopener\">https://github.com/kubernetes/contrib/tree/master/exec-healthz。</a></p>\n<p>●  从图中可以发现，Pod查询DNS是通过ServiceName.Namespace子域名来查询的，但在之前的示例中只用了Service名称，什么原理呢？其实当我们只使用Service名称时会默认Namespace为default，而上面示例中的my-nginx Service就是在default Namespace中，因此是可以正常运行的。关于这一点，后续再深入介绍。</p>\n<p>●  skydns-rc.yaml中可以发现livenessProbe是设置在kube2sky容器中的，其意图应该是希望通过重启kube2sky来重新写入DNS规则</p>\n<h2 id=\"域名格式\"><a href=\"#域名格式\" class=\"headerlink\" title=\"域名格式\"></a>域名格式</h2><p>接下来了解一下kube-dns支持的域名格式，具体为：..svc.。</p>\n<p>其中cluster_domain可以使用kubelet的–cluster-domain=SomeDomain参数进行设置，同时也要保证kube2sky容器的启动参数中–domain参数设置了相同的值。通常设置为cluster.local。那么之前示例中的my-nginx Service对应的完整域名就是my-nginx.default.svc.cluster.local。看到这里，相信很多人会有疑问，既然完整域名是这样的，那为什么在Pod中只通过Service名称和Namespace就能访问Service呢？下面来解释其中原因。</p>\n<h1 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h1><h2 id=\"域名解析配置\"><a href=\"#域名解析配置\" class=\"headerlink\" title=\"域名解析配置\"></a>域名解析配置</h2><p>为了在Pod中调用其他Service，kubelet会自动在容器中创建域名解析配置（/etc/resolv.conf），内容为：</p>\n<p><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/16.png\" alt=\"\"></p>\n<p>感兴趣的可以在网上查找一些resolv.conf的资料来了解具体的含义。之所以能够通过Service名称和Namespace就能访问Service，就是因为search配置的规则。在解析域名时会自动拼接成完整域名去查询DNS。</p>\n<p>刚才提到的kubelet –cluster-domain参数与search的具体配置是相对应的。而kube2sky容器的–domain参数影响的是写入到etcd中的域名，kube2sky会获取Service的名称和Namespace，并使用–domain参数拼接完整域名。这也就是让两个参数保持一致的原因。</p>\n<h2 id=\"NS-相关配置\"><a href=\"#NS-相关配置\" class=\"headerlink\" title=\"NS 相关配置\"></a>NS 相关配置</h2><p>kube-dns可以让Pod发现其他Service，那Pod又是如何自动发现kube-dns的呢？在上一节中的/etc/resolv.conf中可以看到nameserver，这个配置就会告诉Pod去哪访问域名解析服务器。</p>\n<p><img src=\"http://blog.tenxcloud.com/wp-content/uploads/2016/10/17.png\" alt=\"\"></p>\n<p>相应的，可以在之前提到的skydns-svc.yaml中看到spec.clusterIP配置了相同的值。通常来说创建一个Service并不需要指定clusterIP，k8s会自动为其分配，但kube-dns比较特殊，需要指定clusterIP使其与/etc/resolv.conf中的nameserver保持一致。</p>\n<p>修改nameserver配置同样需要修改两个地方，一个是kubelet的–cluster-dns参数，另一个就是kube-dns Service的clusterIP。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>接下来重新梳理一下本文的主要内容：</p>\n<blockquote>\n<p>●    在k8s集群中，服务是运行在Pod中的，Pod的发现和副本间负载均衡是我们面临的问题。<br>●    通过Service可以解决这两个问题，但访问Service也需要对应的IP，因此又引入了Service发现的问题。<br>●    得益于kube-dns插件，我们可以通过域名来访问集群内的Service，解决了Service发现的问题。<br>●    为了让Pod中的容器可以使用kube-dns来解析域名，k8s会修改容器的/etc/resolv.conf配置。</p>\n</blockquote>\n<p>有了以上机制的保证，就可以在Pod中通过Service名称和namespace非常方便地访问对应的服务了。</p>"},{"title":"Python笔记","date":"2017-07-05T04:00:00.000Z","toc":true,"_content":"## str类   ##\n<!--more-->\n  \n    class str(basestring):\n      \"\"\"\n      str(object='') -> string\n    \n      Return a nice string representation of the object.\n      If the argument is a string, the return value is the same object.\n      \"\"\"\n      def capitalize(self):  \n\t\t\t\"\"\" 首字母变大写 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.capitalize() -> string\n     \n\t\t\tReturn a copy of the string S with only its first character\n\t\t\tcapitalized.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n      def center(self, width, fillchar=None):  \n\t\t\t\"\"\" 内容居中，width：总长度；fillchar：空白处填充内容，默认无 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.center(width[, fillchar]) -> string\n    \n\t\t\tReturn S centered in a string of length width. Padding is\n\t\t\tdone using the specified fill character (default is a space)\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n      \n      def count(self, sub, start=None, end=None):  \n\t\t\t\"\"\" 子序列个数 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.count(sub[, start[, end]]) -> int\n    \n\t\t\tReturn the number of non-overlapping occurrences of substring sub in\n\t\t\tstring S[start:end].  Optional arguments start and end are interpreted\n\t\t\tas in slice notation.\n\t\t\t\"\"\"\n\t\t\treturn 0\n\t\t\n      def decode(self, encoding=None, errors=None):  \n\t\t\t\"\"\" 解码 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.decode([encoding[,errors]]) -> object\n    \n\t\t\tDecodes S using the codec registered for encoding. encoding defaults\n\t\t\tto the default encoding. errors may be given to set a different error\n\t\t\thandling scheme. Default is 'strict' meaning that encoding errors raise\n\t\t\ta UnicodeDecodeError. Other possible values are 'ignore' and 'replace'\n\t\t\tas well as any other name registered with codecs.register_error that is\n\t\t\table to handle UnicodeDecodeErrors.\n\t\t\t\"\"\"\n\t\t\treturn object()\n    \n      def encode(self, encoding=None, errors=None):  \n\t\t\t\"\"\" 编码，针对unicode \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.encode([encoding[,errors]]) -> object\n    \n\t\t\tEncodes S using the codec registered for encoding. encoding defaults\n\t\t\tto the default encoding. errors may be given to set a different error\n\t\t\thandling scheme. Default is 'strict' meaning that encoding errors raise\n\t\t\ta UnicodeEncodeError. Other possible values are 'ignore', 'replace' and\n\t\t\t'xmlcharrefreplace' as well as any other name registered with\n\t\t\tcodecs.register_error that is able to handle UnicodeEncodeErrors.\n\t\t\t\"\"\"\n\t\t\treturn object()\n    \n\t  def endswith(self, suffix, start=None, end=None):  \n\t\t\t\"\"\" 是否以 xxx 结束 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.endswith(suffix[, start[, end]]) -> bool\n    \n\t\t\tReturn True if S ends with the specified suffix, False otherwise.\n\t\t\tWith optional start, test S beginning at that position.\n\t\t\tWith optional end, stop comparing S at that position.\n\t\t\tsuffix can also be a tuple of strings to try.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n\t   def expandtabs(self, tabsize=None):  \n\t\t\t\"\"\" 将tab转换成空格，默认一个tab转换成8个空格 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.expandtabs([tabsize]) -> string\n    \n\t\t\tReturn a copy of S where all tab characters are expanded using spaces.\n\t\t\tIf tabsize is not given, a tab size of 8 characters is assumed.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def find(self, sub, start=None, end=None):  \n\t\t\t\"\"\" 寻找子序列位置，如果没找到，返回 -1 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.find(sub [,start [,end]]) -> int\n    \n\t\t\tReturn the lowest index in S where substring sub is found,\n\t\t\tsuch that sub is contained within S[start:end].  Optional\n\t\t\targuments start and end are interpreted as in slice notation.\n    \n\t\t\tReturn -1 on failure.\n\t\t\t\"\"\"\n\t\t\treturn 0\n    \n       def format(*args, **kwargs): # known special case of str.format\n\t\t\t\"\"\" 字符串格式化，动态参数，将函数式编程时细说 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.format(*args, **kwargs) -> string\n    \n\t\t\tReturn a formatted version of S, using substitutions from args and kwargs.\n\t\t\tThe substitutions are identified by braces ('{' and '}').\n\t\t\t\"\"\"\n\t\t\tpass\n    \n       def index(self, sub, start=None, end=None):  \n\t\t\t\"\"\" 子序列位置，如果没找到，报错 \"\"\"\n\t\t\tS.index(sub [,start [,end]]) -> int\n    \n\t\t\tLike S.find() but raise ValueError when the substring is not found.\n\t\t\t\"\"\"\n\t\t\treturn 0\n    \n       def isalnum(self):  \n\t\t\t\"\"\" 是否是字母和数字 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.isalnum() -> bool\n    \n\t\t\tReturn True if all characters in S are alphanumeric\n\t\t\tand there is at least one character in S, False otherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def isalpha(self):  \n\t\t\t\"\"\" 是否是字母 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.isalpha() -> bool\n    \n\t\t\tReturn True if all characters in S are alphabetic\n\t\t\tand there is at least one character in S, False otherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def isdigit(self):  \n\t\t\t\"\"\" 是否是数字 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.isdigit() -> bool\n    \n\t\t\tReturn True if all characters in S are digits\n\t\t\tand there is at least one character in S, False otherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def islower(self):  \n\t\t\t\"\"\" 是否小写 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.islower() -> bool\n    \n\t\t\tReturn True if all cased characters in S are lowercase and there is\n\t\t\tat least one cased character in S, False otherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def isspace(self):  \n\t\t\t\"\"\"\n\t\t\tS.isspace() -> bool\n    \n\t\t\tReturn True if all characters in S are whitespace\n\t\t\tand there is at least one character in S, False otherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def istitle(self):  \n\t\t\t\"\"\"\n\t\t\tS.istitle() -> bool\n\t\t\n\t\t\tReturn True if S is a titlecased string and there is at least one\n\t\t\tcharacter in S, i.e. uppercase characters may only follow uncased\n\t\t\tcharacters and lowercase characters only cased ones. Return False\n\t\t\totherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def isupper(self):  \n\t\t\t\"\"\"\n\t\t\tS.isupper() -> bool\n    \n\t\t\tReturn True if all cased characters in S are uppercase and there is\n\t\t\tat least one cased character in S, False otherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def join(self, iterable):  \n\t\t\t\"\"\" 连接 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.join(iterable) -> string\n    \n\t\t\tReturn a string which is the concatenation of the strings in the\n\t\t\titerable.  The separator between elements is S.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def ljust(self, width, fillchar=None):  \n\t\t\t\"\"\" 内容左对齐，右侧填充 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.ljust(width[, fillchar]) -> string\n    \n\t\t\tReturn S left-justified in a string of length width. Padding is\n\t\t\tdone using the specified fill character (default is a space).\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def lower(self):  \n\t\t\t\"\"\" 变小写 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.lower() -> string\n    \n\t\t\tReturn a copy of the string S converted to lowercase.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def lstrip(self, chars=None):  \n\t\t\t\"\"\" 移除左侧空白 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.lstrip([chars]) -> string or unicode\n    \n\t\t\tReturn a copy of the string S with leading whitespace removed.\n\t\t\tIf chars is given and not None, remove characters in chars instead.\n\t\t\tIf chars is unicode, S will be converted to unicode before stripping\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def partition(self, sep):  \n\t\t\t\"\"\" 分割，前，中，后三部分 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.partition(sep) -> (head, sep, tail)\n    \n\t\t\tSearch for the separator sep in S, and return the part before it,\n\t\t\tthe separator itself, and the part after it.  If the separator is not\n\t\t\tfound, return S and two empty strings.\n\t\t\t\"\"\"\n\t\t\tpass\n    \n       def replace(self, old, new, count=None):  \n\t\t\t\"\"\" 替换 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.replace(old, new[, count]) -> string\n    \n\t\t\tReturn a copy of string S with all occurrences of substring\n\t\t\told replaced by new.  If the optional argument count is\n\t\t\tgiven, only the first count occurrences are replaced.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def rfind(self, sub, start=None, end=None):  \n\t\t\t\"\"\"\n\t\t\tS.rfind(sub [,start [,end]]) -> int\n    \n\t\t\tReturn the highest index in S where substring sub is found,\n\t\t\tsuch that sub is contained within S[start:end].  Optional\n\t\t\targuments start and end are interpreted as in slice notation.\n    \n\t\t\tReturn -1 on failure.\n\t\t\t\"\"\"\n\t\t\treturn 0\n    \n       def rindex(self, sub, start=None, end=None):  \n\t\t\t\"\"\"\n\t\t\tS.rindex(sub [,start [,end]]) -> int\n    \n\t\t\tLike S.rfind() but raise ValueError when the substring is not found.\n\t\t\t\"\"\"\n\t\t\treturn 0\n    \n       def rjust(self, width, fillchar=None):  \n\t\t\t\"\"\"\n\t\t\tS.rjust(width[, fillchar]) -> string\n    \n\t\t\tReturn S right-justified in a string of length width. Padding is\n\t\t\tdone using the specified fill character (default is a space)\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def rpartition(self, sep):  \n\t\t\t\"\"\"\n\t\t\tS.rpartition(sep) -> (head, sep, tail)\n    \n\t\t\tSearch for the separator sep in S, starting at the end of S, and return\n\t\t\tthe part before it, the separator itself, and the part after it.  If the\n\t\t\tseparator is not found, return two empty strings and S.\n\t\t\t\"\"\"\n\t\t\tpass\n    \n       def rsplit(self, sep=None, maxsplit=None):  \n\t\t\t\"\"\"\n\t\t\tS.rsplit([sep [,maxsplit]]) -> list of strings\n    \n\t\t\tReturn a list of the words in the string S, using sep as the\n\t\t\tdelimiter string, starting at the end of the string and working\n\t\t\tto the front.  If maxsplit is given, at most maxsplit splits are\n\t\t\tdone. If sep is not specified or is None, any whitespace string\n\t\t\tis a separator.\n\t\t\t\"\"\"\n\t\t\treturn []\n    \n       def rstrip(self, chars=None):  \n\t\t\t\"\"\"\n\t\t\tS.rstrip([chars]) -> string or unicode\n    \n\t\t\tReturn a copy of the string S with trailing whitespace removed.\n\t\t\tIf chars is given and not None, remove characters in chars instead.\n\t\t\tIf chars is unicode, S will be converted to unicode before stripping\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def split(self, sep=None, maxsplit=None):  \n\t\t\t\"\"\" 分割， maxsplit最多分割几次 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.split([sep [,maxsplit]]) -> list of strings\n    \n\t\t\tReturn a list of the words in the string S, using sep as the\n\t\t\tdelimiter string.  If maxsplit is given, at most maxsplit\n\t\t\tsplits are done. If sep is not specified or is None, any\n\t\t\twhitespace string is a separator and empty strings are removed\n\t\t\tfrom the result.\n\t\t\t\"\"\"\n\t\t\treturn []\n    \n       def splitlines(self, keepends=False):  \n\t\t\t\"\"\" 根据换行分割 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.splitlines(keepends=False) -> list of strings\n    \n\t\t\tReturn a list of the lines in S, breaking at line boundaries.\n\t\t\tLine breaks are not included in the resulting list unless keepends\n\t\t\tis given and true.\n\t\t\t\"\"\"\n\t\t\treturn []\n    \n       def startswith(self, prefix, start=None, end=None):  \n\t\t\t\"\"\" 是否起始 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.startswith(prefix[, start[, end]]) -> bool\n    \n\t\t\tReturn True if S starts with the specified prefix, False otherwise.\n\t\t\tWith optional start, test S beginning at that position.\n\t\t\tWith optional end, stop comparing S at that position.\n\t\t\tprefix can also be a tuple of strings to try.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def strip(self, chars=None):  \n\t\t\t\"\"\" 移除两段空白 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.strip([chars]) -> string or unicode\n    \n\t\t\tReturn a copy of the string S with leading and trailing\n\t\t\twhitespace removed.\n\t\t\tIf chars is given and not None, remove characters in chars instead.\n\t\t\tIf chars is unicode, S will be converted to unicode before stripping\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def swapcase(self):  \n\t\t\t\"\"\" 大写变小写，小写变大写 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.swapcase() -> string\n    \n\t\t\tReturn a copy of the string S with uppercase characters\n\t\t\tconverted to lowercase and vice versa.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def title(self):  \n\t\t\t\"\"\"\n\t\t\tS.title() -> string\n\t\t\n\t\t\tReturn a titlecased version of S, i.e. words start with uppercase\n\t\t\tcharacters, all remaining cased characters have lowercase.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def translate(self, table, deletechars=None):  \n\t\t\t\"\"\"\n\t\t\t转换，需要先做一个对应表，最后一个表示删除字符集合\n\t\t\tintab = \"aeiou\"\n\t\t\touttab = \"12345\"\n\t\t\ttrantab = maketrans(intab, outtab)\n\t\t\tstr = \"this is string example....wow!!!\"\n\t\t\tprint str.translate(trantab, 'xm')\n\t\t\t\"\"\"\n    \n\t\t\t\"\"\"\n\t\t\tS.translate(table [,deletechars]) -> string\n    \n\t\t\tReturn a copy of the string S, where all characters occurring\n\t\t\tin the optional argument deletechars are removed, and the\n\t\t\tremaining characters have been mapped through the given\n\t\t\ttranslation table, which must be a string of length 256 or None.\n\t\t\tIf the table argument is None, no translation is applied and\n\t\t\tthe operation simply removes the characters in deletechars.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def upper(self):  \n\t\t\t\"\"\"\n\t\t\tS.upper() -> string\n    \n\t\t\tReturn a copy of the string S converted to uppercase.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def zfill(self, width):  \n\t\t\t\"\"\"方法返回指定长度的字符串，原字符串右对齐，前面填充0。\"\"\"\n\t\t\t\"\"\"\n\t\t\tS.zfill(width) -> string\n    \n\t\t\tPad a numeric string S with zeros on the left, to fill a field\n\t\t\tof the specified width.  The string S is never truncated.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def _formatter_field_name_split(self, *args, **kwargs): # real signature unknown\n\t\t\tpass\n    \n\t   def _formatter_parser(self, *args, **kwargs): # real signature unknown\n\t\t\tpass\n    \n       def __add__(self, y):  \n\t\t\t\"\"\" x.__add__(y) <==> x+y \"\"\"\n\t\t\tpass\n    \n       def __contains__(self, y):  \n\t\t\t\"\"\" x.__contains__(y) <==> y in x \"\"\"\n\t\t\tpass\n    \n       def __eq__(self, y):  \n\t\t\t\"\"\" x.__eq__(y) <==> x==y \"\"\"\n\t\t\tpass\n    \n       def __format__(self, format_spec):  \n\t\t\t\"\"\"\n\t\t\tS.__format__(format_spec) -> string\n    \n\t\t\tReturn a formatted version of S as described by format_spec.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def __getattribute__(self, name):  \n\t\t\t\"\"\" x.__getattribute__('name') <==> x.name \"\"\"\n\t\t\tpass\n    \n       def __getitem__(self, y):  \n\t\t\t\"\"\" x.__getitem__(y) <==> x[y] \"\"\"\n\t\t\tpass\n    \n       def __getnewargs__(self, *args, **kwargs): # real signature unknown\n\t\t\tpass\n    \n\t   def __getslice__(self, i, j):  \n\t\t\t\"\"\"\n\t\t\tx.__getslice__(i, j) <==> x[i:j]\n       \n\t\t\tUse of negative indices is not supported.\n\t\t\t\"\"\"\n\t\t\tpass\n    \n       def __ge__(self, y):  \n\t\t\t\"\"\" x.__ge__(y) <==> x>=y \"\"\"\n\t\t\tpass\n    \n\t   def __gt__(self, y):  \n\t\t\t\"\"\" x.__gt__(y) <==> x>y \"\"\"\n\t\t\tpass\n    \n\t   def __hash__(self):  \n\t\t\t\"\"\" x.__hash__() <==> hash(x) \"\"\"\n\t\t\tpass\n    \n       def __init__(self, string=''): # known special case of str.__init__\n\t\t\t\"\"\"\n\t\t\tstr(object='') -> string\n    \n\t\t\tReturn a nice string representation of the object.\n\t\t\tIf the argument is a string, the return value is the same object.\n\t\t\t# (copied from class doc)\n\t\t\t\"\"\"\n\t\t\tpass\n    \n       def __len__(self):  \n\t\t\t\"\"\" x.__len__() <==> len(x) \"\"\"\n\t\t\tpass\n    \n       def __le__(self, y):  \n\t\t\t\"\"\" x.__le__(y) <==> x<=y \"\"\"\n\t\t\tpass\n    \n       def __lt__(self, y):  \n\t\t\t\"\"\" x.__lt__(y) <==> x<y \"\"\"\n\t\t\tpass\n    \n       def __mod__(self, y):  \n\t\t\t\"\"\" x.__mod__(y) <==> x%y \"\"\"\n\t\t\tpass\n    \n       def __mul__(self, n):  \n\t\t\t\"\"\" x.__mul__(n) <==> x*n \"\"\"\n\t\t\tpass\n    \n\t\t\t@staticmethod # known case of __new__\n\t   def __new__(S, *more):  \n\t\t\t\"\"\" T.__new__(S, ...) -> a new object with type S, a subtype of T \"\"\"\n\t\t\tpass\n    \n       def __ne__(self, y):  \n\t\t\t\"\"\" x.__ne__(y) <==> x!=y \"\"\"\n\t\t\tpass\n    \n       def __repr__(self):  \n\t\t\t\"\"\" x.__repr__() <==> repr(x) \"\"\"\n\t\t\tpass\n    \n       def __rmod__(self, y):  \n\t\t\t\"\"\" x.__rmod__(y) <==> y%x \"\"\"\n\t\t\tpass\n    \n       def __rmul__(self, n):  \n\t\t\t\"\"\" x.__rmul__(n) <==> n*x \"\"\"\n\t\t\tpass\n    \n       def __sizeof__(self):  \n\t\t\t\"\"\" S.__sizeof__() -> size of S in memory, in bytes \"\"\"\n\t\t\tpass\n    \n       def __str__(self):  \n\t\t\t\"\"\" x.__str__() <==> str(x) \"\"\"\n\t\t\tpass\n\n\n\n## int数字    ## \n    \n    class int(object):\n\t\t\"\"\"\n\t \t int(x=0) -> int or long\n\t\t int(x, base=10) -> int or long\n    \n\t\t Convert a number or string to an integer, or return 0 if no arguments\n\t\t are given.  If x is floating point, the conversion truncates towards zero.\n\t\t If x is outside the integer range, the function returns a long instead.\n    \n\t\t If x is not a number or if base is given, then x must be a string or\n\t\t Unicode object representing an integer literal in the given base.  The\n\t\t literal can be preceded by '+' or '-' and be surrounded by whitespace.\n\t\t The base defaults to 10.  Valid bases are 0 and 2-36.  Base 0 means to\n\t\t interpret the base from the string as an integer literal.\n\t\t >>> int('0b100', base=0)\n\t\t 4\n\t\t\"\"\"\n\t   def bit_length(self): \n\t\t\t\"\"\" 返回表示该数字的时占用的最少位数 \"\"\"\n\t\t\t\"\"\"\n\t\t\tint.bit_length() -> int\n        \n\t\t\tNumber of bits necessary to represent self in binary.\n\t\t\t>>> bin(37)\n\t\t\t'0b100101'\n\t\t\t>>> (37).bit_length()\n\t\t\t6\n\t\t\t\"\"\"\n\t\t\treturn 0\n\n       def conjugate(self, *args, **kwargs): # real signature unknown\n\t\t\t\"\"\" 返回该复数的共轭复数 \"\"\"\n\t\t\t\"\"\" Returns self, the complex conjugate of any int. \"\"\"\n\t\t\tpass\n\n       def __abs__(self):\n\t\t\t\"\"\" 返回绝对值 \"\"\"\n\t\t\t\"\"\" x.__abs__() <==> abs(x) \"\"\"\n\t\t\tpass\n\n       def __add__(self, y):\n\t\t\t\"\"\" x.__add__(y) <==> x+y \"\"\"\n\t\t\tpass\n\n       def __and__(self, y):\n\t\t\t\"\"\" x.__and__(y) <==> x&y \"\"\"\n\t\t\tpass\n\n       def __cmp__(self, y): \n\t\t\t\"\"\" 比较两个数大小 \"\"\"\n\t\t\t\"\"\" x.__cmp__(y) <==> cmp(x,y) \"\"\"\n\t\t\tpass\n\n       def __coerce__(self, y):\n\t\t\t\"\"\" 强制生成一个元组 \"\"\" \n\t\t\t\"\"\" x.__coerce__(y) <==> coerce(x, y) \"\"\"\n\t\t\tpass\n\n       def __divmod__(self, y): \n\t\t\t\"\"\" 相除，得到商和余数组成的元组 \"\"\" \n\t\t\t\"\"\" x.__divmod__(y) <==> divmod(x, y) \"\"\"\n\t\t\tpass\n\n       def __div__(self, y): \n\t\t\t\"\"\" x.__div__(y) <==> x/y \"\"\"\n\t\t\tpass\n\n       def __float__(self): \n\t\t\t\"\"\" 转换为浮点类型 \"\"\" \n\t\t\t\"\"\" x.__float__() <==> float(x) \"\"\"\n\t\t\tpass\n\n       def __floordiv__(self, y): \n\t\t\t\"\"\" x.__floordiv__(y) <==> x//y \"\"\"\n\t\t\tpass\n\n       def __format__(self, *args, **kwargs): # real signature unknown\n\t\t\tpass\n\n       def __getattribute__(self, name): \n\t\t\t\"\"\" x.__getattribute__('name') <==> x.name \"\"\"\n\t\t\tpass\n\n       def __getnewargs__(self, *args, **kwargs): # real signature unknown\n\t\t\t\"\"\" 内部调用 __new__方法或创建对象时传入参数使用 \"\"\" \n\t\t\tpass\n\n       def __hash__(self): \n\t\t\t\"\"\"如果对象object为哈希表类型，返回对象object的哈希值。哈希值为整数。在字典查找中，哈希值用于快速比较字典的键。两个数值如果相等，则哈希值也相等。\"\"\"\n\t\t\t\"\"\" x.__hash__() <==> hash(x) \"\"\"\n\t\t\tpass\n\n       def __hex__(self): \n\t\t\t\"\"\" 返回当前数的 十六进制 表示 \"\"\" \n\t\t\t\"\"\" x.__hex__() <==> hex(x) \"\"\"\n\t\t\tpass\n\n\t   def __index__(self): \n\t\t\t\"\"\" 用于切片，数字无意义 \"\"\"\n\t\t\t\"\"\" x[y:z] <==> x[y.__index__():z.__index__()] \"\"\"\n\t\t\tpass\n\n\t   def __init__(self, x, base=10): # known special case of int.__init__\n\t\t\t\"\"\" 构造方法，执行 x = 123 或 x = int(10) 时，自动调用，暂时忽略 \"\"\" \n\t\t\t\"\"\"\n\t\t\tint(x=0) -> int or long\n\t\t\tint(x, base=10) -> int or long\n        \n\t\t\tConvert a number or string to an integer, or return 0 if no arguments\n\t\t\tare given.  If x is floating point, the conversion truncates towards zero.\n\t\t\tIf x is outside the integer range, the function returns a long instead.\n        \n\t\t\tIf x is not a number or if base is given, then x must be a string or\n\t\t\tUnicode object representing an integer literal in the given base.  The\n\t\t\tliteral can be preceded by '+' or '-' and be surrounded by whitespace.\n\t\t\tThe base defaults to 10.  Valid bases are 0 and 2-36.  Base 0 means to\n\t\t\tinterpret the base from the string as an integer literal.\n\t\t\t>>> int('0b100', base=0)\n\t\t\t4\n\t\t\t# (copied from class doc)\n\t\t\t\"\"\"\n\t\t\tpass\n\n       def __int__(self): \n\t\t\t\"\"\" 转换为整数 \"\"\" \n\t\t\t\"\"\" x.__int__() <==> int(x) \"\"\"\n\t\t\tpass\n\n       def __invert__(self): \n\t\t\t\"\"\" x.__invert__() <==> ~x \"\"\"\n\t\t\tpass\n\n       def __long__(self): \n\t\t\t\"\"\" 转换为长整数 \"\"\" \n\t\t\t\"\"\" x.__long__() <==> long(x) \"\"\"\n\t\t\tpass\n\n       def __lshift__(self, y): \n\t\t\t\"\"\" x.__lshift__(y) <==> x<<y \"\"\"\n        pass\n\n       def __mod__(self, y): \n\t\t\t\"\"\" x.__mod__(y) <==> x%y \"\"\"\n\t\t\tpass\n\n       def __mul__(self, y): \n\t\t\t\"\"\" x.__mul__(y) <==> x*y \"\"\"\n\t\t\tpass\n\n       def __neg__(self): \n\t\t\t\"\"\" x.__neg__() <==> -x \"\"\"\n\t\t\tpass\n\n\t\t\t@staticmethod # known case of __new__\n\t   def __new__(S, *more): \n\t\t\t\"\"\" T.__new__(S, ...) -> a new object with type S, a subtype of T \"\"\"\n\t\t\tpass\n\n       def __nonzero__(self): \n\t\t\t\"\"\" x.__nonzero__() <==> x != 0 \"\"\"\n\t\t\tpass\n\n       def __oct__(self): \n\t\t\t\"\"\" 返回改值的 八进制 表示 \"\"\" \n\t\t\t\"\"\" x.__oct__() <==> oct(x) \"\"\"\n\t\t\tpass\n\n       def __or__(self, y): \n\t\t\t\"\"\" x.__or__(y) <==> x|y \"\"\"\n\t\t\tpass\n\n       def __pos__(self): \n\t\t\t\"\"\" x.__pos__() <==> +x \"\"\"\n\t\t\tpass\n\n       def __pow__(self, y, z=None): \n\t\t\t\"\"\" 幂，次方 \"\"\" \n\t\t\t\"\"\" x.__pow__(y[, z]) <==> pow(x, y[, z]) \"\"\"\n\t\t\tpass\n\n       def __radd__(self, y): \n\t\t\t\"\"\" x.__radd__(y) <==> y+x \"\"\"\n\t\t\tpass\n\n       def __rand__(self, y): \n\t\t\t\"\"\" x.__rand__(y) <==> y&x \"\"\"\n\t\t\tpass\n\n       def __rdivmod__(self, y): \n\t\t\t\"\"\" x.__rdivmod__(y) <==> divmod(y, x) \"\"\"\n\t\t\tpass\n\n       def __rdiv__(self, y): \n\t\t\t\"\"\" x.__rdiv__(y) <==> y/x \"\"\"\n\t\t\tpass\n\n       def __repr__(self): \n\t\t\t\"\"\"转化为解释器可读取的形式 \"\"\"\n\t\t\t\"\"\" x.__repr__() <==> repr(x) \"\"\"\n\t\t\tpass\n\n       def __str__(self): \n\t\t\t\"\"\"转换为人阅读的形式，如果没有适于人阅读的解释形式的话，则返回解释器课阅读的形式\"\"\"\n\t\t\t\"\"\" x.__str__() <==> str(x) \"\"\"\n\t\t\tpass\n\n       def __rfloordiv__(self, y): \n\t\t\t\"\"\" x.__rfloordiv__(y) <==> y//x \"\"\"\n\t\t\tpass\n\n       def __rlshift__(self, y): \n\t\t\t\"\"\" x.__rlshift__(y) <==> y<<x \"\"\"\n\t\t\tpass\n\n       def __rmod__(self, y): \n\t\t\t\"\"\" x.__rmod__(y) <==> y%x \"\"\"\n\t\t\tpass\n\n       def __rmul__(self, y): \n\t\t\t\"\"\" x.__rmul__(y) <==> y*x \"\"\"\n\t\t\tpass\n\n       def __ror__(self, y): \n\t\t\t\"\"\" x.__ror__(y) <==> y|x \"\"\"\n\t\t\tpass\n\n       def __rpow__(self, x, z=None): \n\t\t\t\"\"\" y.__rpow__(x[, z]) <==> pow(x, y[, z]) \"\"\"\n\t\t\tpass\n\n       def __rrshift__(self, y): \n\t\t\t\"\"\" x.__rrshift__(y) <==> y>>x \"\"\"\n\t\t\tpass\n\n       def __rshift__(self, y): \n\t\t\t\"\"\" x.__rshift__(y) <==> x>>y \"\"\"\n\t\t\tpass\n\n       def __rsub__(self, y): \n\t\t\t\"\"\" x.__rsub__(y) <==> y-x \"\"\"\n\t\t\tpass\n\n       def __rtruediv__(self, y): \n\t\t\t\"\"\" x.__rtruediv__(y) <==> y/x \"\"\"\n\t\t\tpass\n\n       def __rxor__(self, y): \n\t\t\t\"\"\" x.__rxor__(y) <==> y^x \"\"\"\n\t\t\tpass\n\n       def __sub__(self, y): \n\t\t\t\"\"\" x.__sub__(y) <==> x-y \"\"\"\n\t\t\tpass\n\n       def __truediv__(self, y): \n\t\t\t\"\"\" x.__truediv__(y) <==> x/y \"\"\"\n\t\t\tpass\n\n       def __trunc__(self, *args, **kwargs): \n\t\t\t\"\"\" 返回数值被截取为整形的值，在整形中无意义 \"\"\"\n\t\t\tpass\n\n       def __xor__(self, y): \n\t\t\t\"\"\" x.__xor__(y) <==> x^y \"\"\"\n\t\t\tpass\n\n\t\t\tdenominator = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n\t\t\t\"\"\" 分母 = 1 \"\"\"\n\t\t\t\"\"\"the denominator of a rational number in lowest terms\"\"\"\n\n\t\t\timag = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n\t\t\t\"\"\" 虚数，无意义 \"\"\"\n\t\t\t\"\"\"the imaginary part of a complex number\"\"\"\n\n\t\t\tnumerator = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n\t\t\t\"\"\" 分子 = 数字大小 \"\"\"\n\t\t\t\"\"\"the numerator of a rational number in lowest terms\"\"\"\n\n\t\t\treal = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n\t\t\t\"\"\" 实属，无意义 \"\"\"\n\t\t\t\"\"\"the real part of a complex number\"\"\"\n","source":"_posts/Python(基础数据类型)详解.md","raw":"---\ntitle: Python笔记\ndate: 2017-07-05\ntags: python\ncategories: python\ntoc: true\n---\n## str类   ##\n<!--more-->\n  \n    class str(basestring):\n      \"\"\"\n      str(object='') -> string\n    \n      Return a nice string representation of the object.\n      If the argument is a string, the return value is the same object.\n      \"\"\"\n      def capitalize(self):  \n\t\t\t\"\"\" 首字母变大写 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.capitalize() -> string\n     \n\t\t\tReturn a copy of the string S with only its first character\n\t\t\tcapitalized.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n      def center(self, width, fillchar=None):  \n\t\t\t\"\"\" 内容居中，width：总长度；fillchar：空白处填充内容，默认无 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.center(width[, fillchar]) -> string\n    \n\t\t\tReturn S centered in a string of length width. Padding is\n\t\t\tdone using the specified fill character (default is a space)\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n      \n      def count(self, sub, start=None, end=None):  \n\t\t\t\"\"\" 子序列个数 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.count(sub[, start[, end]]) -> int\n    \n\t\t\tReturn the number of non-overlapping occurrences of substring sub in\n\t\t\tstring S[start:end].  Optional arguments start and end are interpreted\n\t\t\tas in slice notation.\n\t\t\t\"\"\"\n\t\t\treturn 0\n\t\t\n      def decode(self, encoding=None, errors=None):  \n\t\t\t\"\"\" 解码 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.decode([encoding[,errors]]) -> object\n    \n\t\t\tDecodes S using the codec registered for encoding. encoding defaults\n\t\t\tto the default encoding. errors may be given to set a different error\n\t\t\thandling scheme. Default is 'strict' meaning that encoding errors raise\n\t\t\ta UnicodeDecodeError. Other possible values are 'ignore' and 'replace'\n\t\t\tas well as any other name registered with codecs.register_error that is\n\t\t\table to handle UnicodeDecodeErrors.\n\t\t\t\"\"\"\n\t\t\treturn object()\n    \n      def encode(self, encoding=None, errors=None):  \n\t\t\t\"\"\" 编码，针对unicode \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.encode([encoding[,errors]]) -> object\n    \n\t\t\tEncodes S using the codec registered for encoding. encoding defaults\n\t\t\tto the default encoding. errors may be given to set a different error\n\t\t\thandling scheme. Default is 'strict' meaning that encoding errors raise\n\t\t\ta UnicodeEncodeError. Other possible values are 'ignore', 'replace' and\n\t\t\t'xmlcharrefreplace' as well as any other name registered with\n\t\t\tcodecs.register_error that is able to handle UnicodeEncodeErrors.\n\t\t\t\"\"\"\n\t\t\treturn object()\n    \n\t  def endswith(self, suffix, start=None, end=None):  \n\t\t\t\"\"\" 是否以 xxx 结束 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.endswith(suffix[, start[, end]]) -> bool\n    \n\t\t\tReturn True if S ends with the specified suffix, False otherwise.\n\t\t\tWith optional start, test S beginning at that position.\n\t\t\tWith optional end, stop comparing S at that position.\n\t\t\tsuffix can also be a tuple of strings to try.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n\t   def expandtabs(self, tabsize=None):  \n\t\t\t\"\"\" 将tab转换成空格，默认一个tab转换成8个空格 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.expandtabs([tabsize]) -> string\n    \n\t\t\tReturn a copy of S where all tab characters are expanded using spaces.\n\t\t\tIf tabsize is not given, a tab size of 8 characters is assumed.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def find(self, sub, start=None, end=None):  \n\t\t\t\"\"\" 寻找子序列位置，如果没找到，返回 -1 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.find(sub [,start [,end]]) -> int\n    \n\t\t\tReturn the lowest index in S where substring sub is found,\n\t\t\tsuch that sub is contained within S[start:end].  Optional\n\t\t\targuments start and end are interpreted as in slice notation.\n    \n\t\t\tReturn -1 on failure.\n\t\t\t\"\"\"\n\t\t\treturn 0\n    \n       def format(*args, **kwargs): # known special case of str.format\n\t\t\t\"\"\" 字符串格式化，动态参数，将函数式编程时细说 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.format(*args, **kwargs) -> string\n    \n\t\t\tReturn a formatted version of S, using substitutions from args and kwargs.\n\t\t\tThe substitutions are identified by braces ('{' and '}').\n\t\t\t\"\"\"\n\t\t\tpass\n    \n       def index(self, sub, start=None, end=None):  \n\t\t\t\"\"\" 子序列位置，如果没找到，报错 \"\"\"\n\t\t\tS.index(sub [,start [,end]]) -> int\n    \n\t\t\tLike S.find() but raise ValueError when the substring is not found.\n\t\t\t\"\"\"\n\t\t\treturn 0\n    \n       def isalnum(self):  \n\t\t\t\"\"\" 是否是字母和数字 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.isalnum() -> bool\n    \n\t\t\tReturn True if all characters in S are alphanumeric\n\t\t\tand there is at least one character in S, False otherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def isalpha(self):  \n\t\t\t\"\"\" 是否是字母 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.isalpha() -> bool\n    \n\t\t\tReturn True if all characters in S are alphabetic\n\t\t\tand there is at least one character in S, False otherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def isdigit(self):  \n\t\t\t\"\"\" 是否是数字 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.isdigit() -> bool\n    \n\t\t\tReturn True if all characters in S are digits\n\t\t\tand there is at least one character in S, False otherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def islower(self):  \n\t\t\t\"\"\" 是否小写 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.islower() -> bool\n    \n\t\t\tReturn True if all cased characters in S are lowercase and there is\n\t\t\tat least one cased character in S, False otherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def isspace(self):  \n\t\t\t\"\"\"\n\t\t\tS.isspace() -> bool\n    \n\t\t\tReturn True if all characters in S are whitespace\n\t\t\tand there is at least one character in S, False otherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def istitle(self):  \n\t\t\t\"\"\"\n\t\t\tS.istitle() -> bool\n\t\t\n\t\t\tReturn True if S is a titlecased string and there is at least one\n\t\t\tcharacter in S, i.e. uppercase characters may only follow uncased\n\t\t\tcharacters and lowercase characters only cased ones. Return False\n\t\t\totherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def isupper(self):  \n\t\t\t\"\"\"\n\t\t\tS.isupper() -> bool\n    \n\t\t\tReturn True if all cased characters in S are uppercase and there is\n\t\t\tat least one cased character in S, False otherwise.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def join(self, iterable):  \n\t\t\t\"\"\" 连接 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.join(iterable) -> string\n    \n\t\t\tReturn a string which is the concatenation of the strings in the\n\t\t\titerable.  The separator between elements is S.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def ljust(self, width, fillchar=None):  \n\t\t\t\"\"\" 内容左对齐，右侧填充 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.ljust(width[, fillchar]) -> string\n    \n\t\t\tReturn S left-justified in a string of length width. Padding is\n\t\t\tdone using the specified fill character (default is a space).\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def lower(self):  \n\t\t\t\"\"\" 变小写 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.lower() -> string\n    \n\t\t\tReturn a copy of the string S converted to lowercase.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def lstrip(self, chars=None):  \n\t\t\t\"\"\" 移除左侧空白 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.lstrip([chars]) -> string or unicode\n    \n\t\t\tReturn a copy of the string S with leading whitespace removed.\n\t\t\tIf chars is given and not None, remove characters in chars instead.\n\t\t\tIf chars is unicode, S will be converted to unicode before stripping\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def partition(self, sep):  \n\t\t\t\"\"\" 分割，前，中，后三部分 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.partition(sep) -> (head, sep, tail)\n    \n\t\t\tSearch for the separator sep in S, and return the part before it,\n\t\t\tthe separator itself, and the part after it.  If the separator is not\n\t\t\tfound, return S and two empty strings.\n\t\t\t\"\"\"\n\t\t\tpass\n    \n       def replace(self, old, new, count=None):  \n\t\t\t\"\"\" 替换 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.replace(old, new[, count]) -> string\n    \n\t\t\tReturn a copy of string S with all occurrences of substring\n\t\t\told replaced by new.  If the optional argument count is\n\t\t\tgiven, only the first count occurrences are replaced.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def rfind(self, sub, start=None, end=None):  \n\t\t\t\"\"\"\n\t\t\tS.rfind(sub [,start [,end]]) -> int\n    \n\t\t\tReturn the highest index in S where substring sub is found,\n\t\t\tsuch that sub is contained within S[start:end].  Optional\n\t\t\targuments start and end are interpreted as in slice notation.\n    \n\t\t\tReturn -1 on failure.\n\t\t\t\"\"\"\n\t\t\treturn 0\n    \n       def rindex(self, sub, start=None, end=None):  \n\t\t\t\"\"\"\n\t\t\tS.rindex(sub [,start [,end]]) -> int\n    \n\t\t\tLike S.rfind() but raise ValueError when the substring is not found.\n\t\t\t\"\"\"\n\t\t\treturn 0\n    \n       def rjust(self, width, fillchar=None):  \n\t\t\t\"\"\"\n\t\t\tS.rjust(width[, fillchar]) -> string\n    \n\t\t\tReturn S right-justified in a string of length width. Padding is\n\t\t\tdone using the specified fill character (default is a space)\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def rpartition(self, sep):  \n\t\t\t\"\"\"\n\t\t\tS.rpartition(sep) -> (head, sep, tail)\n    \n\t\t\tSearch for the separator sep in S, starting at the end of S, and return\n\t\t\tthe part before it, the separator itself, and the part after it.  If the\n\t\t\tseparator is not found, return two empty strings and S.\n\t\t\t\"\"\"\n\t\t\tpass\n    \n       def rsplit(self, sep=None, maxsplit=None):  \n\t\t\t\"\"\"\n\t\t\tS.rsplit([sep [,maxsplit]]) -> list of strings\n    \n\t\t\tReturn a list of the words in the string S, using sep as the\n\t\t\tdelimiter string, starting at the end of the string and working\n\t\t\tto the front.  If maxsplit is given, at most maxsplit splits are\n\t\t\tdone. If sep is not specified or is None, any whitespace string\n\t\t\tis a separator.\n\t\t\t\"\"\"\n\t\t\treturn []\n    \n       def rstrip(self, chars=None):  \n\t\t\t\"\"\"\n\t\t\tS.rstrip([chars]) -> string or unicode\n    \n\t\t\tReturn a copy of the string S with trailing whitespace removed.\n\t\t\tIf chars is given and not None, remove characters in chars instead.\n\t\t\tIf chars is unicode, S will be converted to unicode before stripping\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def split(self, sep=None, maxsplit=None):  \n\t\t\t\"\"\" 分割， maxsplit最多分割几次 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.split([sep [,maxsplit]]) -> list of strings\n    \n\t\t\tReturn a list of the words in the string S, using sep as the\n\t\t\tdelimiter string.  If maxsplit is given, at most maxsplit\n\t\t\tsplits are done. If sep is not specified or is None, any\n\t\t\twhitespace string is a separator and empty strings are removed\n\t\t\tfrom the result.\n\t\t\t\"\"\"\n\t\t\treturn []\n    \n       def splitlines(self, keepends=False):  \n\t\t\t\"\"\" 根据换行分割 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.splitlines(keepends=False) -> list of strings\n    \n\t\t\tReturn a list of the lines in S, breaking at line boundaries.\n\t\t\tLine breaks are not included in the resulting list unless keepends\n\t\t\tis given and true.\n\t\t\t\"\"\"\n\t\t\treturn []\n    \n       def startswith(self, prefix, start=None, end=None):  \n\t\t\t\"\"\" 是否起始 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.startswith(prefix[, start[, end]]) -> bool\n    \n\t\t\tReturn True if S starts with the specified prefix, False otherwise.\n\t\t\tWith optional start, test S beginning at that position.\n\t\t\tWith optional end, stop comparing S at that position.\n\t\t\tprefix can also be a tuple of strings to try.\n\t\t\t\"\"\"\n\t\t\treturn False\n    \n       def strip(self, chars=None):  \n\t\t\t\"\"\" 移除两段空白 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.strip([chars]) -> string or unicode\n    \n\t\t\tReturn a copy of the string S with leading and trailing\n\t\t\twhitespace removed.\n\t\t\tIf chars is given and not None, remove characters in chars instead.\n\t\t\tIf chars is unicode, S will be converted to unicode before stripping\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def swapcase(self):  \n\t\t\t\"\"\" 大写变小写，小写变大写 \"\"\"\n\t\t\t\"\"\"\n\t\t\tS.swapcase() -> string\n    \n\t\t\tReturn a copy of the string S with uppercase characters\n\t\t\tconverted to lowercase and vice versa.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def title(self):  \n\t\t\t\"\"\"\n\t\t\tS.title() -> string\n\t\t\n\t\t\tReturn a titlecased version of S, i.e. words start with uppercase\n\t\t\tcharacters, all remaining cased characters have lowercase.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def translate(self, table, deletechars=None):  \n\t\t\t\"\"\"\n\t\t\t转换，需要先做一个对应表，最后一个表示删除字符集合\n\t\t\tintab = \"aeiou\"\n\t\t\touttab = \"12345\"\n\t\t\ttrantab = maketrans(intab, outtab)\n\t\t\tstr = \"this is string example....wow!!!\"\n\t\t\tprint str.translate(trantab, 'xm')\n\t\t\t\"\"\"\n    \n\t\t\t\"\"\"\n\t\t\tS.translate(table [,deletechars]) -> string\n    \n\t\t\tReturn a copy of the string S, where all characters occurring\n\t\t\tin the optional argument deletechars are removed, and the\n\t\t\tremaining characters have been mapped through the given\n\t\t\ttranslation table, which must be a string of length 256 or None.\n\t\t\tIf the table argument is None, no translation is applied and\n\t\t\tthe operation simply removes the characters in deletechars.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def upper(self):  \n\t\t\t\"\"\"\n\t\t\tS.upper() -> string\n    \n\t\t\tReturn a copy of the string S converted to uppercase.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def zfill(self, width):  \n\t\t\t\"\"\"方法返回指定长度的字符串，原字符串右对齐，前面填充0。\"\"\"\n\t\t\t\"\"\"\n\t\t\tS.zfill(width) -> string\n    \n\t\t\tPad a numeric string S with zeros on the left, to fill a field\n\t\t\tof the specified width.  The string S is never truncated.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def _formatter_field_name_split(self, *args, **kwargs): # real signature unknown\n\t\t\tpass\n    \n\t   def _formatter_parser(self, *args, **kwargs): # real signature unknown\n\t\t\tpass\n    \n       def __add__(self, y):  \n\t\t\t\"\"\" x.__add__(y) <==> x+y \"\"\"\n\t\t\tpass\n    \n       def __contains__(self, y):  \n\t\t\t\"\"\" x.__contains__(y) <==> y in x \"\"\"\n\t\t\tpass\n    \n       def __eq__(self, y):  \n\t\t\t\"\"\" x.__eq__(y) <==> x==y \"\"\"\n\t\t\tpass\n    \n       def __format__(self, format_spec):  \n\t\t\t\"\"\"\n\t\t\tS.__format__(format_spec) -> string\n    \n\t\t\tReturn a formatted version of S as described by format_spec.\n\t\t\t\"\"\"\n\t\t\treturn \"\"\n    \n       def __getattribute__(self, name):  \n\t\t\t\"\"\" x.__getattribute__('name') <==> x.name \"\"\"\n\t\t\tpass\n    \n       def __getitem__(self, y):  \n\t\t\t\"\"\" x.__getitem__(y) <==> x[y] \"\"\"\n\t\t\tpass\n    \n       def __getnewargs__(self, *args, **kwargs): # real signature unknown\n\t\t\tpass\n    \n\t   def __getslice__(self, i, j):  \n\t\t\t\"\"\"\n\t\t\tx.__getslice__(i, j) <==> x[i:j]\n       \n\t\t\tUse of negative indices is not supported.\n\t\t\t\"\"\"\n\t\t\tpass\n    \n       def __ge__(self, y):  \n\t\t\t\"\"\" x.__ge__(y) <==> x>=y \"\"\"\n\t\t\tpass\n    \n\t   def __gt__(self, y):  \n\t\t\t\"\"\" x.__gt__(y) <==> x>y \"\"\"\n\t\t\tpass\n    \n\t   def __hash__(self):  \n\t\t\t\"\"\" x.__hash__() <==> hash(x) \"\"\"\n\t\t\tpass\n    \n       def __init__(self, string=''): # known special case of str.__init__\n\t\t\t\"\"\"\n\t\t\tstr(object='') -> string\n    \n\t\t\tReturn a nice string representation of the object.\n\t\t\tIf the argument is a string, the return value is the same object.\n\t\t\t# (copied from class doc)\n\t\t\t\"\"\"\n\t\t\tpass\n    \n       def __len__(self):  \n\t\t\t\"\"\" x.__len__() <==> len(x) \"\"\"\n\t\t\tpass\n    \n       def __le__(self, y):  \n\t\t\t\"\"\" x.__le__(y) <==> x<=y \"\"\"\n\t\t\tpass\n    \n       def __lt__(self, y):  \n\t\t\t\"\"\" x.__lt__(y) <==> x<y \"\"\"\n\t\t\tpass\n    \n       def __mod__(self, y):  \n\t\t\t\"\"\" x.__mod__(y) <==> x%y \"\"\"\n\t\t\tpass\n    \n       def __mul__(self, n):  \n\t\t\t\"\"\" x.__mul__(n) <==> x*n \"\"\"\n\t\t\tpass\n    \n\t\t\t@staticmethod # known case of __new__\n\t   def __new__(S, *more):  \n\t\t\t\"\"\" T.__new__(S, ...) -> a new object with type S, a subtype of T \"\"\"\n\t\t\tpass\n    \n       def __ne__(self, y):  \n\t\t\t\"\"\" x.__ne__(y) <==> x!=y \"\"\"\n\t\t\tpass\n    \n       def __repr__(self):  \n\t\t\t\"\"\" x.__repr__() <==> repr(x) \"\"\"\n\t\t\tpass\n    \n       def __rmod__(self, y):  \n\t\t\t\"\"\" x.__rmod__(y) <==> y%x \"\"\"\n\t\t\tpass\n    \n       def __rmul__(self, n):  \n\t\t\t\"\"\" x.__rmul__(n) <==> n*x \"\"\"\n\t\t\tpass\n    \n       def __sizeof__(self):  \n\t\t\t\"\"\" S.__sizeof__() -> size of S in memory, in bytes \"\"\"\n\t\t\tpass\n    \n       def __str__(self):  \n\t\t\t\"\"\" x.__str__() <==> str(x) \"\"\"\n\t\t\tpass\n\n\n\n## int数字    ## \n    \n    class int(object):\n\t\t\"\"\"\n\t \t int(x=0) -> int or long\n\t\t int(x, base=10) -> int or long\n    \n\t\t Convert a number or string to an integer, or return 0 if no arguments\n\t\t are given.  If x is floating point, the conversion truncates towards zero.\n\t\t If x is outside the integer range, the function returns a long instead.\n    \n\t\t If x is not a number or if base is given, then x must be a string or\n\t\t Unicode object representing an integer literal in the given base.  The\n\t\t literal can be preceded by '+' or '-' and be surrounded by whitespace.\n\t\t The base defaults to 10.  Valid bases are 0 and 2-36.  Base 0 means to\n\t\t interpret the base from the string as an integer literal.\n\t\t >>> int('0b100', base=0)\n\t\t 4\n\t\t\"\"\"\n\t   def bit_length(self): \n\t\t\t\"\"\" 返回表示该数字的时占用的最少位数 \"\"\"\n\t\t\t\"\"\"\n\t\t\tint.bit_length() -> int\n        \n\t\t\tNumber of bits necessary to represent self in binary.\n\t\t\t>>> bin(37)\n\t\t\t'0b100101'\n\t\t\t>>> (37).bit_length()\n\t\t\t6\n\t\t\t\"\"\"\n\t\t\treturn 0\n\n       def conjugate(self, *args, **kwargs): # real signature unknown\n\t\t\t\"\"\" 返回该复数的共轭复数 \"\"\"\n\t\t\t\"\"\" Returns self, the complex conjugate of any int. \"\"\"\n\t\t\tpass\n\n       def __abs__(self):\n\t\t\t\"\"\" 返回绝对值 \"\"\"\n\t\t\t\"\"\" x.__abs__() <==> abs(x) \"\"\"\n\t\t\tpass\n\n       def __add__(self, y):\n\t\t\t\"\"\" x.__add__(y) <==> x+y \"\"\"\n\t\t\tpass\n\n       def __and__(self, y):\n\t\t\t\"\"\" x.__and__(y) <==> x&y \"\"\"\n\t\t\tpass\n\n       def __cmp__(self, y): \n\t\t\t\"\"\" 比较两个数大小 \"\"\"\n\t\t\t\"\"\" x.__cmp__(y) <==> cmp(x,y) \"\"\"\n\t\t\tpass\n\n       def __coerce__(self, y):\n\t\t\t\"\"\" 强制生成一个元组 \"\"\" \n\t\t\t\"\"\" x.__coerce__(y) <==> coerce(x, y) \"\"\"\n\t\t\tpass\n\n       def __divmod__(self, y): \n\t\t\t\"\"\" 相除，得到商和余数组成的元组 \"\"\" \n\t\t\t\"\"\" x.__divmod__(y) <==> divmod(x, y) \"\"\"\n\t\t\tpass\n\n       def __div__(self, y): \n\t\t\t\"\"\" x.__div__(y) <==> x/y \"\"\"\n\t\t\tpass\n\n       def __float__(self): \n\t\t\t\"\"\" 转换为浮点类型 \"\"\" \n\t\t\t\"\"\" x.__float__() <==> float(x) \"\"\"\n\t\t\tpass\n\n       def __floordiv__(self, y): \n\t\t\t\"\"\" x.__floordiv__(y) <==> x//y \"\"\"\n\t\t\tpass\n\n       def __format__(self, *args, **kwargs): # real signature unknown\n\t\t\tpass\n\n       def __getattribute__(self, name): \n\t\t\t\"\"\" x.__getattribute__('name') <==> x.name \"\"\"\n\t\t\tpass\n\n       def __getnewargs__(self, *args, **kwargs): # real signature unknown\n\t\t\t\"\"\" 内部调用 __new__方法或创建对象时传入参数使用 \"\"\" \n\t\t\tpass\n\n       def __hash__(self): \n\t\t\t\"\"\"如果对象object为哈希表类型，返回对象object的哈希值。哈希值为整数。在字典查找中，哈希值用于快速比较字典的键。两个数值如果相等，则哈希值也相等。\"\"\"\n\t\t\t\"\"\" x.__hash__() <==> hash(x) \"\"\"\n\t\t\tpass\n\n       def __hex__(self): \n\t\t\t\"\"\" 返回当前数的 十六进制 表示 \"\"\" \n\t\t\t\"\"\" x.__hex__() <==> hex(x) \"\"\"\n\t\t\tpass\n\n\t   def __index__(self): \n\t\t\t\"\"\" 用于切片，数字无意义 \"\"\"\n\t\t\t\"\"\" x[y:z] <==> x[y.__index__():z.__index__()] \"\"\"\n\t\t\tpass\n\n\t   def __init__(self, x, base=10): # known special case of int.__init__\n\t\t\t\"\"\" 构造方法，执行 x = 123 或 x = int(10) 时，自动调用，暂时忽略 \"\"\" \n\t\t\t\"\"\"\n\t\t\tint(x=0) -> int or long\n\t\t\tint(x, base=10) -> int or long\n        \n\t\t\tConvert a number or string to an integer, or return 0 if no arguments\n\t\t\tare given.  If x is floating point, the conversion truncates towards zero.\n\t\t\tIf x is outside the integer range, the function returns a long instead.\n        \n\t\t\tIf x is not a number or if base is given, then x must be a string or\n\t\t\tUnicode object representing an integer literal in the given base.  The\n\t\t\tliteral can be preceded by '+' or '-' and be surrounded by whitespace.\n\t\t\tThe base defaults to 10.  Valid bases are 0 and 2-36.  Base 0 means to\n\t\t\tinterpret the base from the string as an integer literal.\n\t\t\t>>> int('0b100', base=0)\n\t\t\t4\n\t\t\t# (copied from class doc)\n\t\t\t\"\"\"\n\t\t\tpass\n\n       def __int__(self): \n\t\t\t\"\"\" 转换为整数 \"\"\" \n\t\t\t\"\"\" x.__int__() <==> int(x) \"\"\"\n\t\t\tpass\n\n       def __invert__(self): \n\t\t\t\"\"\" x.__invert__() <==> ~x \"\"\"\n\t\t\tpass\n\n       def __long__(self): \n\t\t\t\"\"\" 转换为长整数 \"\"\" \n\t\t\t\"\"\" x.__long__() <==> long(x) \"\"\"\n\t\t\tpass\n\n       def __lshift__(self, y): \n\t\t\t\"\"\" x.__lshift__(y) <==> x<<y \"\"\"\n        pass\n\n       def __mod__(self, y): \n\t\t\t\"\"\" x.__mod__(y) <==> x%y \"\"\"\n\t\t\tpass\n\n       def __mul__(self, y): \n\t\t\t\"\"\" x.__mul__(y) <==> x*y \"\"\"\n\t\t\tpass\n\n       def __neg__(self): \n\t\t\t\"\"\" x.__neg__() <==> -x \"\"\"\n\t\t\tpass\n\n\t\t\t@staticmethod # known case of __new__\n\t   def __new__(S, *more): \n\t\t\t\"\"\" T.__new__(S, ...) -> a new object with type S, a subtype of T \"\"\"\n\t\t\tpass\n\n       def __nonzero__(self): \n\t\t\t\"\"\" x.__nonzero__() <==> x != 0 \"\"\"\n\t\t\tpass\n\n       def __oct__(self): \n\t\t\t\"\"\" 返回改值的 八进制 表示 \"\"\" \n\t\t\t\"\"\" x.__oct__() <==> oct(x) \"\"\"\n\t\t\tpass\n\n       def __or__(self, y): \n\t\t\t\"\"\" x.__or__(y) <==> x|y \"\"\"\n\t\t\tpass\n\n       def __pos__(self): \n\t\t\t\"\"\" x.__pos__() <==> +x \"\"\"\n\t\t\tpass\n\n       def __pow__(self, y, z=None): \n\t\t\t\"\"\" 幂，次方 \"\"\" \n\t\t\t\"\"\" x.__pow__(y[, z]) <==> pow(x, y[, z]) \"\"\"\n\t\t\tpass\n\n       def __radd__(self, y): \n\t\t\t\"\"\" x.__radd__(y) <==> y+x \"\"\"\n\t\t\tpass\n\n       def __rand__(self, y): \n\t\t\t\"\"\" x.__rand__(y) <==> y&x \"\"\"\n\t\t\tpass\n\n       def __rdivmod__(self, y): \n\t\t\t\"\"\" x.__rdivmod__(y) <==> divmod(y, x) \"\"\"\n\t\t\tpass\n\n       def __rdiv__(self, y): \n\t\t\t\"\"\" x.__rdiv__(y) <==> y/x \"\"\"\n\t\t\tpass\n\n       def __repr__(self): \n\t\t\t\"\"\"转化为解释器可读取的形式 \"\"\"\n\t\t\t\"\"\" x.__repr__() <==> repr(x) \"\"\"\n\t\t\tpass\n\n       def __str__(self): \n\t\t\t\"\"\"转换为人阅读的形式，如果没有适于人阅读的解释形式的话，则返回解释器课阅读的形式\"\"\"\n\t\t\t\"\"\" x.__str__() <==> str(x) \"\"\"\n\t\t\tpass\n\n       def __rfloordiv__(self, y): \n\t\t\t\"\"\" x.__rfloordiv__(y) <==> y//x \"\"\"\n\t\t\tpass\n\n       def __rlshift__(self, y): \n\t\t\t\"\"\" x.__rlshift__(y) <==> y<<x \"\"\"\n\t\t\tpass\n\n       def __rmod__(self, y): \n\t\t\t\"\"\" x.__rmod__(y) <==> y%x \"\"\"\n\t\t\tpass\n\n       def __rmul__(self, y): \n\t\t\t\"\"\" x.__rmul__(y) <==> y*x \"\"\"\n\t\t\tpass\n\n       def __ror__(self, y): \n\t\t\t\"\"\" x.__ror__(y) <==> y|x \"\"\"\n\t\t\tpass\n\n       def __rpow__(self, x, z=None): \n\t\t\t\"\"\" y.__rpow__(x[, z]) <==> pow(x, y[, z]) \"\"\"\n\t\t\tpass\n\n       def __rrshift__(self, y): \n\t\t\t\"\"\" x.__rrshift__(y) <==> y>>x \"\"\"\n\t\t\tpass\n\n       def __rshift__(self, y): \n\t\t\t\"\"\" x.__rshift__(y) <==> x>>y \"\"\"\n\t\t\tpass\n\n       def __rsub__(self, y): \n\t\t\t\"\"\" x.__rsub__(y) <==> y-x \"\"\"\n\t\t\tpass\n\n       def __rtruediv__(self, y): \n\t\t\t\"\"\" x.__rtruediv__(y) <==> y/x \"\"\"\n\t\t\tpass\n\n       def __rxor__(self, y): \n\t\t\t\"\"\" x.__rxor__(y) <==> y^x \"\"\"\n\t\t\tpass\n\n       def __sub__(self, y): \n\t\t\t\"\"\" x.__sub__(y) <==> x-y \"\"\"\n\t\t\tpass\n\n       def __truediv__(self, y): \n\t\t\t\"\"\" x.__truediv__(y) <==> x/y \"\"\"\n\t\t\tpass\n\n       def __trunc__(self, *args, **kwargs): \n\t\t\t\"\"\" 返回数值被截取为整形的值，在整形中无意义 \"\"\"\n\t\t\tpass\n\n       def __xor__(self, y): \n\t\t\t\"\"\" x.__xor__(y) <==> x^y \"\"\"\n\t\t\tpass\n\n\t\t\tdenominator = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n\t\t\t\"\"\" 分母 = 1 \"\"\"\n\t\t\t\"\"\"the denominator of a rational number in lowest terms\"\"\"\n\n\t\t\timag = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n\t\t\t\"\"\" 虚数，无意义 \"\"\"\n\t\t\t\"\"\"the imaginary part of a complex number\"\"\"\n\n\t\t\tnumerator = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n\t\t\t\"\"\" 分子 = 数字大小 \"\"\"\n\t\t\t\"\"\"the numerator of a rational number in lowest terms\"\"\"\n\n\t\t\treal = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n\t\t\t\"\"\" 实属，无意义 \"\"\"\n\t\t\t\"\"\"the real part of a complex number\"\"\"\n","slug":"Python(基础数据类型)详解","published":1,"updated":"2019-06-18T08:07:01.113Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9si90006hcb7webzep3k","content":"<h2 id=\"str类\"><a href=\"#str类\" class=\"headerlink\" title=\"str类\"></a>str类</h2><a id=\"more\"></a>\n<pre><code>class str(basestring):\n  &quot;&quot;&quot;\n  str(object=&apos;&apos;) -&gt; string\n\n  Return a nice string representation of the object.\n  If the argument is a string, the return value is the same object.\n  &quot;&quot;&quot;\n  def capitalize(self):  \n        &quot;&quot;&quot; 首字母变大写 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.capitalize() -&gt; string\n\n        Return a copy of the string S with only its first character\n        capitalized.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n  def center(self, width, fillchar=None):  \n        &quot;&quot;&quot; 内容居中，width：总长度；fillchar：空白处填充内容，默认无 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.center(width[, fillchar]) -&gt; string\n\n        Return S centered in a string of length width. Padding is\n        done using the specified fill character (default is a space)\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n  def count(self, sub, start=None, end=None):  \n        &quot;&quot;&quot; 子序列个数 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.count(sub[, start[, end]]) -&gt; int\n\n        Return the number of non-overlapping occurrences of substring sub in\n        string S[start:end].  Optional arguments start and end are interpreted\n        as in slice notation.\n        &quot;&quot;&quot;\n        return 0\n\n  def decode(self, encoding=None, errors=None):  \n        &quot;&quot;&quot; 解码 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.decode([encoding[,errors]]) -&gt; object\n\n        Decodes S using the codec registered for encoding. encoding defaults\n        to the default encoding. errors may be given to set a different error\n        handling scheme. Default is &apos;strict&apos; meaning that encoding errors raise\n        a UnicodeDecodeError. Other possible values are &apos;ignore&apos; and &apos;replace&apos;\n        as well as any other name registered with codecs.register_error that is\n        able to handle UnicodeDecodeErrors.\n        &quot;&quot;&quot;\n        return object()\n\n  def encode(self, encoding=None, errors=None):  \n        &quot;&quot;&quot; 编码，针对unicode &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.encode([encoding[,errors]]) -&gt; object\n\n        Encodes S using the codec registered for encoding. encoding defaults\n        to the default encoding. errors may be given to set a different error\n        handling scheme. Default is &apos;strict&apos; meaning that encoding errors raise\n        a UnicodeEncodeError. Other possible values are &apos;ignore&apos;, &apos;replace&apos; and\n        &apos;xmlcharrefreplace&apos; as well as any other name registered with\n        codecs.register_error that is able to handle UnicodeEncodeErrors.\n        &quot;&quot;&quot;\n        return object()\n\n  def endswith(self, suffix, start=None, end=None):  \n        &quot;&quot;&quot; 是否以 xxx 结束 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.endswith(suffix[, start[, end]]) -&gt; bool\n\n        Return True if S ends with the specified suffix, False otherwise.\n        With optional start, test S beginning at that position.\n        With optional end, stop comparing S at that position.\n        suffix can also be a tuple of strings to try.\n        &quot;&quot;&quot;\n        return False\n\n   def expandtabs(self, tabsize=None):  \n        &quot;&quot;&quot; 将tab转换成空格，默认一个tab转换成8个空格 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.expandtabs([tabsize]) -&gt; string\n\n        Return a copy of S where all tab characters are expanded using spaces.\n        If tabsize is not given, a tab size of 8 characters is assumed.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def find(self, sub, start=None, end=None):  \n        &quot;&quot;&quot; 寻找子序列位置，如果没找到，返回 -1 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.find(sub [,start [,end]]) -&gt; int\n\n        Return the lowest index in S where substring sub is found,\n        such that sub is contained within S[start:end].  Optional\n        arguments start and end are interpreted as in slice notation.\n\n        Return -1 on failure.\n        &quot;&quot;&quot;\n        return 0\n\n   def format(*args, **kwargs): # known special case of str.format\n        &quot;&quot;&quot; 字符串格式化，动态参数，将函数式编程时细说 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.format(*args, **kwargs) -&gt; string\n\n        Return a formatted version of S, using substitutions from args and kwargs.\n        The substitutions are identified by braces (&apos;{&apos; and &apos;}&apos;).\n        &quot;&quot;&quot;\n        pass\n\n   def index(self, sub, start=None, end=None):  \n        &quot;&quot;&quot; 子序列位置，如果没找到，报错 &quot;&quot;&quot;\n        S.index(sub [,start [,end]]) -&gt; int\n\n        Like S.find() but raise ValueError when the substring is not found.\n        &quot;&quot;&quot;\n        return 0\n\n   def isalnum(self):  \n        &quot;&quot;&quot; 是否是字母和数字 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.isalnum() -&gt; bool\n\n        Return True if all characters in S are alphanumeric\n        and there is at least one character in S, False otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def isalpha(self):  \n        &quot;&quot;&quot; 是否是字母 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.isalpha() -&gt; bool\n\n        Return True if all characters in S are alphabetic\n        and there is at least one character in S, False otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def isdigit(self):  \n        &quot;&quot;&quot; 是否是数字 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.isdigit() -&gt; bool\n\n        Return True if all characters in S are digits\n        and there is at least one character in S, False otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def islower(self):  \n        &quot;&quot;&quot; 是否小写 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.islower() -&gt; bool\n\n        Return True if all cased characters in S are lowercase and there is\n        at least one cased character in S, False otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def isspace(self):  \n        &quot;&quot;&quot;\n        S.isspace() -&gt; bool\n\n        Return True if all characters in S are whitespace\n        and there is at least one character in S, False otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def istitle(self):  \n        &quot;&quot;&quot;\n        S.istitle() -&gt; bool\n\n        Return True if S is a titlecased string and there is at least one\n        character in S, i.e. uppercase characters may only follow uncased\n        characters and lowercase characters only cased ones. Return False\n        otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def isupper(self):  \n        &quot;&quot;&quot;\n        S.isupper() -&gt; bool\n\n        Return True if all cased characters in S are uppercase and there is\n        at least one cased character in S, False otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def join(self, iterable):  \n        &quot;&quot;&quot; 连接 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.join(iterable) -&gt; string\n\n        Return a string which is the concatenation of the strings in the\n        iterable.  The separator between elements is S.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def ljust(self, width, fillchar=None):  \n        &quot;&quot;&quot; 内容左对齐，右侧填充 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.ljust(width[, fillchar]) -&gt; string\n\n        Return S left-justified in a string of length width. Padding is\n        done using the specified fill character (default is a space).\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def lower(self):  \n        &quot;&quot;&quot; 变小写 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.lower() -&gt; string\n\n        Return a copy of the string S converted to lowercase.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def lstrip(self, chars=None):  \n        &quot;&quot;&quot; 移除左侧空白 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.lstrip([chars]) -&gt; string or unicode\n\n        Return a copy of the string S with leading whitespace removed.\n        If chars is given and not None, remove characters in chars instead.\n        If chars is unicode, S will be converted to unicode before stripping\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def partition(self, sep):  \n        &quot;&quot;&quot; 分割，前，中，后三部分 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.partition(sep) -&gt; (head, sep, tail)\n\n        Search for the separator sep in S, and return the part before it,\n        the separator itself, and the part after it.  If the separator is not\n        found, return S and two empty strings.\n        &quot;&quot;&quot;\n        pass\n\n   def replace(self, old, new, count=None):  \n        &quot;&quot;&quot; 替换 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.replace(old, new[, count]) -&gt; string\n\n        Return a copy of string S with all occurrences of substring\n        old replaced by new.  If the optional argument count is\n        given, only the first count occurrences are replaced.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def rfind(self, sub, start=None, end=None):  \n        &quot;&quot;&quot;\n        S.rfind(sub [,start [,end]]) -&gt; int\n\n        Return the highest index in S where substring sub is found,\n        such that sub is contained within S[start:end].  Optional\n        arguments start and end are interpreted as in slice notation.\n\n        Return -1 on failure.\n        &quot;&quot;&quot;\n        return 0\n\n   def rindex(self, sub, start=None, end=None):  \n        &quot;&quot;&quot;\n        S.rindex(sub [,start [,end]]) -&gt; int\n\n        Like S.rfind() but raise ValueError when the substring is not found.\n        &quot;&quot;&quot;\n        return 0\n\n   def rjust(self, width, fillchar=None):  \n        &quot;&quot;&quot;\n        S.rjust(width[, fillchar]) -&gt; string\n\n        Return S right-justified in a string of length width. Padding is\n        done using the specified fill character (default is a space)\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def rpartition(self, sep):  \n        &quot;&quot;&quot;\n        S.rpartition(sep) -&gt; (head, sep, tail)\n\n        Search for the separator sep in S, starting at the end of S, and return\n        the part before it, the separator itself, and the part after it.  If the\n        separator is not found, return two empty strings and S.\n        &quot;&quot;&quot;\n        pass\n\n   def rsplit(self, sep=None, maxsplit=None):  \n        &quot;&quot;&quot;\n        S.rsplit([sep [,maxsplit]]) -&gt; list of strings\n\n        Return a list of the words in the string S, using sep as the\n        delimiter string, starting at the end of the string and working\n        to the front.  If maxsplit is given, at most maxsplit splits are\n        done. If sep is not specified or is None, any whitespace string\n        is a separator.\n        &quot;&quot;&quot;\n        return []\n\n   def rstrip(self, chars=None):  \n        &quot;&quot;&quot;\n        S.rstrip([chars]) -&gt; string or unicode\n\n        Return a copy of the string S with trailing whitespace removed.\n        If chars is given and not None, remove characters in chars instead.\n        If chars is unicode, S will be converted to unicode before stripping\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def split(self, sep=None, maxsplit=None):  \n        &quot;&quot;&quot; 分割， maxsplit最多分割几次 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.split([sep [,maxsplit]]) -&gt; list of strings\n\n        Return a list of the words in the string S, using sep as the\n        delimiter string.  If maxsplit is given, at most maxsplit\n        splits are done. If sep is not specified or is None, any\n        whitespace string is a separator and empty strings are removed\n        from the result.\n        &quot;&quot;&quot;\n        return []\n\n   def splitlines(self, keepends=False):  \n        &quot;&quot;&quot; 根据换行分割 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.splitlines(keepends=False) -&gt; list of strings\n\n        Return a list of the lines in S, breaking at line boundaries.\n        Line breaks are not included in the resulting list unless keepends\n        is given and true.\n        &quot;&quot;&quot;\n        return []\n\n   def startswith(self, prefix, start=None, end=None):  \n        &quot;&quot;&quot; 是否起始 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.startswith(prefix[, start[, end]]) -&gt; bool\n\n        Return True if S starts with the specified prefix, False otherwise.\n        With optional start, test S beginning at that position.\n        With optional end, stop comparing S at that position.\n        prefix can also be a tuple of strings to try.\n        &quot;&quot;&quot;\n        return False\n\n   def strip(self, chars=None):  \n        &quot;&quot;&quot; 移除两段空白 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.strip([chars]) -&gt; string or unicode\n\n        Return a copy of the string S with leading and trailing\n        whitespace removed.\n        If chars is given and not None, remove characters in chars instead.\n        If chars is unicode, S will be converted to unicode before stripping\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def swapcase(self):  \n        &quot;&quot;&quot; 大写变小写，小写变大写 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.swapcase() -&gt; string\n\n        Return a copy of the string S with uppercase characters\n        converted to lowercase and vice versa.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def title(self):  \n        &quot;&quot;&quot;\n        S.title() -&gt; string\n\n        Return a titlecased version of S, i.e. words start with uppercase\n        characters, all remaining cased characters have lowercase.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def translate(self, table, deletechars=None):  \n        &quot;&quot;&quot;\n        转换，需要先做一个对应表，最后一个表示删除字符集合\n        intab = &quot;aeiou&quot;\n        outtab = &quot;12345&quot;\n        trantab = maketrans(intab, outtab)\n        str = &quot;this is string example....wow!!!&quot;\n        print str.translate(trantab, &apos;xm&apos;)\n        &quot;&quot;&quot;\n\n        &quot;&quot;&quot;\n        S.translate(table [,deletechars]) -&gt; string\n\n        Return a copy of the string S, where all characters occurring\n        in the optional argument deletechars are removed, and the\n        remaining characters have been mapped through the given\n        translation table, which must be a string of length 256 or None.\n        If the table argument is None, no translation is applied and\n        the operation simply removes the characters in deletechars.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def upper(self):  \n        &quot;&quot;&quot;\n        S.upper() -&gt; string\n\n        Return a copy of the string S converted to uppercase.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def zfill(self, width):  \n        &quot;&quot;&quot;方法返回指定长度的字符串，原字符串右对齐，前面填充0。&quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.zfill(width) -&gt; string\n\n        Pad a numeric string S with zeros on the left, to fill a field\n        of the specified width.  The string S is never truncated.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def _formatter_field_name_split(self, *args, **kwargs): # real signature unknown\n        pass\n\n   def _formatter_parser(self, *args, **kwargs): # real signature unknown\n        pass\n\n   def __add__(self, y):  \n        &quot;&quot;&quot; x.__add__(y) &lt;==&gt; x+y &quot;&quot;&quot;\n        pass\n\n   def __contains__(self, y):  \n        &quot;&quot;&quot; x.__contains__(y) &lt;==&gt; y in x &quot;&quot;&quot;\n        pass\n\n   def __eq__(self, y):  \n        &quot;&quot;&quot; x.__eq__(y) &lt;==&gt; x==y &quot;&quot;&quot;\n        pass\n\n   def __format__(self, format_spec):  \n        &quot;&quot;&quot;\n        S.__format__(format_spec) -&gt; string\n\n        Return a formatted version of S as described by format_spec.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def __getattribute__(self, name):  \n        &quot;&quot;&quot; x.__getattribute__(&apos;name&apos;) &lt;==&gt; x.name &quot;&quot;&quot;\n        pass\n\n   def __getitem__(self, y):  \n        &quot;&quot;&quot; x.__getitem__(y) &lt;==&gt; x[y] &quot;&quot;&quot;\n        pass\n\n   def __getnewargs__(self, *args, **kwargs): # real signature unknown\n        pass\n\n   def __getslice__(self, i, j):  \n        &quot;&quot;&quot;\n        x.__getslice__(i, j) &lt;==&gt; x[i:j]\n\n        Use of negative indices is not supported.\n        &quot;&quot;&quot;\n        pass\n\n   def __ge__(self, y):  \n        &quot;&quot;&quot; x.__ge__(y) &lt;==&gt; x&gt;=y &quot;&quot;&quot;\n        pass\n\n   def __gt__(self, y):  \n        &quot;&quot;&quot; x.__gt__(y) &lt;==&gt; x&gt;y &quot;&quot;&quot;\n        pass\n\n   def __hash__(self):  \n        &quot;&quot;&quot; x.__hash__() &lt;==&gt; hash(x) &quot;&quot;&quot;\n        pass\n\n   def __init__(self, string=&apos;&apos;): # known special case of str.__init__\n        &quot;&quot;&quot;\n        str(object=&apos;&apos;) -&gt; string\n\n        Return a nice string representation of the object.\n        If the argument is a string, the return value is the same object.\n        # (copied from class doc)\n        &quot;&quot;&quot;\n        pass\n\n   def __len__(self):  \n        &quot;&quot;&quot; x.__len__() &lt;==&gt; len(x) &quot;&quot;&quot;\n        pass\n\n   def __le__(self, y):  \n        &quot;&quot;&quot; x.__le__(y) &lt;==&gt; x&lt;=y &quot;&quot;&quot;\n        pass\n\n   def __lt__(self, y):  \n        &quot;&quot;&quot; x.__lt__(y) &lt;==&gt; x&lt;y &quot;&quot;&quot;\n        pass\n\n   def __mod__(self, y):  \n        &quot;&quot;&quot; x.__mod__(y) &lt;==&gt; x%y &quot;&quot;&quot;\n        pass\n\n   def __mul__(self, n):  \n        &quot;&quot;&quot; x.__mul__(n) &lt;==&gt; x*n &quot;&quot;&quot;\n        pass\n\n        @staticmethod # known case of __new__\n   def __new__(S, *more):  \n        &quot;&quot;&quot; T.__new__(S, ...) -&gt; a new object with type S, a subtype of T &quot;&quot;&quot;\n        pass\n\n   def __ne__(self, y):  \n        &quot;&quot;&quot; x.__ne__(y) &lt;==&gt; x!=y &quot;&quot;&quot;\n        pass\n\n   def __repr__(self):  \n        &quot;&quot;&quot; x.__repr__() &lt;==&gt; repr(x) &quot;&quot;&quot;\n        pass\n\n   def __rmod__(self, y):  \n        &quot;&quot;&quot; x.__rmod__(y) &lt;==&gt; y%x &quot;&quot;&quot;\n        pass\n\n   def __rmul__(self, n):  \n        &quot;&quot;&quot; x.__rmul__(n) &lt;==&gt; n*x &quot;&quot;&quot;\n        pass\n\n   def __sizeof__(self):  \n        &quot;&quot;&quot; S.__sizeof__() -&gt; size of S in memory, in bytes &quot;&quot;&quot;\n        pass\n\n   def __str__(self):  \n        &quot;&quot;&quot; x.__str__() &lt;==&gt; str(x) &quot;&quot;&quot;\n        pass\n</code></pre><h2 id=\"int数字\"><a href=\"#int数字\" class=\"headerlink\" title=\"int数字\"></a>int数字</h2><pre><code>class int(object):\n    &quot;&quot;&quot;\n      int(x=0) -&gt; int or long\n     int(x, base=10) -&gt; int or long\n\n     Convert a number or string to an integer, or return 0 if no arguments\n     are given.  If x is floating point, the conversion truncates towards zero.\n     If x is outside the integer range, the function returns a long instead.\n\n     If x is not a number or if base is given, then x must be a string or\n     Unicode object representing an integer literal in the given base.  The\n     literal can be preceded by &apos;+&apos; or &apos;-&apos; and be surrounded by whitespace.\n     The base defaults to 10.  Valid bases are 0 and 2-36.  Base 0 means to\n     interpret the base from the string as an integer literal.\n     &gt;&gt;&gt; int(&apos;0b100&apos;, base=0)\n     4\n    &quot;&quot;&quot;\n   def bit_length(self): \n        &quot;&quot;&quot; 返回表示该数字的时占用的最少位数 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        int.bit_length() -&gt; int\n\n        Number of bits necessary to represent self in binary.\n        &gt;&gt;&gt; bin(37)\n        &apos;0b100101&apos;\n        &gt;&gt;&gt; (37).bit_length()\n        6\n        &quot;&quot;&quot;\n        return 0\n\n   def conjugate(self, *args, **kwargs): # real signature unknown\n        &quot;&quot;&quot; 返回该复数的共轭复数 &quot;&quot;&quot;\n        &quot;&quot;&quot; Returns self, the complex conjugate of any int. &quot;&quot;&quot;\n        pass\n\n   def __abs__(self):\n        &quot;&quot;&quot; 返回绝对值 &quot;&quot;&quot;\n        &quot;&quot;&quot; x.__abs__() &lt;==&gt; abs(x) &quot;&quot;&quot;\n        pass\n\n   def __add__(self, y):\n        &quot;&quot;&quot; x.__add__(y) &lt;==&gt; x+y &quot;&quot;&quot;\n        pass\n\n   def __and__(self, y):\n        &quot;&quot;&quot; x.__and__(y) &lt;==&gt; x&amp;y &quot;&quot;&quot;\n        pass\n\n   def __cmp__(self, y): \n        &quot;&quot;&quot; 比较两个数大小 &quot;&quot;&quot;\n        &quot;&quot;&quot; x.__cmp__(y) &lt;==&gt; cmp(x,y) &quot;&quot;&quot;\n        pass\n\n   def __coerce__(self, y):\n        &quot;&quot;&quot; 强制生成一个元组 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__coerce__(y) &lt;==&gt; coerce(x, y) &quot;&quot;&quot;\n        pass\n\n   def __divmod__(self, y): \n        &quot;&quot;&quot; 相除，得到商和余数组成的元组 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__divmod__(y) &lt;==&gt; divmod(x, y) &quot;&quot;&quot;\n        pass\n\n   def __div__(self, y): \n        &quot;&quot;&quot; x.__div__(y) &lt;==&gt; x/y &quot;&quot;&quot;\n        pass\n\n   def __float__(self): \n        &quot;&quot;&quot; 转换为浮点类型 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__float__() &lt;==&gt; float(x) &quot;&quot;&quot;\n        pass\n\n   def __floordiv__(self, y): \n        &quot;&quot;&quot; x.__floordiv__(y) &lt;==&gt; x//y &quot;&quot;&quot;\n        pass\n\n   def __format__(self, *args, **kwargs): # real signature unknown\n        pass\n\n   def __getattribute__(self, name): \n        &quot;&quot;&quot; x.__getattribute__(&apos;name&apos;) &lt;==&gt; x.name &quot;&quot;&quot;\n        pass\n\n   def __getnewargs__(self, *args, **kwargs): # real signature unknown\n        &quot;&quot;&quot; 内部调用 __new__方法或创建对象时传入参数使用 &quot;&quot;&quot; \n        pass\n\n   def __hash__(self): \n        &quot;&quot;&quot;如果对象object为哈希表类型，返回对象object的哈希值。哈希值为整数。在字典查找中，哈希值用于快速比较字典的键。两个数值如果相等，则哈希值也相等。&quot;&quot;&quot;\n        &quot;&quot;&quot; x.__hash__() &lt;==&gt; hash(x) &quot;&quot;&quot;\n        pass\n\n   def __hex__(self): \n        &quot;&quot;&quot; 返回当前数的 十六进制 表示 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__hex__() &lt;==&gt; hex(x) &quot;&quot;&quot;\n        pass\n\n   def __index__(self): \n        &quot;&quot;&quot; 用于切片，数字无意义 &quot;&quot;&quot;\n        &quot;&quot;&quot; x[y:z] &lt;==&gt; x[y.__index__():z.__index__()] &quot;&quot;&quot;\n        pass\n\n   def __init__(self, x, base=10): # known special case of int.__init__\n        &quot;&quot;&quot; 构造方法，执行 x = 123 或 x = int(10) 时，自动调用，暂时忽略 &quot;&quot;&quot; \n        &quot;&quot;&quot;\n        int(x=0) -&gt; int or long\n        int(x, base=10) -&gt; int or long\n\n        Convert a number or string to an integer, or return 0 if no arguments\n        are given.  If x is floating point, the conversion truncates towards zero.\n        If x is outside the integer range, the function returns a long instead.\n\n        If x is not a number or if base is given, then x must be a string or\n        Unicode object representing an integer literal in the given base.  The\n        literal can be preceded by &apos;+&apos; or &apos;-&apos; and be surrounded by whitespace.\n        The base defaults to 10.  Valid bases are 0 and 2-36.  Base 0 means to\n        interpret the base from the string as an integer literal.\n        &gt;&gt;&gt; int(&apos;0b100&apos;, base=0)\n        4\n        # (copied from class doc)\n        &quot;&quot;&quot;\n        pass\n\n   def __int__(self): \n        &quot;&quot;&quot; 转换为整数 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__int__() &lt;==&gt; int(x) &quot;&quot;&quot;\n        pass\n\n   def __invert__(self): \n        &quot;&quot;&quot; x.__invert__() &lt;==&gt; ~x &quot;&quot;&quot;\n        pass\n\n   def __long__(self): \n        &quot;&quot;&quot; 转换为长整数 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__long__() &lt;==&gt; long(x) &quot;&quot;&quot;\n        pass\n\n   def __lshift__(self, y): \n        &quot;&quot;&quot; x.__lshift__(y) &lt;==&gt; x&lt;&lt;y &quot;&quot;&quot;\n    pass\n\n   def __mod__(self, y): \n        &quot;&quot;&quot; x.__mod__(y) &lt;==&gt; x%y &quot;&quot;&quot;\n        pass\n\n   def __mul__(self, y): \n        &quot;&quot;&quot; x.__mul__(y) &lt;==&gt; x*y &quot;&quot;&quot;\n        pass\n\n   def __neg__(self): \n        &quot;&quot;&quot; x.__neg__() &lt;==&gt; -x &quot;&quot;&quot;\n        pass\n\n        @staticmethod # known case of __new__\n   def __new__(S, *more): \n        &quot;&quot;&quot; T.__new__(S, ...) -&gt; a new object with type S, a subtype of T &quot;&quot;&quot;\n        pass\n\n   def __nonzero__(self): \n        &quot;&quot;&quot; x.__nonzero__() &lt;==&gt; x != 0 &quot;&quot;&quot;\n        pass\n\n   def __oct__(self): \n        &quot;&quot;&quot; 返回改值的 八进制 表示 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__oct__() &lt;==&gt; oct(x) &quot;&quot;&quot;\n        pass\n\n   def __or__(self, y): \n        &quot;&quot;&quot; x.__or__(y) &lt;==&gt; x|y &quot;&quot;&quot;\n        pass\n\n   def __pos__(self): \n        &quot;&quot;&quot; x.__pos__() &lt;==&gt; +x &quot;&quot;&quot;\n        pass\n\n   def __pow__(self, y, z=None): \n        &quot;&quot;&quot; 幂，次方 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__pow__(y[, z]) &lt;==&gt; pow(x, y[, z]) &quot;&quot;&quot;\n        pass\n\n   def __radd__(self, y): \n        &quot;&quot;&quot; x.__radd__(y) &lt;==&gt; y+x &quot;&quot;&quot;\n        pass\n\n   def __rand__(self, y): \n        &quot;&quot;&quot; x.__rand__(y) &lt;==&gt; y&amp;x &quot;&quot;&quot;\n        pass\n\n   def __rdivmod__(self, y): \n        &quot;&quot;&quot; x.__rdivmod__(y) &lt;==&gt; divmod(y, x) &quot;&quot;&quot;\n        pass\n\n   def __rdiv__(self, y): \n        &quot;&quot;&quot; x.__rdiv__(y) &lt;==&gt; y/x &quot;&quot;&quot;\n        pass\n\n   def __repr__(self): \n        &quot;&quot;&quot;转化为解释器可读取的形式 &quot;&quot;&quot;\n        &quot;&quot;&quot; x.__repr__() &lt;==&gt; repr(x) &quot;&quot;&quot;\n        pass\n\n   def __str__(self): \n        &quot;&quot;&quot;转换为人阅读的形式，如果没有适于人阅读的解释形式的话，则返回解释器课阅读的形式&quot;&quot;&quot;\n        &quot;&quot;&quot; x.__str__() &lt;==&gt; str(x) &quot;&quot;&quot;\n        pass\n\n   def __rfloordiv__(self, y): \n        &quot;&quot;&quot; x.__rfloordiv__(y) &lt;==&gt; y//x &quot;&quot;&quot;\n        pass\n\n   def __rlshift__(self, y): \n        &quot;&quot;&quot; x.__rlshift__(y) &lt;==&gt; y&lt;&lt;x &quot;&quot;&quot;\n        pass\n\n   def __rmod__(self, y): \n        &quot;&quot;&quot; x.__rmod__(y) &lt;==&gt; y%x &quot;&quot;&quot;\n        pass\n\n   def __rmul__(self, y): \n        &quot;&quot;&quot; x.__rmul__(y) &lt;==&gt; y*x &quot;&quot;&quot;\n        pass\n\n   def __ror__(self, y): \n        &quot;&quot;&quot; x.__ror__(y) &lt;==&gt; y|x &quot;&quot;&quot;\n        pass\n\n   def __rpow__(self, x, z=None): \n        &quot;&quot;&quot; y.__rpow__(x[, z]) &lt;==&gt; pow(x, y[, z]) &quot;&quot;&quot;\n        pass\n\n   def __rrshift__(self, y): \n        &quot;&quot;&quot; x.__rrshift__(y) &lt;==&gt; y&gt;&gt;x &quot;&quot;&quot;\n        pass\n\n   def __rshift__(self, y): \n        &quot;&quot;&quot; x.__rshift__(y) &lt;==&gt; x&gt;&gt;y &quot;&quot;&quot;\n        pass\n\n   def __rsub__(self, y): \n        &quot;&quot;&quot; x.__rsub__(y) &lt;==&gt; y-x &quot;&quot;&quot;\n        pass\n\n   def __rtruediv__(self, y): \n        &quot;&quot;&quot; x.__rtruediv__(y) &lt;==&gt; y/x &quot;&quot;&quot;\n        pass\n\n   def __rxor__(self, y): \n        &quot;&quot;&quot; x.__rxor__(y) &lt;==&gt; y^x &quot;&quot;&quot;\n        pass\n\n   def __sub__(self, y): \n        &quot;&quot;&quot; x.__sub__(y) &lt;==&gt; x-y &quot;&quot;&quot;\n        pass\n\n   def __truediv__(self, y): \n        &quot;&quot;&quot; x.__truediv__(y) &lt;==&gt; x/y &quot;&quot;&quot;\n        pass\n\n   def __trunc__(self, *args, **kwargs): \n        &quot;&quot;&quot; 返回数值被截取为整形的值，在整形中无意义 &quot;&quot;&quot;\n        pass\n\n   def __xor__(self, y): \n        &quot;&quot;&quot; x.__xor__(y) &lt;==&gt; x^y &quot;&quot;&quot;\n        pass\n\n        denominator = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n        &quot;&quot;&quot; 分母 = 1 &quot;&quot;&quot;\n        &quot;&quot;&quot;the denominator of a rational number in lowest terms&quot;&quot;&quot;\n\n        imag = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n        &quot;&quot;&quot; 虚数，无意义 &quot;&quot;&quot;\n        &quot;&quot;&quot;the imaginary part of a complex number&quot;&quot;&quot;\n\n        numerator = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n        &quot;&quot;&quot; 分子 = 数字大小 &quot;&quot;&quot;\n        &quot;&quot;&quot;the numerator of a rational number in lowest terms&quot;&quot;&quot;\n\n        real = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n        &quot;&quot;&quot; 实属，无意义 &quot;&quot;&quot;\n        &quot;&quot;&quot;the real part of a complex number&quot;&quot;&quot;\n</code></pre>","site":{"data":{}},"excerpt":"<h2 id=\"str类\"><a href=\"#str类\" class=\"headerlink\" title=\"str类\"></a>str类</h2>","more":"<pre><code>class str(basestring):\n  &quot;&quot;&quot;\n  str(object=&apos;&apos;) -&gt; string\n\n  Return a nice string representation of the object.\n  If the argument is a string, the return value is the same object.\n  &quot;&quot;&quot;\n  def capitalize(self):  \n        &quot;&quot;&quot; 首字母变大写 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.capitalize() -&gt; string\n\n        Return a copy of the string S with only its first character\n        capitalized.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n  def center(self, width, fillchar=None):  \n        &quot;&quot;&quot; 内容居中，width：总长度；fillchar：空白处填充内容，默认无 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.center(width[, fillchar]) -&gt; string\n\n        Return S centered in a string of length width. Padding is\n        done using the specified fill character (default is a space)\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n  def count(self, sub, start=None, end=None):  \n        &quot;&quot;&quot; 子序列个数 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.count(sub[, start[, end]]) -&gt; int\n\n        Return the number of non-overlapping occurrences of substring sub in\n        string S[start:end].  Optional arguments start and end are interpreted\n        as in slice notation.\n        &quot;&quot;&quot;\n        return 0\n\n  def decode(self, encoding=None, errors=None):  \n        &quot;&quot;&quot; 解码 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.decode([encoding[,errors]]) -&gt; object\n\n        Decodes S using the codec registered for encoding. encoding defaults\n        to the default encoding. errors may be given to set a different error\n        handling scheme. Default is &apos;strict&apos; meaning that encoding errors raise\n        a UnicodeDecodeError. Other possible values are &apos;ignore&apos; and &apos;replace&apos;\n        as well as any other name registered with codecs.register_error that is\n        able to handle UnicodeDecodeErrors.\n        &quot;&quot;&quot;\n        return object()\n\n  def encode(self, encoding=None, errors=None):  \n        &quot;&quot;&quot; 编码，针对unicode &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.encode([encoding[,errors]]) -&gt; object\n\n        Encodes S using the codec registered for encoding. encoding defaults\n        to the default encoding. errors may be given to set a different error\n        handling scheme. Default is &apos;strict&apos; meaning that encoding errors raise\n        a UnicodeEncodeError. Other possible values are &apos;ignore&apos;, &apos;replace&apos; and\n        &apos;xmlcharrefreplace&apos; as well as any other name registered with\n        codecs.register_error that is able to handle UnicodeEncodeErrors.\n        &quot;&quot;&quot;\n        return object()\n\n  def endswith(self, suffix, start=None, end=None):  \n        &quot;&quot;&quot; 是否以 xxx 结束 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.endswith(suffix[, start[, end]]) -&gt; bool\n\n        Return True if S ends with the specified suffix, False otherwise.\n        With optional start, test S beginning at that position.\n        With optional end, stop comparing S at that position.\n        suffix can also be a tuple of strings to try.\n        &quot;&quot;&quot;\n        return False\n\n   def expandtabs(self, tabsize=None):  \n        &quot;&quot;&quot; 将tab转换成空格，默认一个tab转换成8个空格 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.expandtabs([tabsize]) -&gt; string\n\n        Return a copy of S where all tab characters are expanded using spaces.\n        If tabsize is not given, a tab size of 8 characters is assumed.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def find(self, sub, start=None, end=None):  \n        &quot;&quot;&quot; 寻找子序列位置，如果没找到，返回 -1 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.find(sub [,start [,end]]) -&gt; int\n\n        Return the lowest index in S where substring sub is found,\n        such that sub is contained within S[start:end].  Optional\n        arguments start and end are interpreted as in slice notation.\n\n        Return -1 on failure.\n        &quot;&quot;&quot;\n        return 0\n\n   def format(*args, **kwargs): # known special case of str.format\n        &quot;&quot;&quot; 字符串格式化，动态参数，将函数式编程时细说 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.format(*args, **kwargs) -&gt; string\n\n        Return a formatted version of S, using substitutions from args and kwargs.\n        The substitutions are identified by braces (&apos;{&apos; and &apos;}&apos;).\n        &quot;&quot;&quot;\n        pass\n\n   def index(self, sub, start=None, end=None):  \n        &quot;&quot;&quot; 子序列位置，如果没找到，报错 &quot;&quot;&quot;\n        S.index(sub [,start [,end]]) -&gt; int\n\n        Like S.find() but raise ValueError when the substring is not found.\n        &quot;&quot;&quot;\n        return 0\n\n   def isalnum(self):  \n        &quot;&quot;&quot; 是否是字母和数字 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.isalnum() -&gt; bool\n\n        Return True if all characters in S are alphanumeric\n        and there is at least one character in S, False otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def isalpha(self):  \n        &quot;&quot;&quot; 是否是字母 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.isalpha() -&gt; bool\n\n        Return True if all characters in S are alphabetic\n        and there is at least one character in S, False otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def isdigit(self):  \n        &quot;&quot;&quot; 是否是数字 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.isdigit() -&gt; bool\n\n        Return True if all characters in S are digits\n        and there is at least one character in S, False otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def islower(self):  \n        &quot;&quot;&quot; 是否小写 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.islower() -&gt; bool\n\n        Return True if all cased characters in S are lowercase and there is\n        at least one cased character in S, False otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def isspace(self):  \n        &quot;&quot;&quot;\n        S.isspace() -&gt; bool\n\n        Return True if all characters in S are whitespace\n        and there is at least one character in S, False otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def istitle(self):  \n        &quot;&quot;&quot;\n        S.istitle() -&gt; bool\n\n        Return True if S is a titlecased string and there is at least one\n        character in S, i.e. uppercase characters may only follow uncased\n        characters and lowercase characters only cased ones. Return False\n        otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def isupper(self):  \n        &quot;&quot;&quot;\n        S.isupper() -&gt; bool\n\n        Return True if all cased characters in S are uppercase and there is\n        at least one cased character in S, False otherwise.\n        &quot;&quot;&quot;\n        return False\n\n   def join(self, iterable):  \n        &quot;&quot;&quot; 连接 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.join(iterable) -&gt; string\n\n        Return a string which is the concatenation of the strings in the\n        iterable.  The separator between elements is S.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def ljust(self, width, fillchar=None):  \n        &quot;&quot;&quot; 内容左对齐，右侧填充 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.ljust(width[, fillchar]) -&gt; string\n\n        Return S left-justified in a string of length width. Padding is\n        done using the specified fill character (default is a space).\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def lower(self):  \n        &quot;&quot;&quot; 变小写 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.lower() -&gt; string\n\n        Return a copy of the string S converted to lowercase.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def lstrip(self, chars=None):  \n        &quot;&quot;&quot; 移除左侧空白 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.lstrip([chars]) -&gt; string or unicode\n\n        Return a copy of the string S with leading whitespace removed.\n        If chars is given and not None, remove characters in chars instead.\n        If chars is unicode, S will be converted to unicode before stripping\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def partition(self, sep):  \n        &quot;&quot;&quot; 分割，前，中，后三部分 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.partition(sep) -&gt; (head, sep, tail)\n\n        Search for the separator sep in S, and return the part before it,\n        the separator itself, and the part after it.  If the separator is not\n        found, return S and two empty strings.\n        &quot;&quot;&quot;\n        pass\n\n   def replace(self, old, new, count=None):  \n        &quot;&quot;&quot; 替换 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.replace(old, new[, count]) -&gt; string\n\n        Return a copy of string S with all occurrences of substring\n        old replaced by new.  If the optional argument count is\n        given, only the first count occurrences are replaced.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def rfind(self, sub, start=None, end=None):  \n        &quot;&quot;&quot;\n        S.rfind(sub [,start [,end]]) -&gt; int\n\n        Return the highest index in S where substring sub is found,\n        such that sub is contained within S[start:end].  Optional\n        arguments start and end are interpreted as in slice notation.\n\n        Return -1 on failure.\n        &quot;&quot;&quot;\n        return 0\n\n   def rindex(self, sub, start=None, end=None):  \n        &quot;&quot;&quot;\n        S.rindex(sub [,start [,end]]) -&gt; int\n\n        Like S.rfind() but raise ValueError when the substring is not found.\n        &quot;&quot;&quot;\n        return 0\n\n   def rjust(self, width, fillchar=None):  \n        &quot;&quot;&quot;\n        S.rjust(width[, fillchar]) -&gt; string\n\n        Return S right-justified in a string of length width. Padding is\n        done using the specified fill character (default is a space)\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def rpartition(self, sep):  \n        &quot;&quot;&quot;\n        S.rpartition(sep) -&gt; (head, sep, tail)\n\n        Search for the separator sep in S, starting at the end of S, and return\n        the part before it, the separator itself, and the part after it.  If the\n        separator is not found, return two empty strings and S.\n        &quot;&quot;&quot;\n        pass\n\n   def rsplit(self, sep=None, maxsplit=None):  \n        &quot;&quot;&quot;\n        S.rsplit([sep [,maxsplit]]) -&gt; list of strings\n\n        Return a list of the words in the string S, using sep as the\n        delimiter string, starting at the end of the string and working\n        to the front.  If maxsplit is given, at most maxsplit splits are\n        done. If sep is not specified or is None, any whitespace string\n        is a separator.\n        &quot;&quot;&quot;\n        return []\n\n   def rstrip(self, chars=None):  \n        &quot;&quot;&quot;\n        S.rstrip([chars]) -&gt; string or unicode\n\n        Return a copy of the string S with trailing whitespace removed.\n        If chars is given and not None, remove characters in chars instead.\n        If chars is unicode, S will be converted to unicode before stripping\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def split(self, sep=None, maxsplit=None):  \n        &quot;&quot;&quot; 分割， maxsplit最多分割几次 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.split([sep [,maxsplit]]) -&gt; list of strings\n\n        Return a list of the words in the string S, using sep as the\n        delimiter string.  If maxsplit is given, at most maxsplit\n        splits are done. If sep is not specified or is None, any\n        whitespace string is a separator and empty strings are removed\n        from the result.\n        &quot;&quot;&quot;\n        return []\n\n   def splitlines(self, keepends=False):  \n        &quot;&quot;&quot; 根据换行分割 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.splitlines(keepends=False) -&gt; list of strings\n\n        Return a list of the lines in S, breaking at line boundaries.\n        Line breaks are not included in the resulting list unless keepends\n        is given and true.\n        &quot;&quot;&quot;\n        return []\n\n   def startswith(self, prefix, start=None, end=None):  \n        &quot;&quot;&quot; 是否起始 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.startswith(prefix[, start[, end]]) -&gt; bool\n\n        Return True if S starts with the specified prefix, False otherwise.\n        With optional start, test S beginning at that position.\n        With optional end, stop comparing S at that position.\n        prefix can also be a tuple of strings to try.\n        &quot;&quot;&quot;\n        return False\n\n   def strip(self, chars=None):  \n        &quot;&quot;&quot; 移除两段空白 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.strip([chars]) -&gt; string or unicode\n\n        Return a copy of the string S with leading and trailing\n        whitespace removed.\n        If chars is given and not None, remove characters in chars instead.\n        If chars is unicode, S will be converted to unicode before stripping\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def swapcase(self):  \n        &quot;&quot;&quot; 大写变小写，小写变大写 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.swapcase() -&gt; string\n\n        Return a copy of the string S with uppercase characters\n        converted to lowercase and vice versa.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def title(self):  \n        &quot;&quot;&quot;\n        S.title() -&gt; string\n\n        Return a titlecased version of S, i.e. words start with uppercase\n        characters, all remaining cased characters have lowercase.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def translate(self, table, deletechars=None):  \n        &quot;&quot;&quot;\n        转换，需要先做一个对应表，最后一个表示删除字符集合\n        intab = &quot;aeiou&quot;\n        outtab = &quot;12345&quot;\n        trantab = maketrans(intab, outtab)\n        str = &quot;this is string example....wow!!!&quot;\n        print str.translate(trantab, &apos;xm&apos;)\n        &quot;&quot;&quot;\n\n        &quot;&quot;&quot;\n        S.translate(table [,deletechars]) -&gt; string\n\n        Return a copy of the string S, where all characters occurring\n        in the optional argument deletechars are removed, and the\n        remaining characters have been mapped through the given\n        translation table, which must be a string of length 256 or None.\n        If the table argument is None, no translation is applied and\n        the operation simply removes the characters in deletechars.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def upper(self):  \n        &quot;&quot;&quot;\n        S.upper() -&gt; string\n\n        Return a copy of the string S converted to uppercase.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def zfill(self, width):  \n        &quot;&quot;&quot;方法返回指定长度的字符串，原字符串右对齐，前面填充0。&quot;&quot;&quot;\n        &quot;&quot;&quot;\n        S.zfill(width) -&gt; string\n\n        Pad a numeric string S with zeros on the left, to fill a field\n        of the specified width.  The string S is never truncated.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def _formatter_field_name_split(self, *args, **kwargs): # real signature unknown\n        pass\n\n   def _formatter_parser(self, *args, **kwargs): # real signature unknown\n        pass\n\n   def __add__(self, y):  \n        &quot;&quot;&quot; x.__add__(y) &lt;==&gt; x+y &quot;&quot;&quot;\n        pass\n\n   def __contains__(self, y):  \n        &quot;&quot;&quot; x.__contains__(y) &lt;==&gt; y in x &quot;&quot;&quot;\n        pass\n\n   def __eq__(self, y):  \n        &quot;&quot;&quot; x.__eq__(y) &lt;==&gt; x==y &quot;&quot;&quot;\n        pass\n\n   def __format__(self, format_spec):  \n        &quot;&quot;&quot;\n        S.__format__(format_spec) -&gt; string\n\n        Return a formatted version of S as described by format_spec.\n        &quot;&quot;&quot;\n        return &quot;&quot;\n\n   def __getattribute__(self, name):  \n        &quot;&quot;&quot; x.__getattribute__(&apos;name&apos;) &lt;==&gt; x.name &quot;&quot;&quot;\n        pass\n\n   def __getitem__(self, y):  \n        &quot;&quot;&quot; x.__getitem__(y) &lt;==&gt; x[y] &quot;&quot;&quot;\n        pass\n\n   def __getnewargs__(self, *args, **kwargs): # real signature unknown\n        pass\n\n   def __getslice__(self, i, j):  \n        &quot;&quot;&quot;\n        x.__getslice__(i, j) &lt;==&gt; x[i:j]\n\n        Use of negative indices is not supported.\n        &quot;&quot;&quot;\n        pass\n\n   def __ge__(self, y):  \n        &quot;&quot;&quot; x.__ge__(y) &lt;==&gt; x&gt;=y &quot;&quot;&quot;\n        pass\n\n   def __gt__(self, y):  \n        &quot;&quot;&quot; x.__gt__(y) &lt;==&gt; x&gt;y &quot;&quot;&quot;\n        pass\n\n   def __hash__(self):  \n        &quot;&quot;&quot; x.__hash__() &lt;==&gt; hash(x) &quot;&quot;&quot;\n        pass\n\n   def __init__(self, string=&apos;&apos;): # known special case of str.__init__\n        &quot;&quot;&quot;\n        str(object=&apos;&apos;) -&gt; string\n\n        Return a nice string representation of the object.\n        If the argument is a string, the return value is the same object.\n        # (copied from class doc)\n        &quot;&quot;&quot;\n        pass\n\n   def __len__(self):  \n        &quot;&quot;&quot; x.__len__() &lt;==&gt; len(x) &quot;&quot;&quot;\n        pass\n\n   def __le__(self, y):  \n        &quot;&quot;&quot; x.__le__(y) &lt;==&gt; x&lt;=y &quot;&quot;&quot;\n        pass\n\n   def __lt__(self, y):  \n        &quot;&quot;&quot; x.__lt__(y) &lt;==&gt; x&lt;y &quot;&quot;&quot;\n        pass\n\n   def __mod__(self, y):  \n        &quot;&quot;&quot; x.__mod__(y) &lt;==&gt; x%y &quot;&quot;&quot;\n        pass\n\n   def __mul__(self, n):  \n        &quot;&quot;&quot; x.__mul__(n) &lt;==&gt; x*n &quot;&quot;&quot;\n        pass\n\n        @staticmethod # known case of __new__\n   def __new__(S, *more):  \n        &quot;&quot;&quot; T.__new__(S, ...) -&gt; a new object with type S, a subtype of T &quot;&quot;&quot;\n        pass\n\n   def __ne__(self, y):  \n        &quot;&quot;&quot; x.__ne__(y) &lt;==&gt; x!=y &quot;&quot;&quot;\n        pass\n\n   def __repr__(self):  \n        &quot;&quot;&quot; x.__repr__() &lt;==&gt; repr(x) &quot;&quot;&quot;\n        pass\n\n   def __rmod__(self, y):  \n        &quot;&quot;&quot; x.__rmod__(y) &lt;==&gt; y%x &quot;&quot;&quot;\n        pass\n\n   def __rmul__(self, n):  \n        &quot;&quot;&quot; x.__rmul__(n) &lt;==&gt; n*x &quot;&quot;&quot;\n        pass\n\n   def __sizeof__(self):  \n        &quot;&quot;&quot; S.__sizeof__() -&gt; size of S in memory, in bytes &quot;&quot;&quot;\n        pass\n\n   def __str__(self):  \n        &quot;&quot;&quot; x.__str__() &lt;==&gt; str(x) &quot;&quot;&quot;\n        pass\n</code></pre><h2 id=\"int数字\"><a href=\"#int数字\" class=\"headerlink\" title=\"int数字\"></a>int数字</h2><pre><code>class int(object):\n    &quot;&quot;&quot;\n      int(x=0) -&gt; int or long\n     int(x, base=10) -&gt; int or long\n\n     Convert a number or string to an integer, or return 0 if no arguments\n     are given.  If x is floating point, the conversion truncates towards zero.\n     If x is outside the integer range, the function returns a long instead.\n\n     If x is not a number or if base is given, then x must be a string or\n     Unicode object representing an integer literal in the given base.  The\n     literal can be preceded by &apos;+&apos; or &apos;-&apos; and be surrounded by whitespace.\n     The base defaults to 10.  Valid bases are 0 and 2-36.  Base 0 means to\n     interpret the base from the string as an integer literal.\n     &gt;&gt;&gt; int(&apos;0b100&apos;, base=0)\n     4\n    &quot;&quot;&quot;\n   def bit_length(self): \n        &quot;&quot;&quot; 返回表示该数字的时占用的最少位数 &quot;&quot;&quot;\n        &quot;&quot;&quot;\n        int.bit_length() -&gt; int\n\n        Number of bits necessary to represent self in binary.\n        &gt;&gt;&gt; bin(37)\n        &apos;0b100101&apos;\n        &gt;&gt;&gt; (37).bit_length()\n        6\n        &quot;&quot;&quot;\n        return 0\n\n   def conjugate(self, *args, **kwargs): # real signature unknown\n        &quot;&quot;&quot; 返回该复数的共轭复数 &quot;&quot;&quot;\n        &quot;&quot;&quot; Returns self, the complex conjugate of any int. &quot;&quot;&quot;\n        pass\n\n   def __abs__(self):\n        &quot;&quot;&quot; 返回绝对值 &quot;&quot;&quot;\n        &quot;&quot;&quot; x.__abs__() &lt;==&gt; abs(x) &quot;&quot;&quot;\n        pass\n\n   def __add__(self, y):\n        &quot;&quot;&quot; x.__add__(y) &lt;==&gt; x+y &quot;&quot;&quot;\n        pass\n\n   def __and__(self, y):\n        &quot;&quot;&quot; x.__and__(y) &lt;==&gt; x&amp;y &quot;&quot;&quot;\n        pass\n\n   def __cmp__(self, y): \n        &quot;&quot;&quot; 比较两个数大小 &quot;&quot;&quot;\n        &quot;&quot;&quot; x.__cmp__(y) &lt;==&gt; cmp(x,y) &quot;&quot;&quot;\n        pass\n\n   def __coerce__(self, y):\n        &quot;&quot;&quot; 强制生成一个元组 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__coerce__(y) &lt;==&gt; coerce(x, y) &quot;&quot;&quot;\n        pass\n\n   def __divmod__(self, y): \n        &quot;&quot;&quot; 相除，得到商和余数组成的元组 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__divmod__(y) &lt;==&gt; divmod(x, y) &quot;&quot;&quot;\n        pass\n\n   def __div__(self, y): \n        &quot;&quot;&quot; x.__div__(y) &lt;==&gt; x/y &quot;&quot;&quot;\n        pass\n\n   def __float__(self): \n        &quot;&quot;&quot; 转换为浮点类型 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__float__() &lt;==&gt; float(x) &quot;&quot;&quot;\n        pass\n\n   def __floordiv__(self, y): \n        &quot;&quot;&quot; x.__floordiv__(y) &lt;==&gt; x//y &quot;&quot;&quot;\n        pass\n\n   def __format__(self, *args, **kwargs): # real signature unknown\n        pass\n\n   def __getattribute__(self, name): \n        &quot;&quot;&quot; x.__getattribute__(&apos;name&apos;) &lt;==&gt; x.name &quot;&quot;&quot;\n        pass\n\n   def __getnewargs__(self, *args, **kwargs): # real signature unknown\n        &quot;&quot;&quot; 内部调用 __new__方法或创建对象时传入参数使用 &quot;&quot;&quot; \n        pass\n\n   def __hash__(self): \n        &quot;&quot;&quot;如果对象object为哈希表类型，返回对象object的哈希值。哈希值为整数。在字典查找中，哈希值用于快速比较字典的键。两个数值如果相等，则哈希值也相等。&quot;&quot;&quot;\n        &quot;&quot;&quot; x.__hash__() &lt;==&gt; hash(x) &quot;&quot;&quot;\n        pass\n\n   def __hex__(self): \n        &quot;&quot;&quot; 返回当前数的 十六进制 表示 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__hex__() &lt;==&gt; hex(x) &quot;&quot;&quot;\n        pass\n\n   def __index__(self): \n        &quot;&quot;&quot; 用于切片，数字无意义 &quot;&quot;&quot;\n        &quot;&quot;&quot; x[y:z] &lt;==&gt; x[y.__index__():z.__index__()] &quot;&quot;&quot;\n        pass\n\n   def __init__(self, x, base=10): # known special case of int.__init__\n        &quot;&quot;&quot; 构造方法，执行 x = 123 或 x = int(10) 时，自动调用，暂时忽略 &quot;&quot;&quot; \n        &quot;&quot;&quot;\n        int(x=0) -&gt; int or long\n        int(x, base=10) -&gt; int or long\n\n        Convert a number or string to an integer, or return 0 if no arguments\n        are given.  If x is floating point, the conversion truncates towards zero.\n        If x is outside the integer range, the function returns a long instead.\n\n        If x is not a number or if base is given, then x must be a string or\n        Unicode object representing an integer literal in the given base.  The\n        literal can be preceded by &apos;+&apos; or &apos;-&apos; and be surrounded by whitespace.\n        The base defaults to 10.  Valid bases are 0 and 2-36.  Base 0 means to\n        interpret the base from the string as an integer literal.\n        &gt;&gt;&gt; int(&apos;0b100&apos;, base=0)\n        4\n        # (copied from class doc)\n        &quot;&quot;&quot;\n        pass\n\n   def __int__(self): \n        &quot;&quot;&quot; 转换为整数 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__int__() &lt;==&gt; int(x) &quot;&quot;&quot;\n        pass\n\n   def __invert__(self): \n        &quot;&quot;&quot; x.__invert__() &lt;==&gt; ~x &quot;&quot;&quot;\n        pass\n\n   def __long__(self): \n        &quot;&quot;&quot; 转换为长整数 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__long__() &lt;==&gt; long(x) &quot;&quot;&quot;\n        pass\n\n   def __lshift__(self, y): \n        &quot;&quot;&quot; x.__lshift__(y) &lt;==&gt; x&lt;&lt;y &quot;&quot;&quot;\n    pass\n\n   def __mod__(self, y): \n        &quot;&quot;&quot; x.__mod__(y) &lt;==&gt; x%y &quot;&quot;&quot;\n        pass\n\n   def __mul__(self, y): \n        &quot;&quot;&quot; x.__mul__(y) &lt;==&gt; x*y &quot;&quot;&quot;\n        pass\n\n   def __neg__(self): \n        &quot;&quot;&quot; x.__neg__() &lt;==&gt; -x &quot;&quot;&quot;\n        pass\n\n        @staticmethod # known case of __new__\n   def __new__(S, *more): \n        &quot;&quot;&quot; T.__new__(S, ...) -&gt; a new object with type S, a subtype of T &quot;&quot;&quot;\n        pass\n\n   def __nonzero__(self): \n        &quot;&quot;&quot; x.__nonzero__() &lt;==&gt; x != 0 &quot;&quot;&quot;\n        pass\n\n   def __oct__(self): \n        &quot;&quot;&quot; 返回改值的 八进制 表示 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__oct__() &lt;==&gt; oct(x) &quot;&quot;&quot;\n        pass\n\n   def __or__(self, y): \n        &quot;&quot;&quot; x.__or__(y) &lt;==&gt; x|y &quot;&quot;&quot;\n        pass\n\n   def __pos__(self): \n        &quot;&quot;&quot; x.__pos__() &lt;==&gt; +x &quot;&quot;&quot;\n        pass\n\n   def __pow__(self, y, z=None): \n        &quot;&quot;&quot; 幂，次方 &quot;&quot;&quot; \n        &quot;&quot;&quot; x.__pow__(y[, z]) &lt;==&gt; pow(x, y[, z]) &quot;&quot;&quot;\n        pass\n\n   def __radd__(self, y): \n        &quot;&quot;&quot; x.__radd__(y) &lt;==&gt; y+x &quot;&quot;&quot;\n        pass\n\n   def __rand__(self, y): \n        &quot;&quot;&quot; x.__rand__(y) &lt;==&gt; y&amp;x &quot;&quot;&quot;\n        pass\n\n   def __rdivmod__(self, y): \n        &quot;&quot;&quot; x.__rdivmod__(y) &lt;==&gt; divmod(y, x) &quot;&quot;&quot;\n        pass\n\n   def __rdiv__(self, y): \n        &quot;&quot;&quot; x.__rdiv__(y) &lt;==&gt; y/x &quot;&quot;&quot;\n        pass\n\n   def __repr__(self): \n        &quot;&quot;&quot;转化为解释器可读取的形式 &quot;&quot;&quot;\n        &quot;&quot;&quot; x.__repr__() &lt;==&gt; repr(x) &quot;&quot;&quot;\n        pass\n\n   def __str__(self): \n        &quot;&quot;&quot;转换为人阅读的形式，如果没有适于人阅读的解释形式的话，则返回解释器课阅读的形式&quot;&quot;&quot;\n        &quot;&quot;&quot; x.__str__() &lt;==&gt; str(x) &quot;&quot;&quot;\n        pass\n\n   def __rfloordiv__(self, y): \n        &quot;&quot;&quot; x.__rfloordiv__(y) &lt;==&gt; y//x &quot;&quot;&quot;\n        pass\n\n   def __rlshift__(self, y): \n        &quot;&quot;&quot; x.__rlshift__(y) &lt;==&gt; y&lt;&lt;x &quot;&quot;&quot;\n        pass\n\n   def __rmod__(self, y): \n        &quot;&quot;&quot; x.__rmod__(y) &lt;==&gt; y%x &quot;&quot;&quot;\n        pass\n\n   def __rmul__(self, y): \n        &quot;&quot;&quot; x.__rmul__(y) &lt;==&gt; y*x &quot;&quot;&quot;\n        pass\n\n   def __ror__(self, y): \n        &quot;&quot;&quot; x.__ror__(y) &lt;==&gt; y|x &quot;&quot;&quot;\n        pass\n\n   def __rpow__(self, x, z=None): \n        &quot;&quot;&quot; y.__rpow__(x[, z]) &lt;==&gt; pow(x, y[, z]) &quot;&quot;&quot;\n        pass\n\n   def __rrshift__(self, y): \n        &quot;&quot;&quot; x.__rrshift__(y) &lt;==&gt; y&gt;&gt;x &quot;&quot;&quot;\n        pass\n\n   def __rshift__(self, y): \n        &quot;&quot;&quot; x.__rshift__(y) &lt;==&gt; x&gt;&gt;y &quot;&quot;&quot;\n        pass\n\n   def __rsub__(self, y): \n        &quot;&quot;&quot; x.__rsub__(y) &lt;==&gt; y-x &quot;&quot;&quot;\n        pass\n\n   def __rtruediv__(self, y): \n        &quot;&quot;&quot; x.__rtruediv__(y) &lt;==&gt; y/x &quot;&quot;&quot;\n        pass\n\n   def __rxor__(self, y): \n        &quot;&quot;&quot; x.__rxor__(y) &lt;==&gt; y^x &quot;&quot;&quot;\n        pass\n\n   def __sub__(self, y): \n        &quot;&quot;&quot; x.__sub__(y) &lt;==&gt; x-y &quot;&quot;&quot;\n        pass\n\n   def __truediv__(self, y): \n        &quot;&quot;&quot; x.__truediv__(y) &lt;==&gt; x/y &quot;&quot;&quot;\n        pass\n\n   def __trunc__(self, *args, **kwargs): \n        &quot;&quot;&quot; 返回数值被截取为整形的值，在整形中无意义 &quot;&quot;&quot;\n        pass\n\n   def __xor__(self, y): \n        &quot;&quot;&quot; x.__xor__(y) &lt;==&gt; x^y &quot;&quot;&quot;\n        pass\n\n        denominator = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n        &quot;&quot;&quot; 分母 = 1 &quot;&quot;&quot;\n        &quot;&quot;&quot;the denominator of a rational number in lowest terms&quot;&quot;&quot;\n\n        imag = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n        &quot;&quot;&quot; 虚数，无意义 &quot;&quot;&quot;\n        &quot;&quot;&quot;the imaginary part of a complex number&quot;&quot;&quot;\n\n        numerator = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n        &quot;&quot;&quot; 分子 = 数字大小 &quot;&quot;&quot;\n        &quot;&quot;&quot;the numerator of a rational number in lowest terms&quot;&quot;&quot;\n\n        real = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default\n        &quot;&quot;&quot; 实属，无意义 &quot;&quot;&quot;\n        &quot;&quot;&quot;the real part of a complex number&quot;&quot;&quot;\n</code></pre>"},{"title":"Traefik-kubernetes 初试","date":"2019-06-27T04:00:00.000Z","_content":"\n# Traefik-kubernetes 初试\n> traefik 是一个前端负载均衡器，对于微服务架构尤其是 kubernetes 等编排工具具有良好的支持；同 nginx 等相比，traefik 能够自动感知后端容器变化，从而实现自动服务发现；今天小试了一下，在此记录一下使用过程\n<!--more-->\n\n从 kubernetes 1.2 版本开始，kubernetes提供了 Ingress 对象来实现对外暴露服务；到目前为止 kubernetes 总共有三种暴露服务的方式:\n\n 1. LoadBlancer Service\n 2. NodePort Service\n 3. Ingress\n \n## LoadBlancer Service\nLoadBlancer Service 是 kubernetes 深度结合云平台的一个组件；当使用 LoadBlancer Service 暴露服务时，实际上是通过向底层云平台申请创建一个负载均衡器来向外暴露服务；目前 LoadBlancer Service 支持的云平台已经相对完善，比如国外的 GCE、DigitalOcean，国内的 阿里云，私有云 Openstack 等等，由于 LoadBlancer Service 深度结合了云平台，所以只能在一些云平台上来使用\n\n## NodePort Service\nNodePort Service 顾名思义，实质上就是通过在集群的每个 node 上暴露一个端口，然后将这个端口映射到某个具体的 service 来实现的，虽然每个 node 的端口有很多(0~65535)，但是由于安全性和易用性(服务多了就乱了，还有端口冲突问题)实际使用可能并不多\n\n### Ingress\nIngress 这个东西是 1.2 后才出现的，通过 Ingress 用户可以实现使用 nginx 等开源的反向代理负载均衡器实现对外暴露服务，以下详细说一下 Ingress，毕竟 traefik 用的就是 Ingress\n ### 使用 Ingress 时一般会有三个组件:\n   1. 反向代理负载均衡器\n   2. Ingress Controller\n   3. Ingress\n\n### 反向代理负载均衡器\n反向代理负载均衡器很简单，说白了就是 nginx、apache 什么的；在集群中反向代理负载均衡器可以自由部署，可以使用 Replication Controller、Deployment、DaemonSet 等等，不过个人喜欢以 DaemonSet 的方式部署，感觉比较方便\n \n## Ingress Controller\nIngress Controller 实质上可以理解为是个监视器，Ingress Controller 通过不断地跟 kubernetes API 打交道，实时的感知后端 service、pod 等变化，比如新增和减少 pod，service 增加与减少等；当得到这些变化信息后，Ingress Controller 再结合下文的 Ingress 生成配置，然后更新反向代理负载均衡器，并刷新其配置，达到服务发现的作用\n\n### Ingress\nIngress 简单理解就是个规则定义；比如说某个域名对应某个 service，即当某个域名的请求进来时转发给某个 service;这个规则将与 Ingress Controller 结合，然后 Ingress Controller 将其动态写入到负载均衡器配置中，从而实现整体的服务发现和负载均衡\n\n![](http://www.liuhaihua.cn/wp-content/uploads/2016/12/IJJV3qV.jpg)\n从上图中可以很清晰的看到，实际上请求进来还是被负载均衡器拦截，比如 nginx，然后 Ingress Controller 通过跟 Ingress 交互得知某个域名对应哪个 service，再通过跟 kubernetes API 交互得知 service 地址等信息；综合以后生成配置文件实时写入负载均衡器，然后负载均衡器 reload 该规则便可实现服务发现，即动态映射\n\n了解了以上内容以后，这也就很好的说明了我为什么喜欢把负载均衡器部署为 Daemon Set；因为无论如何请求首先是被负载均衡器拦截的，所以在每个 node 上都部署一下，同时 hostport 方式监听 80 端口；那么就解决了其他方式部署不确定 负载均衡器在哪的问题，同时访问每个 node 的 80 都能正确解析请求；如果前端再 放个 nginx 就又实现了一层负载均衡\n# Traefik 使用\n由于微服务架构以及 Docker 技术和 kubernetes 编排工具最近几年才开始逐渐流行，所以一开始的反向代理服务器比如 nginx、apache 并未提供其支持，毕竟他们也不是先知；所以才会出现 Ingress Controller 这种东西来做 kubernetes 和前端负载均衡器如 nginx 之间做衔接；即 Ingress Controller 的存在就是为了能跟 kubernetes 交互，又能写 nginx 配置，还能 reload 它，这是一种折中方案；而最近开始出现的 traefik 天生就是提供了对 kubernetes 的支持，也就是说 traefik 本身就能跟 kubernetes API 交互，感知后端变化，因此可以得知: 在使用 traefik 时，Ingress Controller 已经无卵用了，所以整体架构如下\n![](http://www.liuhaihua.cn/wp-content/uploads/2016/12/Rfe67b3.jpg)\n## 部署 Traefik\n已经从大体上搞懂了 Ingress 和 traefik，那么部署起来就很简单\n### 部署 Daemon Set\n首先以 Daemon Set 的方式在每个 node 上启动一个 traefik，并使用 hostPort 的方式让其监听每个 node 的 80 端口(有没有感觉这就是个 NodePort? 不过区别就是这个 Port 后面有负载均衡器 –>手动)\n\n```\nkubectl create -f traefik.ds.yaml\n\n # Daemon set 文件如下\napiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  name: traefik-ingress-lb\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      terminationGracePeriodSeconds: 60\n      hostNetwork: true\n      restartPolicy: Always\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        resources:\n          limits:\n            cpu: 200m\n            memory: 30Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n        - name: admin\n          containerPort: 8580\n        args:\n        - --web\n        - --web.address=:8580\n        - --kubernetes\n```\n其中 traefik 监听 node 的 80 和 8580 端口，80 提供正常服务，8580 是其自带的 UI 界面，原本默认是 8080，因为环境里端口冲突了，所以这里临时改一下\n### 部署 Ingress\n从上面的长篇大论已经得知了 Ingress Controller 是无需部署的，所以直接部署 Ingress 即可\n```\nkubectl create -f traefik.ing.yaml\n\n# Ingress 文件如下\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: traefik-ingress\nspec:\n  rules:\n  - host: traefik.www.test.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: test-www\n          servicePort: 8080\n  - host: traefik.api.test.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: test-api\n          servicePort: 8080\n```\n实际上事先集群中已经存在了相应的名为 test-www 和 test-api 的 service，对应的 service 后端也有很多 pod；所以这里就不在具体写部署实际业务容器(test-www、test-api)的过程了，各位测试时，只需要把这个 test 的 service 替换成自己业务的 service 即可\n\n### 部署 Traefik UI\ntraefik 本身还提供了一套 UI 供我们使用，其同样以 Ingress 方式暴露，只需要创建一下即可\n\n```\nkubectl create -f ui.yaml\n\n# ui yaml 如下\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n  - name: web\n    port: 80\n    targetPort: 8580\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\nspec:\n  rules:\n  - host: traefik-ui.local\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: traefik-web-ui\n          servicePort: web\n```\n### 访问测试\n都创建无误以后，只需要将待测试的域名解析到任意一台 node 上即可，页面就不截图了，截图就暴露了…..下面来两张 ui 的\n![](http://www.liuhaihua.cn/wp-content/uploads/2016/12/ErURbiu.jpg)\n![](http://www.liuhaihua.cn/wp-content/uploads/2016/12/qaMjqir.jpg)\n## 健康检查\n关于健康检查，测试可以使用 kubernetes 的 Liveness Probe 实现，如果 Liveness Probe检查失败，则 traefik 会自动移除该 pod，以下是一个 示例\n\ntest 的 deployment，健康检查方式是 cat /tmp/health，容器启动 2 分钟后会删掉这个文件，模拟健康检查失败\n```\napiVersion: v1\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: test\n  namespace: default\n  labels:\n    test: alpine\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      test: alpine\n  template:\n    metadata:\n      labels:\n        test: alpine\n        name: test\n    spec:\n      containers:\n      - image: mritd/alpine:3.4\n        name: alpine\n        resources:\n          limits:\n            cpu: 200m\n            memory: 30Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n        ports:\n        - name: http\n          containerPort: 80\n        args:\n        command:\n        - \"bash\"\n        - \"-c\"\n        - \"echo ok > /tmp/health;sleep 120;rm -f /tmp/health\"\n        livenessProbe:\n          exec:\n            command:\n            - cat\n            - /tmp/health\n          initialDelaySeconds: 20\n```\n\ntest 的 service\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: test \n  labels:\n    name: test\nspec:\n  ports:\n  - port: 8123\n    targetPort: 80\n  selector:\n    name: test\n\n```\ntest 的 Ingress\n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: test\nspec:\n  rules:\n  - host: test.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: test\n          servicePort: 8123\n```\n全部创建好以后，进入 traefik ui 界面，可以观察到每隔 2 分钟健康检查失败后，kubernetes 重建 pod，同时 traefik 会从后端列表中移除这个 pod\n\n","source":"_posts/Traefik-kubernetes 初试.md","raw":"---\ntitle: Traefik-kubernetes 初试\ndate: 2019-06-27\ntags: ingress\ncategories: ingress\n---\n\n# Traefik-kubernetes 初试\n> traefik 是一个前端负载均衡器，对于微服务架构尤其是 kubernetes 等编排工具具有良好的支持；同 nginx 等相比，traefik 能够自动感知后端容器变化，从而实现自动服务发现；今天小试了一下，在此记录一下使用过程\n<!--more-->\n\n从 kubernetes 1.2 版本开始，kubernetes提供了 Ingress 对象来实现对外暴露服务；到目前为止 kubernetes 总共有三种暴露服务的方式:\n\n 1. LoadBlancer Service\n 2. NodePort Service\n 3. Ingress\n \n## LoadBlancer Service\nLoadBlancer Service 是 kubernetes 深度结合云平台的一个组件；当使用 LoadBlancer Service 暴露服务时，实际上是通过向底层云平台申请创建一个负载均衡器来向外暴露服务；目前 LoadBlancer Service 支持的云平台已经相对完善，比如国外的 GCE、DigitalOcean，国内的 阿里云，私有云 Openstack 等等，由于 LoadBlancer Service 深度结合了云平台，所以只能在一些云平台上来使用\n\n## NodePort Service\nNodePort Service 顾名思义，实质上就是通过在集群的每个 node 上暴露一个端口，然后将这个端口映射到某个具体的 service 来实现的，虽然每个 node 的端口有很多(0~65535)，但是由于安全性和易用性(服务多了就乱了，还有端口冲突问题)实际使用可能并不多\n\n### Ingress\nIngress 这个东西是 1.2 后才出现的，通过 Ingress 用户可以实现使用 nginx 等开源的反向代理负载均衡器实现对外暴露服务，以下详细说一下 Ingress，毕竟 traefik 用的就是 Ingress\n ### 使用 Ingress 时一般会有三个组件:\n   1. 反向代理负载均衡器\n   2. Ingress Controller\n   3. Ingress\n\n### 反向代理负载均衡器\n反向代理负载均衡器很简单，说白了就是 nginx、apache 什么的；在集群中反向代理负载均衡器可以自由部署，可以使用 Replication Controller、Deployment、DaemonSet 等等，不过个人喜欢以 DaemonSet 的方式部署，感觉比较方便\n \n## Ingress Controller\nIngress Controller 实质上可以理解为是个监视器，Ingress Controller 通过不断地跟 kubernetes API 打交道，实时的感知后端 service、pod 等变化，比如新增和减少 pod，service 增加与减少等；当得到这些变化信息后，Ingress Controller 再结合下文的 Ingress 生成配置，然后更新反向代理负载均衡器，并刷新其配置，达到服务发现的作用\n\n### Ingress\nIngress 简单理解就是个规则定义；比如说某个域名对应某个 service，即当某个域名的请求进来时转发给某个 service;这个规则将与 Ingress Controller 结合，然后 Ingress Controller 将其动态写入到负载均衡器配置中，从而实现整体的服务发现和负载均衡\n\n![](http://www.liuhaihua.cn/wp-content/uploads/2016/12/IJJV3qV.jpg)\n从上图中可以很清晰的看到，实际上请求进来还是被负载均衡器拦截，比如 nginx，然后 Ingress Controller 通过跟 Ingress 交互得知某个域名对应哪个 service，再通过跟 kubernetes API 交互得知 service 地址等信息；综合以后生成配置文件实时写入负载均衡器，然后负载均衡器 reload 该规则便可实现服务发现，即动态映射\n\n了解了以上内容以后，这也就很好的说明了我为什么喜欢把负载均衡器部署为 Daemon Set；因为无论如何请求首先是被负载均衡器拦截的，所以在每个 node 上都部署一下，同时 hostport 方式监听 80 端口；那么就解决了其他方式部署不确定 负载均衡器在哪的问题，同时访问每个 node 的 80 都能正确解析请求；如果前端再 放个 nginx 就又实现了一层负载均衡\n# Traefik 使用\n由于微服务架构以及 Docker 技术和 kubernetes 编排工具最近几年才开始逐渐流行，所以一开始的反向代理服务器比如 nginx、apache 并未提供其支持，毕竟他们也不是先知；所以才会出现 Ingress Controller 这种东西来做 kubernetes 和前端负载均衡器如 nginx 之间做衔接；即 Ingress Controller 的存在就是为了能跟 kubernetes 交互，又能写 nginx 配置，还能 reload 它，这是一种折中方案；而最近开始出现的 traefik 天生就是提供了对 kubernetes 的支持，也就是说 traefik 本身就能跟 kubernetes API 交互，感知后端变化，因此可以得知: 在使用 traefik 时，Ingress Controller 已经无卵用了，所以整体架构如下\n![](http://www.liuhaihua.cn/wp-content/uploads/2016/12/Rfe67b3.jpg)\n## 部署 Traefik\n已经从大体上搞懂了 Ingress 和 traefik，那么部署起来就很简单\n### 部署 Daemon Set\n首先以 Daemon Set 的方式在每个 node 上启动一个 traefik，并使用 hostPort 的方式让其监听每个 node 的 80 端口(有没有感觉这就是个 NodePort? 不过区别就是这个 Port 后面有负载均衡器 –>手动)\n\n```\nkubectl create -f traefik.ds.yaml\n\n # Daemon set 文件如下\napiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  name: traefik-ingress-lb\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      terminationGracePeriodSeconds: 60\n      hostNetwork: true\n      restartPolicy: Always\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        resources:\n          limits:\n            cpu: 200m\n            memory: 30Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n        - name: admin\n          containerPort: 8580\n        args:\n        - --web\n        - --web.address=:8580\n        - --kubernetes\n```\n其中 traefik 监听 node 的 80 和 8580 端口，80 提供正常服务，8580 是其自带的 UI 界面，原本默认是 8080，因为环境里端口冲突了，所以这里临时改一下\n### 部署 Ingress\n从上面的长篇大论已经得知了 Ingress Controller 是无需部署的，所以直接部署 Ingress 即可\n```\nkubectl create -f traefik.ing.yaml\n\n# Ingress 文件如下\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: traefik-ingress\nspec:\n  rules:\n  - host: traefik.www.test.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: test-www\n          servicePort: 8080\n  - host: traefik.api.test.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: test-api\n          servicePort: 8080\n```\n实际上事先集群中已经存在了相应的名为 test-www 和 test-api 的 service，对应的 service 后端也有很多 pod；所以这里就不在具体写部署实际业务容器(test-www、test-api)的过程了，各位测试时，只需要把这个 test 的 service 替换成自己业务的 service 即可\n\n### 部署 Traefik UI\ntraefik 本身还提供了一套 UI 供我们使用，其同样以 Ingress 方式暴露，只需要创建一下即可\n\n```\nkubectl create -f ui.yaml\n\n# ui yaml 如下\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n  - name: web\n    port: 80\n    targetPort: 8580\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\nspec:\n  rules:\n  - host: traefik-ui.local\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: traefik-web-ui\n          servicePort: web\n```\n### 访问测试\n都创建无误以后，只需要将待测试的域名解析到任意一台 node 上即可，页面就不截图了，截图就暴露了…..下面来两张 ui 的\n![](http://www.liuhaihua.cn/wp-content/uploads/2016/12/ErURbiu.jpg)\n![](http://www.liuhaihua.cn/wp-content/uploads/2016/12/qaMjqir.jpg)\n## 健康检查\n关于健康检查，测试可以使用 kubernetes 的 Liveness Probe 实现，如果 Liveness Probe检查失败，则 traefik 会自动移除该 pod，以下是一个 示例\n\ntest 的 deployment，健康检查方式是 cat /tmp/health，容器启动 2 分钟后会删掉这个文件，模拟健康检查失败\n```\napiVersion: v1\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: test\n  namespace: default\n  labels:\n    test: alpine\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      test: alpine\n  template:\n    metadata:\n      labels:\n        test: alpine\n        name: test\n    spec:\n      containers:\n      - image: mritd/alpine:3.4\n        name: alpine\n        resources:\n          limits:\n            cpu: 200m\n            memory: 30Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n        ports:\n        - name: http\n          containerPort: 80\n        args:\n        command:\n        - \"bash\"\n        - \"-c\"\n        - \"echo ok > /tmp/health;sleep 120;rm -f /tmp/health\"\n        livenessProbe:\n          exec:\n            command:\n            - cat\n            - /tmp/health\n          initialDelaySeconds: 20\n```\n\ntest 的 service\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: test \n  labels:\n    name: test\nspec:\n  ports:\n  - port: 8123\n    targetPort: 80\n  selector:\n    name: test\n\n```\ntest 的 Ingress\n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: test\nspec:\n  rules:\n  - host: test.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: test\n          servicePort: 8123\n```\n全部创建好以后，进入 traefik ui 界面，可以观察到每隔 2 分钟健康检查失败后，kubernetes 重建 pod，同时 traefik 会从后端列表中移除这个 pod\n\n","slug":"Traefik-kubernetes 初试","published":1,"updated":"2019-06-28T02:14:58.289Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sii0007hcb71vse8n35","content":"<h1 id=\"Traefik-kubernetes-初试\"><a href=\"#Traefik-kubernetes-初试\" class=\"headerlink\" title=\"Traefik-kubernetes 初试\"></a>Traefik-kubernetes 初试</h1><blockquote>\n<p>traefik 是一个前端负载均衡器，对于微服务架构尤其是 kubernetes 等编排工具具有良好的支持；同 nginx 等相比，traefik 能够自动感知后端容器变化，从而实现自动服务发现；今天小试了一下，在此记录一下使用过程<br><a id=\"more\"></a></p>\n</blockquote>\n<p>从 kubernetes 1.2 版本开始，kubernetes提供了 Ingress 对象来实现对外暴露服务；到目前为止 kubernetes 总共有三种暴露服务的方式:</p>\n<ol>\n<li>LoadBlancer Service</li>\n<li>NodePort Service</li>\n<li>Ingress</li>\n</ol>\n<h2 id=\"LoadBlancer-Service\"><a href=\"#LoadBlancer-Service\" class=\"headerlink\" title=\"LoadBlancer Service\"></a>LoadBlancer Service</h2><p>LoadBlancer Service 是 kubernetes 深度结合云平台的一个组件；当使用 LoadBlancer Service 暴露服务时，实际上是通过向底层云平台申请创建一个负载均衡器来向外暴露服务；目前 LoadBlancer Service 支持的云平台已经相对完善，比如国外的 GCE、DigitalOcean，国内的 阿里云，私有云 Openstack 等等，由于 LoadBlancer Service 深度结合了云平台，所以只能在一些云平台上来使用</p>\n<h2 id=\"NodePort-Service\"><a href=\"#NodePort-Service\" class=\"headerlink\" title=\"NodePort Service\"></a>NodePort Service</h2><p>NodePort Service 顾名思义，实质上就是通过在集群的每个 node 上暴露一个端口，然后将这个端口映射到某个具体的 service 来实现的，虽然每个 node 的端口有很多(0~65535)，但是由于安全性和易用性(服务多了就乱了，还有端口冲突问题)实际使用可能并不多</p>\n<h3 id=\"Ingress\"><a href=\"#Ingress\" class=\"headerlink\" title=\"Ingress\"></a>Ingress</h3><p>Ingress 这个东西是 1.2 后才出现的，通过 Ingress 用户可以实现使用 nginx 等开源的反向代理负载均衡器实现对外暴露服务，以下详细说一下 Ingress，毕竟 traefik 用的就是 Ingress</p>\n<h3 id=\"使用-Ingress-时一般会有三个组件\"><a href=\"#使用-Ingress-时一般会有三个组件\" class=\"headerlink\" title=\"使用 Ingress 时一般会有三个组件:\"></a>使用 Ingress 时一般会有三个组件:</h3><ol>\n<li>反向代理负载均衡器</li>\n<li>Ingress Controller</li>\n<li>Ingress</li>\n</ol>\n<h3 id=\"反向代理负载均衡器\"><a href=\"#反向代理负载均衡器\" class=\"headerlink\" title=\"反向代理负载均衡器\"></a>反向代理负载均衡器</h3><p>反向代理负载均衡器很简单，说白了就是 nginx、apache 什么的；在集群中反向代理负载均衡器可以自由部署，可以使用 Replication Controller、Deployment、DaemonSet 等等，不过个人喜欢以 DaemonSet 的方式部署，感觉比较方便</p>\n<h2 id=\"Ingress-Controller\"><a href=\"#Ingress-Controller\" class=\"headerlink\" title=\"Ingress Controller\"></a>Ingress Controller</h2><p>Ingress Controller 实质上可以理解为是个监视器，Ingress Controller 通过不断地跟 kubernetes API 打交道，实时的感知后端 service、pod 等变化，比如新增和减少 pod，service 增加与减少等；当得到这些变化信息后，Ingress Controller 再结合下文的 Ingress 生成配置，然后更新反向代理负载均衡器，并刷新其配置，达到服务发现的作用</p>\n<h3 id=\"Ingress-1\"><a href=\"#Ingress-1\" class=\"headerlink\" title=\"Ingress\"></a>Ingress</h3><p>Ingress 简单理解就是个规则定义；比如说某个域名对应某个 service，即当某个域名的请求进来时转发给某个 service;这个规则将与 Ingress Controller 结合，然后 Ingress Controller 将其动态写入到负载均衡器配置中，从而实现整体的服务发现和负载均衡</p>\n<p><img src=\"http://www.liuhaihua.cn/wp-content/uploads/2016/12/IJJV3qV.jpg\" alt=\"\"><br>从上图中可以很清晰的看到，实际上请求进来还是被负载均衡器拦截，比如 nginx，然后 Ingress Controller 通过跟 Ingress 交互得知某个域名对应哪个 service，再通过跟 kubernetes API 交互得知 service 地址等信息；综合以后生成配置文件实时写入负载均衡器，然后负载均衡器 reload 该规则便可实现服务发现，即动态映射</p>\n<p>了解了以上内容以后，这也就很好的说明了我为什么喜欢把负载均衡器部署为 Daemon Set；因为无论如何请求首先是被负载均衡器拦截的，所以在每个 node 上都部署一下，同时 hostport 方式监听 80 端口；那么就解决了其他方式部署不确定 负载均衡器在哪的问题，同时访问每个 node 的 80 都能正确解析请求；如果前端再 放个 nginx 就又实现了一层负载均衡</p>\n<h1 id=\"Traefik-使用\"><a href=\"#Traefik-使用\" class=\"headerlink\" title=\"Traefik 使用\"></a>Traefik 使用</h1><p>由于微服务架构以及 Docker 技术和 kubernetes 编排工具最近几年才开始逐渐流行，所以一开始的反向代理服务器比如 nginx、apache 并未提供其支持，毕竟他们也不是先知；所以才会出现 Ingress Controller 这种东西来做 kubernetes 和前端负载均衡器如 nginx 之间做衔接；即 Ingress Controller 的存在就是为了能跟 kubernetes 交互，又能写 nginx 配置，还能 reload 它，这是一种折中方案；而最近开始出现的 traefik 天生就是提供了对 kubernetes 的支持，也就是说 traefik 本身就能跟 kubernetes API 交互，感知后端变化，因此可以得知: 在使用 traefik 时，Ingress Controller 已经无卵用了，所以整体架构如下<br><img src=\"http://www.liuhaihua.cn/wp-content/uploads/2016/12/Rfe67b3.jpg\" alt=\"\"></p>\n<h2 id=\"部署-Traefik\"><a href=\"#部署-Traefik\" class=\"headerlink\" title=\"部署 Traefik\"></a>部署 Traefik</h2><p>已经从大体上搞懂了 Ingress 和 traefik，那么部署起来就很简单</p>\n<h3 id=\"部署-Daemon-Set\"><a href=\"#部署-Daemon-Set\" class=\"headerlink\" title=\"部署 Daemon Set\"></a>部署 Daemon Set</h3><p>首先以 Daemon Set 的方式在每个 node 上启动一个 traefik，并使用 hostPort 的方式让其监听每个 node 的 80 端口(有没有感觉这就是个 NodePort? 不过区别就是这个 Port 后面有负载均衡器 –&gt;手动)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl create -f traefik.ds.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"> # Daemon set 文件如下</span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: DaemonSet</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: traefik-ingress-lb</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: traefik-ingress-lb</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        k8s-app: traefik-ingress-lb</span><br><span class=\"line\">        name: traefik-ingress-lb</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      terminationGracePeriodSeconds: 60</span><br><span class=\"line\">      hostNetwork: true</span><br><span class=\"line\">      restartPolicy: Always</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - image: traefik</span><br><span class=\"line\">        name: traefik-ingress-lb</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          limits:</span><br><span class=\"line\">            cpu: 200m</span><br><span class=\"line\">            memory: 30Mi</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            cpu: 100m</span><br><span class=\"line\">            memory: 20Mi</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - name: http</span><br><span class=\"line\">          containerPort: 80</span><br><span class=\"line\">          hostPort: 80</span><br><span class=\"line\">        - name: admin</span><br><span class=\"line\">          containerPort: 8580</span><br><span class=\"line\">        args:</span><br><span class=\"line\">        - --web</span><br><span class=\"line\">        - --web.address=:8580</span><br><span class=\"line\">        - --kubernetes</span><br></pre></td></tr></table></figure>\n<p>其中 traefik 监听 node 的 80 和 8580 端口，80 提供正常服务，8580 是其自带的 UI 界面，原本默认是 8080，因为环境里端口冲突了，所以这里临时改一下</p>\n<h3 id=\"部署-Ingress\"><a href=\"#部署-Ingress\" class=\"headerlink\" title=\"部署 Ingress\"></a>部署 Ingress</h3><p>从上面的长篇大论已经得知了 Ingress Controller 是无需部署的，所以直接部署 Ingress 即可<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl create -f traefik.ing.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># Ingress 文件如下</span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: traefik-ingress</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: traefik.www.test.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          serviceName: test-www</span><br><span class=\"line\">          servicePort: 8080</span><br><span class=\"line\">  - host: traefik.api.test.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          serviceName: test-api</span><br><span class=\"line\">          servicePort: 8080</span><br></pre></td></tr></table></figure></p>\n<p>实际上事先集群中已经存在了相应的名为 test-www 和 test-api 的 service，对应的 service 后端也有很多 pod；所以这里就不在具体写部署实际业务容器(test-www、test-api)的过程了，各位测试时，只需要把这个 test 的 service 替换成自己业务的 service 即可</p>\n<h3 id=\"部署-Traefik-UI\"><a href=\"#部署-Traefik-UI\" class=\"headerlink\" title=\"部署 Traefik UI\"></a>部署 Traefik UI</h3><p>traefik 本身还提供了一套 UI 供我们使用，其同样以 Ingress 方式暴露，只需要创建一下即可</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl create -f ui.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># ui yaml 如下</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: traefik-web-ui</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    k8s-app: traefik-ingress-lb</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - name: web</span><br><span class=\"line\">    port: 80</span><br><span class=\"line\">    targetPort: 8580</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: traefik-web-ui</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: traefik-ui.local</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          serviceName: traefik-web-ui</span><br><span class=\"line\">          servicePort: web</span><br></pre></td></tr></table></figure>\n<h3 id=\"访问测试\"><a href=\"#访问测试\" class=\"headerlink\" title=\"访问测试\"></a>访问测试</h3><p>都创建无误以后，只需要将待测试的域名解析到任意一台 node 上即可，页面就不截图了，截图就暴露了…..下面来两张 ui 的<br><img src=\"http://www.liuhaihua.cn/wp-content/uploads/2016/12/ErURbiu.jpg\" alt=\"\"><br><img src=\"http://www.liuhaihua.cn/wp-content/uploads/2016/12/qaMjqir.jpg\" alt=\"\"></p>\n<h2 id=\"健康检查\"><a href=\"#健康检查\" class=\"headerlink\" title=\"健康检查\"></a>健康检查</h2><p>关于健康检查，测试可以使用 kubernetes 的 Liveness Probe 实现，如果 Liveness Probe检查失败，则 traefik 会自动移除该 pod，以下是一个 示例</p>\n<p>test 的 deployment，健康检查方式是 cat /tmp/health，容器启动 2 分钟后会删掉这个文件，模拟健康检查失败<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: test</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    test: alpine</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      test: alpine</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        test: alpine</span><br><span class=\"line\">        name: test</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - image: mritd/alpine:3.4</span><br><span class=\"line\">        name: alpine</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          limits:</span><br><span class=\"line\">            cpu: 200m</span><br><span class=\"line\">            memory: 30Mi</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            cpu: 100m</span><br><span class=\"line\">            memory: 20Mi</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - name: http</span><br><span class=\"line\">          containerPort: 80</span><br><span class=\"line\">        args:</span><br><span class=\"line\">        command:</span><br><span class=\"line\">        - &quot;bash&quot;</span><br><span class=\"line\">        - &quot;-c&quot;</span><br><span class=\"line\">        - &quot;echo ok &gt; /tmp/health;sleep 120;rm -f /tmp/health&quot;</span><br><span class=\"line\">        livenessProbe:</span><br><span class=\"line\">          exec:</span><br><span class=\"line\">            command:</span><br><span class=\"line\">            - cat</span><br><span class=\"line\">            - /tmp/health</span><br><span class=\"line\">          initialDelaySeconds: 20</span><br></pre></td></tr></table></figure></p>\n<p>test 的 service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: test </span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    name: test</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - port: 8123</span><br><span class=\"line\">    targetPort: 80</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    name: test</span><br></pre></td></tr></table></figure>\n<p>test 的 Ingress</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: test</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: test.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          serviceName: test</span><br><span class=\"line\">          servicePort: 8123</span><br></pre></td></tr></table></figure>\n<p>全部创建好以后，进入 traefik ui 界面，可以观察到每隔 2 分钟健康检查失败后，kubernetes 重建 pod，同时 traefik 会从后端列表中移除这个 pod</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"Traefik-kubernetes-初试\"><a href=\"#Traefik-kubernetes-初试\" class=\"headerlink\" title=\"Traefik-kubernetes 初试\"></a>Traefik-kubernetes 初试</h1><blockquote>\n<p>traefik 是一个前端负载均衡器，对于微服务架构尤其是 kubernetes 等编排工具具有良好的支持；同 nginx 等相比，traefik 能够自动感知后端容器变化，从而实现自动服务发现；今天小试了一下，在此记录一下使用过程<br>","more":"</p>\n</blockquote>\n<p>从 kubernetes 1.2 版本开始，kubernetes提供了 Ingress 对象来实现对外暴露服务；到目前为止 kubernetes 总共有三种暴露服务的方式:</p>\n<ol>\n<li>LoadBlancer Service</li>\n<li>NodePort Service</li>\n<li>Ingress</li>\n</ol>\n<h2 id=\"LoadBlancer-Service\"><a href=\"#LoadBlancer-Service\" class=\"headerlink\" title=\"LoadBlancer Service\"></a>LoadBlancer Service</h2><p>LoadBlancer Service 是 kubernetes 深度结合云平台的一个组件；当使用 LoadBlancer Service 暴露服务时，实际上是通过向底层云平台申请创建一个负载均衡器来向外暴露服务；目前 LoadBlancer Service 支持的云平台已经相对完善，比如国外的 GCE、DigitalOcean，国内的 阿里云，私有云 Openstack 等等，由于 LoadBlancer Service 深度结合了云平台，所以只能在一些云平台上来使用</p>\n<h2 id=\"NodePort-Service\"><a href=\"#NodePort-Service\" class=\"headerlink\" title=\"NodePort Service\"></a>NodePort Service</h2><p>NodePort Service 顾名思义，实质上就是通过在集群的每个 node 上暴露一个端口，然后将这个端口映射到某个具体的 service 来实现的，虽然每个 node 的端口有很多(0~65535)，但是由于安全性和易用性(服务多了就乱了，还有端口冲突问题)实际使用可能并不多</p>\n<h3 id=\"Ingress\"><a href=\"#Ingress\" class=\"headerlink\" title=\"Ingress\"></a>Ingress</h3><p>Ingress 这个东西是 1.2 后才出现的，通过 Ingress 用户可以实现使用 nginx 等开源的反向代理负载均衡器实现对外暴露服务，以下详细说一下 Ingress，毕竟 traefik 用的就是 Ingress</p>\n<h3 id=\"使用-Ingress-时一般会有三个组件\"><a href=\"#使用-Ingress-时一般会有三个组件\" class=\"headerlink\" title=\"使用 Ingress 时一般会有三个组件:\"></a>使用 Ingress 时一般会有三个组件:</h3><ol>\n<li>反向代理负载均衡器</li>\n<li>Ingress Controller</li>\n<li>Ingress</li>\n</ol>\n<h3 id=\"反向代理负载均衡器\"><a href=\"#反向代理负载均衡器\" class=\"headerlink\" title=\"反向代理负载均衡器\"></a>反向代理负载均衡器</h3><p>反向代理负载均衡器很简单，说白了就是 nginx、apache 什么的；在集群中反向代理负载均衡器可以自由部署，可以使用 Replication Controller、Deployment、DaemonSet 等等，不过个人喜欢以 DaemonSet 的方式部署，感觉比较方便</p>\n<h2 id=\"Ingress-Controller\"><a href=\"#Ingress-Controller\" class=\"headerlink\" title=\"Ingress Controller\"></a>Ingress Controller</h2><p>Ingress Controller 实质上可以理解为是个监视器，Ingress Controller 通过不断地跟 kubernetes API 打交道，实时的感知后端 service、pod 等变化，比如新增和减少 pod，service 增加与减少等；当得到这些变化信息后，Ingress Controller 再结合下文的 Ingress 生成配置，然后更新反向代理负载均衡器，并刷新其配置，达到服务发现的作用</p>\n<h3 id=\"Ingress-1\"><a href=\"#Ingress-1\" class=\"headerlink\" title=\"Ingress\"></a>Ingress</h3><p>Ingress 简单理解就是个规则定义；比如说某个域名对应某个 service，即当某个域名的请求进来时转发给某个 service;这个规则将与 Ingress Controller 结合，然后 Ingress Controller 将其动态写入到负载均衡器配置中，从而实现整体的服务发现和负载均衡</p>\n<p><img src=\"http://www.liuhaihua.cn/wp-content/uploads/2016/12/IJJV3qV.jpg\" alt=\"\"><br>从上图中可以很清晰的看到，实际上请求进来还是被负载均衡器拦截，比如 nginx，然后 Ingress Controller 通过跟 Ingress 交互得知某个域名对应哪个 service，再通过跟 kubernetes API 交互得知 service 地址等信息；综合以后生成配置文件实时写入负载均衡器，然后负载均衡器 reload 该规则便可实现服务发现，即动态映射</p>\n<p>了解了以上内容以后，这也就很好的说明了我为什么喜欢把负载均衡器部署为 Daemon Set；因为无论如何请求首先是被负载均衡器拦截的，所以在每个 node 上都部署一下，同时 hostport 方式监听 80 端口；那么就解决了其他方式部署不确定 负载均衡器在哪的问题，同时访问每个 node 的 80 都能正确解析请求；如果前端再 放个 nginx 就又实现了一层负载均衡</p>\n<h1 id=\"Traefik-使用\"><a href=\"#Traefik-使用\" class=\"headerlink\" title=\"Traefik 使用\"></a>Traefik 使用</h1><p>由于微服务架构以及 Docker 技术和 kubernetes 编排工具最近几年才开始逐渐流行，所以一开始的反向代理服务器比如 nginx、apache 并未提供其支持，毕竟他们也不是先知；所以才会出现 Ingress Controller 这种东西来做 kubernetes 和前端负载均衡器如 nginx 之间做衔接；即 Ingress Controller 的存在就是为了能跟 kubernetes 交互，又能写 nginx 配置，还能 reload 它，这是一种折中方案；而最近开始出现的 traefik 天生就是提供了对 kubernetes 的支持，也就是说 traefik 本身就能跟 kubernetes API 交互，感知后端变化，因此可以得知: 在使用 traefik 时，Ingress Controller 已经无卵用了，所以整体架构如下<br><img src=\"http://www.liuhaihua.cn/wp-content/uploads/2016/12/Rfe67b3.jpg\" alt=\"\"></p>\n<h2 id=\"部署-Traefik\"><a href=\"#部署-Traefik\" class=\"headerlink\" title=\"部署 Traefik\"></a>部署 Traefik</h2><p>已经从大体上搞懂了 Ingress 和 traefik，那么部署起来就很简单</p>\n<h3 id=\"部署-Daemon-Set\"><a href=\"#部署-Daemon-Set\" class=\"headerlink\" title=\"部署 Daemon Set\"></a>部署 Daemon Set</h3><p>首先以 Daemon Set 的方式在每个 node 上启动一个 traefik，并使用 hostPort 的方式让其监听每个 node 的 80 端口(有没有感觉这就是个 NodePort? 不过区别就是这个 Port 后面有负载均衡器 –&gt;手动)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl create -f traefik.ds.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"> # Daemon set 文件如下</span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: DaemonSet</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: traefik-ingress-lb</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: traefik-ingress-lb</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        k8s-app: traefik-ingress-lb</span><br><span class=\"line\">        name: traefik-ingress-lb</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      terminationGracePeriodSeconds: 60</span><br><span class=\"line\">      hostNetwork: true</span><br><span class=\"line\">      restartPolicy: Always</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - image: traefik</span><br><span class=\"line\">        name: traefik-ingress-lb</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          limits:</span><br><span class=\"line\">            cpu: 200m</span><br><span class=\"line\">            memory: 30Mi</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            cpu: 100m</span><br><span class=\"line\">            memory: 20Mi</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - name: http</span><br><span class=\"line\">          containerPort: 80</span><br><span class=\"line\">          hostPort: 80</span><br><span class=\"line\">        - name: admin</span><br><span class=\"line\">          containerPort: 8580</span><br><span class=\"line\">        args:</span><br><span class=\"line\">        - --web</span><br><span class=\"line\">        - --web.address=:8580</span><br><span class=\"line\">        - --kubernetes</span><br></pre></td></tr></table></figure>\n<p>其中 traefik 监听 node 的 80 和 8580 端口，80 提供正常服务，8580 是其自带的 UI 界面，原本默认是 8080，因为环境里端口冲突了，所以这里临时改一下</p>\n<h3 id=\"部署-Ingress\"><a href=\"#部署-Ingress\" class=\"headerlink\" title=\"部署 Ingress\"></a>部署 Ingress</h3><p>从上面的长篇大论已经得知了 Ingress Controller 是无需部署的，所以直接部署 Ingress 即可<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl create -f traefik.ing.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># Ingress 文件如下</span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: traefik-ingress</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: traefik.www.test.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          serviceName: test-www</span><br><span class=\"line\">          servicePort: 8080</span><br><span class=\"line\">  - host: traefik.api.test.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          serviceName: test-api</span><br><span class=\"line\">          servicePort: 8080</span><br></pre></td></tr></table></figure></p>\n<p>实际上事先集群中已经存在了相应的名为 test-www 和 test-api 的 service，对应的 service 后端也有很多 pod；所以这里就不在具体写部署实际业务容器(test-www、test-api)的过程了，各位测试时，只需要把这个 test 的 service 替换成自己业务的 service 即可</p>\n<h3 id=\"部署-Traefik-UI\"><a href=\"#部署-Traefik-UI\" class=\"headerlink\" title=\"部署 Traefik UI\"></a>部署 Traefik UI</h3><p>traefik 本身还提供了一套 UI 供我们使用，其同样以 Ingress 方式暴露，只需要创建一下即可</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl create -f ui.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># ui yaml 如下</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: traefik-web-ui</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    k8s-app: traefik-ingress-lb</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - name: web</span><br><span class=\"line\">    port: 80</span><br><span class=\"line\">    targetPort: 8580</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: traefik-web-ui</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: traefik-ui.local</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          serviceName: traefik-web-ui</span><br><span class=\"line\">          servicePort: web</span><br></pre></td></tr></table></figure>\n<h3 id=\"访问测试\"><a href=\"#访问测试\" class=\"headerlink\" title=\"访问测试\"></a>访问测试</h3><p>都创建无误以后，只需要将待测试的域名解析到任意一台 node 上即可，页面就不截图了，截图就暴露了…..下面来两张 ui 的<br><img src=\"http://www.liuhaihua.cn/wp-content/uploads/2016/12/ErURbiu.jpg\" alt=\"\"><br><img src=\"http://www.liuhaihua.cn/wp-content/uploads/2016/12/qaMjqir.jpg\" alt=\"\"></p>\n<h2 id=\"健康检查\"><a href=\"#健康检查\" class=\"headerlink\" title=\"健康检查\"></a>健康检查</h2><p>关于健康检查，测试可以使用 kubernetes 的 Liveness Probe 实现，如果 Liveness Probe检查失败，则 traefik 会自动移除该 pod，以下是一个 示例</p>\n<p>test 的 deployment，健康检查方式是 cat /tmp/health，容器启动 2 分钟后会删掉这个文件，模拟健康检查失败<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: test</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    test: alpine</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      test: alpine</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        test: alpine</span><br><span class=\"line\">        name: test</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - image: mritd/alpine:3.4</span><br><span class=\"line\">        name: alpine</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          limits:</span><br><span class=\"line\">            cpu: 200m</span><br><span class=\"line\">            memory: 30Mi</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            cpu: 100m</span><br><span class=\"line\">            memory: 20Mi</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - name: http</span><br><span class=\"line\">          containerPort: 80</span><br><span class=\"line\">        args:</span><br><span class=\"line\">        command:</span><br><span class=\"line\">        - &quot;bash&quot;</span><br><span class=\"line\">        - &quot;-c&quot;</span><br><span class=\"line\">        - &quot;echo ok &gt; /tmp/health;sleep 120;rm -f /tmp/health&quot;</span><br><span class=\"line\">        livenessProbe:</span><br><span class=\"line\">          exec:</span><br><span class=\"line\">            command:</span><br><span class=\"line\">            - cat</span><br><span class=\"line\">            - /tmp/health</span><br><span class=\"line\">          initialDelaySeconds: 20</span><br></pre></td></tr></table></figure></p>\n<p>test 的 service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: test </span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    name: test</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - port: 8123</span><br><span class=\"line\">    targetPort: 80</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    name: test</span><br></pre></td></tr></table></figure>\n<p>test 的 Ingress</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: test</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: test.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          serviceName: test</span><br><span class=\"line\">          servicePort: 8123</span><br></pre></td></tr></table></figure>\n<p>全部创建好以后，进入 traefik ui 界面，可以观察到每隔 2 分钟健康检查失败后，kubernetes 重建 pod，同时 traefik 会从后端列表中移除这个 pod</p>"},{"title":"git使用说明","date":"2016-09-02T04:00:00.000Z","_content":"在linux下搭建git环境\n###1、创建Github账号，https://github.com\n<!--more-->\n###2、Linux创建SSH密钥：\n\n    ssh-keygen  ##一直默认就可以了  \n###3、将公钥加入到Github账户信息Account Settings->SSH Key\n###4、测试验证是否成功。\n    ssh -T git@github.com \n    Hi someone! You've successfully authenticated, but GitHub does not provide shell access.  \n    \n#同步github到本地\n###1、复制项目到本地：\n \n    git clone git://github.com:xxxx/test.git ##以gitreadonly方式克隆到本地，只可以读    \n    git clone git@github.com:xxx/test.git  ##以SSH方式克隆到本地，可以读写  \n    git clone https://github.com/xxx/test.git ##以https方式克隆到本地，可以读写  \n    git fetch git@github.com:xxx/xxx.git  ##获取到本地但不合并  \n    git pull git@github.com:xxx/xxx.git ##获取并合并内容到本地  \n\n#本地提交项目到github\n###1、本地配置\n    git config --global user.name 'onovps'\n    git config --global user.email 'onovps@onovps.com' #全局联系方式，可选  \n\n###2、新建Git项目并提交到Github。\n    mkdir testdir & cd testdir  \n    touch README.md  \n    git init #初始化一个本地库  \n    git add README.md #添加文件到本地仓库  \n    git rm README.md #本地倒库内删除  \n    git commit -m \"first commit\" #提交到本地库并备注，此时变更仍在本地。  \n    git commit -a  ##自动更新变化的文件，a可以理解为auto  \n    git remote add xxx git@github.com:xxx/xxx.git  #增加一个远程服务器的别名。  \n    git remote rm xxx   ##删除远程版本库的别名  \n    git push -u remotename master #将本地文件提交到Github的remoname版本库中。此时才更新了本地变更到github服务上。  \n    \n#分支版本操作\n###1、创建和合并分支\n    git branch #显示当前分支是master  \n    git branch new-feature  #创建分支  \n    git checkout new-feature  #切换到新分支  \n    vi page_cache.inc.php  \n    git add page_cache.inc.php  \n    git commit -a -m \"added initial version of page cache\"  \n    git push origin new-feature  ##把分支提交到远程服务器，只是把分支结构和内容提交到远程，并没有发生和主干的合并行为。  \n###2、如果new-feature分支成熟了，觉得有必要合并进master\n    git checkout master  #切换到新主干  \n    git merge new-feature  ##把分支合并到主干  \n    git branch #显示当前分支是master  \n    git push  #此时主干中也合并了new-feature的代码  \n","source":"_posts/git.md","raw":"---\ntitle: git使用说明\ndate: 2016-09-02\ntags: git\ncategories: git\n---\n在linux下搭建git环境\n###1、创建Github账号，https://github.com\n<!--more-->\n###2、Linux创建SSH密钥：\n\n    ssh-keygen  ##一直默认就可以了  \n###3、将公钥加入到Github账户信息Account Settings->SSH Key\n###4、测试验证是否成功。\n    ssh -T git@github.com \n    Hi someone! You've successfully authenticated, but GitHub does not provide shell access.  \n    \n#同步github到本地\n###1、复制项目到本地：\n \n    git clone git://github.com:xxxx/test.git ##以gitreadonly方式克隆到本地，只可以读    \n    git clone git@github.com:xxx/test.git  ##以SSH方式克隆到本地，可以读写  \n    git clone https://github.com/xxx/test.git ##以https方式克隆到本地，可以读写  \n    git fetch git@github.com:xxx/xxx.git  ##获取到本地但不合并  \n    git pull git@github.com:xxx/xxx.git ##获取并合并内容到本地  \n\n#本地提交项目到github\n###1、本地配置\n    git config --global user.name 'onovps'\n    git config --global user.email 'onovps@onovps.com' #全局联系方式，可选  \n\n###2、新建Git项目并提交到Github。\n    mkdir testdir & cd testdir  \n    touch README.md  \n    git init #初始化一个本地库  \n    git add README.md #添加文件到本地仓库  \n    git rm README.md #本地倒库内删除  \n    git commit -m \"first commit\" #提交到本地库并备注，此时变更仍在本地。  \n    git commit -a  ##自动更新变化的文件，a可以理解为auto  \n    git remote add xxx git@github.com:xxx/xxx.git  #增加一个远程服务器的别名。  \n    git remote rm xxx   ##删除远程版本库的别名  \n    git push -u remotename master #将本地文件提交到Github的remoname版本库中。此时才更新了本地变更到github服务上。  \n    \n#分支版本操作\n###1、创建和合并分支\n    git branch #显示当前分支是master  \n    git branch new-feature  #创建分支  \n    git checkout new-feature  #切换到新分支  \n    vi page_cache.inc.php  \n    git add page_cache.inc.php  \n    git commit -a -m \"added initial version of page cache\"  \n    git push origin new-feature  ##把分支提交到远程服务器，只是把分支结构和内容提交到远程，并没有发生和主干的合并行为。  \n###2、如果new-feature分支成熟了，觉得有必要合并进master\n    git checkout master  #切换到新主干  \n    git merge new-feature  ##把分支合并到主干  \n    git branch #显示当前分支是master  \n    git push  #此时主干中也合并了new-feature的代码  \n","slug":"git","published":1,"updated":"2019-06-18T08:07:01.113Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sio0008hcb75bql7c4z","content":"<p>在linux下搭建git环境</p>\n<p>###1、创建Github账号，<a href=\"https://github.com\" target=\"_blank\" rel=\"noopener\">https://github.com</a><br><a id=\"more\"></a></p>\n<p>###2、Linux创建SSH密钥：</p>\n<pre><code>ssh-keygen  ##一直默认就可以了  \n</code></pre><p>###3、将公钥加入到Github账户信息Account Settings-&gt;SSH Key</p>\n<p>###4、测试验证是否成功。<br>    ssh -T <a href=\"mailto:git@github.com\" target=\"_blank\" rel=\"noopener\">git@github.com</a><br>    Hi someone! You’ve successfully authenticated, but GitHub does not provide shell access.  </p>\n<p>#同步github到本地</p>\n<p>###1、复制项目到本地：</p>\n<pre><code>git clone git://github.com:xxxx/test.git ##以gitreadonly方式克隆到本地，只可以读    \ngit clone git@github.com:xxx/test.git  ##以SSH方式克隆到本地，可以读写  \ngit clone https://github.com/xxx/test.git ##以https方式克隆到本地，可以读写  \ngit fetch git@github.com:xxx/xxx.git  ##获取到本地但不合并  \ngit pull git@github.com:xxx/xxx.git ##获取并合并内容到本地  \n</code></pre><p>#本地提交项目到github</p>\n<p>###1、本地配置<br>    git config –global user.name ‘onovps’<br>    git config –global user.email <a href=\"mailto:&#39;onovps@onovps.com\" target=\"_blank\" rel=\"noopener\">&#39;onovps@onovps.com</a>‘ #全局联系方式，可选  </p>\n<p>###2、新建Git项目并提交到Github。<br>    mkdir testdir &amp; cd testdir<br>    touch README.md<br>    git init #初始化一个本地库<br>    git add README.md #添加文件到本地仓库<br>    git rm README.md #本地倒库内删除<br>    git commit -m “first commit” #提交到本地库并备注，此时变更仍在本地。<br>    git commit -a  ##自动更新变化的文件，a可以理解为auto<br>    git remote add xxx <a href=\"mailto:git@github.com\" target=\"_blank\" rel=\"noopener\">git@github.com</a>:xxx/xxx.git  #增加一个远程服务器的别名。<br>    git remote rm xxx   ##删除远程版本库的别名<br>    git push -u remotename master #将本地文件提交到Github的remoname版本库中。此时才更新了本地变更到github服务上。  </p>\n<p>#分支版本操作</p>\n<p>###1、创建和合并分支<br>    git branch #显示当前分支是master<br>    git branch new-feature  #创建分支<br>    git checkout new-feature  #切换到新分支<br>    vi page_cache.inc.php<br>    git add page_cache.inc.php<br>    git commit -a -m “added initial version of page cache”<br>    git push origin new-feature  ##把分支提交到远程服务器，只是把分支结构和内容提交到远程，并没有发生和主干的合并行为。  </p>\n<p>###2、如果new-feature分支成熟了，觉得有必要合并进master<br>    git checkout master  #切换到新主干<br>    git merge new-feature  ##把分支合并到主干<br>    git branch #显示当前分支是master<br>    git push  #此时主干中也合并了new-feature的代码  </p>\n","site":{"data":{}},"excerpt":"<p>在linux下搭建git环境</p>\n<p>###1、创建Github账号，<a href=\"https://github.com\" target=\"_blank\" rel=\"noopener\">https://github.com</a><br>","more":"</p>\n<p>###2、Linux创建SSH密钥：</p>\n<pre><code>ssh-keygen  ##一直默认就可以了  \n</code></pre><p>###3、将公钥加入到Github账户信息Account Settings-&gt;SSH Key</p>\n<p>###4、测试验证是否成功。<br>    ssh -T <a href=\"mailto:git@github.com\" target=\"_blank\" rel=\"noopener\">git@github.com</a><br>    Hi someone! You’ve successfully authenticated, but GitHub does not provide shell access.  </p>\n<p>#同步github到本地</p>\n<p>###1、复制项目到本地：</p>\n<pre><code>git clone git://github.com:xxxx/test.git ##以gitreadonly方式克隆到本地，只可以读    \ngit clone git@github.com:xxx/test.git  ##以SSH方式克隆到本地，可以读写  \ngit clone https://github.com/xxx/test.git ##以https方式克隆到本地，可以读写  \ngit fetch git@github.com:xxx/xxx.git  ##获取到本地但不合并  \ngit pull git@github.com:xxx/xxx.git ##获取并合并内容到本地  \n</code></pre><p>#本地提交项目到github</p>\n<p>###1、本地配置<br>    git config –global user.name ‘onovps’<br>    git config –global user.email <a href=\"mailto:&#39;onovps@onovps.com\" target=\"_blank\" rel=\"noopener\">&#39;onovps@onovps.com</a>‘ #全局联系方式，可选  </p>\n<p>###2、新建Git项目并提交到Github。<br>    mkdir testdir &amp; cd testdir<br>    touch README.md<br>    git init #初始化一个本地库<br>    git add README.md #添加文件到本地仓库<br>    git rm README.md #本地倒库内删除<br>    git commit -m “first commit” #提交到本地库并备注，此时变更仍在本地。<br>    git commit -a  ##自动更新变化的文件，a可以理解为auto<br>    git remote add xxx <a href=\"mailto:git@github.com\" target=\"_blank\" rel=\"noopener\">git@github.com</a>:xxx/xxx.git  #增加一个远程服务器的别名。<br>    git remote rm xxx   ##删除远程版本库的别名<br>    git push -u remotename master #将本地文件提交到Github的remoname版本库中。此时才更新了本地变更到github服务上。  </p>\n<p>#分支版本操作</p>\n<p>###1、创建和合并分支<br>    git branch #显示当前分支是master<br>    git branch new-feature  #创建分支<br>    git checkout new-feature  #切换到新分支<br>    vi page_cache.inc.php<br>    git add page_cache.inc.php<br>    git commit -a -m “added initial version of page cache”<br>    git push origin new-feature  ##把分支提交到远程服务器，只是把分支结构和内容提交到远程，并没有发生和主干的合并行为。  </p>\n<p>###2、如果new-feature分支成熟了，觉得有必要合并进master<br>    git checkout master  #切换到新主干<br>    git merge new-feature  ##把分支合并到主干<br>    git branch #显示当前分支是master<br>    git push  #此时主干中也合并了new-feature的代码  </p>"},{"title":"centos 7 部署 gitlab","date":"2017-09-08T04:00:00.000Z","_content":"## gitlab的安装搭建\n<!--more-->\n\n### 安装基础环境包\n\n    yum -y install curl policycoreutils openssh-server openssh-clients\n\n### 启动sshd\n\n    systemctl enable sshd\n    systemctl start sshd\n\n### 安装postfix\n\n    yum -y install postfix\n    systemctl enable postfix\n    systemctl start postfix\n\n### 添加防火墙规则\n\n    firewall-cmd --permanent --add-service=http\n    systemctl reload firewalld\nor\n    yum install firewalld\n    systemctl unmadk firewalld\n\n### 下载并安装软件包\n\n    curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash\n    yum install gitlab-ce\n\n如遇到time out，请更换成国内源\n    vim /etc/yum.repos.d/gitlab-ce.repo\n> [gitlab-ce]\n> name=gitlab-ce\n> baseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7\n> repo_gpgcheck=0\n> gp0gcheck=0\n> enabled=1\n> gpgkey=https://packages.gitlab.com/gpg.key\n\n    yum makecache\n    yum install gitlab-ce -y\n\n\nor 下载相应版本gitlab的rpm包\n\n    https://packages.gitlab.com/gitlab/gitlab-ce/    \n\n安装完毕后\n\n    gitlab-ctl reconfigure \n> gitlab: GitLab should be reachable at http://iZ2851te7e5Z  \ngitlab: Otherwise configure GitLab for your system by editing /etc/gitlab/gitlab.rb file  \ngitlab: And running reconfigure again.  \ngitlab:   \ngitlab: For a comprehensive list of configuration options please see the Omnibus GitLab readme  \ngitlab: https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md  \ngitlab:   \nIt looks like GitLab has not been configured yet; skipping the upgrade script.  \n  验证中      : gitlab-ce-8.7.6-ce.0.el7.x86_64                                                                                             1/1     \n已安装:  \n  gitlab-ce.x86_64 0:8.7.6-ce.0.el7                                                                                                         \n完毕！\n\n### 配置并启动gitlab\n\n如果遇到\n>安装GitLab出现ruby_block[supervise_redis_sleep] action run\n\n那么需要运行\n\n\tsystemctl restart gitlab-runsvdir\n    gitlab-ctl reconfigure\n\n### 默认账号密码是\n\n    Username: root\n    Password: 5iveL!fe\n测试地址（默认80端口）\n    http://127.0.0.1/\n\n## gitlab的备份\n\n### 备份命令\n    gitlab-rake gitlab:backup:create\n默认的备份目录为： /var/opt/gitlab/backups  备份文件名类似： 时间戳_gitlab_backup.tar\n\n如要修改备份目录：\n    vim /etc/gitlab/gitlab.rd\n    gitlab_rails['backup_path'] = '/mnt/gitlab_backups'\n\n### gitlab数据的恢复或还原\n提示：gitlab数据的恢复或者迁移成功的前提--两台服务器的gitlab的版本必须相同，若不同侧可能迁移或者恢复失败  \n\n>将备份文件放在gitlab的默认备份目录  \n比如/var/opt/gitlab/backups下的1504693308_gitlab_backup.tar     \n  \n设置自动备份\n\n    0 2 * * * /opt/gitlab/bin/gitlab-rake gitlab:backup:create\n\n恢复或者还原  \n\n停服务\n\n    gitlab-ctl stop unicorn\n\tgitlab-ctl stop sidekiq\n\n恢复数据\n\n    gitlab-rake gitlab:backup:restore BACKUP=1504693308\n\nBACKUP后面跟的是备份文件的时间戳，比如恢复备份文件1504693308_gitlab_backup.tar\n\n恢复完启动服务\n\n    gitlab-ctl start\n\n## gitlab nginx的修改\n\n配置文件 /var/opt/gitlab/nginx/conf/gitlab-http.conf。这个文件是gitlab内置的nginx的配置文件，里面可以影响到nginx真实监听端口。\n\n    server {\n        listen *:80;\n\t\tserver_name ip\n\t\tserver_tokens off; ##Don't show the nginx version number, a security best practice \t\t\n    }\n\n修改完成后，重启下就可以了\n    gitlab-ctl restart\n\n## 汉化\n\n### 查看自己gitlab的版本号\n    cat /opt/gitlab/embedded/service/gitlab-rails/VERSION\n    9.3.5\n\n当前版本为v9.3.5,并确认汉化版本库是否包含该版本的汉化标签(-zh结尾),也就是是否包含 v9.3.5-zh\n\n### 下载汉化包并汉化\n\n克隆汉化版本库，此处用了好久的时间，拉取这个分支，没有更好的办法，可以自行百度一下Git慢的解决方式\n\n    git clone https://gitlab.com/xhang/gitlab.git\n\n如果已经克隆过，则进行更新\n\n    git fetch\n\n比较汉化标签和原标签，导出 patch 用的 diff 文件.进入刚才的目录git clone 的目录\n\n    cd gitlab\n\tgit diff v9.3.5 v9.3.5-zh > ../9.3.5-zh.diff\n\n上传9.3.5-zh.diff文件到服务器停止 gitlab\n\n    gitlab-ctl stop\n\tpatch -d /opt/gitlab/embedded/service/gitlab-rails -p1 < ../9.3.6-zh.diff\n>这里path 如果也出现 command not found 说明path安装包没有安装，然后在运行前边的代码就可以了  \nyum -y install patch \n\n\n重启gitlab即可.\n\n    gitlab-ctl start\n\n执行重新配置命令\n\n    gitlab-ctl reconfigure\n\n\n\n## 升级\n\n### 关闭gitlab服务\n\n\tgitlab-ctl stop unicorn\n\tgitlab-ctl stop sidekiq\n\tgitlab-ctl stop nginx\n\n\n### 备份gitlab\n\n\tgitlab-rake gitlab:backup:create\n\n### 下载gitlab的RPM包并进行升级\n\n\tcurl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash\n\tyum update gitlab-ce\n或者直接上官网下载相应gitlab的版本所对应的软件包（[https://packages.gitlab.com/gitlab/gitlab-ce/](https://packages.gitlab.com/gitlab/gitlab-ce/)）\n\n\tyum install gitlab-ce-8.8.3-ce.0.el7.x86_64\n\n### 启动并查看gitlab的版本信息\n\n\tgitlab-ctl reconfigure\n\tgitlab-ctl restart\n\thead -1 /opt/gitlab/version-manifest.txt\n\tcat /opt/gitlab/embedded/service/gitlab-rails/VERSION\n\n### 可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务\n\n\tvim /etc/gitlab/gitlab.rd\n\n>设置nginx为dalse，关闭自带nginx  \n>nginx['enable'] = false  \n>检查默认nginx配置文件，并迁移至新nginx服务。  \n>/var/opt/gitlab/nginx/conf/nginx.conf  #nginx配置文件，包含gitlab-http.conf文件  \n>/var/ope/gitlab/nginx/conf/gitlab-http.conf #gitlab核心nginx配置文件\n \n重启nginx、gitlab服务\n\n\tgitlab-ctl reconfigure\n\tsystemctl restart nginx\n\n访问报502。原因是nginx用户无法访问gitlab用户的socket文件。重启gitlab需要重新授权\n\n\tchmod -R o+x /var/opt/gitlab/gitlab-rails\n\tgitlab-ctl restart\n\n\n##  卸载\n\n前提：必须在Gitlab运行状态下才能卸载\n\n    gitlab-ctl uninstall\n    rpm -e gitlab-ce\n\n在卸载gitlab然后再次安装执行gitlab-ctl reconfigure的时候往往会出现:ruby_block[supervise_redis_sleep] action run,会一直卡无法往下进行！   \n解决方案：  \n\n按住CTRL+C强制结束  \n\n运行:  \n\n    systemctl restart gitlab-runsvdir\n    gitlab-ctl reconfigure\n\n\n## 报错解决\n### 迁移后页面500错误\n如果遇到迁移项目后web页面点击项目报500错误，查看相关日志如下\n\n\t==> /var/log/gitlab/gitlab-rails/production.log <==  \n\tStarted GET \"/ops/install_php\" for 127.0.0.1 at   2017-09-13 10:32:45 +0800  \n\tProcessing by ProjectsController#show as HTML    \n\t Parameters: {\"namespace_id\"=>\"ops\",  \"id\"=>\"install_php\"}  \n\tCompleted 500 Internal Server Error in 36ms (ActiveRecord: 2.2ms)  \n\n\tOpenSSL::Cipher::CipherError (bad decrypt):  \n\t  app/models/project.rb:383:in `import_url'\n\t  app/models/project.rb:413:in `external_import?'\n\t  app/models/project.rb:405:in `import?'\n\t  app/models/project.rb:421:in `import_in_progress?'\n\t  app/controllers/projects_controller.rb:93:in `show'\n\t  lib/gitlab/middleware/go.rb:16:in `call'\n\n可得知是OpenSSL解密出现了问题，经调查后发现\n这个是gitlab数据迁移的时候一个缺陷\n\n\n### 解决方案\n1.覆盖原来gitlab的db_key_base到新的gitlab\n\ndb_key_base位置在/etc/gitlab/gitlab-secrets.json\n\n2.EE版本执行\n\n\tsudo gitlab-rails runner \"Project.where(mirror: false).where.not(import_url: nil).each { |p| p.import_data.destroy if p.import_data }\"\n\n3.CE版本执行\n\n\tsudo gitlab-rails runner \"Project.where.not(import_url: nil).each { |p| p.import_data.destroy if p.import_data }\"\n\n\n\n### 备机web界面项目地址显示主机名问题\n\n\tvim /var/opt/gitlab/gitlab-rails/etc/gitlab.yml\n\n修改host项\n\n>由host: localhost改成  \n>host: ******\n\ngitlab重启即可\n\t\n\tgitlab-ctl restart\n\n\n","source":"_posts/gitlab安装.md","raw":"---\ntitle: centos 7 部署 gitlab\ndate: 2017-09-08\ntags: git\ncategories: git\n---\n## gitlab的安装搭建\n<!--more-->\n\n### 安装基础环境包\n\n    yum -y install curl policycoreutils openssh-server openssh-clients\n\n### 启动sshd\n\n    systemctl enable sshd\n    systemctl start sshd\n\n### 安装postfix\n\n    yum -y install postfix\n    systemctl enable postfix\n    systemctl start postfix\n\n### 添加防火墙规则\n\n    firewall-cmd --permanent --add-service=http\n    systemctl reload firewalld\nor\n    yum install firewalld\n    systemctl unmadk firewalld\n\n### 下载并安装软件包\n\n    curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash\n    yum install gitlab-ce\n\n如遇到time out，请更换成国内源\n    vim /etc/yum.repos.d/gitlab-ce.repo\n> [gitlab-ce]\n> name=gitlab-ce\n> baseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7\n> repo_gpgcheck=0\n> gp0gcheck=0\n> enabled=1\n> gpgkey=https://packages.gitlab.com/gpg.key\n\n    yum makecache\n    yum install gitlab-ce -y\n\n\nor 下载相应版本gitlab的rpm包\n\n    https://packages.gitlab.com/gitlab/gitlab-ce/    \n\n安装完毕后\n\n    gitlab-ctl reconfigure \n> gitlab: GitLab should be reachable at http://iZ2851te7e5Z  \ngitlab: Otherwise configure GitLab for your system by editing /etc/gitlab/gitlab.rb file  \ngitlab: And running reconfigure again.  \ngitlab:   \ngitlab: For a comprehensive list of configuration options please see the Omnibus GitLab readme  \ngitlab: https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md  \ngitlab:   \nIt looks like GitLab has not been configured yet; skipping the upgrade script.  \n  验证中      : gitlab-ce-8.7.6-ce.0.el7.x86_64                                                                                             1/1     \n已安装:  \n  gitlab-ce.x86_64 0:8.7.6-ce.0.el7                                                                                                         \n完毕！\n\n### 配置并启动gitlab\n\n如果遇到\n>安装GitLab出现ruby_block[supervise_redis_sleep] action run\n\n那么需要运行\n\n\tsystemctl restart gitlab-runsvdir\n    gitlab-ctl reconfigure\n\n### 默认账号密码是\n\n    Username: root\n    Password: 5iveL!fe\n测试地址（默认80端口）\n    http://127.0.0.1/\n\n## gitlab的备份\n\n### 备份命令\n    gitlab-rake gitlab:backup:create\n默认的备份目录为： /var/opt/gitlab/backups  备份文件名类似： 时间戳_gitlab_backup.tar\n\n如要修改备份目录：\n    vim /etc/gitlab/gitlab.rd\n    gitlab_rails['backup_path'] = '/mnt/gitlab_backups'\n\n### gitlab数据的恢复或还原\n提示：gitlab数据的恢复或者迁移成功的前提--两台服务器的gitlab的版本必须相同，若不同侧可能迁移或者恢复失败  \n\n>将备份文件放在gitlab的默认备份目录  \n比如/var/opt/gitlab/backups下的1504693308_gitlab_backup.tar     \n  \n设置自动备份\n\n    0 2 * * * /opt/gitlab/bin/gitlab-rake gitlab:backup:create\n\n恢复或者还原  \n\n停服务\n\n    gitlab-ctl stop unicorn\n\tgitlab-ctl stop sidekiq\n\n恢复数据\n\n    gitlab-rake gitlab:backup:restore BACKUP=1504693308\n\nBACKUP后面跟的是备份文件的时间戳，比如恢复备份文件1504693308_gitlab_backup.tar\n\n恢复完启动服务\n\n    gitlab-ctl start\n\n## gitlab nginx的修改\n\n配置文件 /var/opt/gitlab/nginx/conf/gitlab-http.conf。这个文件是gitlab内置的nginx的配置文件，里面可以影响到nginx真实监听端口。\n\n    server {\n        listen *:80;\n\t\tserver_name ip\n\t\tserver_tokens off; ##Don't show the nginx version number, a security best practice \t\t\n    }\n\n修改完成后，重启下就可以了\n    gitlab-ctl restart\n\n## 汉化\n\n### 查看自己gitlab的版本号\n    cat /opt/gitlab/embedded/service/gitlab-rails/VERSION\n    9.3.5\n\n当前版本为v9.3.5,并确认汉化版本库是否包含该版本的汉化标签(-zh结尾),也就是是否包含 v9.3.5-zh\n\n### 下载汉化包并汉化\n\n克隆汉化版本库，此处用了好久的时间，拉取这个分支，没有更好的办法，可以自行百度一下Git慢的解决方式\n\n    git clone https://gitlab.com/xhang/gitlab.git\n\n如果已经克隆过，则进行更新\n\n    git fetch\n\n比较汉化标签和原标签，导出 patch 用的 diff 文件.进入刚才的目录git clone 的目录\n\n    cd gitlab\n\tgit diff v9.3.5 v9.3.5-zh > ../9.3.5-zh.diff\n\n上传9.3.5-zh.diff文件到服务器停止 gitlab\n\n    gitlab-ctl stop\n\tpatch -d /opt/gitlab/embedded/service/gitlab-rails -p1 < ../9.3.6-zh.diff\n>这里path 如果也出现 command not found 说明path安装包没有安装，然后在运行前边的代码就可以了  \nyum -y install patch \n\n\n重启gitlab即可.\n\n    gitlab-ctl start\n\n执行重新配置命令\n\n    gitlab-ctl reconfigure\n\n\n\n## 升级\n\n### 关闭gitlab服务\n\n\tgitlab-ctl stop unicorn\n\tgitlab-ctl stop sidekiq\n\tgitlab-ctl stop nginx\n\n\n### 备份gitlab\n\n\tgitlab-rake gitlab:backup:create\n\n### 下载gitlab的RPM包并进行升级\n\n\tcurl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash\n\tyum update gitlab-ce\n或者直接上官网下载相应gitlab的版本所对应的软件包（[https://packages.gitlab.com/gitlab/gitlab-ce/](https://packages.gitlab.com/gitlab/gitlab-ce/)）\n\n\tyum install gitlab-ce-8.8.3-ce.0.el7.x86_64\n\n### 启动并查看gitlab的版本信息\n\n\tgitlab-ctl reconfigure\n\tgitlab-ctl restart\n\thead -1 /opt/gitlab/version-manifest.txt\n\tcat /opt/gitlab/embedded/service/gitlab-rails/VERSION\n\n### 可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务\n\n\tvim /etc/gitlab/gitlab.rd\n\n>设置nginx为dalse，关闭自带nginx  \n>nginx['enable'] = false  \n>检查默认nginx配置文件，并迁移至新nginx服务。  \n>/var/opt/gitlab/nginx/conf/nginx.conf  #nginx配置文件，包含gitlab-http.conf文件  \n>/var/ope/gitlab/nginx/conf/gitlab-http.conf #gitlab核心nginx配置文件\n \n重启nginx、gitlab服务\n\n\tgitlab-ctl reconfigure\n\tsystemctl restart nginx\n\n访问报502。原因是nginx用户无法访问gitlab用户的socket文件。重启gitlab需要重新授权\n\n\tchmod -R o+x /var/opt/gitlab/gitlab-rails\n\tgitlab-ctl restart\n\n\n##  卸载\n\n前提：必须在Gitlab运行状态下才能卸载\n\n    gitlab-ctl uninstall\n    rpm -e gitlab-ce\n\n在卸载gitlab然后再次安装执行gitlab-ctl reconfigure的时候往往会出现:ruby_block[supervise_redis_sleep] action run,会一直卡无法往下进行！   \n解决方案：  \n\n按住CTRL+C强制结束  \n\n运行:  \n\n    systemctl restart gitlab-runsvdir\n    gitlab-ctl reconfigure\n\n\n## 报错解决\n### 迁移后页面500错误\n如果遇到迁移项目后web页面点击项目报500错误，查看相关日志如下\n\n\t==> /var/log/gitlab/gitlab-rails/production.log <==  \n\tStarted GET \"/ops/install_php\" for 127.0.0.1 at   2017-09-13 10:32:45 +0800  \n\tProcessing by ProjectsController#show as HTML    \n\t Parameters: {\"namespace_id\"=>\"ops\",  \"id\"=>\"install_php\"}  \n\tCompleted 500 Internal Server Error in 36ms (ActiveRecord: 2.2ms)  \n\n\tOpenSSL::Cipher::CipherError (bad decrypt):  \n\t  app/models/project.rb:383:in `import_url'\n\t  app/models/project.rb:413:in `external_import?'\n\t  app/models/project.rb:405:in `import?'\n\t  app/models/project.rb:421:in `import_in_progress?'\n\t  app/controllers/projects_controller.rb:93:in `show'\n\t  lib/gitlab/middleware/go.rb:16:in `call'\n\n可得知是OpenSSL解密出现了问题，经调查后发现\n这个是gitlab数据迁移的时候一个缺陷\n\n\n### 解决方案\n1.覆盖原来gitlab的db_key_base到新的gitlab\n\ndb_key_base位置在/etc/gitlab/gitlab-secrets.json\n\n2.EE版本执行\n\n\tsudo gitlab-rails runner \"Project.where(mirror: false).where.not(import_url: nil).each { |p| p.import_data.destroy if p.import_data }\"\n\n3.CE版本执行\n\n\tsudo gitlab-rails runner \"Project.where.not(import_url: nil).each { |p| p.import_data.destroy if p.import_data }\"\n\n\n\n### 备机web界面项目地址显示主机名问题\n\n\tvim /var/opt/gitlab/gitlab-rails/etc/gitlab.yml\n\n修改host项\n\n>由host: localhost改成  \n>host: ******\n\ngitlab重启即可\n\t\n\tgitlab-ctl restart\n\n\n","slug":"gitlab安装","published":1,"updated":"2019-06-18T08:07:01.113Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sj0000chcb7g5zki9pm","content":"<h2 id=\"gitlab的安装搭建\"><a href=\"#gitlab的安装搭建\" class=\"headerlink\" title=\"gitlab的安装搭建\"></a>gitlab的安装搭建</h2><a id=\"more\"></a>\n<h3 id=\"安装基础环境包\"><a href=\"#安装基础环境包\" class=\"headerlink\" title=\"安装基础环境包\"></a>安装基础环境包</h3><pre><code>yum -y install curl policycoreutils openssh-server openssh-clients\n</code></pre><h3 id=\"启动sshd\"><a href=\"#启动sshd\" class=\"headerlink\" title=\"启动sshd\"></a>启动sshd</h3><pre><code>systemctl enable sshd\nsystemctl start sshd\n</code></pre><h3 id=\"安装postfix\"><a href=\"#安装postfix\" class=\"headerlink\" title=\"安装postfix\"></a>安装postfix</h3><pre><code>yum -y install postfix\nsystemctl enable postfix\nsystemctl start postfix\n</code></pre><h3 id=\"添加防火墙规则\"><a href=\"#添加防火墙规则\" class=\"headerlink\" title=\"添加防火墙规则\"></a>添加防火墙规则</h3><pre><code>firewall-cmd --permanent --add-service=http\nsystemctl reload firewalld\n</code></pre><p>or<br>    yum install firewalld<br>    systemctl unmadk firewalld</p>\n<h3 id=\"下载并安装软件包\"><a href=\"#下载并安装软件包\" class=\"headerlink\" title=\"下载并安装软件包\"></a>下载并安装软件包</h3><pre><code>curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash\nyum install gitlab-ce\n</code></pre><p>如遇到time out，请更换成国内源<br>    vim /etc/yum.repos.d/gitlab-ce.repo</p>\n<blockquote>\n<p>[gitlab-ce]<br>name=gitlab-ce<br>baseurl=<a href=\"http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7\" target=\"_blank\" rel=\"noopener\">http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7</a><br>repo_gpgcheck=0<br>gp0gcheck=0<br>enabled=1<br>gpgkey=<a href=\"https://packages.gitlab.com/gpg.key\" target=\"_blank\" rel=\"noopener\">https://packages.gitlab.com/gpg.key</a></p>\n</blockquote>\n<pre><code>yum makecache\nyum install gitlab-ce -y\n</code></pre><p>or 下载相应版本gitlab的rpm包</p>\n<pre><code>https://packages.gitlab.com/gitlab/gitlab-ce/    \n</code></pre><p>安装完毕后</p>\n<pre><code>gitlab-ctl reconfigure \n</code></pre><blockquote>\n<p>gitlab: GitLab should be reachable at <a href=\"http://iZ2851te7e5Z\" target=\"_blank\" rel=\"noopener\">http://iZ2851te7e5Z</a><br>gitlab: Otherwise configure GitLab for your system by editing /etc/gitlab/gitlab.rb file<br>gitlab: And running reconfigure again.<br>gitlab:<br>gitlab: For a comprehensive list of configuration options please see the Omnibus GitLab readme<br>gitlab: <a href=\"https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md\" target=\"_blank\" rel=\"noopener\">https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md</a><br>gitlab:<br>It looks like GitLab has not been configured yet; skipping the upgrade script.<br>  验证中      : gitlab-ce-8.7.6-ce.0.el7.x86_64                                                                                             1/1<br>已安装:<br>  gitlab-ce.x86_64 0:8.7.6-ce.0.el7<br>完毕！</p>\n</blockquote>\n<h3 id=\"配置并启动gitlab\"><a href=\"#配置并启动gitlab\" class=\"headerlink\" title=\"配置并启动gitlab\"></a>配置并启动gitlab</h3><p>如果遇到</p>\n<blockquote>\n<p>安装GitLab出现ruby_block[supervise_redis_sleep] action run</p>\n</blockquote>\n<p>那么需要运行</p>\n<pre><code>systemctl restart gitlab-runsvdir\ngitlab-ctl reconfigure\n</code></pre><h3 id=\"默认账号密码是\"><a href=\"#默认账号密码是\" class=\"headerlink\" title=\"默认账号密码是\"></a>默认账号密码是</h3><pre><code>Username: root\nPassword: 5iveL!fe\n</code></pre><p>测试地址（默认80端口）<br>    <a href=\"http://127.0.0.1/\" target=\"_blank\" rel=\"noopener\">http://127.0.0.1/</a></p>\n<h2 id=\"gitlab的备份\"><a href=\"#gitlab的备份\" class=\"headerlink\" title=\"gitlab的备份\"></a>gitlab的备份</h2><h3 id=\"备份命令\"><a href=\"#备份命令\" class=\"headerlink\" title=\"备份命令\"></a>备份命令</h3><pre><code>gitlab-rake gitlab:backup:create\n</code></pre><p>默认的备份目录为： /var/opt/gitlab/backups  备份文件名类似： 时间戳_gitlab_backup.tar</p>\n<p>如要修改备份目录：<br>    vim /etc/gitlab/gitlab.rd<br>    gitlab_rails[‘backup_path’] = ‘/mnt/gitlab_backups’</p>\n<h3 id=\"gitlab数据的恢复或还原\"><a href=\"#gitlab数据的恢复或还原\" class=\"headerlink\" title=\"gitlab数据的恢复或还原\"></a>gitlab数据的恢复或还原</h3><p>提示：gitlab数据的恢复或者迁移成功的前提–两台服务器的gitlab的版本必须相同，若不同侧可能迁移或者恢复失败  </p>\n<blockquote>\n<p>将备份文件放在gitlab的默认备份目录<br>比如/var/opt/gitlab/backups下的1504693308_gitlab_backup.tar     </p>\n</blockquote>\n<p>设置自动备份</p>\n<pre><code>0 2 * * * /opt/gitlab/bin/gitlab-rake gitlab:backup:create\n</code></pre><p>恢复或者还原  </p>\n<p>停服务</p>\n<pre><code>gitlab-ctl stop unicorn\ngitlab-ctl stop sidekiq\n</code></pre><p>恢复数据</p>\n<pre><code>gitlab-rake gitlab:backup:restore BACKUP=1504693308\n</code></pre><p>BACKUP后面跟的是备份文件的时间戳，比如恢复备份文件1504693308_gitlab_backup.tar</p>\n<p>恢复完启动服务</p>\n<pre><code>gitlab-ctl start\n</code></pre><h2 id=\"gitlab-nginx的修改\"><a href=\"#gitlab-nginx的修改\" class=\"headerlink\" title=\"gitlab nginx的修改\"></a>gitlab nginx的修改</h2><p>配置文件 /var/opt/gitlab/nginx/conf/gitlab-http.conf。这个文件是gitlab内置的nginx的配置文件，里面可以影响到nginx真实监听端口。</p>\n<pre><code>server {\n    listen *:80;\n    server_name ip\n    server_tokens off; ##Don&apos;t show the nginx version number, a security best practice         \n}\n</code></pre><p>修改完成后，重启下就可以了<br>    gitlab-ctl restart</p>\n<h2 id=\"汉化\"><a href=\"#汉化\" class=\"headerlink\" title=\"汉化\"></a>汉化</h2><h3 id=\"查看自己gitlab的版本号\"><a href=\"#查看自己gitlab的版本号\" class=\"headerlink\" title=\"查看自己gitlab的版本号\"></a>查看自己gitlab的版本号</h3><pre><code>cat /opt/gitlab/embedded/service/gitlab-rails/VERSION\n9.3.5\n</code></pre><p>当前版本为v9.3.5,并确认汉化版本库是否包含该版本的汉化标签(-zh结尾),也就是是否包含 v9.3.5-zh</p>\n<h3 id=\"下载汉化包并汉化\"><a href=\"#下载汉化包并汉化\" class=\"headerlink\" title=\"下载汉化包并汉化\"></a>下载汉化包并汉化</h3><p>克隆汉化版本库，此处用了好久的时间，拉取这个分支，没有更好的办法，可以自行百度一下Git慢的解决方式</p>\n<pre><code>git clone https://gitlab.com/xhang/gitlab.git\n</code></pre><p>如果已经克隆过，则进行更新</p>\n<pre><code>git fetch\n</code></pre><p>比较汉化标签和原标签，导出 patch 用的 diff 文件.进入刚才的目录git clone 的目录</p>\n<pre><code>cd gitlab\ngit diff v9.3.5 v9.3.5-zh &gt; ../9.3.5-zh.diff\n</code></pre><p>上传9.3.5-zh.diff文件到服务器停止 gitlab</p>\n<pre><code>gitlab-ctl stop\npatch -d /opt/gitlab/embedded/service/gitlab-rails -p1 &lt; ../9.3.6-zh.diff\n</code></pre><blockquote>\n<p>这里path 如果也出现 command not found 说明path安装包没有安装，然后在运行前边的代码就可以了<br>yum -y install patch </p>\n</blockquote>\n<p>重启gitlab即可.</p>\n<pre><code>gitlab-ctl start\n</code></pre><p>执行重新配置命令</p>\n<pre><code>gitlab-ctl reconfigure\n</code></pre><h2 id=\"升级\"><a href=\"#升级\" class=\"headerlink\" title=\"升级\"></a>升级</h2><h3 id=\"关闭gitlab服务\"><a href=\"#关闭gitlab服务\" class=\"headerlink\" title=\"关闭gitlab服务\"></a>关闭gitlab服务</h3><pre><code>gitlab-ctl stop unicorn\ngitlab-ctl stop sidekiq\ngitlab-ctl stop nginx\n</code></pre><h3 id=\"备份gitlab\"><a href=\"#备份gitlab\" class=\"headerlink\" title=\"备份gitlab\"></a>备份gitlab</h3><pre><code>gitlab-rake gitlab:backup:create\n</code></pre><h3 id=\"下载gitlab的RPM包并进行升级\"><a href=\"#下载gitlab的RPM包并进行升级\" class=\"headerlink\" title=\"下载gitlab的RPM包并进行升级\"></a>下载gitlab的RPM包并进行升级</h3><pre><code>curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash\nyum update gitlab-ce\n</code></pre><p>或者直接上官网下载相应gitlab的版本所对应的软件包（<a href=\"https://packages.gitlab.com/gitlab/gitlab-ce/\" target=\"_blank\" rel=\"noopener\">https://packages.gitlab.com/gitlab/gitlab-ce/</a>）</p>\n<pre><code>yum install gitlab-ce-8.8.3-ce.0.el7.x86_64\n</code></pre><h3 id=\"启动并查看gitlab的版本信息\"><a href=\"#启动并查看gitlab的版本信息\" class=\"headerlink\" title=\"启动并查看gitlab的版本信息\"></a>启动并查看gitlab的版本信息</h3><pre><code>gitlab-ctl reconfigure\ngitlab-ctl restart\nhead -1 /opt/gitlab/version-manifest.txt\ncat /opt/gitlab/embedded/service/gitlab-rails/VERSION\n</code></pre><h3 id=\"可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务\"><a href=\"#可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务\" class=\"headerlink\" title=\"可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务\"></a>可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务</h3><pre><code>vim /etc/gitlab/gitlab.rd\n</code></pre><blockquote>\n<p>设置nginx为dalse，关闭自带nginx<br>nginx[‘enable’] = false<br>检查默认nginx配置文件，并迁移至新nginx服务。<br>/var/opt/gitlab/nginx/conf/nginx.conf  #nginx配置文件，包含gitlab-http.conf文件<br>/var/ope/gitlab/nginx/conf/gitlab-http.conf #gitlab核心nginx配置文件</p>\n</blockquote>\n<p>重启nginx、gitlab服务</p>\n<pre><code>gitlab-ctl reconfigure\nsystemctl restart nginx\n</code></pre><p>访问报502。原因是nginx用户无法访问gitlab用户的socket文件。重启gitlab需要重新授权</p>\n<pre><code>chmod -R o+x /var/opt/gitlab/gitlab-rails\ngitlab-ctl restart\n</code></pre><h2 id=\"卸载\"><a href=\"#卸载\" class=\"headerlink\" title=\"卸载\"></a>卸载</h2><p>前提：必须在Gitlab运行状态下才能卸载</p>\n<pre><code>gitlab-ctl uninstall\nrpm -e gitlab-ce\n</code></pre><p>在卸载gitlab然后再次安装执行gitlab-ctl reconfigure的时候往往会出现:ruby_block[supervise_redis_sleep] action run,会一直卡无法往下进行！<br>解决方案：  </p>\n<p>按住CTRL+C强制结束  </p>\n<p>运行:  </p>\n<pre><code>systemctl restart gitlab-runsvdir\ngitlab-ctl reconfigure\n</code></pre><h2 id=\"报错解决\"><a href=\"#报错解决\" class=\"headerlink\" title=\"报错解决\"></a>报错解决</h2><h3 id=\"迁移后页面500错误\"><a href=\"#迁移后页面500错误\" class=\"headerlink\" title=\"迁移后页面500错误\"></a>迁移后页面500错误</h3><p>如果遇到迁移项目后web页面点击项目报500错误，查看相关日志如下</p>\n<pre><code>==&gt; /var/log/gitlab/gitlab-rails/production.log &lt;==  \nStarted GET &quot;/ops/install_php&quot; for 127.0.0.1 at   2017-09-13 10:32:45 +0800  \nProcessing by ProjectsController#show as HTML    \n Parameters: {&quot;namespace_id&quot;=&gt;&quot;ops&quot;,  &quot;id&quot;=&gt;&quot;install_php&quot;}  \nCompleted 500 Internal Server Error in 36ms (ActiveRecord: 2.2ms)  \n\nOpenSSL::Cipher::CipherError (bad decrypt):  \n  app/models/project.rb:383:in `import_url&apos;\n  app/models/project.rb:413:in `external_import?&apos;\n  app/models/project.rb:405:in `import?&apos;\n  app/models/project.rb:421:in `import_in_progress?&apos;\n  app/controllers/projects_controller.rb:93:in `show&apos;\n  lib/gitlab/middleware/go.rb:16:in `call&apos;\n</code></pre><p>可得知是OpenSSL解密出现了问题，经调查后发现<br>这个是gitlab数据迁移的时候一个缺陷</p>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><p>1.覆盖原来gitlab的db_key_base到新的gitlab</p>\n<p>db_key_base位置在/etc/gitlab/gitlab-secrets.json</p>\n<p>2.EE版本执行</p>\n<pre><code>sudo gitlab-rails runner &quot;Project.where(mirror: false).where.not(import_url: nil).each { |p| p.import_data.destroy if p.import_data }&quot;\n</code></pre><p>3.CE版本执行</p>\n<pre><code>sudo gitlab-rails runner &quot;Project.where.not(import_url: nil).each { |p| p.import_data.destroy if p.import_data }&quot;\n</code></pre><h3 id=\"备机web界面项目地址显示主机名问题\"><a href=\"#备机web界面项目地址显示主机名问题\" class=\"headerlink\" title=\"备机web界面项目地址显示主机名问题\"></a>备机web界面项目地址显示主机名问题</h3><pre><code>vim /var/opt/gitlab/gitlab-rails/etc/gitlab.yml\n</code></pre><p>修改host项</p>\n<blockquote>\n<p>由host: localhost改成<br>host: <strong>**</strong></p>\n</blockquote>\n<p>gitlab重启即可</p>\n<pre><code>gitlab-ctl restart\n</code></pre>","site":{"data":{}},"excerpt":"<h2 id=\"gitlab的安装搭建\"><a href=\"#gitlab的安装搭建\" class=\"headerlink\" title=\"gitlab的安装搭建\"></a>gitlab的安装搭建</h2>","more":"<h3 id=\"安装基础环境包\"><a href=\"#安装基础环境包\" class=\"headerlink\" title=\"安装基础环境包\"></a>安装基础环境包</h3><pre><code>yum -y install curl policycoreutils openssh-server openssh-clients\n</code></pre><h3 id=\"启动sshd\"><a href=\"#启动sshd\" class=\"headerlink\" title=\"启动sshd\"></a>启动sshd</h3><pre><code>systemctl enable sshd\nsystemctl start sshd\n</code></pre><h3 id=\"安装postfix\"><a href=\"#安装postfix\" class=\"headerlink\" title=\"安装postfix\"></a>安装postfix</h3><pre><code>yum -y install postfix\nsystemctl enable postfix\nsystemctl start postfix\n</code></pre><h3 id=\"添加防火墙规则\"><a href=\"#添加防火墙规则\" class=\"headerlink\" title=\"添加防火墙规则\"></a>添加防火墙规则</h3><pre><code>firewall-cmd --permanent --add-service=http\nsystemctl reload firewalld\n</code></pre><p>or<br>    yum install firewalld<br>    systemctl unmadk firewalld</p>\n<h3 id=\"下载并安装软件包\"><a href=\"#下载并安装软件包\" class=\"headerlink\" title=\"下载并安装软件包\"></a>下载并安装软件包</h3><pre><code>curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash\nyum install gitlab-ce\n</code></pre><p>如遇到time out，请更换成国内源<br>    vim /etc/yum.repos.d/gitlab-ce.repo</p>\n<blockquote>\n<p>[gitlab-ce]<br>name=gitlab-ce<br>baseurl=<a href=\"http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7\" target=\"_blank\" rel=\"noopener\">http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7</a><br>repo_gpgcheck=0<br>gp0gcheck=0<br>enabled=1<br>gpgkey=<a href=\"https://packages.gitlab.com/gpg.key\" target=\"_blank\" rel=\"noopener\">https://packages.gitlab.com/gpg.key</a></p>\n</blockquote>\n<pre><code>yum makecache\nyum install gitlab-ce -y\n</code></pre><p>or 下载相应版本gitlab的rpm包</p>\n<pre><code>https://packages.gitlab.com/gitlab/gitlab-ce/    \n</code></pre><p>安装完毕后</p>\n<pre><code>gitlab-ctl reconfigure \n</code></pre><blockquote>\n<p>gitlab: GitLab should be reachable at <a href=\"http://iZ2851te7e5Z\" target=\"_blank\" rel=\"noopener\">http://iZ2851te7e5Z</a><br>gitlab: Otherwise configure GitLab for your system by editing /etc/gitlab/gitlab.rb file<br>gitlab: And running reconfigure again.<br>gitlab:<br>gitlab: For a comprehensive list of configuration options please see the Omnibus GitLab readme<br>gitlab: <a href=\"https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md\" target=\"_blank\" rel=\"noopener\">https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md</a><br>gitlab:<br>It looks like GitLab has not been configured yet; skipping the upgrade script.<br>  验证中      : gitlab-ce-8.7.6-ce.0.el7.x86_64                                                                                             1/1<br>已安装:<br>  gitlab-ce.x86_64 0:8.7.6-ce.0.el7<br>完毕！</p>\n</blockquote>\n<h3 id=\"配置并启动gitlab\"><a href=\"#配置并启动gitlab\" class=\"headerlink\" title=\"配置并启动gitlab\"></a>配置并启动gitlab</h3><p>如果遇到</p>\n<blockquote>\n<p>安装GitLab出现ruby_block[supervise_redis_sleep] action run</p>\n</blockquote>\n<p>那么需要运行</p>\n<pre><code>systemctl restart gitlab-runsvdir\ngitlab-ctl reconfigure\n</code></pre><h3 id=\"默认账号密码是\"><a href=\"#默认账号密码是\" class=\"headerlink\" title=\"默认账号密码是\"></a>默认账号密码是</h3><pre><code>Username: root\nPassword: 5iveL!fe\n</code></pre><p>测试地址（默认80端口）<br>    <a href=\"http://127.0.0.1/\" target=\"_blank\" rel=\"noopener\">http://127.0.0.1/</a></p>\n<h2 id=\"gitlab的备份\"><a href=\"#gitlab的备份\" class=\"headerlink\" title=\"gitlab的备份\"></a>gitlab的备份</h2><h3 id=\"备份命令\"><a href=\"#备份命令\" class=\"headerlink\" title=\"备份命令\"></a>备份命令</h3><pre><code>gitlab-rake gitlab:backup:create\n</code></pre><p>默认的备份目录为： /var/opt/gitlab/backups  备份文件名类似： 时间戳_gitlab_backup.tar</p>\n<p>如要修改备份目录：<br>    vim /etc/gitlab/gitlab.rd<br>    gitlab_rails[‘backup_path’] = ‘/mnt/gitlab_backups’</p>\n<h3 id=\"gitlab数据的恢复或还原\"><a href=\"#gitlab数据的恢复或还原\" class=\"headerlink\" title=\"gitlab数据的恢复或还原\"></a>gitlab数据的恢复或还原</h3><p>提示：gitlab数据的恢复或者迁移成功的前提–两台服务器的gitlab的版本必须相同，若不同侧可能迁移或者恢复失败  </p>\n<blockquote>\n<p>将备份文件放在gitlab的默认备份目录<br>比如/var/opt/gitlab/backups下的1504693308_gitlab_backup.tar     </p>\n</blockquote>\n<p>设置自动备份</p>\n<pre><code>0 2 * * * /opt/gitlab/bin/gitlab-rake gitlab:backup:create\n</code></pre><p>恢复或者还原  </p>\n<p>停服务</p>\n<pre><code>gitlab-ctl stop unicorn\ngitlab-ctl stop sidekiq\n</code></pre><p>恢复数据</p>\n<pre><code>gitlab-rake gitlab:backup:restore BACKUP=1504693308\n</code></pre><p>BACKUP后面跟的是备份文件的时间戳，比如恢复备份文件1504693308_gitlab_backup.tar</p>\n<p>恢复完启动服务</p>\n<pre><code>gitlab-ctl start\n</code></pre><h2 id=\"gitlab-nginx的修改\"><a href=\"#gitlab-nginx的修改\" class=\"headerlink\" title=\"gitlab nginx的修改\"></a>gitlab nginx的修改</h2><p>配置文件 /var/opt/gitlab/nginx/conf/gitlab-http.conf。这个文件是gitlab内置的nginx的配置文件，里面可以影响到nginx真实监听端口。</p>\n<pre><code>server {\n    listen *:80;\n    server_name ip\n    server_tokens off; ##Don&apos;t show the nginx version number, a security best practice         \n}\n</code></pre><p>修改完成后，重启下就可以了<br>    gitlab-ctl restart</p>\n<h2 id=\"汉化\"><a href=\"#汉化\" class=\"headerlink\" title=\"汉化\"></a>汉化</h2><h3 id=\"查看自己gitlab的版本号\"><a href=\"#查看自己gitlab的版本号\" class=\"headerlink\" title=\"查看自己gitlab的版本号\"></a>查看自己gitlab的版本号</h3><pre><code>cat /opt/gitlab/embedded/service/gitlab-rails/VERSION\n9.3.5\n</code></pre><p>当前版本为v9.3.5,并确认汉化版本库是否包含该版本的汉化标签(-zh结尾),也就是是否包含 v9.3.5-zh</p>\n<h3 id=\"下载汉化包并汉化\"><a href=\"#下载汉化包并汉化\" class=\"headerlink\" title=\"下载汉化包并汉化\"></a>下载汉化包并汉化</h3><p>克隆汉化版本库，此处用了好久的时间，拉取这个分支，没有更好的办法，可以自行百度一下Git慢的解决方式</p>\n<pre><code>git clone https://gitlab.com/xhang/gitlab.git\n</code></pre><p>如果已经克隆过，则进行更新</p>\n<pre><code>git fetch\n</code></pre><p>比较汉化标签和原标签，导出 patch 用的 diff 文件.进入刚才的目录git clone 的目录</p>\n<pre><code>cd gitlab\ngit diff v9.3.5 v9.3.5-zh &gt; ../9.3.5-zh.diff\n</code></pre><p>上传9.3.5-zh.diff文件到服务器停止 gitlab</p>\n<pre><code>gitlab-ctl stop\npatch -d /opt/gitlab/embedded/service/gitlab-rails -p1 &lt; ../9.3.6-zh.diff\n</code></pre><blockquote>\n<p>这里path 如果也出现 command not found 说明path安装包没有安装，然后在运行前边的代码就可以了<br>yum -y install patch </p>\n</blockquote>\n<p>重启gitlab即可.</p>\n<pre><code>gitlab-ctl start\n</code></pre><p>执行重新配置命令</p>\n<pre><code>gitlab-ctl reconfigure\n</code></pre><h2 id=\"升级\"><a href=\"#升级\" class=\"headerlink\" title=\"升级\"></a>升级</h2><h3 id=\"关闭gitlab服务\"><a href=\"#关闭gitlab服务\" class=\"headerlink\" title=\"关闭gitlab服务\"></a>关闭gitlab服务</h3><pre><code>gitlab-ctl stop unicorn\ngitlab-ctl stop sidekiq\ngitlab-ctl stop nginx\n</code></pre><h3 id=\"备份gitlab\"><a href=\"#备份gitlab\" class=\"headerlink\" title=\"备份gitlab\"></a>备份gitlab</h3><pre><code>gitlab-rake gitlab:backup:create\n</code></pre><h3 id=\"下载gitlab的RPM包并进行升级\"><a href=\"#下载gitlab的RPM包并进行升级\" class=\"headerlink\" title=\"下载gitlab的RPM包并进行升级\"></a>下载gitlab的RPM包并进行升级</h3><pre><code>curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash\nyum update gitlab-ce\n</code></pre><p>或者直接上官网下载相应gitlab的版本所对应的软件包（<a href=\"https://packages.gitlab.com/gitlab/gitlab-ce/\" target=\"_blank\" rel=\"noopener\">https://packages.gitlab.com/gitlab/gitlab-ce/</a>）</p>\n<pre><code>yum install gitlab-ce-8.8.3-ce.0.el7.x86_64\n</code></pre><h3 id=\"启动并查看gitlab的版本信息\"><a href=\"#启动并查看gitlab的版本信息\" class=\"headerlink\" title=\"启动并查看gitlab的版本信息\"></a>启动并查看gitlab的版本信息</h3><pre><code>gitlab-ctl reconfigure\ngitlab-ctl restart\nhead -1 /opt/gitlab/version-manifest.txt\ncat /opt/gitlab/embedded/service/gitlab-rails/VERSION\n</code></pre><h3 id=\"可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务\"><a href=\"#可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务\" class=\"headerlink\" title=\"可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务\"></a>可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务</h3><pre><code>vim /etc/gitlab/gitlab.rd\n</code></pre><blockquote>\n<p>设置nginx为dalse，关闭自带nginx<br>nginx[‘enable’] = false<br>检查默认nginx配置文件，并迁移至新nginx服务。<br>/var/opt/gitlab/nginx/conf/nginx.conf  #nginx配置文件，包含gitlab-http.conf文件<br>/var/ope/gitlab/nginx/conf/gitlab-http.conf #gitlab核心nginx配置文件</p>\n</blockquote>\n<p>重启nginx、gitlab服务</p>\n<pre><code>gitlab-ctl reconfigure\nsystemctl restart nginx\n</code></pre><p>访问报502。原因是nginx用户无法访问gitlab用户的socket文件。重启gitlab需要重新授权</p>\n<pre><code>chmod -R o+x /var/opt/gitlab/gitlab-rails\ngitlab-ctl restart\n</code></pre><h2 id=\"卸载\"><a href=\"#卸载\" class=\"headerlink\" title=\"卸载\"></a>卸载</h2><p>前提：必须在Gitlab运行状态下才能卸载</p>\n<pre><code>gitlab-ctl uninstall\nrpm -e gitlab-ce\n</code></pre><p>在卸载gitlab然后再次安装执行gitlab-ctl reconfigure的时候往往会出现:ruby_block[supervise_redis_sleep] action run,会一直卡无法往下进行！<br>解决方案：  </p>\n<p>按住CTRL+C强制结束  </p>\n<p>运行:  </p>\n<pre><code>systemctl restart gitlab-runsvdir\ngitlab-ctl reconfigure\n</code></pre><h2 id=\"报错解决\"><a href=\"#报错解决\" class=\"headerlink\" title=\"报错解决\"></a>报错解决</h2><h3 id=\"迁移后页面500错误\"><a href=\"#迁移后页面500错误\" class=\"headerlink\" title=\"迁移后页面500错误\"></a>迁移后页面500错误</h3><p>如果遇到迁移项目后web页面点击项目报500错误，查看相关日志如下</p>\n<pre><code>==&gt; /var/log/gitlab/gitlab-rails/production.log &lt;==  \nStarted GET &quot;/ops/install_php&quot; for 127.0.0.1 at   2017-09-13 10:32:45 +0800  \nProcessing by ProjectsController#show as HTML    \n Parameters: {&quot;namespace_id&quot;=&gt;&quot;ops&quot;,  &quot;id&quot;=&gt;&quot;install_php&quot;}  \nCompleted 500 Internal Server Error in 36ms (ActiveRecord: 2.2ms)  \n\nOpenSSL::Cipher::CipherError (bad decrypt):  \n  app/models/project.rb:383:in `import_url&apos;\n  app/models/project.rb:413:in `external_import?&apos;\n  app/models/project.rb:405:in `import?&apos;\n  app/models/project.rb:421:in `import_in_progress?&apos;\n  app/controllers/projects_controller.rb:93:in `show&apos;\n  lib/gitlab/middleware/go.rb:16:in `call&apos;\n</code></pre><p>可得知是OpenSSL解密出现了问题，经调查后发现<br>这个是gitlab数据迁移的时候一个缺陷</p>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><p>1.覆盖原来gitlab的db_key_base到新的gitlab</p>\n<p>db_key_base位置在/etc/gitlab/gitlab-secrets.json</p>\n<p>2.EE版本执行</p>\n<pre><code>sudo gitlab-rails runner &quot;Project.where(mirror: false).where.not(import_url: nil).each { |p| p.import_data.destroy if p.import_data }&quot;\n</code></pre><p>3.CE版本执行</p>\n<pre><code>sudo gitlab-rails runner &quot;Project.where.not(import_url: nil).each { |p| p.import_data.destroy if p.import_data }&quot;\n</code></pre><h3 id=\"备机web界面项目地址显示主机名问题\"><a href=\"#备机web界面项目地址显示主机名问题\" class=\"headerlink\" title=\"备机web界面项目地址显示主机名问题\"></a>备机web界面项目地址显示主机名问题</h3><pre><code>vim /var/opt/gitlab/gitlab-rails/etc/gitlab.yml\n</code></pre><p>修改host项</p>\n<blockquote>\n<p>由host: localhost改成<br>host: <strong>**</strong></p>\n</blockquote>\n<p>gitlab重启即可</p>\n<pre><code>gitlab-ctl restart\n</code></pre>"},{"title":"git使用说明详解","date":"2017-06-16T04:00:00.000Z","_content":"1.下载geekery.repo文件，具体操作如下：\n<!--more-->\n找到存放yum文件的目录，命令如下：  \n      \n  `cd /etc/yum.repos.d/`\n   \n>  [geekery]  \n> name = geekery repository  \n> baseurl = http://geekery.altervista.org/geekery/el6/x86_64  \n> `#mirrorlist = http://geekery.altervista.org/mirrors-geekery`  \n> enabled = 1  \n> protect = 0  \n> gpgkey = http://geekery.altervista.org/download.php?filename=GEEKERY-GPG-KEY  \n> gpgcheck = 1  \n\n\n2.下载rpmforge-release rpm包  \n\ni386 http://apt.sw.be/redhat/el5/en/i386/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.i386.rpm  \nx86_64 http://apt.sw.be/redhat/el5/en/x86_64/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.x86_64.rpm\n\n`rpm -ivh rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm`\n\n3.下载epel-release rpm包，地址：http://rpm.pbone.net/，搜索epel-release，下载对应系统和适应的rmp包，之后执行安装命令如下：  \n\n`rpm -ivh epel-release-6-8.1.noarch.rpm`  \n\n\n4.安装git  \n`yum -y install git`\n\n\n\n5.git使用  \n     \n## 配置git   \n\n   首先配置git信息（git使用者的用户名及邮箱）  \n   配置好这两项，用户就可以知道谁做了什么\n\n   `git config --global user.name \"My Name\"`  \n   `git config --global user.email myEmail@example.com`  \n\n\n\n\n##  创建一个新仓库 ##\ngit 会把所有文件以及历史记录保存在你的项目中，创建一个新的仓库，首先要去到项目路径，执行 git init。然后git会创建一个隐藏的文件夹.git，所有的信息都储存在其中。  \n`cd Desktop/git_exercise/`  \n`git init`  \n现在项目还什么都没有新建一个hello.txt文件试试\n\n## 检查状态 ##\ngit status 是另一个非常重要的命令，它会告诉我们创库的当前状态：是否为最新代码，有什么更新等等执行git status:  \n`git status`\n>  $ git status\n> \n> On branch master\n> \n> Initial commit\n> \n> Untracked files:\n>   (use \"git add ...\" to include in what will be committed)\n> \n>   hello.txt  \n> git  \n\n告诉我们，hello.txt尚未跟踪，这是因为这个文件是新的，git不知道是应该跟踪它的变动呢，还是直接忽略不管呢。为了跟踪我们的新文件，我们需要暂存它。\n\n## 暂存git ##  \n\ngit 有个概念叫 暂存区，你可以把它看成一块空白帆布，包裹着所有你可能会提交的变动。它一开始为空，你可以通过 git add 命令添加内容，并使用 git commit 提交。\n这个例子中只有一个文件：  \n\n提交hello.txt文件：\n`git add hello.txt`  \n\n如果需要提交目录下的所有内容，可以这样：  \n`git add -A`  \n\n再次使用git status查看：  \n`git status`\n\n> On branch master\n> \n> Initial commit\n> \n> Changes to be committed:\n>   (use \"git rm --cached ...\" to unstage)\n> \n> new file:   hello.txt\n\n我们的文件已经提交了。状态信息还会告诉我们暂存区文件发生了什么变动，不过这里我们提交的是一个全新文件。\n\n\n## 提交本地git分支 ##\n一次提交代表着我们的仓库到了一个交付状态，通常是完成了某一块小功能。它就像是一个快照，允许我们像使用时光机一样回到旧时光。\n创建提交，需要我们提交东西到暂存区（git add），然后：  \n>    `git commit -m \"Initial commit.\"  `  \n> 这就创建了一次提交，-m “Initial commit.”表示对这次提交的描述，建议使用有意义的描述性信息。  \n> 远端仓库  \n> 到目前为止，我们的操作都是在本地的，它存在于.git文件中。为了能够协同开发，我们需要把代码发布到远端仓库上。  \n> 1.链接远端仓库 - git remote add  \n> 为了能够上传到远端仓库，我们需要先建立起链接，这篇教程中，远端仓库的地址为：https://github.com/tutorialzine/awesome-project,但你应该自己在Github,   \n> BitBucket上搭建仓库，自己一步一步尝试。  \n> 添加测试用的远端仓库  \n> ` git remote add origin https://github.com/tutorialzine/awesome-project.git`  \n> 一个项目可以同时拥有好几个远端仓库为了能够区分，通常会起不同的名字。通常主远端仓库被称为origin。  \n> 2.上传到服务器 - git push    \n> 每次我们要提交代码到服务器上时，都会使用到git push。    \n> git push命令会有两个参数，远端仓库的名字，以及分支的名字：  \n> ` git push origin master`\n> \n> Counting objects: 3, done.  \n> Writing objects: 100% (3/3), 212 bytes | 0 bytes/s, done.  \n> Total 3 (delta 0), reused 0 (delta 0)  \n> To https://github.com/tutorialzine/awesome-project.git  \n>  * [new branch]      master -master  \n\n\n> 取决于你使用的服务器，push过程你可能需要验证身份。如果没有出差错，现在使用浏览器去你的远端分支上看，hello.txt已经在那里等着你了。  \n> 3.克隆仓库 - git clone  \n> 放在Github上的开源项目，人们可以看到你的代码。可以使用 git clone进行下载到本地。  \n> ` git clone https://github.com/tutorialzine/awesome-project.git `  \n> 本地也会创建一个新的仓库，并自动将github上的分支设为远端分支。  \n> 4.从服务器上拉取代码 - git pull  \n> 如果你更新了代码到仓库上，其他人可以通过git pull命令拉取你的变动：  \n> ` git pull origin master `  \n> From https://github.com/tutorialzine/awesome-project  \n>  * branch            master     -FETCH_HEAD  \n> Already up-to-date.  \n\n  \n> 因为暂时没有其他人提交，所有没有任何变动分支\n> \n> branchs  \n> 当你在做一个新功能的时候，最好是在一个独立的区域上开发，通常称之为分支。分支之间相互独立，并且拥有自己的历史记录。这样做的原因是：  \n> 稳定版本的代码不会被破坏  \n> 不同的功能可以由不同开发者同时开发。  \n> 开发者可以专注于自己的分支，不用担心被其他人破坏了环境  \n> 在不确定之前，同一个特性可以拥有几个版本，便于比较  \n> 1.创建新分支 - git branch  \n> 每一个仓库的默认分支都叫master, 创建新分支可以这样：  \n> ` git branch amazing_new_feature`  \n> 创建了一个名为amazing_new_feature的新分支，它跟当前分支同一起点  \n> 2.切换分支 - git checkout  \n> 单独使用git branch，可以查看分支状态：  \n> ` git branch`\n>   amazing_new_feature  \n> * master  \n>   \n> * 号表示当前活跃分支为master，使用git checkout切换分支。  \n> $ git checkout amazing_new_feature  \n> 3.合并分支 - git merge  \n> 我们的 amazing_new_feature 分支的任务是增加一个featuer.txt。我们来创建，添加到暂存区，提交。  \n> ` git add feature.txt`  \n> ` git commit -m \"New feature complete.\"`  \n> 新分支任务完成了，回到master分支  \n> `git checkout master`  \n> 现在去查看文件，你会发现，之前创建的feature.txt文件不见了，因为master分支上并没有feature.txt。使用git merge 把 amazing_new_feature 分支合并到master上。  \n> `git merge amazing_new_feature`  \n> ok! 然后再把amazing_new_feature 分支删掉吧。  \n> ` git branch -d amazing_new_feature`  \n> \n> \n> 高级  \n> 1.比对两个不同提交之间的差别\n> 每次提交都有一个唯一id，查看所有提交和他们的id，可以使用 git log:  \n> `git log`\n> \n> commit ba25c0ff30e1b2f0259157b42b9f8f5d174d80d7   \n> Author: Tutorialzine  \n> Date:   Mon May 30 17:15:28 2016 +0300  \n> \n>   New feature complete  \n> \n> commit b10cc1238e355c02a044ef9f9860811ff605c9b4  \n> Author: Tutorialzine  \n> Date:   Mon May 30 16:30:04 2016 +0300  \n> \n>    Added content to hello.txt  \n> \n> commit 09bd8cc171d7084e78e4d118a2346b7487dca059  \n> Author: Tutorialzine  \n> Date:   Sat May 28 17:52:14 2016 +0300  \n> \n>    Initial commit  \n> id 很长，但是你并不需要复制整个字符串，前一小部分就够了。  \n> 查看某一次提交更新了什么，使用 git show:  \n> ` git show b10cc123`  \n> \n> commit b10cc1238e355c02a044ef9f9860811ff605c9b4  \n> Author: Tutorialzine  \n> Date:   Mon May 30 16:30:04 2016 +0300  \n> \n>    Added content to hello.txt  \n> \n> diff --git a/hello.txt b/hello.txt  \n> index e69de29..b546a21 100644  \n> --- a/hello.txt  \n> +++ b/hello.txt  \n> @@ -0,0 +1 @@  \n> +Nice weather today, isn't it?  \n> 查看两次提交的不同，可以使用git diff [commit-from]..[commit-to] 语法：  \n> ` git diff 09bd8cc..ba25c0ff`  \n>   \n> diff --git a/feature.txt b/feature.txt  \n> new file mode 100644  \n> index 0000000..e69de29  \n> diff --git a/hello.txt b/hello.txt  \n> index e69de29..b546a21 100644  \n> --- a/hello.txt  \n> +++ b/hello.txt  \n> @@ -0,0 +1 @@  \n> +Nice weather today, isn't it?  \n> 比较首次提交和最后一次提交，我们可以看到所有的更改。当然使用git difftool命令更加方便。  \n> 2.回滚某个文件到之前的版本  \n> git 允许我们将某个特定的文件回滚到特定的提交，使用的也是 git checkout。  \n> 下面的例子，我们将hello.txt回滚到最初的状态，需要指定回滚到哪个提交，以及文件的全路径。  \n> ` git checkout 09bd8cc1 hello.txt`  \n> 3.回滚提交  \n> 如果你发现最新的一次提交完了加某个文件，你可以通过 git commit —amend来修复，它会把最新的提交打回暂存区，并尝试重新提交。  \n> 如果是更复杂的情况，比如不是最新的提交了。那你可以使用git revert。  \n> 最新的一次提交别名也叫HEAD。  \n> ` git revert HEAD`\n> 其他提交可以使用id:  \n> ` git revert b10cc123`  \n> 混滚提交时，发生冲突是非常频繁的。当文件被后面的提交修改了以后，git不能正确回滚。  \n> 4.解决合并冲突  \n> 冲突经常出现在合并分支或者是拉去别人的代码。有些时候git能自动处理冲突，但大部分需要我们手动处理。  \n> 比如John 和 Tim 分别在各自的分支上写了两部分代码。  \n> John 喜欢 for:  \n> // Use a for loop to console.log contents.  \n> for(var i=0; i<arr.length;   \n> i++) {  \n> console.log(arr[i]);  \n> }  \n> Tim 喜欢 forEach:  \n> // Use forEach to console.log contents.  \n> arr.forEach(function(item)   \n> {  \n> console.log(item);  \n> });  \n> 假设John 现在去拉取 Tim的代码:  \n> ` git merge tim_branch `  \n> \n> Auto-merging print_array.js  \n> CONFLICT (content): Merge conflict in print_array.js  \n> Automatic merge failed; fix conflicts and then commit the result.  \n> 这时候git并不知道如何解决冲突，因为他不知道John和Tim谁写得更好。  \n> 于是它就在代码中插入标记。  \n> <<<<<<< HEAD  \n> // Use a for loop to console.log contents.  \n> for(var i=0; i<arr.length; i++) {  \n>     console.log(arr[i]); } \n>\n> =======  \n> // Use forEach to console.log contents.  \n> arr.forEach(function(item) {  \n>     console.log(item);  \n> });  \n> \n>  \n> ====   \n> 号上方是当前最新一次提交，下方是冲突的代码。我们需要解决这样的冲突，经过组委会成员讨论，一致认定，在座的各位都是垃圾！两个都不要。改成下面的代码。  \n> // Not using for loop or forEach.  \n> // Use Array.toString() to console.log contents.  \n> console.log(arr.toString());  \n> 好了，再提交一下：  \n> `git add -A`  \n> ` git commit -m \"Array printing conflict resolved.\"`  \n> 如果在大型项目中，这个过程可能容易出问题。你可以使用GUI 工具来帮助你。使用 git mergetool。  \n> 5.配置 .gitignore  \n> 大部分项目中，会有写文件，文件夹是我们不想提交的。为了防止一不小心提交，我们需要gitignore文件：  \n> 在项目根目录创建.gitignore文件  \n> 在文件中列出不需要提交的文件名，文件夹名，每个一行  \n> .gitignore文件需要提交，就像普通文件一样  \n> 通常会被ignore的文件有：  \n> log文件  \n> task runner builds  \n> node_modules等文件夹  \n> IDEs生成的文件  \n> 个人笔记  \n> 例如：  \n> *.log  \n> build/  \n> node_modules/  \n> .idea/  \n> my_notes.txt  \n> \n","source":"_posts/git使用说明.md","raw":"---\ntitle: git使用说明详解\ndate: 2017-06-16\ntags: git\ncategories: git\n---\n1.下载geekery.repo文件，具体操作如下：\n<!--more-->\n找到存放yum文件的目录，命令如下：  \n      \n  `cd /etc/yum.repos.d/`\n   \n>  [geekery]  \n> name = geekery repository  \n> baseurl = http://geekery.altervista.org/geekery/el6/x86_64  \n> `#mirrorlist = http://geekery.altervista.org/mirrors-geekery`  \n> enabled = 1  \n> protect = 0  \n> gpgkey = http://geekery.altervista.org/download.php?filename=GEEKERY-GPG-KEY  \n> gpgcheck = 1  \n\n\n2.下载rpmforge-release rpm包  \n\ni386 http://apt.sw.be/redhat/el5/en/i386/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.i386.rpm  \nx86_64 http://apt.sw.be/redhat/el5/en/x86_64/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.x86_64.rpm\n\n`rpm -ivh rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm`\n\n3.下载epel-release rpm包，地址：http://rpm.pbone.net/，搜索epel-release，下载对应系统和适应的rmp包，之后执行安装命令如下：  \n\n`rpm -ivh epel-release-6-8.1.noarch.rpm`  \n\n\n4.安装git  \n`yum -y install git`\n\n\n\n5.git使用  \n     \n## 配置git   \n\n   首先配置git信息（git使用者的用户名及邮箱）  \n   配置好这两项，用户就可以知道谁做了什么\n\n   `git config --global user.name \"My Name\"`  \n   `git config --global user.email myEmail@example.com`  \n\n\n\n\n##  创建一个新仓库 ##\ngit 会把所有文件以及历史记录保存在你的项目中，创建一个新的仓库，首先要去到项目路径，执行 git init。然后git会创建一个隐藏的文件夹.git，所有的信息都储存在其中。  \n`cd Desktop/git_exercise/`  \n`git init`  \n现在项目还什么都没有新建一个hello.txt文件试试\n\n## 检查状态 ##\ngit status 是另一个非常重要的命令，它会告诉我们创库的当前状态：是否为最新代码，有什么更新等等执行git status:  \n`git status`\n>  $ git status\n> \n> On branch master\n> \n> Initial commit\n> \n> Untracked files:\n>   (use \"git add ...\" to include in what will be committed)\n> \n>   hello.txt  \n> git  \n\n告诉我们，hello.txt尚未跟踪，这是因为这个文件是新的，git不知道是应该跟踪它的变动呢，还是直接忽略不管呢。为了跟踪我们的新文件，我们需要暂存它。\n\n## 暂存git ##  \n\ngit 有个概念叫 暂存区，你可以把它看成一块空白帆布，包裹着所有你可能会提交的变动。它一开始为空，你可以通过 git add 命令添加内容，并使用 git commit 提交。\n这个例子中只有一个文件：  \n\n提交hello.txt文件：\n`git add hello.txt`  \n\n如果需要提交目录下的所有内容，可以这样：  \n`git add -A`  \n\n再次使用git status查看：  \n`git status`\n\n> On branch master\n> \n> Initial commit\n> \n> Changes to be committed:\n>   (use \"git rm --cached ...\" to unstage)\n> \n> new file:   hello.txt\n\n我们的文件已经提交了。状态信息还会告诉我们暂存区文件发生了什么变动，不过这里我们提交的是一个全新文件。\n\n\n## 提交本地git分支 ##\n一次提交代表着我们的仓库到了一个交付状态，通常是完成了某一块小功能。它就像是一个快照，允许我们像使用时光机一样回到旧时光。\n创建提交，需要我们提交东西到暂存区（git add），然后：  \n>    `git commit -m \"Initial commit.\"  `  \n> 这就创建了一次提交，-m “Initial commit.”表示对这次提交的描述，建议使用有意义的描述性信息。  \n> 远端仓库  \n> 到目前为止，我们的操作都是在本地的，它存在于.git文件中。为了能够协同开发，我们需要把代码发布到远端仓库上。  \n> 1.链接远端仓库 - git remote add  \n> 为了能够上传到远端仓库，我们需要先建立起链接，这篇教程中，远端仓库的地址为：https://github.com/tutorialzine/awesome-project,但你应该自己在Github,   \n> BitBucket上搭建仓库，自己一步一步尝试。  \n> 添加测试用的远端仓库  \n> ` git remote add origin https://github.com/tutorialzine/awesome-project.git`  \n> 一个项目可以同时拥有好几个远端仓库为了能够区分，通常会起不同的名字。通常主远端仓库被称为origin。  \n> 2.上传到服务器 - git push    \n> 每次我们要提交代码到服务器上时，都会使用到git push。    \n> git push命令会有两个参数，远端仓库的名字，以及分支的名字：  \n> ` git push origin master`\n> \n> Counting objects: 3, done.  \n> Writing objects: 100% (3/3), 212 bytes | 0 bytes/s, done.  \n> Total 3 (delta 0), reused 0 (delta 0)  \n> To https://github.com/tutorialzine/awesome-project.git  \n>  * [new branch]      master -master  \n\n\n> 取决于你使用的服务器，push过程你可能需要验证身份。如果没有出差错，现在使用浏览器去你的远端分支上看，hello.txt已经在那里等着你了。  \n> 3.克隆仓库 - git clone  \n> 放在Github上的开源项目，人们可以看到你的代码。可以使用 git clone进行下载到本地。  \n> ` git clone https://github.com/tutorialzine/awesome-project.git `  \n> 本地也会创建一个新的仓库，并自动将github上的分支设为远端分支。  \n> 4.从服务器上拉取代码 - git pull  \n> 如果你更新了代码到仓库上，其他人可以通过git pull命令拉取你的变动：  \n> ` git pull origin master `  \n> From https://github.com/tutorialzine/awesome-project  \n>  * branch            master     -FETCH_HEAD  \n> Already up-to-date.  \n\n  \n> 因为暂时没有其他人提交，所有没有任何变动分支\n> \n> branchs  \n> 当你在做一个新功能的时候，最好是在一个独立的区域上开发，通常称之为分支。分支之间相互独立，并且拥有自己的历史记录。这样做的原因是：  \n> 稳定版本的代码不会被破坏  \n> 不同的功能可以由不同开发者同时开发。  \n> 开发者可以专注于自己的分支，不用担心被其他人破坏了环境  \n> 在不确定之前，同一个特性可以拥有几个版本，便于比较  \n> 1.创建新分支 - git branch  \n> 每一个仓库的默认分支都叫master, 创建新分支可以这样：  \n> ` git branch amazing_new_feature`  \n> 创建了一个名为amazing_new_feature的新分支，它跟当前分支同一起点  \n> 2.切换分支 - git checkout  \n> 单独使用git branch，可以查看分支状态：  \n> ` git branch`\n>   amazing_new_feature  \n> * master  \n>   \n> * 号表示当前活跃分支为master，使用git checkout切换分支。  \n> $ git checkout amazing_new_feature  \n> 3.合并分支 - git merge  \n> 我们的 amazing_new_feature 分支的任务是增加一个featuer.txt。我们来创建，添加到暂存区，提交。  \n> ` git add feature.txt`  \n> ` git commit -m \"New feature complete.\"`  \n> 新分支任务完成了，回到master分支  \n> `git checkout master`  \n> 现在去查看文件，你会发现，之前创建的feature.txt文件不见了，因为master分支上并没有feature.txt。使用git merge 把 amazing_new_feature 分支合并到master上。  \n> `git merge amazing_new_feature`  \n> ok! 然后再把amazing_new_feature 分支删掉吧。  \n> ` git branch -d amazing_new_feature`  \n> \n> \n> 高级  \n> 1.比对两个不同提交之间的差别\n> 每次提交都有一个唯一id，查看所有提交和他们的id，可以使用 git log:  \n> `git log`\n> \n> commit ba25c0ff30e1b2f0259157b42b9f8f5d174d80d7   \n> Author: Tutorialzine  \n> Date:   Mon May 30 17:15:28 2016 +0300  \n> \n>   New feature complete  \n> \n> commit b10cc1238e355c02a044ef9f9860811ff605c9b4  \n> Author: Tutorialzine  \n> Date:   Mon May 30 16:30:04 2016 +0300  \n> \n>    Added content to hello.txt  \n> \n> commit 09bd8cc171d7084e78e4d118a2346b7487dca059  \n> Author: Tutorialzine  \n> Date:   Sat May 28 17:52:14 2016 +0300  \n> \n>    Initial commit  \n> id 很长，但是你并不需要复制整个字符串，前一小部分就够了。  \n> 查看某一次提交更新了什么，使用 git show:  \n> ` git show b10cc123`  \n> \n> commit b10cc1238e355c02a044ef9f9860811ff605c9b4  \n> Author: Tutorialzine  \n> Date:   Mon May 30 16:30:04 2016 +0300  \n> \n>    Added content to hello.txt  \n> \n> diff --git a/hello.txt b/hello.txt  \n> index e69de29..b546a21 100644  \n> --- a/hello.txt  \n> +++ b/hello.txt  \n> @@ -0,0 +1 @@  \n> +Nice weather today, isn't it?  \n> 查看两次提交的不同，可以使用git diff [commit-from]..[commit-to] 语法：  \n> ` git diff 09bd8cc..ba25c0ff`  \n>   \n> diff --git a/feature.txt b/feature.txt  \n> new file mode 100644  \n> index 0000000..e69de29  \n> diff --git a/hello.txt b/hello.txt  \n> index e69de29..b546a21 100644  \n> --- a/hello.txt  \n> +++ b/hello.txt  \n> @@ -0,0 +1 @@  \n> +Nice weather today, isn't it?  \n> 比较首次提交和最后一次提交，我们可以看到所有的更改。当然使用git difftool命令更加方便。  \n> 2.回滚某个文件到之前的版本  \n> git 允许我们将某个特定的文件回滚到特定的提交，使用的也是 git checkout。  \n> 下面的例子，我们将hello.txt回滚到最初的状态，需要指定回滚到哪个提交，以及文件的全路径。  \n> ` git checkout 09bd8cc1 hello.txt`  \n> 3.回滚提交  \n> 如果你发现最新的一次提交完了加某个文件，你可以通过 git commit —amend来修复，它会把最新的提交打回暂存区，并尝试重新提交。  \n> 如果是更复杂的情况，比如不是最新的提交了。那你可以使用git revert。  \n> 最新的一次提交别名也叫HEAD。  \n> ` git revert HEAD`\n> 其他提交可以使用id:  \n> ` git revert b10cc123`  \n> 混滚提交时，发生冲突是非常频繁的。当文件被后面的提交修改了以后，git不能正确回滚。  \n> 4.解决合并冲突  \n> 冲突经常出现在合并分支或者是拉去别人的代码。有些时候git能自动处理冲突，但大部分需要我们手动处理。  \n> 比如John 和 Tim 分别在各自的分支上写了两部分代码。  \n> John 喜欢 for:  \n> // Use a for loop to console.log contents.  \n> for(var i=0; i<arr.length;   \n> i++) {  \n> console.log(arr[i]);  \n> }  \n> Tim 喜欢 forEach:  \n> // Use forEach to console.log contents.  \n> arr.forEach(function(item)   \n> {  \n> console.log(item);  \n> });  \n> 假设John 现在去拉取 Tim的代码:  \n> ` git merge tim_branch `  \n> \n> Auto-merging print_array.js  \n> CONFLICT (content): Merge conflict in print_array.js  \n> Automatic merge failed; fix conflicts and then commit the result.  \n> 这时候git并不知道如何解决冲突，因为他不知道John和Tim谁写得更好。  \n> 于是它就在代码中插入标记。  \n> <<<<<<< HEAD  \n> // Use a for loop to console.log contents.  \n> for(var i=0; i<arr.length; i++) {  \n>     console.log(arr[i]); } \n>\n> =======  \n> // Use forEach to console.log contents.  \n> arr.forEach(function(item) {  \n>     console.log(item);  \n> });  \n> \n>  \n> ====   \n> 号上方是当前最新一次提交，下方是冲突的代码。我们需要解决这样的冲突，经过组委会成员讨论，一致认定，在座的各位都是垃圾！两个都不要。改成下面的代码。  \n> // Not using for loop or forEach.  \n> // Use Array.toString() to console.log contents.  \n> console.log(arr.toString());  \n> 好了，再提交一下：  \n> `git add -A`  \n> ` git commit -m \"Array printing conflict resolved.\"`  \n> 如果在大型项目中，这个过程可能容易出问题。你可以使用GUI 工具来帮助你。使用 git mergetool。  \n> 5.配置 .gitignore  \n> 大部分项目中，会有写文件，文件夹是我们不想提交的。为了防止一不小心提交，我们需要gitignore文件：  \n> 在项目根目录创建.gitignore文件  \n> 在文件中列出不需要提交的文件名，文件夹名，每个一行  \n> .gitignore文件需要提交，就像普通文件一样  \n> 通常会被ignore的文件有：  \n> log文件  \n> task runner builds  \n> node_modules等文件夹  \n> IDEs生成的文件  \n> 个人笔记  \n> 例如：  \n> *.log  \n> build/  \n> node_modules/  \n> .idea/  \n> my_notes.txt  \n> \n","slug":"git使用说明","published":1,"updated":"2019-06-18T08:07:01.113Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sj8000dhcb794iug0by","content":"<p>1.下载geekery.repo文件，具体操作如下：<br><a id=\"more\"></a><br>找到存放yum文件的目录，命令如下：  </p>\n<p>  <code>cd /etc/yum.repos.d/</code></p>\n<blockquote>\n<p> [geekery]<br>name = geekery repository<br>baseurl = <a href=\"http://geekery.altervista.org/geekery/el6/x86_64\" target=\"_blank\" rel=\"noopener\">http://geekery.altervista.org/geekery/el6/x86_64</a><br><code>#mirrorlist = http://geekery.altervista.org/mirrors-geekery</code><br>enabled = 1<br>protect = 0<br>gpgkey = <a href=\"http://geekery.altervista.org/download.php?filename=GEEKERY-GPG-KEY\" target=\"_blank\" rel=\"noopener\">http://geekery.altervista.org/download.php?filename=GEEKERY-GPG-KEY</a><br>gpgcheck = 1  </p>\n</blockquote>\n<p>2.下载rpmforge-release rpm包  </p>\n<p>i386 <a href=\"http://apt.sw.be/redhat/el5/en/i386/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.i386.rpm\" target=\"_blank\" rel=\"noopener\">http://apt.sw.be/redhat/el5/en/i386/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.i386.rpm</a><br>x86_64 <a href=\"http://apt.sw.be/redhat/el5/en/x86_64/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.x86_64.rpm\" target=\"_blank\" rel=\"noopener\">http://apt.sw.be/redhat/el5/en/x86_64/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.x86_64.rpm</a></p>\n<p><code>rpm -ivh rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm</code></p>\n<p>3.下载epel-release rpm包，地址：<a href=\"http://rpm.pbone.net/，搜索epel-release，下载对应系统和适应的rmp包，之后执行安装命令如下：\" target=\"_blank\" rel=\"noopener\">http://rpm.pbone.net/，搜索epel-release，下载对应系统和适应的rmp包，之后执行安装命令如下：</a>  </p>\n<p><code>rpm -ivh epel-release-6-8.1.noarch.rpm</code>  </p>\n<p>4.安装git<br><code>yum -y install git</code></p>\n<p>5.git使用  </p>\n<h2 id=\"配置git\"><a href=\"#配置git\" class=\"headerlink\" title=\"配置git\"></a>配置git</h2><p>   首先配置git信息（git使用者的用户名及邮箱）<br>   配置好这两项，用户就可以知道谁做了什么</p>\n<p>   <code>git config --global user.name &quot;My Name&quot;</code><br>   <code>git config --global user.email myEmail@example.com</code>  </p>\n<h2 id=\"创建一个新仓库\"><a href=\"#创建一个新仓库\" class=\"headerlink\" title=\"创建一个新仓库\"></a>创建一个新仓库</h2><p>git 会把所有文件以及历史记录保存在你的项目中，创建一个新的仓库，首先要去到项目路径，执行 git init。然后git会创建一个隐藏的文件夹.git，所有的信息都储存在其中。<br><code>cd Desktop/git_exercise/</code><br><code>git init</code><br>现在项目还什么都没有新建一个hello.txt文件试试</p>\n<h2 id=\"检查状态\"><a href=\"#检查状态\" class=\"headerlink\" title=\"检查状态\"></a>检查状态</h2><p>git status 是另一个非常重要的命令，它会告诉我们创库的当前状态：是否为最新代码，有什么更新等等执行git status:<br><code>git status</code></p>\n<blockquote>\n<p> $ git status</p>\n<p>On branch master</p>\n<p>Initial commit</p>\n<p>Untracked files:<br>  (use “git add …” to include in what will be committed)</p>\n<p>  hello.txt<br>git  </p>\n</blockquote>\n<p>告诉我们，hello.txt尚未跟踪，这是因为这个文件是新的，git不知道是应该跟踪它的变动呢，还是直接忽略不管呢。为了跟踪我们的新文件，我们需要暂存它。</p>\n<h2 id=\"暂存git\"><a href=\"#暂存git\" class=\"headerlink\" title=\"暂存git\"></a>暂存git</h2><p>git 有个概念叫 暂存区，你可以把它看成一块空白帆布，包裹着所有你可能会提交的变动。它一开始为空，你可以通过 git add 命令添加内容，并使用 git commit 提交。<br>这个例子中只有一个文件：  </p>\n<p>提交hello.txt文件：<br><code>git add hello.txt</code>  </p>\n<p>如果需要提交目录下的所有内容，可以这样：<br><code>git add -A</code>  </p>\n<p>再次使用git status查看：<br><code>git status</code></p>\n<blockquote>\n<p>On branch master</p>\n<p>Initial commit</p>\n<p>Changes to be committed:<br>  (use “git rm –cached …” to unstage)</p>\n<p>new file:   hello.txt</p>\n</blockquote>\n<p>我们的文件已经提交了。状态信息还会告诉我们暂存区文件发生了什么变动，不过这里我们提交的是一个全新文件。</p>\n<h2 id=\"提交本地git分支\"><a href=\"#提交本地git分支\" class=\"headerlink\" title=\"提交本地git分支\"></a>提交本地git分支</h2><p>一次提交代表着我们的仓库到了一个交付状态，通常是完成了某一块小功能。它就像是一个快照，允许我们像使用时光机一样回到旧时光。<br>创建提交，需要我们提交东西到暂存区（git add），然后：  </p>\n<blockquote>\n<p>   <code>git commit -m &quot;Initial commit.&quot;</code><br>这就创建了一次提交，-m “Initial commit.”表示对这次提交的描述，建议使用有意义的描述性信息。<br>远端仓库<br>到目前为止，我们的操作都是在本地的，它存在于.git文件中。为了能够协同开发，我们需要把代码发布到远端仓库上。<br>1.链接远端仓库 - git remote add<br>为了能够上传到远端仓库，我们需要先建立起链接，这篇教程中，远端仓库的地址为：<a href=\"https://github.com/tutorialzine/awesome-project,但你应该自己在Github\" target=\"_blank\" rel=\"noopener\">https://github.com/tutorialzine/awesome-project,但你应该自己在Github</a>,<br>BitBucket上搭建仓库，自己一步一步尝试。<br>添加测试用的远端仓库<br><code>git remote add origin https://github.com/tutorialzine/awesome-project.git</code><br>一个项目可以同时拥有好几个远端仓库为了能够区分，通常会起不同的名字。通常主远端仓库被称为origin。<br>2.上传到服务器 - git push<br>每次我们要提交代码到服务器上时，都会使用到git push。<br>git push命令会有两个参数，远端仓库的名字，以及分支的名字：<br><code>git push origin master</code></p>\n<p>Counting objects: 3, done.<br>Writing objects: 100% (3/3), 212 bytes | 0 bytes/s, done.<br>Total 3 (delta 0), reused 0 (delta 0)<br>To <a href=\"https://github.com/tutorialzine/awesome-project.git\" target=\"_blank\" rel=\"noopener\">https://github.com/tutorialzine/awesome-project.git</a>  </p>\n<ul>\n<li>[new branch]      master -master  </li>\n</ul>\n</blockquote>\n<blockquote>\n<p>取决于你使用的服务器，push过程你可能需要验证身份。如果没有出差错，现在使用浏览器去你的远端分支上看，hello.txt已经在那里等着你了。<br>3.克隆仓库 - git clone<br>放在Github上的开源项目，人们可以看到你的代码。可以使用 git clone进行下载到本地。<br><code>git clone https://github.com/tutorialzine/awesome-project.git</code><br>本地也会创建一个新的仓库，并自动将github上的分支设为远端分支。<br>4.从服务器上拉取代码 - git pull<br>如果你更新了代码到仓库上，其他人可以通过git pull命令拉取你的变动：<br><code>git pull origin master</code><br>From <a href=\"https://github.com/tutorialzine/awesome-project\" target=\"_blank\" rel=\"noopener\">https://github.com/tutorialzine/awesome-project</a>  </p>\n<ul>\n<li>branch            master     -FETCH_HEAD<br>Already up-to-date.  </li>\n</ul>\n</blockquote>\n<blockquote>\n<p>因为暂时没有其他人提交，所有没有任何变动分支</p>\n<p>branchs<br>当你在做一个新功能的时候，最好是在一个独立的区域上开发，通常称之为分支。分支之间相互独立，并且拥有自己的历史记录。这样做的原因是：<br>稳定版本的代码不会被破坏<br>不同的功能可以由不同开发者同时开发。<br>开发者可以专注于自己的分支，不用担心被其他人破坏了环境<br>在不确定之前，同一个特性可以拥有几个版本，便于比较<br>1.创建新分支 - git branch<br>每一个仓库的默认分支都叫master, 创建新分支可以这样：<br><code>git branch amazing_new_feature</code><br>创建了一个名为amazing_new_feature的新分支，它跟当前分支同一起点<br>2.切换分支 - git checkout<br>单独使用git branch，可以查看分支状态：<br><code>git branch</code><br>  amazing_new_feature  </p>\n<ul>\n<li><p>master  </p>\n</li>\n<li><p>号表示当前活跃分支为master，使用git checkout切换分支。<br>$ git checkout amazing_new_feature<br>3.合并分支 - git merge<br>我们的 amazing_new_feature 分支的任务是增加一个featuer.txt。我们来创建，添加到暂存区，提交。<br><code>git add feature.txt</code><br><code>git commit -m &quot;New feature complete.&quot;</code><br>新分支任务完成了，回到master分支<br><code>git checkout master</code><br>现在去查看文件，你会发现，之前创建的feature.txt文件不见了，因为master分支上并没有feature.txt。使用git merge 把 amazing_new_feature 分支合并到master上。<br><code>git merge amazing_new_feature</code><br>ok! 然后再把amazing_new_feature 分支删掉吧。<br><code>git branch -d amazing_new_feature</code>  </p>\n</li>\n</ul>\n<p>高级<br>1.比对两个不同提交之间的差别<br>每次提交都有一个唯一id，查看所有提交和他们的id，可以使用 git log:<br><code>git log</code></p>\n<p>commit ba25c0ff30e1b2f0259157b42b9f8f5d174d80d7<br>Author: Tutorialzine<br>Date:   Mon May 30 17:15:28 2016 +0300  </p>\n<p>  New feature complete  </p>\n<p>commit b10cc1238e355c02a044ef9f9860811ff605c9b4<br>Author: Tutorialzine<br>Date:   Mon May 30 16:30:04 2016 +0300  </p>\n<p>   Added content to hello.txt  </p>\n<p>commit 09bd8cc171d7084e78e4d118a2346b7487dca059<br>Author: Tutorialzine<br>Date:   Sat May 28 17:52:14 2016 +0300  </p>\n<p>   Initial commit<br>id 很长，但是你并不需要复制整个字符串，前一小部分就够了。<br>查看某一次提交更新了什么，使用 git show:<br><code>git show b10cc123</code>  </p>\n<p>commit b10cc1238e355c02a044ef9f9860811ff605c9b4<br>Author: Tutorialzine<br>Date:   Mon May 30 16:30:04 2016 +0300  </p>\n<p>   Added content to hello.txt  </p>\n<p>diff –git a/hello.txt b/hello.txt<br>index e69de29..b546a21 100644<br>— a/hello.txt<br>+++ b/hello.txt<br>@@ -0,0 +1 @@<br>+Nice weather today, isn’t it?<br>查看两次提交的不同，可以使用git diff [commit-from]..[commit-to] 语法：<br><code>git diff 09bd8cc..ba25c0ff</code>  </p>\n<p>diff –git a/feature.txt b/feature.txt<br>new file mode 100644<br>index 0000000..e69de29<br>diff –git a/hello.txt b/hello.txt<br>index e69de29..b546a21 100644<br>— a/hello.txt<br>+++ b/hello.txt<br>@@ -0,0 +1 @@<br>+Nice weather today, isn’t it?<br>比较首次提交和最后一次提交，我们可以看到所有的更改。当然使用git difftool命令更加方便。<br>2.回滚某个文件到之前的版本<br>git 允许我们将某个特定的文件回滚到特定的提交，使用的也是 git checkout。<br>下面的例子，我们将hello.txt回滚到最初的状态，需要指定回滚到哪个提交，以及文件的全路径。<br><code>git checkout 09bd8cc1 hello.txt</code><br>3.回滚提交<br>如果你发现最新的一次提交完了加某个文件，你可以通过 git commit —amend来修复，它会把最新的提交打回暂存区，并尝试重新提交。<br>如果是更复杂的情况，比如不是最新的提交了。那你可以使用git revert。<br>最新的一次提交别名也叫HEAD。<br><code>git revert HEAD</code><br>其他提交可以使用id:<br><code>git revert b10cc123</code><br>混滚提交时，发生冲突是非常频繁的。当文件被后面的提交修改了以后，git不能正确回滚。<br>4.解决合并冲突<br>冲突经常出现在合并分支或者是拉去别人的代码。有些时候git能自动处理冲突，但大部分需要我们手动处理。<br>比如John 和 Tim 分别在各自的分支上写了两部分代码。<br>John 喜欢 for:<br>// Use a for loop to console.log contents.<br>for(var i=0; i&lt;arr.length;<br>i++) {<br>console.log(arr[i]);<br>}<br>Tim 喜欢 forEach:<br>// Use forEach to console.log contents.<br>arr.forEach(function(item)<br>{<br>console.log(item);<br>});<br>假设John 现在去拉取 Tim的代码:<br><code>git merge tim_branch</code>  </p>\n<p>Auto-merging print_array.js<br>CONFLICT (content): Merge conflict in print_array.js<br>Automatic merge failed; fix conflicts and then commit the result.<br>这时候git并不知道如何解决冲突，因为他不知道John和Tim谁写得更好。<br>于是它就在代码中插入标记。<br>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD<br>// Use a for loop to console.log contents.<br>for(var i=0; i&lt;arr.length; i++) {<br>    console.log(arr[i]); } </p>\n<p>=======<br>// Use forEach to console.log contents.<br>arr.forEach(function(item) {<br>    console.log(item);<br>});  </p>\n<p>====<br>号上方是当前最新一次提交，下方是冲突的代码。我们需要解决这样的冲突，经过组委会成员讨论，一致认定，在座的各位都是垃圾！两个都不要。改成下面的代码。<br>// Not using for loop or forEach.<br>// Use Array.toString() to console.log contents.<br>console.log(arr.toString());<br>好了，再提交一下：<br><code>git add -A</code><br><code>git commit -m &quot;Array printing conflict resolved.&quot;</code><br>如果在大型项目中，这个过程可能容易出问题。你可以使用GUI 工具来帮助你。使用 git mergetool。<br>5.配置 .gitignore<br>大部分项目中，会有写文件，文件夹是我们不想提交的。为了防止一不小心提交，我们需要gitignore文件：<br>在项目根目录创建.gitignore文件<br>在文件中列出不需要提交的文件名，文件夹名，每个一行<br>.gitignore文件需要提交，就像普通文件一样<br>通常会被ignore的文件有：<br>log文件<br>task runner builds<br>node_modules等文件夹<br>IDEs生成的文件<br>个人笔记<br>例如：<br>*.log<br>build/<br>node_modules/<br>.idea/<br>my_notes.txt  </p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<p>1.下载geekery.repo文件，具体操作如下：<br>","more":"<br>找到存放yum文件的目录，命令如下：  </p>\n<p>  <code>cd /etc/yum.repos.d/</code></p>\n<blockquote>\n<p> [geekery]<br>name = geekery repository<br>baseurl = <a href=\"http://geekery.altervista.org/geekery/el6/x86_64\" target=\"_blank\" rel=\"noopener\">http://geekery.altervista.org/geekery/el6/x86_64</a><br><code>#mirrorlist = http://geekery.altervista.org/mirrors-geekery</code><br>enabled = 1<br>protect = 0<br>gpgkey = <a href=\"http://geekery.altervista.org/download.php?filename=GEEKERY-GPG-KEY\" target=\"_blank\" rel=\"noopener\">http://geekery.altervista.org/download.php?filename=GEEKERY-GPG-KEY</a><br>gpgcheck = 1  </p>\n</blockquote>\n<p>2.下载rpmforge-release rpm包  </p>\n<p>i386 <a href=\"http://apt.sw.be/redhat/el5/en/i386/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.i386.rpm\" target=\"_blank\" rel=\"noopener\">http://apt.sw.be/redhat/el5/en/i386/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.i386.rpm</a><br>x86_64 <a href=\"http://apt.sw.be/redhat/el5/en/x86_64/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.x86_64.rpm\" target=\"_blank\" rel=\"noopener\">http://apt.sw.be/redhat/el5/en/x86_64/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.x86_64.rpm</a></p>\n<p><code>rpm -ivh rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm</code></p>\n<p>3.下载epel-release rpm包，地址：<a href=\"http://rpm.pbone.net/，搜索epel-release，下载对应系统和适应的rmp包，之后执行安装命令如下：\" target=\"_blank\" rel=\"noopener\">http://rpm.pbone.net/，搜索epel-release，下载对应系统和适应的rmp包，之后执行安装命令如下：</a>  </p>\n<p><code>rpm -ivh epel-release-6-8.1.noarch.rpm</code>  </p>\n<p>4.安装git<br><code>yum -y install git</code></p>\n<p>5.git使用  </p>\n<h2 id=\"配置git\"><a href=\"#配置git\" class=\"headerlink\" title=\"配置git\"></a>配置git</h2><p>   首先配置git信息（git使用者的用户名及邮箱）<br>   配置好这两项，用户就可以知道谁做了什么</p>\n<p>   <code>git config --global user.name &quot;My Name&quot;</code><br>   <code>git config --global user.email myEmail@example.com</code>  </p>\n<h2 id=\"创建一个新仓库\"><a href=\"#创建一个新仓库\" class=\"headerlink\" title=\"创建一个新仓库\"></a>创建一个新仓库</h2><p>git 会把所有文件以及历史记录保存在你的项目中，创建一个新的仓库，首先要去到项目路径，执行 git init。然后git会创建一个隐藏的文件夹.git，所有的信息都储存在其中。<br><code>cd Desktop/git_exercise/</code><br><code>git init</code><br>现在项目还什么都没有新建一个hello.txt文件试试</p>\n<h2 id=\"检查状态\"><a href=\"#检查状态\" class=\"headerlink\" title=\"检查状态\"></a>检查状态</h2><p>git status 是另一个非常重要的命令，它会告诉我们创库的当前状态：是否为最新代码，有什么更新等等执行git status:<br><code>git status</code></p>\n<blockquote>\n<p> $ git status</p>\n<p>On branch master</p>\n<p>Initial commit</p>\n<p>Untracked files:<br>  (use “git add …” to include in what will be committed)</p>\n<p>  hello.txt<br>git  </p>\n</blockquote>\n<p>告诉我们，hello.txt尚未跟踪，这是因为这个文件是新的，git不知道是应该跟踪它的变动呢，还是直接忽略不管呢。为了跟踪我们的新文件，我们需要暂存它。</p>\n<h2 id=\"暂存git\"><a href=\"#暂存git\" class=\"headerlink\" title=\"暂存git\"></a>暂存git</h2><p>git 有个概念叫 暂存区，你可以把它看成一块空白帆布，包裹着所有你可能会提交的变动。它一开始为空，你可以通过 git add 命令添加内容，并使用 git commit 提交。<br>这个例子中只有一个文件：  </p>\n<p>提交hello.txt文件：<br><code>git add hello.txt</code>  </p>\n<p>如果需要提交目录下的所有内容，可以这样：<br><code>git add -A</code>  </p>\n<p>再次使用git status查看：<br><code>git status</code></p>\n<blockquote>\n<p>On branch master</p>\n<p>Initial commit</p>\n<p>Changes to be committed:<br>  (use “git rm –cached …” to unstage)</p>\n<p>new file:   hello.txt</p>\n</blockquote>\n<p>我们的文件已经提交了。状态信息还会告诉我们暂存区文件发生了什么变动，不过这里我们提交的是一个全新文件。</p>\n<h2 id=\"提交本地git分支\"><a href=\"#提交本地git分支\" class=\"headerlink\" title=\"提交本地git分支\"></a>提交本地git分支</h2><p>一次提交代表着我们的仓库到了一个交付状态，通常是完成了某一块小功能。它就像是一个快照，允许我们像使用时光机一样回到旧时光。<br>创建提交，需要我们提交东西到暂存区（git add），然后：  </p>\n<blockquote>\n<p>   <code>git commit -m &quot;Initial commit.&quot;</code><br>这就创建了一次提交，-m “Initial commit.”表示对这次提交的描述，建议使用有意义的描述性信息。<br>远端仓库<br>到目前为止，我们的操作都是在本地的，它存在于.git文件中。为了能够协同开发，我们需要把代码发布到远端仓库上。<br>1.链接远端仓库 - git remote add<br>为了能够上传到远端仓库，我们需要先建立起链接，这篇教程中，远端仓库的地址为：<a href=\"https://github.com/tutorialzine/awesome-project,但你应该自己在Github\" target=\"_blank\" rel=\"noopener\">https://github.com/tutorialzine/awesome-project,但你应该自己在Github</a>,<br>BitBucket上搭建仓库，自己一步一步尝试。<br>添加测试用的远端仓库<br><code>git remote add origin https://github.com/tutorialzine/awesome-project.git</code><br>一个项目可以同时拥有好几个远端仓库为了能够区分，通常会起不同的名字。通常主远端仓库被称为origin。<br>2.上传到服务器 - git push<br>每次我们要提交代码到服务器上时，都会使用到git push。<br>git push命令会有两个参数，远端仓库的名字，以及分支的名字：<br><code>git push origin master</code></p>\n<p>Counting objects: 3, done.<br>Writing objects: 100% (3/3), 212 bytes | 0 bytes/s, done.<br>Total 3 (delta 0), reused 0 (delta 0)<br>To <a href=\"https://github.com/tutorialzine/awesome-project.git\" target=\"_blank\" rel=\"noopener\">https://github.com/tutorialzine/awesome-project.git</a>  </p>\n<ul>\n<li>[new branch]      master -master  </li>\n</ul>\n</blockquote>\n<blockquote>\n<p>取决于你使用的服务器，push过程你可能需要验证身份。如果没有出差错，现在使用浏览器去你的远端分支上看，hello.txt已经在那里等着你了。<br>3.克隆仓库 - git clone<br>放在Github上的开源项目，人们可以看到你的代码。可以使用 git clone进行下载到本地。<br><code>git clone https://github.com/tutorialzine/awesome-project.git</code><br>本地也会创建一个新的仓库，并自动将github上的分支设为远端分支。<br>4.从服务器上拉取代码 - git pull<br>如果你更新了代码到仓库上，其他人可以通过git pull命令拉取你的变动：<br><code>git pull origin master</code><br>From <a href=\"https://github.com/tutorialzine/awesome-project\" target=\"_blank\" rel=\"noopener\">https://github.com/tutorialzine/awesome-project</a>  </p>\n<ul>\n<li>branch            master     -FETCH_HEAD<br>Already up-to-date.  </li>\n</ul>\n</blockquote>\n<blockquote>\n<p>因为暂时没有其他人提交，所有没有任何变动分支</p>\n<p>branchs<br>当你在做一个新功能的时候，最好是在一个独立的区域上开发，通常称之为分支。分支之间相互独立，并且拥有自己的历史记录。这样做的原因是：<br>稳定版本的代码不会被破坏<br>不同的功能可以由不同开发者同时开发。<br>开发者可以专注于自己的分支，不用担心被其他人破坏了环境<br>在不确定之前，同一个特性可以拥有几个版本，便于比较<br>1.创建新分支 - git branch<br>每一个仓库的默认分支都叫master, 创建新分支可以这样：<br><code>git branch amazing_new_feature</code><br>创建了一个名为amazing_new_feature的新分支，它跟当前分支同一起点<br>2.切换分支 - git checkout<br>单独使用git branch，可以查看分支状态：<br><code>git branch</code><br>  amazing_new_feature  </p>\n<ul>\n<li><p>master  </p>\n</li>\n<li><p>号表示当前活跃分支为master，使用git checkout切换分支。<br>$ git checkout amazing_new_feature<br>3.合并分支 - git merge<br>我们的 amazing_new_feature 分支的任务是增加一个featuer.txt。我们来创建，添加到暂存区，提交。<br><code>git add feature.txt</code><br><code>git commit -m &quot;New feature complete.&quot;</code><br>新分支任务完成了，回到master分支<br><code>git checkout master</code><br>现在去查看文件，你会发现，之前创建的feature.txt文件不见了，因为master分支上并没有feature.txt。使用git merge 把 amazing_new_feature 分支合并到master上。<br><code>git merge amazing_new_feature</code><br>ok! 然后再把amazing_new_feature 分支删掉吧。<br><code>git branch -d amazing_new_feature</code>  </p>\n</li>\n</ul>\n<p>高级<br>1.比对两个不同提交之间的差别<br>每次提交都有一个唯一id，查看所有提交和他们的id，可以使用 git log:<br><code>git log</code></p>\n<p>commit ba25c0ff30e1b2f0259157b42b9f8f5d174d80d7<br>Author: Tutorialzine<br>Date:   Mon May 30 17:15:28 2016 +0300  </p>\n<p>  New feature complete  </p>\n<p>commit b10cc1238e355c02a044ef9f9860811ff605c9b4<br>Author: Tutorialzine<br>Date:   Mon May 30 16:30:04 2016 +0300  </p>\n<p>   Added content to hello.txt  </p>\n<p>commit 09bd8cc171d7084e78e4d118a2346b7487dca059<br>Author: Tutorialzine<br>Date:   Sat May 28 17:52:14 2016 +0300  </p>\n<p>   Initial commit<br>id 很长，但是你并不需要复制整个字符串，前一小部分就够了。<br>查看某一次提交更新了什么，使用 git show:<br><code>git show b10cc123</code>  </p>\n<p>commit b10cc1238e355c02a044ef9f9860811ff605c9b4<br>Author: Tutorialzine<br>Date:   Mon May 30 16:30:04 2016 +0300  </p>\n<p>   Added content to hello.txt  </p>\n<p>diff –git a/hello.txt b/hello.txt<br>index e69de29..b546a21 100644<br>— a/hello.txt<br>+++ b/hello.txt<br>@@ -0,0 +1 @@<br>+Nice weather today, isn’t it?<br>查看两次提交的不同，可以使用git diff [commit-from]..[commit-to] 语法：<br><code>git diff 09bd8cc..ba25c0ff</code>  </p>\n<p>diff –git a/feature.txt b/feature.txt<br>new file mode 100644<br>index 0000000..e69de29<br>diff –git a/hello.txt b/hello.txt<br>index e69de29..b546a21 100644<br>— a/hello.txt<br>+++ b/hello.txt<br>@@ -0,0 +1 @@<br>+Nice weather today, isn’t it?<br>比较首次提交和最后一次提交，我们可以看到所有的更改。当然使用git difftool命令更加方便。<br>2.回滚某个文件到之前的版本<br>git 允许我们将某个特定的文件回滚到特定的提交，使用的也是 git checkout。<br>下面的例子，我们将hello.txt回滚到最初的状态，需要指定回滚到哪个提交，以及文件的全路径。<br><code>git checkout 09bd8cc1 hello.txt</code><br>3.回滚提交<br>如果你发现最新的一次提交完了加某个文件，你可以通过 git commit —amend来修复，它会把最新的提交打回暂存区，并尝试重新提交。<br>如果是更复杂的情况，比如不是最新的提交了。那你可以使用git revert。<br>最新的一次提交别名也叫HEAD。<br><code>git revert HEAD</code><br>其他提交可以使用id:<br><code>git revert b10cc123</code><br>混滚提交时，发生冲突是非常频繁的。当文件被后面的提交修改了以后，git不能正确回滚。<br>4.解决合并冲突<br>冲突经常出现在合并分支或者是拉去别人的代码。有些时候git能自动处理冲突，但大部分需要我们手动处理。<br>比如John 和 Tim 分别在各自的分支上写了两部分代码。<br>John 喜欢 for:<br>// Use a for loop to console.log contents.<br>for(var i=0; i&lt;arr.length;<br>i++) {<br>console.log(arr[i]);<br>}<br>Tim 喜欢 forEach:<br>// Use forEach to console.log contents.<br>arr.forEach(function(item)<br>{<br>console.log(item);<br>});<br>假设John 现在去拉取 Tim的代码:<br><code>git merge tim_branch</code>  </p>\n<p>Auto-merging print_array.js<br>CONFLICT (content): Merge conflict in print_array.js<br>Automatic merge failed; fix conflicts and then commit the result.<br>这时候git并不知道如何解决冲突，因为他不知道John和Tim谁写得更好。<br>于是它就在代码中插入标记。<br>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD<br>// Use a for loop to console.log contents.<br>for(var i=0; i&lt;arr.length; i++) {<br>    console.log(arr[i]); } </p>\n<p>=======<br>// Use forEach to console.log contents.<br>arr.forEach(function(item) {<br>    console.log(item);<br>});  </p>\n<p>====<br>号上方是当前最新一次提交，下方是冲突的代码。我们需要解决这样的冲突，经过组委会成员讨论，一致认定，在座的各位都是垃圾！两个都不要。改成下面的代码。<br>// Not using for loop or forEach.<br>// Use Array.toString() to console.log contents.<br>console.log(arr.toString());<br>好了，再提交一下：<br><code>git add -A</code><br><code>git commit -m &quot;Array printing conflict resolved.&quot;</code><br>如果在大型项目中，这个过程可能容易出问题。你可以使用GUI 工具来帮助你。使用 git mergetool。<br>5.配置 .gitignore<br>大部分项目中，会有写文件，文件夹是我们不想提交的。为了防止一不小心提交，我们需要gitignore文件：<br>在项目根目录创建.gitignore文件<br>在文件中列出不需要提交的文件名，文件夹名，每个一行<br>.gitignore文件需要提交，就像普通文件一样<br>通常会被ignore的文件有：<br>log文件<br>task runner builds<br>node_modules等文件夹<br>IDEs生成的文件<br>个人笔记<br>例如：<br>*.log<br>build/<br>node_modules/<br>.idea/<br>my_notes.txt  </p>\n</blockquote>"},{"title":"Hello World","date":"2014-09-02T04:00:00.000Z","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ndate: 2014-09-02\ntags:\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"updated":"2019-06-18T08:07:01.114Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sjf000hhcb7qnfxx1xg","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n"},{"title":"搭建Hexo","date":"2016-09-02T04:00:00.000Z","_content":"1、安装编译npm基础包\n    rpm -Uvh http://download-i2.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm\n<!--more-->\n\n    yum install nodejs npm --enablerepo=epel\n部署 Hexo --- 安装\n    npm install -g hexo\n部署 Hexo --- 初始化\n    mkdir /home/wwwroot && hexo init /home/wwwroot","source":"_posts/hexo.md","raw":"---\ntitle: 搭建Hexo\ndate: 2016-09-02\ntags:\n---\n1、安装编译npm基础包\n    rpm -Uvh http://download-i2.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm\n<!--more-->\n\n    yum install nodejs npm --enablerepo=epel\n部署 Hexo --- 安装\n    npm install -g hexo\n部署 Hexo --- 初始化\n    mkdir /home/wwwroot && hexo init /home/wwwroot","slug":"hexo","published":1,"updated":"2019-06-18T08:07:01.114Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sjk000jhcb7s8p2bm81","content":"<p>1、安装编译npm基础包<br>    rpm -Uvh <a href=\"http://download-i2.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm\" target=\"_blank\" rel=\"noopener\">http://download-i2.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm</a><br><a id=\"more\"></a></p>\n<pre><code>yum install nodejs npm --enablerepo=epel\n</code></pre><p>部署 Hexo — 安装<br>    npm install -g hexo<br>部署 Hexo — 初始化<br>    mkdir /home/wwwroot &amp;&amp; hexo init /home/wwwroot</p>\n","site":{"data":{}},"excerpt":"<p>1、安装编译npm基础包<br>    rpm -Uvh <a href=\"http://download-i2.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm\" target=\"_blank\" rel=\"noopener\">http://download-i2.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm</a><br>","more":"</p>\n<pre><code>yum install nodejs npm --enablerepo=epel\n</code></pre><p>部署 Hexo — 安装<br>    npm install -g hexo<br>部署 Hexo — 初始化<br>    mkdir /home/wwwroot &amp;&amp; hexo init /home/wwwroot</p>"},{"title":"htop使用说明","date":"2016-09-06T04:00:00.000Z","_content":"一、htop 简介\n\nThis is htop, an interactive process viewer for Linux. It is a text-mode application (for console or X terminals) and requires ncurses.\n\nComparison between htop and top\n<!--more-->\nIn 'htop' you can scroll the list vertically and horizontally to see all processes and complete command lines.\nIn 'top' you are subject to a delay for each unassigned key you press (especially annoying when multi-key escape sequences are triggered by accident).\n'htop' starts faster ('top' seems to collect data for a while before displaying anything).\nIn 'htop' you don't need to type the process number to kill a process, in 'top' you do.\nIn 'htop' you don't need to type the process number or the priority value to renice a process, in 'top' you do.\n'htop' supports mouse operation, 'top' doesn't\n'top' is older, hence, more used and tested.\nhtop 是Linux系统中的一个互动的进程查看器，一个文本模式的应用程序(在控制台或者X终端中)，需要ncurses。\n\n与Linux传统的top相比，htop更加人性化。它可让用户交互式操作，支持颜色主题，可横向或纵向滚动浏览进程列表，并支持鼠标操作。\n\n与top相比，htop有以下优点：\n\n可以横向或纵向滚动浏览进程列表，以便看到所有的进程和完整的命令行。\n在启动上，比top 更快。\n杀进程时不需要输入进程号。\nhtop 支持鼠标操作。\ntop 已经很老了。\nhtop 官网：http://htop.sourceforge.net/\n\n二、htop 安装\n\na. 源码包安装\n\n    # tar zxvf htop-1.0.2.tar.gz\n    \n    # cd htop-1.0.2\n    \n    # ./configure\n    \n![](http://images.cnitblog.com/blog/370046/201301/12224043-10fbaaa4ef2d49ba844de4ff1df2cea2.jpg)\n\n    # make && make install\n\n![](http://images.cnitblog.com/blog/370046/201301/12224044-8e70dd81c3594f14bf334dbf7ae12cda.jpg)\n\n若出现错误：\n\n\n    configure: error: You may want to use --disable-unicode or install libncursesw.\n\n则需安装 ncurses-devel\n\n\n    # yum install ncurses-devel\n\nb. RHEL/CentOS 安装\n\n可以通过 yum install htop 来安装它，但前提是要添加epel 的yum源，具体请参考 CentOS yum 源的配置与使用。\n\n    # rpm -ivh http://download.fedoraproject.org/pub/epel/5/i386/epel-release-5-4.noarch.rpm \n    # rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL//导入key \n    # yum install htop\n    \n三、htop 参数\n\n键入htop 命令，打开htop。\n\n\n    # htop\n\n\n ![](http://images.cnitblog.com/blog/370046/201301/12224047-b6fd5270cea14cee87544ff3ca193b34.jpg)\n\n上面左上角显示CPU、内存、交换区的使用情况，右边显示任务、负载、开机时间，下面就是进程实时状况。\n\n下面是 F1~F10 的功能和对应的字母快捷键。\n\n----------\n\nShortcut Key　　　　　　  　　 Function Ke　　　　　　  　　 Description　　　　　　 　　　　　　  　　  中文说明  \n\nh,?　　　　　　  　　　　　　　  　　   F1\t　　　　　　  　　 Invoke htop Help　　　　　　  　　 \t　　　　　　查看htop使用说明  \nS\t　　　　　　  　　 　　　　　　  　　F2　　　　　　  　　 \tHtop Setup Menu\thtop　　　　　　  　　 　　　 设定  \n/\t　　　　　　  　　 　　　　　　   　　  F3\t　　　　　　  　　 Search for a Process\t　　　　　　  　　　　　　 搜索进程  \n\\\t　　　　　　  　　 　　　　　　  　　 F4\t　　　　　　  　　 Incremental process filtering\t　　　　　　  　　 增量进程过滤器  \nt\t　　　　　　  　　 　　　　　　  　　 F5　　　　　　  　　 \tTree View\t　　　　　　  　　 　　　　　　  　　　 显示树形结构  \n<, >\t　　　　　　  　　 　　　　　　  　F6\t　　　　　　  　　 Sort by a column\t　　　　　　  　　　　　　　　   选择排序方式  \n[\t　　　　　　  　　 　　　　　　  　　 F7\t　　　　　　  　　 Nice - (change priority)\t　　　可减少nice值，这样就可以提高对应进程的优先级  \n]\t　　　　　　  　　 　　　　　　  　　 F8\t　　　　　　  　　 Nice + (change priority)\t　　　可增加nice值，这样就可以降低对应进程的优先级  \nk\t　　　　　　  　　 　　　　　　  　　 F9\t　　　　　　  　　 Kill a Process\t　　　　　　  　　 　　　　　　  　可对进程传递信号  \nq\t　　　　　　  　　 　　　　　　  　　 F10\t　　　　　　  　　 Quit htop\t　　　　　　  　　 　　　　　　  　　 结束htop  \n\n----------\n\n命令行选项（COMMAND-LINE OPTIONS）\n\n-C --no-color　　　　 　　 使用一个单色的配色方案\n\n-d --delay=DELAY　　　　 设置延迟更新时间，单位秒\n\n-h --help　　　　　　  　　 显示htop 命令帮助信息\n\n-u --user=USERNAME　　  只显示一个给定的用户的过程\n\n-p --pid=PID,PID…　　　    只显示给定的PIDs\n\n-s --sort-key COLUMN　    依此列来排序\n\n-v –version　　　　　　　   显示版本信息\n\n交互式命令（INTERACTIVE COMMANDS）\n\n----------\n\n\n上下键或PgUP, PgDn 选定想要的进程，左右键或Home, End 移动字段，当然也可以直接用鼠标选定进程；\n\nSpace    标记/取消标记一个进程。命令可以作用于多个进程，例如 \"kill\"，将应用于所有已标记的进程\n\nU    取消标记所有进程\n\ns    选择某一进程，按s:用strace追踪进程的系统调用\n\nl    显示进程打开的文件: 如果安装了lsof，按此键可以显示进程所打开的文件\n\nI    倒转排序顺序，如果排序是正序的，则反转成倒序的，反之亦然\n\n+, -    When in tree view mode, expand or collapse subtree. When a subtree is collapsed a \"+\" sign shows to the left of the process name.\n\na (在有多处理器的机器上)    设置 CPU affinity: 标记一个进程允许使用哪些CPU\n\nu    显示特定用户进程\n\nM    按Memory 使用排序\n\nP    按CPU 使用排序\n\nT    按Time+ 使用排序\n\nF    跟踪进程: 如果排序顺序引起选定的进程在列表上到处移动，让选定条跟随该进程。这对监视一个进程非常有用：通过这种方式，你可以让一个进程在屏幕上一直可见。使用方向键会停止该功能。\n\nK    显示/隐藏内核线程\n\nH    显示/隐藏用户线程\n\nCtrl-L    刷新\n\nNumbers    PID 查找: 输入PID，光标将移动到相应的进程上\n\n----------\n\n\n四、htop 使用\n\n4.1. 显示自带帮助\n\n鼠标点击Help或者按F1 显示自带帮助\n![](http://images.cnitblog.com/blog/370046/201301/12224049-575f66ab3d964c5cb419959aee9032b1.jpg)\n\n\n4.2. htop 设定\n\n鼠标点击Setup或者按下F2 之后进入htop 设定的页面，Meters 页面设定了顶端的一些信息显示，顶端的显示又分为左右两侧，到底能显示些什么可以在最右侧那栏新增，要新增到上方左侧（F5）或是右侧（F6）都可以，这就是个人设定的范围了。这里多加了一个时钟。\n\n![](http://images.cnitblog.com/blog/370046/201301/12224051-9b4d728776d1499190c9d21ab3615f5a.jpg)\n\n上方左右两栏的显示方式分为Text Bar Graph Led 四种，下图我就把 cpu memory swap 改成文本模式显示，然后右栏的改成Bar 显示，clock 用LED方式显示。数据显示都差不多，只是这样看有点不习惯了。\n\n![](http://images.cnitblog.com/blog/370046/201301/12224052-befc1e283e4c4576a59f89e6f72a4337.jpg)\n\n关于Display options 的设定，可要根据管理者自己的需要来设定。\n\n![](http://images.cnitblog.com/blog/370046/201301/12224054-b8d7722ac20b421299bd0c72b3394198.jpg)\n\n颜色选择，除了基本的颜色显示之外，htop 还提供了换面板的功能，其实也只是改变一些色彩显示的设定，虽然说不能自定义到细部的颜色显示，但是至少提供了几种风格可以选择。\n\n![](http://images.cnitblog.com/blog/370046/201301/12224055-b6a13eb2abaa45fab167e61a8db12356.jpg)\n\n最后一项的设定是调整 Columns 的显示，就是在一般htop 指令进来希望可以看到的什么样的数据及信息，字段的调整可以在这边做个人化的设定，一般使用系统默认值就好了。\n\n![](http://images.cnitblog.com/blog/370046/201301/12224058-1ef4f726ccd64dfbaab68142dc9a95be.jpg)\n\n4.3. 搜索进程\n\n鼠标点击Search 或者按下F3 或者输入\"/\"， 输入进程名进行搜索，例如搜索ssh\n\n![](http://images.cnitblog.com/blog/370046/201301/12224100-dab0040192b24614b44d1e28d1b4badb.jpg)\n\n4.4. 过滤器\n\n按下F4，进入过滤器，相当于关键字搜索，不区分大小写，例如过滤dev\n\n![](http://images.cnitblog.com/blog/370046/201301/12224102-6339cac4da0b482097e1a5b218b523c4.jpg)\n\n4.5. 显示树形结构\n\n输入\"t\"或按下F5，显示树形结构，意思跟pstree 差不多，能看到所有程序树状执行的结构，这对于系统管理来说相当方便，理清程序是如何产生的，当然树状结构的浏览也可以依照其他数据来排序。\n\n![](http://images.cnitblog.com/blog/370046/201301/12224104-f5d4a8c905cd4a83b262ad2e5944f3fe.jpg)\n\n4.6. 选择排序方式\n\n按下F6 就可以选择依照什么来排序，最常排序的内容就是cpu 和memory 吧！\n\n![](http://images.cnitblog.com/blog/370046/201301/12224107-6a091d2523cd4829b243f635b1c32a0a.jpg)\n\n4.7 操作进程\n\nF7、F8分别对应nice-和nice+，F9对应kill给进程发信号，选好信号回车就OK了\n\n![](http://images.cnitblog.com/blog/370046/201301/12224112-9dc1706a8dbd4972b78a78af34f75ec7.jpg)\n\n4.8. 显示某个用户的进程，在左侧选择用户\n\n输入\"u\"，在左侧选择用户\n\n![](http://images.cnitblog.com/blog/370046/201301/12224115-289b4cf95c344dada4aa048c25f821ce.jpg)\n\n五、Alias top\n\n也许你用惯了top，我们也可以用top来打开htop。\n\n编辑/root/.bashrc文件，添加如下代码\n\n    if [ -f /usr/local/bin/htop ]; then\n    alias top=’/usr/local/bin/htop’\n    fi\n    # source /root/.bashrc\n","source":"_posts/htop使用说明.md","raw":"---\ntitle: htop使用说明\ndate: 2016-09-06\ntags: linux\ncategories: linux\n---\n一、htop 简介\n\nThis is htop, an interactive process viewer for Linux. It is a text-mode application (for console or X terminals) and requires ncurses.\n\nComparison between htop and top\n<!--more-->\nIn 'htop' you can scroll the list vertically and horizontally to see all processes and complete command lines.\nIn 'top' you are subject to a delay for each unassigned key you press (especially annoying when multi-key escape sequences are triggered by accident).\n'htop' starts faster ('top' seems to collect data for a while before displaying anything).\nIn 'htop' you don't need to type the process number to kill a process, in 'top' you do.\nIn 'htop' you don't need to type the process number or the priority value to renice a process, in 'top' you do.\n'htop' supports mouse operation, 'top' doesn't\n'top' is older, hence, more used and tested.\nhtop 是Linux系统中的一个互动的进程查看器，一个文本模式的应用程序(在控制台或者X终端中)，需要ncurses。\n\n与Linux传统的top相比，htop更加人性化。它可让用户交互式操作，支持颜色主题，可横向或纵向滚动浏览进程列表，并支持鼠标操作。\n\n与top相比，htop有以下优点：\n\n可以横向或纵向滚动浏览进程列表，以便看到所有的进程和完整的命令行。\n在启动上，比top 更快。\n杀进程时不需要输入进程号。\nhtop 支持鼠标操作。\ntop 已经很老了。\nhtop 官网：http://htop.sourceforge.net/\n\n二、htop 安装\n\na. 源码包安装\n\n    # tar zxvf htop-1.0.2.tar.gz\n    \n    # cd htop-1.0.2\n    \n    # ./configure\n    \n![](http://images.cnitblog.com/blog/370046/201301/12224043-10fbaaa4ef2d49ba844de4ff1df2cea2.jpg)\n\n    # make && make install\n\n![](http://images.cnitblog.com/blog/370046/201301/12224044-8e70dd81c3594f14bf334dbf7ae12cda.jpg)\n\n若出现错误：\n\n\n    configure: error: You may want to use --disable-unicode or install libncursesw.\n\n则需安装 ncurses-devel\n\n\n    # yum install ncurses-devel\n\nb. RHEL/CentOS 安装\n\n可以通过 yum install htop 来安装它，但前提是要添加epel 的yum源，具体请参考 CentOS yum 源的配置与使用。\n\n    # rpm -ivh http://download.fedoraproject.org/pub/epel/5/i386/epel-release-5-4.noarch.rpm \n    # rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL//导入key \n    # yum install htop\n    \n三、htop 参数\n\n键入htop 命令，打开htop。\n\n\n    # htop\n\n\n ![](http://images.cnitblog.com/blog/370046/201301/12224047-b6fd5270cea14cee87544ff3ca193b34.jpg)\n\n上面左上角显示CPU、内存、交换区的使用情况，右边显示任务、负载、开机时间，下面就是进程实时状况。\n\n下面是 F1~F10 的功能和对应的字母快捷键。\n\n----------\n\nShortcut Key　　　　　　  　　 Function Ke　　　　　　  　　 Description　　　　　　 　　　　　　  　　  中文说明  \n\nh,?　　　　　　  　　　　　　　  　　   F1\t　　　　　　  　　 Invoke htop Help　　　　　　  　　 \t　　　　　　查看htop使用说明  \nS\t　　　　　　  　　 　　　　　　  　　F2　　　　　　  　　 \tHtop Setup Menu\thtop　　　　　　  　　 　　　 设定  \n/\t　　　　　　  　　 　　　　　　   　　  F3\t　　　　　　  　　 Search for a Process\t　　　　　　  　　　　　　 搜索进程  \n\\\t　　　　　　  　　 　　　　　　  　　 F4\t　　　　　　  　　 Incremental process filtering\t　　　　　　  　　 增量进程过滤器  \nt\t　　　　　　  　　 　　　　　　  　　 F5　　　　　　  　　 \tTree View\t　　　　　　  　　 　　　　　　  　　　 显示树形结构  \n<, >\t　　　　　　  　　 　　　　　　  　F6\t　　　　　　  　　 Sort by a column\t　　　　　　  　　　　　　　　   选择排序方式  \n[\t　　　　　　  　　 　　　　　　  　　 F7\t　　　　　　  　　 Nice - (change priority)\t　　　可减少nice值，这样就可以提高对应进程的优先级  \n]\t　　　　　　  　　 　　　　　　  　　 F8\t　　　　　　  　　 Nice + (change priority)\t　　　可增加nice值，这样就可以降低对应进程的优先级  \nk\t　　　　　　  　　 　　　　　　  　　 F9\t　　　　　　  　　 Kill a Process\t　　　　　　  　　 　　　　　　  　可对进程传递信号  \nq\t　　　　　　  　　 　　　　　　  　　 F10\t　　　　　　  　　 Quit htop\t　　　　　　  　　 　　　　　　  　　 结束htop  \n\n----------\n\n命令行选项（COMMAND-LINE OPTIONS）\n\n-C --no-color　　　　 　　 使用一个单色的配色方案\n\n-d --delay=DELAY　　　　 设置延迟更新时间，单位秒\n\n-h --help　　　　　　  　　 显示htop 命令帮助信息\n\n-u --user=USERNAME　　  只显示一个给定的用户的过程\n\n-p --pid=PID,PID…　　　    只显示给定的PIDs\n\n-s --sort-key COLUMN　    依此列来排序\n\n-v –version　　　　　　　   显示版本信息\n\n交互式命令（INTERACTIVE COMMANDS）\n\n----------\n\n\n上下键或PgUP, PgDn 选定想要的进程，左右键或Home, End 移动字段，当然也可以直接用鼠标选定进程；\n\nSpace    标记/取消标记一个进程。命令可以作用于多个进程，例如 \"kill\"，将应用于所有已标记的进程\n\nU    取消标记所有进程\n\ns    选择某一进程，按s:用strace追踪进程的系统调用\n\nl    显示进程打开的文件: 如果安装了lsof，按此键可以显示进程所打开的文件\n\nI    倒转排序顺序，如果排序是正序的，则反转成倒序的，反之亦然\n\n+, -    When in tree view mode, expand or collapse subtree. When a subtree is collapsed a \"+\" sign shows to the left of the process name.\n\na (在有多处理器的机器上)    设置 CPU affinity: 标记一个进程允许使用哪些CPU\n\nu    显示特定用户进程\n\nM    按Memory 使用排序\n\nP    按CPU 使用排序\n\nT    按Time+ 使用排序\n\nF    跟踪进程: 如果排序顺序引起选定的进程在列表上到处移动，让选定条跟随该进程。这对监视一个进程非常有用：通过这种方式，你可以让一个进程在屏幕上一直可见。使用方向键会停止该功能。\n\nK    显示/隐藏内核线程\n\nH    显示/隐藏用户线程\n\nCtrl-L    刷新\n\nNumbers    PID 查找: 输入PID，光标将移动到相应的进程上\n\n----------\n\n\n四、htop 使用\n\n4.1. 显示自带帮助\n\n鼠标点击Help或者按F1 显示自带帮助\n![](http://images.cnitblog.com/blog/370046/201301/12224049-575f66ab3d964c5cb419959aee9032b1.jpg)\n\n\n4.2. htop 设定\n\n鼠标点击Setup或者按下F2 之后进入htop 设定的页面，Meters 页面设定了顶端的一些信息显示，顶端的显示又分为左右两侧，到底能显示些什么可以在最右侧那栏新增，要新增到上方左侧（F5）或是右侧（F6）都可以，这就是个人设定的范围了。这里多加了一个时钟。\n\n![](http://images.cnitblog.com/blog/370046/201301/12224051-9b4d728776d1499190c9d21ab3615f5a.jpg)\n\n上方左右两栏的显示方式分为Text Bar Graph Led 四种，下图我就把 cpu memory swap 改成文本模式显示，然后右栏的改成Bar 显示，clock 用LED方式显示。数据显示都差不多，只是这样看有点不习惯了。\n\n![](http://images.cnitblog.com/blog/370046/201301/12224052-befc1e283e4c4576a59f89e6f72a4337.jpg)\n\n关于Display options 的设定，可要根据管理者自己的需要来设定。\n\n![](http://images.cnitblog.com/blog/370046/201301/12224054-b8d7722ac20b421299bd0c72b3394198.jpg)\n\n颜色选择，除了基本的颜色显示之外，htop 还提供了换面板的功能，其实也只是改变一些色彩显示的设定，虽然说不能自定义到细部的颜色显示，但是至少提供了几种风格可以选择。\n\n![](http://images.cnitblog.com/blog/370046/201301/12224055-b6a13eb2abaa45fab167e61a8db12356.jpg)\n\n最后一项的设定是调整 Columns 的显示，就是在一般htop 指令进来希望可以看到的什么样的数据及信息，字段的调整可以在这边做个人化的设定，一般使用系统默认值就好了。\n\n![](http://images.cnitblog.com/blog/370046/201301/12224058-1ef4f726ccd64dfbaab68142dc9a95be.jpg)\n\n4.3. 搜索进程\n\n鼠标点击Search 或者按下F3 或者输入\"/\"， 输入进程名进行搜索，例如搜索ssh\n\n![](http://images.cnitblog.com/blog/370046/201301/12224100-dab0040192b24614b44d1e28d1b4badb.jpg)\n\n4.4. 过滤器\n\n按下F4，进入过滤器，相当于关键字搜索，不区分大小写，例如过滤dev\n\n![](http://images.cnitblog.com/blog/370046/201301/12224102-6339cac4da0b482097e1a5b218b523c4.jpg)\n\n4.5. 显示树形结构\n\n输入\"t\"或按下F5，显示树形结构，意思跟pstree 差不多，能看到所有程序树状执行的结构，这对于系统管理来说相当方便，理清程序是如何产生的，当然树状结构的浏览也可以依照其他数据来排序。\n\n![](http://images.cnitblog.com/blog/370046/201301/12224104-f5d4a8c905cd4a83b262ad2e5944f3fe.jpg)\n\n4.6. 选择排序方式\n\n按下F6 就可以选择依照什么来排序，最常排序的内容就是cpu 和memory 吧！\n\n![](http://images.cnitblog.com/blog/370046/201301/12224107-6a091d2523cd4829b243f635b1c32a0a.jpg)\n\n4.7 操作进程\n\nF7、F8分别对应nice-和nice+，F9对应kill给进程发信号，选好信号回车就OK了\n\n![](http://images.cnitblog.com/blog/370046/201301/12224112-9dc1706a8dbd4972b78a78af34f75ec7.jpg)\n\n4.8. 显示某个用户的进程，在左侧选择用户\n\n输入\"u\"，在左侧选择用户\n\n![](http://images.cnitblog.com/blog/370046/201301/12224115-289b4cf95c344dada4aa048c25f821ce.jpg)\n\n五、Alias top\n\n也许你用惯了top，我们也可以用top来打开htop。\n\n编辑/root/.bashrc文件，添加如下代码\n\n    if [ -f /usr/local/bin/htop ]; then\n    alias top=’/usr/local/bin/htop’\n    fi\n    # source /root/.bashrc\n","slug":"htop使用说明","published":1,"updated":"2019-06-18T08:07:01.114Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sjq000nhcb7c3a1znis","content":"<p>一、htop 简介</p>\n<p>This is htop, an interactive process viewer for Linux. It is a text-mode application (for console or X terminals) and requires ncurses.</p>\n<p>Comparison between htop and top<br><a id=\"more\"></a><br>In ‘htop’ you can scroll the list vertically and horizontally to see all processes and complete command lines.<br>In ‘top’ you are subject to a delay for each unassigned key you press (especially annoying when multi-key escape sequences are triggered by accident).<br>‘htop’ starts faster (‘top’ seems to collect data for a while before displaying anything).<br>In ‘htop’ you don’t need to type the process number to kill a process, in ‘top’ you do.<br>In ‘htop’ you don’t need to type the process number or the priority value to renice a process, in ‘top’ you do.<br>‘htop’ supports mouse operation, ‘top’ doesn’t<br>‘top’ is older, hence, more used and tested.<br>htop 是Linux系统中的一个互动的进程查看器，一个文本模式的应用程序(在控制台或者X终端中)，需要ncurses。</p>\n<p>与Linux传统的top相比，htop更加人性化。它可让用户交互式操作，支持颜色主题，可横向或纵向滚动浏览进程列表，并支持鼠标操作。</p>\n<p>与top相比，htop有以下优点：</p>\n<p>可以横向或纵向滚动浏览进程列表，以便看到所有的进程和完整的命令行。<br>在启动上，比top 更快。<br>杀进程时不需要输入进程号。<br>htop 支持鼠标操作。<br>top 已经很老了。<br>htop 官网：<a href=\"http://htop.sourceforge.net/\" target=\"_blank\" rel=\"noopener\">http://htop.sourceforge.net/</a></p>\n<p>二、htop 安装</p>\n<p>a. 源码包安装</p>\n<pre><code># tar zxvf htop-1.0.2.tar.gz\n\n# cd htop-1.0.2\n\n# ./configure\n</code></pre><p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224043-10fbaaa4ef2d49ba844de4ff1df2cea2.jpg\" alt=\"\"></p>\n<pre><code># make &amp;&amp; make install\n</code></pre><p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224044-8e70dd81c3594f14bf334dbf7ae12cda.jpg\" alt=\"\"></p>\n<p>若出现错误：</p>\n<pre><code>configure: error: You may want to use --disable-unicode or install libncursesw.\n</code></pre><p>则需安装 ncurses-devel</p>\n<pre><code># yum install ncurses-devel\n</code></pre><p>b. RHEL/CentOS 安装</p>\n<p>可以通过 yum install htop 来安装它，但前提是要添加epel 的yum源，具体请参考 CentOS yum 源的配置与使用。</p>\n<pre><code># rpm -ivh http://download.fedoraproject.org/pub/epel/5/i386/epel-release-5-4.noarch.rpm \n# rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL//导入key \n# yum install htop\n</code></pre><p>三、htop 参数</p>\n<p>键入htop 命令，打开htop。</p>\n<pre><code># htop\n</code></pre><p> <img src=\"http://images.cnitblog.com/blog/370046/201301/12224047-b6fd5270cea14cee87544ff3ca193b34.jpg\" alt=\"\"></p>\n<p>上面左上角显示CPU、内存、交换区的使用情况，右边显示任务、负载、开机时间，下面就是进程实时状况。</p>\n<p>下面是 F1~F10 的功能和对应的字母快捷键。</p>\n<hr>\n<p>Shortcut Key　　　　　　  　　 Function Ke　　　　　　  　　 Description　　　　　　 　　　　　　  　　  中文说明  </p>\n<p>h,?　　　　　　  　　　　　　　  　　   F1    　　　　　　  　　 Invoke htop Help　　　　　　  　　     　　　　　　查看htop使用说明<br>S    　　　　　　  　　 　　　　　　  　　F2　　　　　　  　　     Htop Setup Menu    htop　　　　　　  　　 　　　 设定<br>/    　　　　　　  　　 　　　　　　   　　  F3    　　　　　　  　　 Search for a Process    　　　　　　  　　　　　　 搜索进程<br>\\    　　　　　　  　　 　　　　　　  　　 F4    　　　　　　  　　 Incremental process filtering    　　　　　　  　　 增量进程过滤器<br>t    　　　　　　  　　 　　　　　　  　　 F5　　　　　　  　　     Tree View    　　　　　　  　　 　　　　　　  　　　 显示树形结构<br>&lt;, &gt;    　　　　　　  　　 　　　　　　  　F6    　　　　　　  　　 Sort by a column    　　　　　　  　　　　　　　　   选择排序方式<br>[    　　　　　　  　　 　　　　　　  　　 F7    　　　　　　  　　 Nice - (change priority)    　　　可减少nice值，这样就可以提高对应进程的优先级<br>]    　　　　　　  　　 　　　　　　  　　 F8    　　　　　　  　　 Nice + (change priority)    　　　可增加nice值，这样就可以降低对应进程的优先级<br>k    　　　　　　  　　 　　　　　　  　　 F9    　　　　　　  　　 Kill a Process    　　　　　　  　　 　　　　　　  　可对进程传递信号<br>q    　　　　　　  　　 　　　　　　  　　 F10    　　　　　　  　　 Quit htop    　　　　　　  　　 　　　　　　  　　 结束htop  </p>\n<hr>\n<p>命令行选项（COMMAND-LINE OPTIONS）</p>\n<p>-C –no-color　　　　 　　 使用一个单色的配色方案</p>\n<p>-d –delay=DELAY　　　　 设置延迟更新时间，单位秒</p>\n<p>-h –help　　　　　　  　　 显示htop 命令帮助信息</p>\n<p>-u –user=USERNAME　　  只显示一个给定的用户的过程</p>\n<p>-p –pid=PID,PID…　　　    只显示给定的PIDs</p>\n<p>-s –sort-key COLUMN　    依此列来排序</p>\n<p>-v –version　　　　　　　   显示版本信息</p>\n<p>交互式命令（INTERACTIVE COMMANDS）</p>\n<hr>\n<p>上下键或PgUP, PgDn 选定想要的进程，左右键或Home, End 移动字段，当然也可以直接用鼠标选定进程；</p>\n<p>Space    标记/取消标记一个进程。命令可以作用于多个进程，例如 “kill”，将应用于所有已标记的进程</p>\n<p>U    取消标记所有进程</p>\n<p>s    选择某一进程，按s:用strace追踪进程的系统调用</p>\n<p>l    显示进程打开的文件: 如果安装了lsof，按此键可以显示进程所打开的文件</p>\n<p>I    倒转排序顺序，如果排序是正序的，则反转成倒序的，反之亦然</p>\n<p>+, -    When in tree view mode, expand or collapse subtree. When a subtree is collapsed a “+” sign shows to the left of the process name.</p>\n<p>a (在有多处理器的机器上)    设置 CPU affinity: 标记一个进程允许使用哪些CPU</p>\n<p>u    显示特定用户进程</p>\n<p>M    按Memory 使用排序</p>\n<p>P    按CPU 使用排序</p>\n<p>T    按Time+ 使用排序</p>\n<p>F    跟踪进程: 如果排序顺序引起选定的进程在列表上到处移动，让选定条跟随该进程。这对监视一个进程非常有用：通过这种方式，你可以让一个进程在屏幕上一直可见。使用方向键会停止该功能。</p>\n<p>K    显示/隐藏内核线程</p>\n<p>H    显示/隐藏用户线程</p>\n<p>Ctrl-L    刷新</p>\n<p>Numbers    PID 查找: 输入PID，光标将移动到相应的进程上</p>\n<hr>\n<p>四、htop 使用</p>\n<p>4.1. 显示自带帮助</p>\n<p>鼠标点击Help或者按F1 显示自带帮助<br><img src=\"http://images.cnitblog.com/blog/370046/201301/12224049-575f66ab3d964c5cb419959aee9032b1.jpg\" alt=\"\"></p>\n<p>4.2. htop 设定</p>\n<p>鼠标点击Setup或者按下F2 之后进入htop 设定的页面，Meters 页面设定了顶端的一些信息显示，顶端的显示又分为左右两侧，到底能显示些什么可以在最右侧那栏新增，要新增到上方左侧（F5）或是右侧（F6）都可以，这就是个人设定的范围了。这里多加了一个时钟。</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224051-9b4d728776d1499190c9d21ab3615f5a.jpg\" alt=\"\"></p>\n<p>上方左右两栏的显示方式分为Text Bar Graph Led 四种，下图我就把 cpu memory swap 改成文本模式显示，然后右栏的改成Bar 显示，clock 用LED方式显示。数据显示都差不多，只是这样看有点不习惯了。</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224052-befc1e283e4c4576a59f89e6f72a4337.jpg\" alt=\"\"></p>\n<p>关于Display options 的设定，可要根据管理者自己的需要来设定。</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224054-b8d7722ac20b421299bd0c72b3394198.jpg\" alt=\"\"></p>\n<p>颜色选择，除了基本的颜色显示之外，htop 还提供了换面板的功能，其实也只是改变一些色彩显示的设定，虽然说不能自定义到细部的颜色显示，但是至少提供了几种风格可以选择。</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224055-b6a13eb2abaa45fab167e61a8db12356.jpg\" alt=\"\"></p>\n<p>最后一项的设定是调整 Columns 的显示，就是在一般htop 指令进来希望可以看到的什么样的数据及信息，字段的调整可以在这边做个人化的设定，一般使用系统默认值就好了。</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224058-1ef4f726ccd64dfbaab68142dc9a95be.jpg\" alt=\"\"></p>\n<p>4.3. 搜索进程</p>\n<p>鼠标点击Search 或者按下F3 或者输入”/“， 输入进程名进行搜索，例如搜索ssh</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224100-dab0040192b24614b44d1e28d1b4badb.jpg\" alt=\"\"></p>\n<p>4.4. 过滤器</p>\n<p>按下F4，进入过滤器，相当于关键字搜索，不区分大小写，例如过滤dev</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224102-6339cac4da0b482097e1a5b218b523c4.jpg\" alt=\"\"></p>\n<p>4.5. 显示树形结构</p>\n<p>输入”t”或按下F5，显示树形结构，意思跟pstree 差不多，能看到所有程序树状执行的结构，这对于系统管理来说相当方便，理清程序是如何产生的，当然树状结构的浏览也可以依照其他数据来排序。</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224104-f5d4a8c905cd4a83b262ad2e5944f3fe.jpg\" alt=\"\"></p>\n<p>4.6. 选择排序方式</p>\n<p>按下F6 就可以选择依照什么来排序，最常排序的内容就是cpu 和memory 吧！</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224107-6a091d2523cd4829b243f635b1c32a0a.jpg\" alt=\"\"></p>\n<p>4.7 操作进程</p>\n<p>F7、F8分别对应nice-和nice+，F9对应kill给进程发信号，选好信号回车就OK了</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224112-9dc1706a8dbd4972b78a78af34f75ec7.jpg\" alt=\"\"></p>\n<p>4.8. 显示某个用户的进程，在左侧选择用户</p>\n<p>输入”u”，在左侧选择用户</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224115-289b4cf95c344dada4aa048c25f821ce.jpg\" alt=\"\"></p>\n<p>五、Alias top</p>\n<p>也许你用惯了top，我们也可以用top来打开htop。</p>\n<p>编辑/root/.bashrc文件，添加如下代码</p>\n<pre><code>if [ -f /usr/local/bin/htop ]; then\nalias top=’/usr/local/bin/htop’\nfi\n# source /root/.bashrc\n</code></pre>","site":{"data":{}},"excerpt":"<p>一、htop 简介</p>\n<p>This is htop, an interactive process viewer for Linux. It is a text-mode application (for console or X terminals) and requires ncurses.</p>\n<p>Comparison between htop and top<br>","more":"<br>In ‘htop’ you can scroll the list vertically and horizontally to see all processes and complete command lines.<br>In ‘top’ you are subject to a delay for each unassigned key you press (especially annoying when multi-key escape sequences are triggered by accident).<br>‘htop’ starts faster (‘top’ seems to collect data for a while before displaying anything).<br>In ‘htop’ you don’t need to type the process number to kill a process, in ‘top’ you do.<br>In ‘htop’ you don’t need to type the process number or the priority value to renice a process, in ‘top’ you do.<br>‘htop’ supports mouse operation, ‘top’ doesn’t<br>‘top’ is older, hence, more used and tested.<br>htop 是Linux系统中的一个互动的进程查看器，一个文本模式的应用程序(在控制台或者X终端中)，需要ncurses。</p>\n<p>与Linux传统的top相比，htop更加人性化。它可让用户交互式操作，支持颜色主题，可横向或纵向滚动浏览进程列表，并支持鼠标操作。</p>\n<p>与top相比，htop有以下优点：</p>\n<p>可以横向或纵向滚动浏览进程列表，以便看到所有的进程和完整的命令行。<br>在启动上，比top 更快。<br>杀进程时不需要输入进程号。<br>htop 支持鼠标操作。<br>top 已经很老了。<br>htop 官网：<a href=\"http://htop.sourceforge.net/\" target=\"_blank\" rel=\"noopener\">http://htop.sourceforge.net/</a></p>\n<p>二、htop 安装</p>\n<p>a. 源码包安装</p>\n<pre><code># tar zxvf htop-1.0.2.tar.gz\n\n# cd htop-1.0.2\n\n# ./configure\n</code></pre><p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224043-10fbaaa4ef2d49ba844de4ff1df2cea2.jpg\" alt=\"\"></p>\n<pre><code># make &amp;&amp; make install\n</code></pre><p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224044-8e70dd81c3594f14bf334dbf7ae12cda.jpg\" alt=\"\"></p>\n<p>若出现错误：</p>\n<pre><code>configure: error: You may want to use --disable-unicode or install libncursesw.\n</code></pre><p>则需安装 ncurses-devel</p>\n<pre><code># yum install ncurses-devel\n</code></pre><p>b. RHEL/CentOS 安装</p>\n<p>可以通过 yum install htop 来安装它，但前提是要添加epel 的yum源，具体请参考 CentOS yum 源的配置与使用。</p>\n<pre><code># rpm -ivh http://download.fedoraproject.org/pub/epel/5/i386/epel-release-5-4.noarch.rpm \n# rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL//导入key \n# yum install htop\n</code></pre><p>三、htop 参数</p>\n<p>键入htop 命令，打开htop。</p>\n<pre><code># htop\n</code></pre><p> <img src=\"http://images.cnitblog.com/blog/370046/201301/12224047-b6fd5270cea14cee87544ff3ca193b34.jpg\" alt=\"\"></p>\n<p>上面左上角显示CPU、内存、交换区的使用情况，右边显示任务、负载、开机时间，下面就是进程实时状况。</p>\n<p>下面是 F1~F10 的功能和对应的字母快捷键。</p>\n<hr>\n<p>Shortcut Key　　　　　　  　　 Function Ke　　　　　　  　　 Description　　　　　　 　　　　　　  　　  中文说明  </p>\n<p>h,?　　　　　　  　　　　　　　  　　   F1    　　　　　　  　　 Invoke htop Help　　　　　　  　　     　　　　　　查看htop使用说明<br>S    　　　　　　  　　 　　　　　　  　　F2　　　　　　  　　     Htop Setup Menu    htop　　　　　　  　　 　　　 设定<br>/    　　　　　　  　　 　　　　　　   　　  F3    　　　　　　  　　 Search for a Process    　　　　　　  　　　　　　 搜索进程<br>\\    　　　　　　  　　 　　　　　　  　　 F4    　　　　　　  　　 Incremental process filtering    　　　　　　  　　 增量进程过滤器<br>t    　　　　　　  　　 　　　　　　  　　 F5　　　　　　  　　     Tree View    　　　　　　  　　 　　　　　　  　　　 显示树形结构<br>&lt;, &gt;    　　　　　　  　　 　　　　　　  　F6    　　　　　　  　　 Sort by a column    　　　　　　  　　　　　　　　   选择排序方式<br>[    　　　　　　  　　 　　　　　　  　　 F7    　　　　　　  　　 Nice - (change priority)    　　　可减少nice值，这样就可以提高对应进程的优先级<br>]    　　　　　　  　　 　　　　　　  　　 F8    　　　　　　  　　 Nice + (change priority)    　　　可增加nice值，这样就可以降低对应进程的优先级<br>k    　　　　　　  　　 　　　　　　  　　 F9    　　　　　　  　　 Kill a Process    　　　　　　  　　 　　　　　　  　可对进程传递信号<br>q    　　　　　　  　　 　　　　　　  　　 F10    　　　　　　  　　 Quit htop    　　　　　　  　　 　　　　　　  　　 结束htop  </p>\n<hr>\n<p>命令行选项（COMMAND-LINE OPTIONS）</p>\n<p>-C –no-color　　　　 　　 使用一个单色的配色方案</p>\n<p>-d –delay=DELAY　　　　 设置延迟更新时间，单位秒</p>\n<p>-h –help　　　　　　  　　 显示htop 命令帮助信息</p>\n<p>-u –user=USERNAME　　  只显示一个给定的用户的过程</p>\n<p>-p –pid=PID,PID…　　　    只显示给定的PIDs</p>\n<p>-s –sort-key COLUMN　    依此列来排序</p>\n<p>-v –version　　　　　　　   显示版本信息</p>\n<p>交互式命令（INTERACTIVE COMMANDS）</p>\n<hr>\n<p>上下键或PgUP, PgDn 选定想要的进程，左右键或Home, End 移动字段，当然也可以直接用鼠标选定进程；</p>\n<p>Space    标记/取消标记一个进程。命令可以作用于多个进程，例如 “kill”，将应用于所有已标记的进程</p>\n<p>U    取消标记所有进程</p>\n<p>s    选择某一进程，按s:用strace追踪进程的系统调用</p>\n<p>l    显示进程打开的文件: 如果安装了lsof，按此键可以显示进程所打开的文件</p>\n<p>I    倒转排序顺序，如果排序是正序的，则反转成倒序的，反之亦然</p>\n<p>+, -    When in tree view mode, expand or collapse subtree. When a subtree is collapsed a “+” sign shows to the left of the process name.</p>\n<p>a (在有多处理器的机器上)    设置 CPU affinity: 标记一个进程允许使用哪些CPU</p>\n<p>u    显示特定用户进程</p>\n<p>M    按Memory 使用排序</p>\n<p>P    按CPU 使用排序</p>\n<p>T    按Time+ 使用排序</p>\n<p>F    跟踪进程: 如果排序顺序引起选定的进程在列表上到处移动，让选定条跟随该进程。这对监视一个进程非常有用：通过这种方式，你可以让一个进程在屏幕上一直可见。使用方向键会停止该功能。</p>\n<p>K    显示/隐藏内核线程</p>\n<p>H    显示/隐藏用户线程</p>\n<p>Ctrl-L    刷新</p>\n<p>Numbers    PID 查找: 输入PID，光标将移动到相应的进程上</p>\n<hr>\n<p>四、htop 使用</p>\n<p>4.1. 显示自带帮助</p>\n<p>鼠标点击Help或者按F1 显示自带帮助<br><img src=\"http://images.cnitblog.com/blog/370046/201301/12224049-575f66ab3d964c5cb419959aee9032b1.jpg\" alt=\"\"></p>\n<p>4.2. htop 设定</p>\n<p>鼠标点击Setup或者按下F2 之后进入htop 设定的页面，Meters 页面设定了顶端的一些信息显示，顶端的显示又分为左右两侧，到底能显示些什么可以在最右侧那栏新增，要新增到上方左侧（F5）或是右侧（F6）都可以，这就是个人设定的范围了。这里多加了一个时钟。</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224051-9b4d728776d1499190c9d21ab3615f5a.jpg\" alt=\"\"></p>\n<p>上方左右两栏的显示方式分为Text Bar Graph Led 四种，下图我就把 cpu memory swap 改成文本模式显示，然后右栏的改成Bar 显示，clock 用LED方式显示。数据显示都差不多，只是这样看有点不习惯了。</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224052-befc1e283e4c4576a59f89e6f72a4337.jpg\" alt=\"\"></p>\n<p>关于Display options 的设定，可要根据管理者自己的需要来设定。</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224054-b8d7722ac20b421299bd0c72b3394198.jpg\" alt=\"\"></p>\n<p>颜色选择，除了基本的颜色显示之外，htop 还提供了换面板的功能，其实也只是改变一些色彩显示的设定，虽然说不能自定义到细部的颜色显示，但是至少提供了几种风格可以选择。</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224055-b6a13eb2abaa45fab167e61a8db12356.jpg\" alt=\"\"></p>\n<p>最后一项的设定是调整 Columns 的显示，就是在一般htop 指令进来希望可以看到的什么样的数据及信息，字段的调整可以在这边做个人化的设定，一般使用系统默认值就好了。</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224058-1ef4f726ccd64dfbaab68142dc9a95be.jpg\" alt=\"\"></p>\n<p>4.3. 搜索进程</p>\n<p>鼠标点击Search 或者按下F3 或者输入”/“， 输入进程名进行搜索，例如搜索ssh</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224100-dab0040192b24614b44d1e28d1b4badb.jpg\" alt=\"\"></p>\n<p>4.4. 过滤器</p>\n<p>按下F4，进入过滤器，相当于关键字搜索，不区分大小写，例如过滤dev</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224102-6339cac4da0b482097e1a5b218b523c4.jpg\" alt=\"\"></p>\n<p>4.5. 显示树形结构</p>\n<p>输入”t”或按下F5，显示树形结构，意思跟pstree 差不多，能看到所有程序树状执行的结构，这对于系统管理来说相当方便，理清程序是如何产生的，当然树状结构的浏览也可以依照其他数据来排序。</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224104-f5d4a8c905cd4a83b262ad2e5944f3fe.jpg\" alt=\"\"></p>\n<p>4.6. 选择排序方式</p>\n<p>按下F6 就可以选择依照什么来排序，最常排序的内容就是cpu 和memory 吧！</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224107-6a091d2523cd4829b243f635b1c32a0a.jpg\" alt=\"\"></p>\n<p>4.7 操作进程</p>\n<p>F7、F8分别对应nice-和nice+，F9对应kill给进程发信号，选好信号回车就OK了</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224112-9dc1706a8dbd4972b78a78af34f75ec7.jpg\" alt=\"\"></p>\n<p>4.8. 显示某个用户的进程，在左侧选择用户</p>\n<p>输入”u”，在左侧选择用户</p>\n<p><img src=\"http://images.cnitblog.com/blog/370046/201301/12224115-289b4cf95c344dada4aa048c25f821ce.jpg\" alt=\"\"></p>\n<p>五、Alias top</p>\n<p>也许你用惯了top，我们也可以用top来打开htop。</p>\n<p>编辑/root/.bashrc文件，添加如下代码</p>\n<pre><code>if [ -f /usr/local/bin/htop ]; then\nalias top=’/usr/local/bin/htop’\nfi\n# source /root/.bashrc\n</code></pre>"},{"title":"Jira和Confluence迁移简介","date":"2019-09-24T04:00:00.000Z","_content":"\n# jira和confluence迁移简介\n>环境说明：\n>1.mysql5.6。\n>2.全部使用Kubelete和docker启动。\n>3.挂载方式为本地目录。\n\n<!--more-->\n## Jira迁移\n### 备份老jira机器上的数据\n老环境的web页面中数据进行备份，页面选择Setting>System>Backup system>\n备份目录为`/var/atlassian/jira/export` \n将备份的zip包拷贝到新的机器\n同时将jira目录拷贝到新的机器上，jira目录为`/var/atlassian/jira/data/attachments`     (此目录是jira上面存储的图片和附件信息)\n\n### 启动Jira跟Mysql\nmysql配置文件my.cnf\n```\n[client]\nport            = 3306\ndefault-character-set=utf8\nsocket          = /var/run/mysqld/mysqld.sock\n\n[mysql]\ndefault-character-set=utf8\n\n[mysqld_safe]\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nnice            = 0\n\n[mysqld]\nskip-host-cache\nskip-name-resolve\nuser            = mysql\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nport            = 3306\nbasedir         = /usr\ndatadir         = /var/lib/mysql\ntmpdir          = /tmp\nlc-messages-dir = /usr/share/mysql\nexplicit_defaults_for_timestamp\ncharacter-set-server=utf8\ndefault-storage-engine=INNODB\nmax_allowed_packet=256M\ninnodb_log_file_size=256M\n\n\n#sql_mode = NO_AUTO_VALUE_ON_ZERO\nsql_mode = \"\"\n\nsymbolic-links=0\n\n[mysqld.safe]\ndefault-character-set=utf8\n[mysql.server]\ndefault-character-set=utf8\n\n#\n!includedir /etc/mysql/conf.d/\n```\n### 启动Mysql有两种方法，一种是docker run 一种是使用Kubelete启动\n\ndocker run方式\n```\ndocker run -d --restart=always --name mysql \\\n  -e MYSQL_ROOT_PASSWORD=root \\\n  -e MYSQL_USER=jira \\\n  -e MYSQL_PASSWORD=jira \\\n  -e MYSQL_DATABASE=jiradb \\\n  -v /data/mysql/config/my.cnf:/etc/mysql/my.cnf \\\n  -v /data/mysql/data:/var/lib/mysql \\\n  -p 3306:3306 \\\n  mysql:5.6\n```\n\nKubelete方式启动\n```\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    app.test.io/name: test-mysql-jira.production-business-jira\n  name: test-mysql-jira-mysql\n  namespace: production-business-jira\n  selfLink: >-\n    /apis/extensions/v1beta1/namespaces/production-business-jira/deployments/test-mysql-jira-mysql\nspec:\n  progressDeadlineSeconds: 600\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.test.io/name: test-mysql-jira.production-business-jira\n      project.test.io/name: production-business\n      service.test.io/name: deployment-test-mysql-jira-mysql\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 25%\n    type: RollingUpdate\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: deployment-test-mysql-jira-mysql\n        app.test.io/name: test-mysql-jira.production-business-jira\n        project.test.io/name: production-business\n        service.test.io/name: deployment-test-mysql-jira-mysql\n        version: v1\n    spec:\n      containers:\n        - env:\n            - name: MYSQL_ROOT_PASSWORD\n              value: root\n            - name: MYSQL_USER\n              value: jira\n            - name: MYSQL_PASSWORD\n              value: jira\n            - name: MYSQL_DATABASE\n              value: jiradb\n          image: 'mysql:5.6'\n          imagePullPolicy: IfNotPresent\n          name: mysql\n          resources:\n            limits:\n              cpu: '4'\n              memory: 4Gi\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n          volumeMounts:\n            - mountPath: /var/lib/mysql\n              name: mysql-data\n            - mountPath: /etc/mysql/my.cnf\n              name: mysql-cnf\n              readOnly: true\n              subPath: my.cnf\n      dnsPolicy: ClusterFirst\n      nodeSelector:\n        kubernetes.io/hostname: slave-4\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\n      tolerations:\n        - operator: Exists\n      volumes:\n        - hostPath:\n            path: /data/mysql/data\n            type: ''\n          name: mysql-data\n        - configMap:\n            defaultMode: 420\n            items:\n              - key: my.cnf\n                path: my.cnf\n            name: mysql\n          name: mysql-cnf\n---\napiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    test.io/creator: admin@test.io\n  labels:\n    app.test.io/name: test-mysql-jira.production-business-jira\n  name: test-mysql-jira-mysql\n  namespace: production-business-jira\n  ownerReferences:\n    - apiVersion: app.k8s.io/v1beta1\n      blockOwnerDeletion: true\n      controller: true\n      kind: Application\n      name: test-mysql-jira\n  resourceVersion: '2489793'\n  selfLink: /api/v1/namespaces/production-business-jira/services/test-mysql-jira-mysql\n  uid: f8ea4a3c-d507-11e9-a5de-525400ed59d9\nspec:\n  ports:\n    - name: tcp-3306-3306\n      port: 3306\n      protocol: TCP\n      targetPort: 3306\n  selector:\n    app.test.io/name: test-mysql-jira.production-business-jira\n    service.test.io/name: deployment-test-mysql-jira-mysql\n  sessionAffinity: ClientIP\n  sessionAffinityConfig:\n    clientIP:\n      timeoutSeconds: 10800\n  type: ClusterIP\n\n```\n\n### 启动Jira\nJira启动也是分为两种，一种是docker run另外一种是Kubelete方式启动\ndocker run方式\n```\ndocker run -d  --restart=always --name jira -p 8080:8080 \\\n  -e JVM_MAXIMUM_MEMORY=6144m \\\n  -e JAVA_OPTS=\"-javaagent:/opt/atlassian-agent.jar\" \\\n  -v /root/atlassian-agent.jar:/opt/atlassian-agent.jar \\\n  -v /data/jira/data:/var/atlassian/jira \\\n  -v /data/jira/logs:/opt/atlassian/jira/logs \\\n  cptactionhank/atlassian-jira\n```\natlassian-agent.jar是破解包，详情请见https://gitee.com/pengzhile/atlassian-agent\n\nKubelete方式\n```\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    app.test.io/name: test-jira.production-business-jira\n  name: test-jira-atlassian-jira\n  namespace: production-business-jira\n  selfLink: >-\n    /apis/extensions/v1beta1/namespaces/production-business-jira/deployments/test-jira-atlassian-jira\nspec:\n  progressDeadlineSeconds: 600\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.test.io/name: test-jira.production-business-jira\n      project.test.io/name: production-business\n      service.test.io/name: deployment-test-jira-atlassian-jira\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 25%\n    type: RollingUpdate\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: deployment-test-jira-atlassian-jira\n        app.test.io/name: test-jira.production-business-jira\n        project.test.io/name: production-business\n        service.test.io/name: deployment-test-jira-atlassian-jira\n        version: v1\n    spec:\n      containers:\n        - env:\n            - name: JAVA_OPTS\n              value: '-javaagent:/opt/atlassian-agent.jar'\n          image: 'cptactionhank/atlassian-jira'\n          imagePullPolicy: IfNotPresent\n          name: atlassian-jira\n          resources:\n            limits:\n              cpu: '8'\n              memory: 16Gi\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n          volumeMounts:\n            - mountPath: /var/atlassian/jira\n              name: new-volume\n            - mountPath: /opt/atlassian/jira/logs\n              name: new-volume1\n      dnsPolicy: ClusterFirst\n      nodeSelector:\n        kubernetes.io/hostname: slave-4\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\n      tolerations:\n        - operator: Exists\n      volumes:\n        - hostPath:\n            path: /data/jira/data\n            type: ''\n          name: new-volume\n        - hostPath:\n            path: /data/jira/logs\n            type: ''\n          name: new-volume1\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.test.io/name: test-jira.production-business-jira\n  name: test-jira-atlassian-jira\n  namespace: production-business-jira\n  selfLink: >-\n    /api/v1/namespaces/production-business-jira/services/test-jira-atlassian-jira\nspec:\n  ports:\n    - name: tcp-8080-8080\n      port: 8080\n      protocol: TCP\n      targetPort: 8080\n  selector:\n    app.test.io/name: test-jira.production-business-jira\n    service.test.io/name: deployment-test-jira-atlassian-jira\n  sessionAffinity: None\n  type: ClusterIP\n\n```\n#### 登录Jira开始对Jira进行初始化\n\n1.选择I'll set it up myself     Next\n2.选择My Own Database (recommended for production environments)\n>Database Type:   MySQL 5.6\n>Hostname: mysql-jira-mysql\n>Port: 3306\n>Database: jiradb\n>Username: jira\n>Password: jira\n\n选择Test Connection，测试链接成功后点击  Next  然后等待数据库初始化完成\n3.填写jira项目信息\n>Application Title: jiar\n>Mode:Private\n>Base URL:http://192.168.8.27:8081\n\n4.破解Jira\n复制Server ID内容\n然后进入jira容器内\n\n >docker exec -it jira bash\n cd /opt/\n ls\n `bash-4.4$ ls\natlassian            atlassian-agent.jar`\njava -jar atlassian-agent.jar -p jira -m aaa@bbb.com -n my_name -o http://datura.top -s XXXXXX\n```\n====================================================\n=======        Atlassian Crack Agent         =======\n=======           https://zhile.io           =======\n=======          QQ Group: 30347511          =======\n====================================================\n\n>Your license code(Don't copy this line!!!):\n\n>AAABjQ0ODAoPeJx9klFr2zAUhd/1Kwx7tmuFpXEDgm222TzsJNRpHvYyrp2bRsOWxZWcNvv1lRsX0\n>jYEBEJC59xP594v6x69ErXHZ14Yzfl0ziPvZ7H2JiG/Y4+EqPad1khBLmtUBtdHjQtoUcTLokjv4\n>+x7zmJCsLJTCVgUg9AP73w+Y1ckCZqapB5U4kE1spUWt15zEnjV0dtbq8385ub/XjYYyI4VIJVFB\n>arG9FlLOo7VIldt5hb7JwneKNOtPFkv8qzI1mnCFn1bIS13DwbJCJ+/wV3x0tRt+9oGw8E33c4+A\n>WHwyejKW6itPKCw1OO7LM/vxz9vnNtAPGHpAZr+NU+xg8YgW9IjKGlOV0MuLpYt2N6VtZ1mcaesM\n>0xdQI0AgG9VVQV1157ALuOeA1zhLy2QRRo5xsSyRORZUqYLP+fT22gWRpxH0+nkXQMu9bxEOiA5+\n>Y/4a+yv/mx++2m+ufV/rcrw0qh9buKqp3oPBj8O2rkY3ZSQJmnG7zlQcQF2TO2VsT3+VW5/AS2KC\n> fkwLAIUYgOdQfGYSq/19VKXo54j+OohnFoCFDNIF/aherXDRLivmm2xF3bE8S47X02j7\n```\n\nServer ID：XXXXXXX\nYour License Key:\n```\nAAABjQ0ODAoPeJx9klFr2zAUhd/1Kwx7tmuFpXEDgm222TzsJNRpHvYyrp2bRsOWxZWcNvv1lRsX0\njYEBEJC59xP594v6x69ErXHZ14Yzfl0ziPvZ7H2JiG/Y4+EqPad1khBLmtUBtdHjQtoUcTLokjv4\n+x7zmJCsLJTCVgUg9AP73w+Y1ckCZqapB5U4kE1spUWt15zEnjV0dtbq8385ub/XjYYyI4VIJVFB\narG9FlLOo7VIldt5hb7JwneKNOtPFkv8qzI1mnCFn1bIS13DwbJCJ+/wV3x0tRt+9oGw8E33c4+A\nWHwyejKW6itPKCw1OO7LM/vxz9vnNtAPGHpAZr+NU+xg8YgW9IjKGlOV0MuLpYt2N6VtZ1mcaesM\n0xdQI0AgG9VVQV1157ALuOeA1zhLy2QRRo5xsSyRORZUqYLP+fT22gWRpxH0+nkXQMu9bxEOiA5+\nY/4a+yv/mx++2m+ufV/rcrw0qh9buKqp3oPBj8O2rkY3ZSQJmnG7zlQcQF2TO2VsT3+VW5/AS2KC\nfkwLAIUYgOdQfGYSq/19VKXo54j+OohnFoCFDNIF/aherXDRLivmm2xF3bE8S47X02j7\n```\n等待初始化Jira\n\n5.创建Jira用户信息\n>Full name ：jiraadmin\nEmail Address :jiraadmin@123.com\nUsername: jiraadmin\nPassword: jiraadmin\nConfirm Password : jiraadmin\n选择 Next\nConfigure Email Notifications ：Later\n选择 Finish\n选择语言\n之后创建Jira项目\n\n6.恢复Jira数据\n将备份的zip包拷贝到新的Jira目录中，目录位置为 \n`/var/atlassian/jira/import`\n返回jira页面，Setting>System>Restore system\n将备份包信息填写到相应位置，License输入上面的key信息\n然后点击Restore\n等待数据恢复，数据恢复后回到命令行\n将老Jira`/var/atlassian/jira/data/attachments`  的目录拷贝到本机的/data/jira/data/data/attachments目录中\n拷贝完成后重启Jira容器\n重启完成后，此时将可以使用老Jira的用户登录新Jira，到此Jira迁移完成。\n\n\n## Confluence 迁移简介\n\n### 备份老Confluence数据\n登录Confluence，Setting>General Configuration>Backup & Restore\n选择Include attachments然后导出或者直接使用Confluence每日自动备份的zip包进行恢复，我这里使用的是每日自动备份的zip包进行恢复的\n包路径为`$CONFLUENCE_HOME/backups`\n将zip包拷贝到新的Confluence机器上\n\n### 启动Confluence和Mysql\nmysql配置文件my.cnf\n```\n[client]\nport            = 3306\ndefault-character-set=utf8\nsocket          = /var/run/mysqld/mysqld.sock\n\n[mysql]\ndefault-character-set=utf8\n\n[mysqld_safe]\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nnice            = 0\n\n[mysqld]\nskip-host-cache\nskip-name-resolve\nuser            = mysql\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nport            = 3306\nbasedir         = /usr\ndatadir         = /var/lib/mysql\ntmpdir          = /tmp\nlc-messages-dir = /usr/share/mysql\nexplicit_defaults_for_timestamp\ncharacter-set-server=utf8\ndefault-storage-engine=INNODB\nmax_allowed_packet=256M\ninnodb_log_file_size=256M\n\n\n#sql_mode = NO_AUTO_VALUE_ON_ZERO\nsql_mode = \"\"\n\nsymbolic-links=0\n\n[mysqld.safe]\ndefault-character-set=utf8\n[mysql.server]\ndefault-character-set=utf8\n\n#\n!includedir /etc/mysql/conf.d/\n```\n### 启动mysql有两种方法，一种是docker run 一种是使用Kubelete启动\n\ndocker run方式\n```\ndocker run -d --restart=always --name mysql \\\n  -e MYSQL_ROOT_PASSWORD=root \\\n  -e MYSQL_USER=confluence \\\n  -e MYSQL_PASSWORD=confluence \\\n  -e MYSQL_DATABASE=confluencedb \\  \n  -v /data/mysql/data:/var/lib/mysql \\\n  -v /data/mysql/config/my.cnf:/etc/mysql/my.cnf \\\n  -p 3306:3306 \\\n  mysql:5.6\n```\nKubelete方式启动\n```\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  generation: 26\n  labels:\n    app.test.io/name: test-mysql-confluence.production-business-confluence\n  name: test-mysql-confluence-mysql-confluence\n  namespace: production-business-confluence\n  selfLink: >-\n    /apis/extensions/v1beta1/namespaces/production-business-confluence/deployments/test-mysql-confluence-mysql-confluence\nspec:\n  progressDeadlineSeconds: 600\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.test.io/name: test-mysql-confluence.production-business-confluence\n      project.test.io/name: production-business\n      service.test.io/name: deployment-test-mysql-confluence-mysql-confluence\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 25%\n    type: RollingUpdate\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: deployment-test-mysql-confluence-mysql-confluence\n        app.test.io/name: test-mysql-confluence.production-business-confluence\n        project.test.io/name: production-business\n        service.test.io/name: deployment-test-mysql-confluence-mysql-confluence\n        version: v1\n    spec:\n      containers:\n        - env:\n            - name: MYSQL_USER\n              value: confluence\n            - name: MYSQL_PASSWORD\n              value: confluence\n            - name: MYSQL_DATABASE\n              value: confluencedb\n            - name: MYSQL_ROOT_PASSWORD\n              value: root\n          image: 'mysql:5.6'\n          imagePullPolicy: IfNotPresent\n          name: mysql-confluence\n          resources:\n            limits:\n              cpu: '2'\n              memory: 4Gi\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n          volumeMounts:\n            - mountPath: /var/lib/mysql\n              name: mysql-data\n            - mountPath: /etc/mysql/my.cnf\n              name: new-volume\n              readOnly: true\n              subPath: my.cnf\n      dnsPolicy: ClusterFirst\n      nodeSelector:\n        kubernetes.io/hostname: slave-2\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\n      tolerations:\n        - operator: Exists\n      volumes:\n        - hostPath:\n            path: /data/mysql/data\n            type: ''\n          name: mysql-data\n        - configMap:\n            defaultMode: 420\n            items:\n              - key: my.cnf\n                path: my.cnf\n            name: confluence-mysql\n          name: new-volume\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.test.io/name: test-mysql-confluence.production-business-confluence\n  name: test-mysql-confluence\n  namespace: production-business-confluence\n  selfLink: >-\n    /api/v1/namespaces/production-business-confluence/services/test-mysql-confluence\nspec:\n  ports:\n    - name: tcp-3306-3306\n      port: 3306\n      protocol: TCP\n      targetPort: 3306\n  selector:\n    app.test.io/name: test-mysql-confluence.production-business-confluence\n    service.test.io/name: deployment-test-mysql-confluence-mysql-confluence\n  sessionAffinity: ClientIP\n  sessionAffinityConfig:\n    clientIP:\n      timeoutSeconds: 10800\n  type: ClusterIP\n\n```\n\n### 启动Confluence\nConfluence启动也是分为两种，一种是docker run另外一种是Kubelete方式启动\ndocker run方式\n```\ndocker run -d --restart=always --name confluence -p 8090:8090 \\\n  -e JVM_MAXIMUM_MEMORY=8196m \\\n  -e JAVA_OPTS=\"-javaagent:/opt/atlassian-agent.jar\" \\\n  -v /data/confluence/data:/var/atlassian/application-data/confluence \\\n  -v /root/atlassian-agent.jar:/opt/atlassian-agent.jar \\\n  -v /data/confluence/logs:/opt/atlassian/confluence/logs \\\ndocker.io/atlassian/confluence-server\n```\n\nKubelete方式启动\n```\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    app.test.io/name: confluence.production-business-confluence\n  name: confluence-confluence\n  namespace: production-business-confluence\n  selfLink: >-\n    /apis/extensions/v1beta1/namespaces/production-business-confluence/deployments/confluence-confluence\nspec:\n  progressDeadlineSeconds: 600\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.test.io/name: confluence.production-business-confluence\n      project.test.io/name: production-business\n      service.test.io/name: deployment-confluence-confluence\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 25%\n    type: RollingUpdate\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: deployment-confluence-confluence\n        app.test.io/name: confluence.production-business-confluence\n        project.test.io/name: production-business\n        service.test.io/name: deployment-confluence-confluence\n        version: v1\n    spec:\n      containers:\n        - env:\n            - name: JAVA_OPTS\n              value: '-javaagent:/opt/atlassian-agent.jar'\n          image: 'docker.io/atlassian/confluence-server'\n          imagePullPolicy: IfNotPresent\n          name: confluence\n          resources:\n            limits:\n              cpu: '4'\n              memory: 16Gi\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n          volumeMounts:\n            - mountPath: /var/atlassian/application-data/confluence\n              name: confluence-data\n            - mountPath: /opt/atlassian/confluence/logs\n              name: confluence-log\n      dnsPolicy: ClusterFirst\n      nodeSelector:\n        kubernetes.io/hostname: slave-2\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\n      tolerations:\n        - operator: Exists\n      volumes:\n        - hostPath:\n            path: /data/confluence/data\n            type: ''\n          name: confluence-data\n        - hostPath:\n            path: /data/confluence/logs\n            type: ''\n          name: confluence-log\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.test.io/name: confluence.production-business-confluence\n  name: confluence-confluence\n  namespace: production-business-confluence\n  selfLink: >-\n    /api/v1/namespaces/production-business-confluence/services/confluence-confluence\nspec:\n  ports:\n    - name: tcp-8090-8090\n      port: 8090\n      protocol: TCP\n      targetPort: 8090\n  selector:\n    app.test.io/name: confluence.production-business-confluence\n    service.test.io/name: deployment-confluence-confluence\n  sessionAffinity: ClientIP\n  sessionAffinityConfig:\n    clientIP:\n      timeoutSeconds: 10800\n  type: ClusterIP\n\n```\n\n#### 登录Confluence开始对Confluence进行初始化\n选择Confluence Team Calendars\n复制Server ID\n登录Confluence机器中的Confluence容器内\n\n>docker exec -it confluence bash\n cd /opt/\n ls\n `bash-4.4$ ls\natlassian            atlassian-agent.jar`\njava -jar atlassian-agent.jar -p conf -m aaa@bbb.com -n my_name -o http://datura.top -s XXXXXX\n```\n====================================================\n=======        Atlassian Crack Agent         =======\n=======           https://zhile.io           =======\n=======          QQ Group: 30347511          =======\n====================================================\nYour license code(Don't copy this line!!!):\nAAABQQ0ODAoPeJxtUNFOgzAUfe9XNPEZXDc3xpImTkCdgWFkm76ZC7tzTaCQtizOr7cDfDFLmjQ9p\n/fcc87NpkWaYUOZR0f+YjJfTDz6lGzoeMR8EigEI2oZgkF+QZyR7zCPRCco247hByg1khB1oUTTI\nVtZikoY3NNSFCg10vxMj8Y0enF7+3MUJbqiJqn6Ail0L3JhLbkH0ypwTd2QopYHFwojTsiNapEEt\nTT2HSUgSg4A93meu0Vd9T8zA8qgGtx0UNwv35wbXEOFPEiTJHoLVsuYWA1pUIIsMPpuhDoP+eY2n\n2cPGWZXIY9XYRatnZhNZ3OPTRjzpnczkqE6obL0w/vOc7wPljqP/vLFmYXPyd/wdeXXVhVH0Pi/0\naGqHSp9KWTcZ1i3VY4qPWy1xbnDiPXCr/gZyulyVudPae9f57CZMDAsAhRpli3TWhHdAL0fOkAeh\n38ZCSuf+QIUfBreVMIH4k/6isdn0HptYXvU608=X02g0\n```\n\nServer ID： XXXXX\nConfluence：\n```\nAAABQQ0ODAoPeJxtUNFOgzAUfe9XNPEZXDc3xpImTkCdgWFkm76ZC7tzTaCQtizOr7cDfDFLmjQ9p\n/fcc87NpkWaYUOZR0f+YjJfTDz6lGzoeMR8EigEI2oZgkF+QZyR7zCPRCco247hByg1khB1oUTTI\nVtZikoY3NNSFCg10vxMj8Y0enF7+3MUJbqiJqn6Ail0L3JhLbkH0ypwTd2QopYHFwojTsiNapEEt\nTT2HSUgSg4A93meu0Vd9T8zA8qgGtx0UNwv35wbXEOFPEiTJHoLVsuYWA1pUIIsMPpuhDoP+eY2n\n2cPGWZXIY9XYRatnZhNZ3OPTRjzpnczkqE6obL0w/vOc7wPljqP/vLFmYXPyd/wdeXXVhVH0Pi/0\naGqHSp9KWTcZ1i3VY4qPWy1xbnDiPXCr/gZyulyVudPae9f57CZMDAsAhRpli3TWhHdAL0fOkAeh\n38ZCSuf+QIUfBreVMIH4k/6isdn0HptYXvU608=X02g0\n```\n\n选择My own database\n>Database type: MySQL\n>Setup type: Simple\n>Hostname: mysql-confluence\n>PortThis: 3306\n>Database name: confluencedb\n>Username: confluence\n>Password: confluence\n\n点击Test connection 后可能会出现\n`Collation error\nThe database collation 'utf8_general_ci' is not supported by Confluence. You need to use 'utf8_bin'.`\n错误\n进入mysql容器\n>docker exec -it mysql bash\n>mysql -uroot -proot\n>`alter database confluencedb character set utf8 COLLATE utf8_bin;\n>SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED;`\n\n然后在点击Test connection，提示Success! Database connected successfully.\n然后点击Next 等待数据库初始化\n然后选择Restore From Backup\n将备份的包拷贝到本机的 `/data/confluence/data/restore/` 目录下\n此时页面上就会有相应的包，选择之后点击import后，等待导入完数据，此时Confluence迁移完成","source":"_posts/jira和confluence迁移记录.md","raw":"---\ntitle: Jira和Confluence迁移简介\ndate: 2019-09-24\ntags: jira\ncategories: jira\n---\n\n# jira和confluence迁移简介\n>环境说明：\n>1.mysql5.6。\n>2.全部使用Kubelete和docker启动。\n>3.挂载方式为本地目录。\n\n<!--more-->\n## Jira迁移\n### 备份老jira机器上的数据\n老环境的web页面中数据进行备份，页面选择Setting>System>Backup system>\n备份目录为`/var/atlassian/jira/export` \n将备份的zip包拷贝到新的机器\n同时将jira目录拷贝到新的机器上，jira目录为`/var/atlassian/jira/data/attachments`     (此目录是jira上面存储的图片和附件信息)\n\n### 启动Jira跟Mysql\nmysql配置文件my.cnf\n```\n[client]\nport            = 3306\ndefault-character-set=utf8\nsocket          = /var/run/mysqld/mysqld.sock\n\n[mysql]\ndefault-character-set=utf8\n\n[mysqld_safe]\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nnice            = 0\n\n[mysqld]\nskip-host-cache\nskip-name-resolve\nuser            = mysql\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nport            = 3306\nbasedir         = /usr\ndatadir         = /var/lib/mysql\ntmpdir          = /tmp\nlc-messages-dir = /usr/share/mysql\nexplicit_defaults_for_timestamp\ncharacter-set-server=utf8\ndefault-storage-engine=INNODB\nmax_allowed_packet=256M\ninnodb_log_file_size=256M\n\n\n#sql_mode = NO_AUTO_VALUE_ON_ZERO\nsql_mode = \"\"\n\nsymbolic-links=0\n\n[mysqld.safe]\ndefault-character-set=utf8\n[mysql.server]\ndefault-character-set=utf8\n\n#\n!includedir /etc/mysql/conf.d/\n```\n### 启动Mysql有两种方法，一种是docker run 一种是使用Kubelete启动\n\ndocker run方式\n```\ndocker run -d --restart=always --name mysql \\\n  -e MYSQL_ROOT_PASSWORD=root \\\n  -e MYSQL_USER=jira \\\n  -e MYSQL_PASSWORD=jira \\\n  -e MYSQL_DATABASE=jiradb \\\n  -v /data/mysql/config/my.cnf:/etc/mysql/my.cnf \\\n  -v /data/mysql/data:/var/lib/mysql \\\n  -p 3306:3306 \\\n  mysql:5.6\n```\n\nKubelete方式启动\n```\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    app.test.io/name: test-mysql-jira.production-business-jira\n  name: test-mysql-jira-mysql\n  namespace: production-business-jira\n  selfLink: >-\n    /apis/extensions/v1beta1/namespaces/production-business-jira/deployments/test-mysql-jira-mysql\nspec:\n  progressDeadlineSeconds: 600\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.test.io/name: test-mysql-jira.production-business-jira\n      project.test.io/name: production-business\n      service.test.io/name: deployment-test-mysql-jira-mysql\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 25%\n    type: RollingUpdate\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: deployment-test-mysql-jira-mysql\n        app.test.io/name: test-mysql-jira.production-business-jira\n        project.test.io/name: production-business\n        service.test.io/name: deployment-test-mysql-jira-mysql\n        version: v1\n    spec:\n      containers:\n        - env:\n            - name: MYSQL_ROOT_PASSWORD\n              value: root\n            - name: MYSQL_USER\n              value: jira\n            - name: MYSQL_PASSWORD\n              value: jira\n            - name: MYSQL_DATABASE\n              value: jiradb\n          image: 'mysql:5.6'\n          imagePullPolicy: IfNotPresent\n          name: mysql\n          resources:\n            limits:\n              cpu: '4'\n              memory: 4Gi\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n          volumeMounts:\n            - mountPath: /var/lib/mysql\n              name: mysql-data\n            - mountPath: /etc/mysql/my.cnf\n              name: mysql-cnf\n              readOnly: true\n              subPath: my.cnf\n      dnsPolicy: ClusterFirst\n      nodeSelector:\n        kubernetes.io/hostname: slave-4\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\n      tolerations:\n        - operator: Exists\n      volumes:\n        - hostPath:\n            path: /data/mysql/data\n            type: ''\n          name: mysql-data\n        - configMap:\n            defaultMode: 420\n            items:\n              - key: my.cnf\n                path: my.cnf\n            name: mysql\n          name: mysql-cnf\n---\napiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    test.io/creator: admin@test.io\n  labels:\n    app.test.io/name: test-mysql-jira.production-business-jira\n  name: test-mysql-jira-mysql\n  namespace: production-business-jira\n  ownerReferences:\n    - apiVersion: app.k8s.io/v1beta1\n      blockOwnerDeletion: true\n      controller: true\n      kind: Application\n      name: test-mysql-jira\n  resourceVersion: '2489793'\n  selfLink: /api/v1/namespaces/production-business-jira/services/test-mysql-jira-mysql\n  uid: f8ea4a3c-d507-11e9-a5de-525400ed59d9\nspec:\n  ports:\n    - name: tcp-3306-3306\n      port: 3306\n      protocol: TCP\n      targetPort: 3306\n  selector:\n    app.test.io/name: test-mysql-jira.production-business-jira\n    service.test.io/name: deployment-test-mysql-jira-mysql\n  sessionAffinity: ClientIP\n  sessionAffinityConfig:\n    clientIP:\n      timeoutSeconds: 10800\n  type: ClusterIP\n\n```\n\n### 启动Jira\nJira启动也是分为两种，一种是docker run另外一种是Kubelete方式启动\ndocker run方式\n```\ndocker run -d  --restart=always --name jira -p 8080:8080 \\\n  -e JVM_MAXIMUM_MEMORY=6144m \\\n  -e JAVA_OPTS=\"-javaagent:/opt/atlassian-agent.jar\" \\\n  -v /root/atlassian-agent.jar:/opt/atlassian-agent.jar \\\n  -v /data/jira/data:/var/atlassian/jira \\\n  -v /data/jira/logs:/opt/atlassian/jira/logs \\\n  cptactionhank/atlassian-jira\n```\natlassian-agent.jar是破解包，详情请见https://gitee.com/pengzhile/atlassian-agent\n\nKubelete方式\n```\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    app.test.io/name: test-jira.production-business-jira\n  name: test-jira-atlassian-jira\n  namespace: production-business-jira\n  selfLink: >-\n    /apis/extensions/v1beta1/namespaces/production-business-jira/deployments/test-jira-atlassian-jira\nspec:\n  progressDeadlineSeconds: 600\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.test.io/name: test-jira.production-business-jira\n      project.test.io/name: production-business\n      service.test.io/name: deployment-test-jira-atlassian-jira\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 25%\n    type: RollingUpdate\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: deployment-test-jira-atlassian-jira\n        app.test.io/name: test-jira.production-business-jira\n        project.test.io/name: production-business\n        service.test.io/name: deployment-test-jira-atlassian-jira\n        version: v1\n    spec:\n      containers:\n        - env:\n            - name: JAVA_OPTS\n              value: '-javaagent:/opt/atlassian-agent.jar'\n          image: 'cptactionhank/atlassian-jira'\n          imagePullPolicy: IfNotPresent\n          name: atlassian-jira\n          resources:\n            limits:\n              cpu: '8'\n              memory: 16Gi\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n          volumeMounts:\n            - mountPath: /var/atlassian/jira\n              name: new-volume\n            - mountPath: /opt/atlassian/jira/logs\n              name: new-volume1\n      dnsPolicy: ClusterFirst\n      nodeSelector:\n        kubernetes.io/hostname: slave-4\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\n      tolerations:\n        - operator: Exists\n      volumes:\n        - hostPath:\n            path: /data/jira/data\n            type: ''\n          name: new-volume\n        - hostPath:\n            path: /data/jira/logs\n            type: ''\n          name: new-volume1\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.test.io/name: test-jira.production-business-jira\n  name: test-jira-atlassian-jira\n  namespace: production-business-jira\n  selfLink: >-\n    /api/v1/namespaces/production-business-jira/services/test-jira-atlassian-jira\nspec:\n  ports:\n    - name: tcp-8080-8080\n      port: 8080\n      protocol: TCP\n      targetPort: 8080\n  selector:\n    app.test.io/name: test-jira.production-business-jira\n    service.test.io/name: deployment-test-jira-atlassian-jira\n  sessionAffinity: None\n  type: ClusterIP\n\n```\n#### 登录Jira开始对Jira进行初始化\n\n1.选择I'll set it up myself     Next\n2.选择My Own Database (recommended for production environments)\n>Database Type:   MySQL 5.6\n>Hostname: mysql-jira-mysql\n>Port: 3306\n>Database: jiradb\n>Username: jira\n>Password: jira\n\n选择Test Connection，测试链接成功后点击  Next  然后等待数据库初始化完成\n3.填写jira项目信息\n>Application Title: jiar\n>Mode:Private\n>Base URL:http://192.168.8.27:8081\n\n4.破解Jira\n复制Server ID内容\n然后进入jira容器内\n\n >docker exec -it jira bash\n cd /opt/\n ls\n `bash-4.4$ ls\natlassian            atlassian-agent.jar`\njava -jar atlassian-agent.jar -p jira -m aaa@bbb.com -n my_name -o http://datura.top -s XXXXXX\n```\n====================================================\n=======        Atlassian Crack Agent         =======\n=======           https://zhile.io           =======\n=======          QQ Group: 30347511          =======\n====================================================\n\n>Your license code(Don't copy this line!!!):\n\n>AAABjQ0ODAoPeJx9klFr2zAUhd/1Kwx7tmuFpXEDgm222TzsJNRpHvYyrp2bRsOWxZWcNvv1lRsX0\n>jYEBEJC59xP594v6x69ErXHZ14Yzfl0ziPvZ7H2JiG/Y4+EqPad1khBLmtUBtdHjQtoUcTLokjv4\n>+x7zmJCsLJTCVgUg9AP73w+Y1ckCZqapB5U4kE1spUWt15zEnjV0dtbq8385ub/XjYYyI4VIJVFB\n>arG9FlLOo7VIldt5hb7JwneKNOtPFkv8qzI1mnCFn1bIS13DwbJCJ+/wV3x0tRt+9oGw8E33c4+A\n>WHwyejKW6itPKCw1OO7LM/vxz9vnNtAPGHpAZr+NU+xg8YgW9IjKGlOV0MuLpYt2N6VtZ1mcaesM\n>0xdQI0AgG9VVQV1157ALuOeA1zhLy2QRRo5xsSyRORZUqYLP+fT22gWRpxH0+nkXQMu9bxEOiA5+\n>Y/4a+yv/mx++2m+ufV/rcrw0qh9buKqp3oPBj8O2rkY3ZSQJmnG7zlQcQF2TO2VsT3+VW5/AS2KC\n> fkwLAIUYgOdQfGYSq/19VKXo54j+OohnFoCFDNIF/aherXDRLivmm2xF3bE8S47X02j7\n```\n\nServer ID：XXXXXXX\nYour License Key:\n```\nAAABjQ0ODAoPeJx9klFr2zAUhd/1Kwx7tmuFpXEDgm222TzsJNRpHvYyrp2bRsOWxZWcNvv1lRsX0\njYEBEJC59xP594v6x69ErXHZ14Yzfl0ziPvZ7H2JiG/Y4+EqPad1khBLmtUBtdHjQtoUcTLokjv4\n+x7zmJCsLJTCVgUg9AP73w+Y1ckCZqapB5U4kE1spUWt15zEnjV0dtbq8385ub/XjYYyI4VIJVFB\narG9FlLOo7VIldt5hb7JwneKNOtPFkv8qzI1mnCFn1bIS13DwbJCJ+/wV3x0tRt+9oGw8E33c4+A\nWHwyejKW6itPKCw1OO7LM/vxz9vnNtAPGHpAZr+NU+xg8YgW9IjKGlOV0MuLpYt2N6VtZ1mcaesM\n0xdQI0AgG9VVQV1157ALuOeA1zhLy2QRRo5xsSyRORZUqYLP+fT22gWRpxH0+nkXQMu9bxEOiA5+\nY/4a+yv/mx++2m+ufV/rcrw0qh9buKqp3oPBj8O2rkY3ZSQJmnG7zlQcQF2TO2VsT3+VW5/AS2KC\nfkwLAIUYgOdQfGYSq/19VKXo54j+OohnFoCFDNIF/aherXDRLivmm2xF3bE8S47X02j7\n```\n等待初始化Jira\n\n5.创建Jira用户信息\n>Full name ：jiraadmin\nEmail Address :jiraadmin@123.com\nUsername: jiraadmin\nPassword: jiraadmin\nConfirm Password : jiraadmin\n选择 Next\nConfigure Email Notifications ：Later\n选择 Finish\n选择语言\n之后创建Jira项目\n\n6.恢复Jira数据\n将备份的zip包拷贝到新的Jira目录中，目录位置为 \n`/var/atlassian/jira/import`\n返回jira页面，Setting>System>Restore system\n将备份包信息填写到相应位置，License输入上面的key信息\n然后点击Restore\n等待数据恢复，数据恢复后回到命令行\n将老Jira`/var/atlassian/jira/data/attachments`  的目录拷贝到本机的/data/jira/data/data/attachments目录中\n拷贝完成后重启Jira容器\n重启完成后，此时将可以使用老Jira的用户登录新Jira，到此Jira迁移完成。\n\n\n## Confluence 迁移简介\n\n### 备份老Confluence数据\n登录Confluence，Setting>General Configuration>Backup & Restore\n选择Include attachments然后导出或者直接使用Confluence每日自动备份的zip包进行恢复，我这里使用的是每日自动备份的zip包进行恢复的\n包路径为`$CONFLUENCE_HOME/backups`\n将zip包拷贝到新的Confluence机器上\n\n### 启动Confluence和Mysql\nmysql配置文件my.cnf\n```\n[client]\nport            = 3306\ndefault-character-set=utf8\nsocket          = /var/run/mysqld/mysqld.sock\n\n[mysql]\ndefault-character-set=utf8\n\n[mysqld_safe]\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nnice            = 0\n\n[mysqld]\nskip-host-cache\nskip-name-resolve\nuser            = mysql\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nport            = 3306\nbasedir         = /usr\ndatadir         = /var/lib/mysql\ntmpdir          = /tmp\nlc-messages-dir = /usr/share/mysql\nexplicit_defaults_for_timestamp\ncharacter-set-server=utf8\ndefault-storage-engine=INNODB\nmax_allowed_packet=256M\ninnodb_log_file_size=256M\n\n\n#sql_mode = NO_AUTO_VALUE_ON_ZERO\nsql_mode = \"\"\n\nsymbolic-links=0\n\n[mysqld.safe]\ndefault-character-set=utf8\n[mysql.server]\ndefault-character-set=utf8\n\n#\n!includedir /etc/mysql/conf.d/\n```\n### 启动mysql有两种方法，一种是docker run 一种是使用Kubelete启动\n\ndocker run方式\n```\ndocker run -d --restart=always --name mysql \\\n  -e MYSQL_ROOT_PASSWORD=root \\\n  -e MYSQL_USER=confluence \\\n  -e MYSQL_PASSWORD=confluence \\\n  -e MYSQL_DATABASE=confluencedb \\  \n  -v /data/mysql/data:/var/lib/mysql \\\n  -v /data/mysql/config/my.cnf:/etc/mysql/my.cnf \\\n  -p 3306:3306 \\\n  mysql:5.6\n```\nKubelete方式启动\n```\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  generation: 26\n  labels:\n    app.test.io/name: test-mysql-confluence.production-business-confluence\n  name: test-mysql-confluence-mysql-confluence\n  namespace: production-business-confluence\n  selfLink: >-\n    /apis/extensions/v1beta1/namespaces/production-business-confluence/deployments/test-mysql-confluence-mysql-confluence\nspec:\n  progressDeadlineSeconds: 600\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.test.io/name: test-mysql-confluence.production-business-confluence\n      project.test.io/name: production-business\n      service.test.io/name: deployment-test-mysql-confluence-mysql-confluence\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 25%\n    type: RollingUpdate\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: deployment-test-mysql-confluence-mysql-confluence\n        app.test.io/name: test-mysql-confluence.production-business-confluence\n        project.test.io/name: production-business\n        service.test.io/name: deployment-test-mysql-confluence-mysql-confluence\n        version: v1\n    spec:\n      containers:\n        - env:\n            - name: MYSQL_USER\n              value: confluence\n            - name: MYSQL_PASSWORD\n              value: confluence\n            - name: MYSQL_DATABASE\n              value: confluencedb\n            - name: MYSQL_ROOT_PASSWORD\n              value: root\n          image: 'mysql:5.6'\n          imagePullPolicy: IfNotPresent\n          name: mysql-confluence\n          resources:\n            limits:\n              cpu: '2'\n              memory: 4Gi\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n          volumeMounts:\n            - mountPath: /var/lib/mysql\n              name: mysql-data\n            - mountPath: /etc/mysql/my.cnf\n              name: new-volume\n              readOnly: true\n              subPath: my.cnf\n      dnsPolicy: ClusterFirst\n      nodeSelector:\n        kubernetes.io/hostname: slave-2\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\n      tolerations:\n        - operator: Exists\n      volumes:\n        - hostPath:\n            path: /data/mysql/data\n            type: ''\n          name: mysql-data\n        - configMap:\n            defaultMode: 420\n            items:\n              - key: my.cnf\n                path: my.cnf\n            name: confluence-mysql\n          name: new-volume\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.test.io/name: test-mysql-confluence.production-business-confluence\n  name: test-mysql-confluence\n  namespace: production-business-confluence\n  selfLink: >-\n    /api/v1/namespaces/production-business-confluence/services/test-mysql-confluence\nspec:\n  ports:\n    - name: tcp-3306-3306\n      port: 3306\n      protocol: TCP\n      targetPort: 3306\n  selector:\n    app.test.io/name: test-mysql-confluence.production-business-confluence\n    service.test.io/name: deployment-test-mysql-confluence-mysql-confluence\n  sessionAffinity: ClientIP\n  sessionAffinityConfig:\n    clientIP:\n      timeoutSeconds: 10800\n  type: ClusterIP\n\n```\n\n### 启动Confluence\nConfluence启动也是分为两种，一种是docker run另外一种是Kubelete方式启动\ndocker run方式\n```\ndocker run -d --restart=always --name confluence -p 8090:8090 \\\n  -e JVM_MAXIMUM_MEMORY=8196m \\\n  -e JAVA_OPTS=\"-javaagent:/opt/atlassian-agent.jar\" \\\n  -v /data/confluence/data:/var/atlassian/application-data/confluence \\\n  -v /root/atlassian-agent.jar:/opt/atlassian-agent.jar \\\n  -v /data/confluence/logs:/opt/atlassian/confluence/logs \\\ndocker.io/atlassian/confluence-server\n```\n\nKubelete方式启动\n```\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    app.test.io/name: confluence.production-business-confluence\n  name: confluence-confluence\n  namespace: production-business-confluence\n  selfLink: >-\n    /apis/extensions/v1beta1/namespaces/production-business-confluence/deployments/confluence-confluence\nspec:\n  progressDeadlineSeconds: 600\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.test.io/name: confluence.production-business-confluence\n      project.test.io/name: production-business\n      service.test.io/name: deployment-confluence-confluence\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 25%\n    type: RollingUpdate\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: deployment-confluence-confluence\n        app.test.io/name: confluence.production-business-confluence\n        project.test.io/name: production-business\n        service.test.io/name: deployment-confluence-confluence\n        version: v1\n    spec:\n      containers:\n        - env:\n            - name: JAVA_OPTS\n              value: '-javaagent:/opt/atlassian-agent.jar'\n          image: 'docker.io/atlassian/confluence-server'\n          imagePullPolicy: IfNotPresent\n          name: confluence\n          resources:\n            limits:\n              cpu: '4'\n              memory: 16Gi\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n          volumeMounts:\n            - mountPath: /var/atlassian/application-data/confluence\n              name: confluence-data\n            - mountPath: /opt/atlassian/confluence/logs\n              name: confluence-log\n      dnsPolicy: ClusterFirst\n      nodeSelector:\n        kubernetes.io/hostname: slave-2\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\n      tolerations:\n        - operator: Exists\n      volumes:\n        - hostPath:\n            path: /data/confluence/data\n            type: ''\n          name: confluence-data\n        - hostPath:\n            path: /data/confluence/logs\n            type: ''\n          name: confluence-log\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.test.io/name: confluence.production-business-confluence\n  name: confluence-confluence\n  namespace: production-business-confluence\n  selfLink: >-\n    /api/v1/namespaces/production-business-confluence/services/confluence-confluence\nspec:\n  ports:\n    - name: tcp-8090-8090\n      port: 8090\n      protocol: TCP\n      targetPort: 8090\n  selector:\n    app.test.io/name: confluence.production-business-confluence\n    service.test.io/name: deployment-confluence-confluence\n  sessionAffinity: ClientIP\n  sessionAffinityConfig:\n    clientIP:\n      timeoutSeconds: 10800\n  type: ClusterIP\n\n```\n\n#### 登录Confluence开始对Confluence进行初始化\n选择Confluence Team Calendars\n复制Server ID\n登录Confluence机器中的Confluence容器内\n\n>docker exec -it confluence bash\n cd /opt/\n ls\n `bash-4.4$ ls\natlassian            atlassian-agent.jar`\njava -jar atlassian-agent.jar -p conf -m aaa@bbb.com -n my_name -o http://datura.top -s XXXXXX\n```\n====================================================\n=======        Atlassian Crack Agent         =======\n=======           https://zhile.io           =======\n=======          QQ Group: 30347511          =======\n====================================================\nYour license code(Don't copy this line!!!):\nAAABQQ0ODAoPeJxtUNFOgzAUfe9XNPEZXDc3xpImTkCdgWFkm76ZC7tzTaCQtizOr7cDfDFLmjQ9p\n/fcc87NpkWaYUOZR0f+YjJfTDz6lGzoeMR8EigEI2oZgkF+QZyR7zCPRCco247hByg1khB1oUTTI\nVtZikoY3NNSFCg10vxMj8Y0enF7+3MUJbqiJqn6Ail0L3JhLbkH0ypwTd2QopYHFwojTsiNapEEt\nTT2HSUgSg4A93meu0Vd9T8zA8qgGtx0UNwv35wbXEOFPEiTJHoLVsuYWA1pUIIsMPpuhDoP+eY2n\n2cPGWZXIY9XYRatnZhNZ3OPTRjzpnczkqE6obL0w/vOc7wPljqP/vLFmYXPyd/wdeXXVhVH0Pi/0\naGqHSp9KWTcZ1i3VY4qPWy1xbnDiPXCr/gZyulyVudPae9f57CZMDAsAhRpli3TWhHdAL0fOkAeh\n38ZCSuf+QIUfBreVMIH4k/6isdn0HptYXvU608=X02g0\n```\n\nServer ID： XXXXX\nConfluence：\n```\nAAABQQ0ODAoPeJxtUNFOgzAUfe9XNPEZXDc3xpImTkCdgWFkm76ZC7tzTaCQtizOr7cDfDFLmjQ9p\n/fcc87NpkWaYUOZR0f+YjJfTDz6lGzoeMR8EigEI2oZgkF+QZyR7zCPRCco247hByg1khB1oUTTI\nVtZikoY3NNSFCg10vxMj8Y0enF7+3MUJbqiJqn6Ail0L3JhLbkH0ypwTd2QopYHFwojTsiNapEEt\nTT2HSUgSg4A93meu0Vd9T8zA8qgGtx0UNwv35wbXEOFPEiTJHoLVsuYWA1pUIIsMPpuhDoP+eY2n\n2cPGWZXIY9XYRatnZhNZ3OPTRjzpnczkqE6obL0w/vOc7wPljqP/vLFmYXPyd/wdeXXVhVH0Pi/0\naGqHSp9KWTcZ1i3VY4qPWy1xbnDiPXCr/gZyulyVudPae9f57CZMDAsAhRpli3TWhHdAL0fOkAeh\n38ZCSuf+QIUfBreVMIH4k/6isdn0HptYXvU608=X02g0\n```\n\n选择My own database\n>Database type: MySQL\n>Setup type: Simple\n>Hostname: mysql-confluence\n>PortThis: 3306\n>Database name: confluencedb\n>Username: confluence\n>Password: confluence\n\n点击Test connection 后可能会出现\n`Collation error\nThe database collation 'utf8_general_ci' is not supported by Confluence. You need to use 'utf8_bin'.`\n错误\n进入mysql容器\n>docker exec -it mysql bash\n>mysql -uroot -proot\n>`alter database confluencedb character set utf8 COLLATE utf8_bin;\n>SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED;`\n\n然后在点击Test connection，提示Success! Database connected successfully.\n然后点击Next 等待数据库初始化\n然后选择Restore From Backup\n将备份的包拷贝到本机的 `/data/confluence/data/restore/` 目录下\n此时页面上就会有相应的包，选择之后点击import后，等待导入完数据，此时Confluence迁移完成","slug":"jira和confluence迁移记录","published":1,"updated":"2019-09-24T09:56:49.931Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sjt000phcb7u2yqjgy9","content":"<h1 id=\"jira和confluence迁移简介\"><a href=\"#jira和confluence迁移简介\" class=\"headerlink\" title=\"jira和confluence迁移简介\"></a>jira和confluence迁移简介</h1><blockquote>\n<p>环境说明：<br>1.mysql5.6。<br>2.全部使用Kubelete和docker启动。<br>3.挂载方式为本地目录。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"Jira迁移\"><a href=\"#Jira迁移\" class=\"headerlink\" title=\"Jira迁移\"></a>Jira迁移</h2><h3 id=\"备份老jira机器上的数据\"><a href=\"#备份老jira机器上的数据\" class=\"headerlink\" title=\"备份老jira机器上的数据\"></a>备份老jira机器上的数据</h3><p>老环境的web页面中数据进行备份，页面选择Setting&gt;System&gt;Backup system&gt;<br>备份目录为<code>/var/atlassian/jira/export</code><br>将备份的zip包拷贝到新的机器<br>同时将jira目录拷贝到新的机器上，jira目录为<code>/var/atlassian/jira/data/attachments</code>     (此目录是jira上面存储的图片和附件信息)</p>\n<h3 id=\"启动Jira跟Mysql\"><a href=\"#启动Jira跟Mysql\" class=\"headerlink\" title=\"启动Jira跟Mysql\"></a>启动Jira跟Mysql</h3><p>mysql配置文件my.cnf<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[client]</span><br><span class=\"line\">port            = 3306</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\">socket          = /var/run/mysqld/mysqld.sock</span><br><span class=\"line\"></span><br><span class=\"line\">[mysql]</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld_safe]</span><br><span class=\"line\">pid-file        = /var/run/mysqld/mysqld.pid</span><br><span class=\"line\">socket          = /var/run/mysqld/mysqld.sock</span><br><span class=\"line\">nice            = 0</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld]</span><br><span class=\"line\">skip-host-cache</span><br><span class=\"line\">skip-name-resolve</span><br><span class=\"line\">user            = mysql</span><br><span class=\"line\">pid-file        = /var/run/mysqld/mysqld.pid</span><br><span class=\"line\">socket          = /var/run/mysqld/mysqld.sock</span><br><span class=\"line\">port            = 3306</span><br><span class=\"line\">basedir         = /usr</span><br><span class=\"line\">datadir         = /var/lib/mysql</span><br><span class=\"line\">tmpdir          = /tmp</span><br><span class=\"line\">lc-messages-dir = /usr/share/mysql</span><br><span class=\"line\">explicit_defaults_for_timestamp</span><br><span class=\"line\">character-set-server=utf8</span><br><span class=\"line\">default-storage-engine=INNODB</span><br><span class=\"line\">max_allowed_packet=256M</span><br><span class=\"line\">innodb_log_file_size=256M</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#sql_mode = NO_AUTO_VALUE_ON_ZERO</span><br><span class=\"line\">sql_mode = &quot;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">symbolic-links=0</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld.safe]</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\">[mysql.server]</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\"></span><br><span class=\"line\">#</span><br><span class=\"line\">!includedir /etc/mysql/conf.d/</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"启动Mysql有两种方法，一种是docker-run-一种是使用Kubelete启动\"><a href=\"#启动Mysql有两种方法，一种是docker-run-一种是使用Kubelete启动\" class=\"headerlink\" title=\"启动Mysql有两种方法，一种是docker run 一种是使用Kubelete启动\"></a>启动Mysql有两种方法，一种是docker run 一种是使用Kubelete启动</h3><p>docker run方式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d --restart=always --name mysql \\</span><br><span class=\"line\">  -e MYSQL_ROOT_PASSWORD=root \\</span><br><span class=\"line\">  -e MYSQL_USER=jira \\</span><br><span class=\"line\">  -e MYSQL_PASSWORD=jira \\</span><br><span class=\"line\">  -e MYSQL_DATABASE=jiradb \\</span><br><span class=\"line\">  -v /data/mysql/config/my.cnf:/etc/mysql/my.cnf \\</span><br><span class=\"line\">  -v /data/mysql/data:/var/lib/mysql \\</span><br><span class=\"line\">  -p 3306:3306 \\</span><br><span class=\"line\">  mysql:5.6</span><br></pre></td></tr></table></figure></p>\n<p>Kubelete方式启动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: test-mysql-jira.production-business-jira</span><br><span class=\"line\">  name: test-mysql-jira-mysql</span><br><span class=\"line\">  namespace: production-business-jira</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /apis/extensions/v1beta1/namespaces/production-business-jira/deployments/test-mysql-jira-mysql</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  progressDeadlineSeconds: 600</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  revisionHistoryLimit: 10</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app.test.io/name: test-mysql-jira.production-business-jira</span><br><span class=\"line\">      project.test.io/name: production-business</span><br><span class=\"line\">      service.test.io/name: deployment-test-mysql-jira-mysql</span><br><span class=\"line\">  strategy:</span><br><span class=\"line\">    rollingUpdate:</span><br><span class=\"line\">      maxSurge: 25%</span><br><span class=\"line\">      maxUnavailable: 25%</span><br><span class=\"line\">    type: RollingUpdate</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      creationTimestamp: null</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: deployment-test-mysql-jira-mysql</span><br><span class=\"line\">        app.test.io/name: test-mysql-jira.production-business-jira</span><br><span class=\"line\">        project.test.io/name: production-business</span><br><span class=\"line\">        service.test.io/name: deployment-test-mysql-jira-mysql</span><br><span class=\"line\">        version: v1</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">        - env:</span><br><span class=\"line\">            - name: MYSQL_ROOT_PASSWORD</span><br><span class=\"line\">              value: root</span><br><span class=\"line\">            - name: MYSQL_USER</span><br><span class=\"line\">              value: jira</span><br><span class=\"line\">            - name: MYSQL_PASSWORD</span><br><span class=\"line\">              value: jira</span><br><span class=\"line\">            - name: MYSQL_DATABASE</span><br><span class=\"line\">              value: jiradb</span><br><span class=\"line\">          image: &apos;mysql:5.6&apos;</span><br><span class=\"line\">          imagePullPolicy: IfNotPresent</span><br><span class=\"line\">          name: mysql</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            limits:</span><br><span class=\"line\">              cpu: &apos;4&apos;</span><br><span class=\"line\">              memory: 4Gi</span><br><span class=\"line\">          terminationMessagePath: /dev/termination-log</span><br><span class=\"line\">          terminationMessagePolicy: File</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">            - mountPath: /var/lib/mysql</span><br><span class=\"line\">              name: mysql-data</span><br><span class=\"line\">            - mountPath: /etc/mysql/my.cnf</span><br><span class=\"line\">              name: mysql-cnf</span><br><span class=\"line\">              readOnly: true</span><br><span class=\"line\">              subPath: my.cnf</span><br><span class=\"line\">      dnsPolicy: ClusterFirst</span><br><span class=\"line\">      nodeSelector:</span><br><span class=\"line\">        kubernetes.io/hostname: slave-4</span><br><span class=\"line\">      restartPolicy: Always</span><br><span class=\"line\">      schedulerName: default-scheduler</span><br><span class=\"line\">      securityContext: &#123;&#125;</span><br><span class=\"line\">      terminationGracePeriodSeconds: 30</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">        - operator: Exists</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">        - hostPath:</span><br><span class=\"line\">            path: /data/mysql/data</span><br><span class=\"line\">            type: &apos;&apos;</span><br><span class=\"line\">          name: mysql-data</span><br><span class=\"line\">        - configMap:</span><br><span class=\"line\">            defaultMode: 420</span><br><span class=\"line\">            items:</span><br><span class=\"line\">              - key: my.cnf</span><br><span class=\"line\">                path: my.cnf</span><br><span class=\"line\">            name: mysql</span><br><span class=\"line\">          name: mysql-cnf</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    test.io/creator: admin@test.io</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: test-mysql-jira.production-business-jira</span><br><span class=\"line\">  name: test-mysql-jira-mysql</span><br><span class=\"line\">  namespace: production-business-jira</span><br><span class=\"line\">  ownerReferences:</span><br><span class=\"line\">    - apiVersion: app.k8s.io/v1beta1</span><br><span class=\"line\">      blockOwnerDeletion: true</span><br><span class=\"line\">      controller: true</span><br><span class=\"line\">      kind: Application</span><br><span class=\"line\">      name: test-mysql-jira</span><br><span class=\"line\">  resourceVersion: &apos;2489793&apos;</span><br><span class=\"line\">  selfLink: /api/v1/namespaces/production-business-jira/services/test-mysql-jira-mysql</span><br><span class=\"line\">  uid: f8ea4a3c-d507-11e9-a5de-525400ed59d9</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">    - name: tcp-3306-3306</span><br><span class=\"line\">      port: 3306</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 3306</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app.test.io/name: test-mysql-jira.production-business-jira</span><br><span class=\"line\">    service.test.io/name: deployment-test-mysql-jira-mysql</span><br><span class=\"line\">  sessionAffinity: ClientIP</span><br><span class=\"line\">  sessionAffinityConfig:</span><br><span class=\"line\">    clientIP:</span><br><span class=\"line\">      timeoutSeconds: 10800</span><br><span class=\"line\">  type: ClusterIP</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"启动Jira\"><a href=\"#启动Jira\" class=\"headerlink\" title=\"启动Jira\"></a>启动Jira</h3><p>Jira启动也是分为两种，一种是docker run另外一种是Kubelete方式启动<br>docker run方式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d  --restart=always --name jira -p 8080:8080 \\</span><br><span class=\"line\">  -e JVM_MAXIMUM_MEMORY=6144m \\</span><br><span class=\"line\">  -e JAVA_OPTS=&quot;-javaagent:/opt/atlassian-agent.jar&quot; \\</span><br><span class=\"line\">  -v /root/atlassian-agent.jar:/opt/atlassian-agent.jar \\</span><br><span class=\"line\">  -v /data/jira/data:/var/atlassian/jira \\</span><br><span class=\"line\">  -v /data/jira/logs:/opt/atlassian/jira/logs \\</span><br><span class=\"line\">  cptactionhank/atlassian-jira</span><br></pre></td></tr></table></figure></p>\n<p>atlassian-agent.jar是破解包，详情请见<a href=\"https://gitee.com/pengzhile/atlassian-agent\" target=\"_blank\" rel=\"noopener\">https://gitee.com/pengzhile/atlassian-agent</a></p>\n<p>Kubelete方式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: test-jira.production-business-jira</span><br><span class=\"line\">  name: test-jira-atlassian-jira</span><br><span class=\"line\">  namespace: production-business-jira</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /apis/extensions/v1beta1/namespaces/production-business-jira/deployments/test-jira-atlassian-jira</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  progressDeadlineSeconds: 600</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  revisionHistoryLimit: 10</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app.test.io/name: test-jira.production-business-jira</span><br><span class=\"line\">      project.test.io/name: production-business</span><br><span class=\"line\">      service.test.io/name: deployment-test-jira-atlassian-jira</span><br><span class=\"line\">  strategy:</span><br><span class=\"line\">    rollingUpdate:</span><br><span class=\"line\">      maxSurge: 25%</span><br><span class=\"line\">      maxUnavailable: 25%</span><br><span class=\"line\">    type: RollingUpdate</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      creationTimestamp: null</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: deployment-test-jira-atlassian-jira</span><br><span class=\"line\">        app.test.io/name: test-jira.production-business-jira</span><br><span class=\"line\">        project.test.io/name: production-business</span><br><span class=\"line\">        service.test.io/name: deployment-test-jira-atlassian-jira</span><br><span class=\"line\">        version: v1</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">        - env:</span><br><span class=\"line\">            - name: JAVA_OPTS</span><br><span class=\"line\">              value: &apos;-javaagent:/opt/atlassian-agent.jar&apos;</span><br><span class=\"line\">          image: &apos;cptactionhank/atlassian-jira&apos;</span><br><span class=\"line\">          imagePullPolicy: IfNotPresent</span><br><span class=\"line\">          name: atlassian-jira</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            limits:</span><br><span class=\"line\">              cpu: &apos;8&apos;</span><br><span class=\"line\">              memory: 16Gi</span><br><span class=\"line\">          terminationMessagePath: /dev/termination-log</span><br><span class=\"line\">          terminationMessagePolicy: File</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">            - mountPath: /var/atlassian/jira</span><br><span class=\"line\">              name: new-volume</span><br><span class=\"line\">            - mountPath: /opt/atlassian/jira/logs</span><br><span class=\"line\">              name: new-volume1</span><br><span class=\"line\">      dnsPolicy: ClusterFirst</span><br><span class=\"line\">      nodeSelector:</span><br><span class=\"line\">        kubernetes.io/hostname: slave-4</span><br><span class=\"line\">      restartPolicy: Always</span><br><span class=\"line\">      schedulerName: default-scheduler</span><br><span class=\"line\">      securityContext: &#123;&#125;</span><br><span class=\"line\">      terminationGracePeriodSeconds: 30</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">        - operator: Exists</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">        - hostPath:</span><br><span class=\"line\">            path: /data/jira/data</span><br><span class=\"line\">            type: &apos;&apos;</span><br><span class=\"line\">          name: new-volume</span><br><span class=\"line\">        - hostPath:</span><br><span class=\"line\">            path: /data/jira/logs</span><br><span class=\"line\">            type: &apos;&apos;</span><br><span class=\"line\">          name: new-volume1</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: test-jira.production-business-jira</span><br><span class=\"line\">  name: test-jira-atlassian-jira</span><br><span class=\"line\">  namespace: production-business-jira</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /api/v1/namespaces/production-business-jira/services/test-jira-atlassian-jira</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">    - name: tcp-8080-8080</span><br><span class=\"line\">      port: 8080</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 8080</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app.test.io/name: test-jira.production-business-jira</span><br><span class=\"line\">    service.test.io/name: deployment-test-jira-atlassian-jira</span><br><span class=\"line\">  sessionAffinity: None</span><br><span class=\"line\">  type: ClusterIP</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"登录Jira开始对Jira进行初始化\"><a href=\"#登录Jira开始对Jira进行初始化\" class=\"headerlink\" title=\"登录Jira开始对Jira进行初始化\"></a>登录Jira开始对Jira进行初始化</h4><p>1.选择I’ll set it up myself     Next<br>2.选择My Own Database (recommended for production environments)</p>\n<blockquote>\n<p>Database Type:   MySQL 5.6<br>Hostname: mysql-jira-mysql<br>Port: 3306<br>Database: jiradb<br>Username: jira<br>Password: jira</p>\n</blockquote>\n<p>选择Test Connection，测试链接成功后点击  Next  然后等待数据库初始化完成<br>3.填写jira项目信息</p>\n<blockquote>\n<p>Application Title: jiar<br>Mode:Private<br>Base URL:<a href=\"http://192.168.8.27:8081\" target=\"_blank\" rel=\"noopener\">http://192.168.8.27:8081</a></p>\n</blockquote>\n<p>4.破解Jira<br>复制Server ID内容<br>然后进入jira容器内</p>\n<blockquote>\n<p>docker exec -it jira bash<br> cd /opt/<br> ls<br> <code>bash-4.4$ ls\natlassian            atlassian-agent.jar</code><br>java -jar atlassian-agent.jar -p jira -m <a href=\"mailto:aaa@bbb.com\" target=\"_blank\" rel=\"noopener\">aaa@bbb.com</a> -n my_name -o <a href=\"http://datura.top\">http://datura.top</a> -s XXXXXX<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">====================================================</span><br><span class=\"line\">=======        Atlassian Crack Agent         =======</span><br><span class=\"line\">=======           https://zhile.io           =======</span><br><span class=\"line\">=======          QQ Group: 30347511          =======</span><br><span class=\"line\">====================================================</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;Your license code(Don&apos;t copy this line!!!):</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;AAABjQ0ODAoPeJx9klFr2zAUhd/1Kwx7tmuFpXEDgm222TzsJNRpHvYyrp2bRsOWxZWcNvv1lRsX0</span><br><span class=\"line\">&gt;jYEBEJC59xP594v6x69ErXHZ14Yzfl0ziPvZ7H2JiG/Y4+EqPad1khBLmtUBtdHjQtoUcTLokjv4</span><br><span class=\"line\">&gt;+x7zmJCsLJTCVgUg9AP73w+Y1ckCZqapB5U4kE1spUWt15zEnjV0dtbq8385ub/XjYYyI4VIJVFB</span><br><span class=\"line\">&gt;arG9FlLOo7VIldt5hb7JwneKNOtPFkv8qzI1mnCFn1bIS13DwbJCJ+/wV3x0tRt+9oGw8E33c4+A</span><br><span class=\"line\">&gt;WHwyejKW6itPKCw1OO7LM/vxz9vnNtAPGHpAZr+NU+xg8YgW9IjKGlOV0MuLpYt2N6VtZ1mcaesM</span><br><span class=\"line\">&gt;0xdQI0AgG9VVQV1157ALuOeA1zhLy2QRRo5xsSyRORZUqYLP+fT22gWRpxH0+nkXQMu9bxEOiA5+</span><br><span class=\"line\">&gt;Y/4a+yv/mx++2m+ufV/rcrw0qh9buKqp3oPBj8O2rkY3ZSQJmnG7zlQcQF2TO2VsT3+VW5/AS2KC</span><br><span class=\"line\">&gt; fkwLAIUYgOdQfGYSq/19VKXo54j+OohnFoCFDNIF/aherXDRLivmm2xF3bE8S47X02j7</span><br></pre></td></tr></table></figure></p>\n</blockquote>\n<p>Server ID：XXXXXXX<br>Your License Key:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AAABjQ0ODAoPeJx9klFr2zAUhd/1Kwx7tmuFpXEDgm222TzsJNRpHvYyrp2bRsOWxZWcNvv1lRsX0</span><br><span class=\"line\">jYEBEJC59xP594v6x69ErXHZ14Yzfl0ziPvZ7H2JiG/Y4+EqPad1khBLmtUBtdHjQtoUcTLokjv4</span><br><span class=\"line\">+x7zmJCsLJTCVgUg9AP73w+Y1ckCZqapB5U4kE1spUWt15zEnjV0dtbq8385ub/XjYYyI4VIJVFB</span><br><span class=\"line\">arG9FlLOo7VIldt5hb7JwneKNOtPFkv8qzI1mnCFn1bIS13DwbJCJ+/wV3x0tRt+9oGw8E33c4+A</span><br><span class=\"line\">WHwyejKW6itPKCw1OO7LM/vxz9vnNtAPGHpAZr+NU+xg8YgW9IjKGlOV0MuLpYt2N6VtZ1mcaesM</span><br><span class=\"line\">0xdQI0AgG9VVQV1157ALuOeA1zhLy2QRRo5xsSyRORZUqYLP+fT22gWRpxH0+nkXQMu9bxEOiA5+</span><br><span class=\"line\">Y/4a+yv/mx++2m+ufV/rcrw0qh9buKqp3oPBj8O2rkY3ZSQJmnG7zlQcQF2TO2VsT3+VW5/AS2KC</span><br><span class=\"line\">fkwLAIUYgOdQfGYSq/19VKXo54j+OohnFoCFDNIF/aherXDRLivmm2xF3bE8S47X02j7</span><br></pre></td></tr></table></figure></p>\n<p>等待初始化Jira</p>\n<p>5.创建Jira用户信息</p>\n<blockquote>\n<p>Full name ：jiraadmin<br>Email Address :<a href=\"mailto:jiraadmin@123.com\" target=\"_blank\" rel=\"noopener\">jiraadmin@123.com</a><br>Username: jiraadmin<br>Password: jiraadmin<br>Confirm Password : jiraadmin<br>选择 Next<br>Configure Email Notifications ：Later<br>选择 Finish<br>选择语言<br>之后创建Jira项目</p>\n</blockquote>\n<p>6.恢复Jira数据<br>将备份的zip包拷贝到新的Jira目录中，目录位置为<br><code>/var/atlassian/jira/import</code><br>返回jira页面，Setting&gt;System&gt;Restore system<br>将备份包信息填写到相应位置，License输入上面的key信息<br>然后点击Restore<br>等待数据恢复，数据恢复后回到命令行<br>将老Jira<code>/var/atlassian/jira/data/attachments</code>  的目录拷贝到本机的/data/jira/data/data/attachments目录中<br>拷贝完成后重启Jira容器<br>重启完成后，此时将可以使用老Jira的用户登录新Jira，到此Jira迁移完成。</p>\n<h2 id=\"Confluence-迁移简介\"><a href=\"#Confluence-迁移简介\" class=\"headerlink\" title=\"Confluence 迁移简介\"></a>Confluence 迁移简介</h2><h3 id=\"备份老Confluence数据\"><a href=\"#备份老Confluence数据\" class=\"headerlink\" title=\"备份老Confluence数据\"></a>备份老Confluence数据</h3><p>登录Confluence，Setting&gt;General Configuration&gt;Backup &amp; Restore<br>选择Include attachments然后导出或者直接使用Confluence每日自动备份的zip包进行恢复，我这里使用的是每日自动备份的zip包进行恢复的<br>包路径为<code>$CONFLUENCE_HOME/backups</code><br>将zip包拷贝到新的Confluence机器上</p>\n<h3 id=\"启动Confluence和Mysql\"><a href=\"#启动Confluence和Mysql\" class=\"headerlink\" title=\"启动Confluence和Mysql\"></a>启动Confluence和Mysql</h3><p>mysql配置文件my.cnf<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[client]</span><br><span class=\"line\">port            = 3306</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\">socket          = /var/run/mysqld/mysqld.sock</span><br><span class=\"line\"></span><br><span class=\"line\">[mysql]</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld_safe]</span><br><span class=\"line\">pid-file        = /var/run/mysqld/mysqld.pid</span><br><span class=\"line\">socket          = /var/run/mysqld/mysqld.sock</span><br><span class=\"line\">nice            = 0</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld]</span><br><span class=\"line\">skip-host-cache</span><br><span class=\"line\">skip-name-resolve</span><br><span class=\"line\">user            = mysql</span><br><span class=\"line\">pid-file        = /var/run/mysqld/mysqld.pid</span><br><span class=\"line\">socket          = /var/run/mysqld/mysqld.sock</span><br><span class=\"line\">port            = 3306</span><br><span class=\"line\">basedir         = /usr</span><br><span class=\"line\">datadir         = /var/lib/mysql</span><br><span class=\"line\">tmpdir          = /tmp</span><br><span class=\"line\">lc-messages-dir = /usr/share/mysql</span><br><span class=\"line\">explicit_defaults_for_timestamp</span><br><span class=\"line\">character-set-server=utf8</span><br><span class=\"line\">default-storage-engine=INNODB</span><br><span class=\"line\">max_allowed_packet=256M</span><br><span class=\"line\">innodb_log_file_size=256M</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#sql_mode = NO_AUTO_VALUE_ON_ZERO</span><br><span class=\"line\">sql_mode = &quot;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">symbolic-links=0</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld.safe]</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\">[mysql.server]</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\"></span><br><span class=\"line\">#</span><br><span class=\"line\">!includedir /etc/mysql/conf.d/</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"启动mysql有两种方法，一种是docker-run-一种是使用Kubelete启动\"><a href=\"#启动mysql有两种方法，一种是docker-run-一种是使用Kubelete启动\" class=\"headerlink\" title=\"启动mysql有两种方法，一种是docker run 一种是使用Kubelete启动\"></a>启动mysql有两种方法，一种是docker run 一种是使用Kubelete启动</h3><p>docker run方式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d --restart=always --name mysql \\</span><br><span class=\"line\">  -e MYSQL_ROOT_PASSWORD=root \\</span><br><span class=\"line\">  -e MYSQL_USER=confluence \\</span><br><span class=\"line\">  -e MYSQL_PASSWORD=confluence \\</span><br><span class=\"line\">  -e MYSQL_DATABASE=confluencedb \\  </span><br><span class=\"line\">  -v /data/mysql/data:/var/lib/mysql \\</span><br><span class=\"line\">  -v /data/mysql/config/my.cnf:/etc/mysql/my.cnf \\</span><br><span class=\"line\">  -p 3306:3306 \\</span><br><span class=\"line\">  mysql:5.6</span><br></pre></td></tr></table></figure></p>\n<p>Kubelete方式启动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  generation: 26</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: test-mysql-confluence.production-business-confluence</span><br><span class=\"line\">  name: test-mysql-confluence-mysql-confluence</span><br><span class=\"line\">  namespace: production-business-confluence</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /apis/extensions/v1beta1/namespaces/production-business-confluence/deployments/test-mysql-confluence-mysql-confluence</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  progressDeadlineSeconds: 600</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  revisionHistoryLimit: 10</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app.test.io/name: test-mysql-confluence.production-business-confluence</span><br><span class=\"line\">      project.test.io/name: production-business</span><br><span class=\"line\">      service.test.io/name: deployment-test-mysql-confluence-mysql-confluence</span><br><span class=\"line\">  strategy:</span><br><span class=\"line\">    rollingUpdate:</span><br><span class=\"line\">      maxSurge: 25%</span><br><span class=\"line\">      maxUnavailable: 25%</span><br><span class=\"line\">    type: RollingUpdate</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      creationTimestamp: null</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: deployment-test-mysql-confluence-mysql-confluence</span><br><span class=\"line\">        app.test.io/name: test-mysql-confluence.production-business-confluence</span><br><span class=\"line\">        project.test.io/name: production-business</span><br><span class=\"line\">        service.test.io/name: deployment-test-mysql-confluence-mysql-confluence</span><br><span class=\"line\">        version: v1</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">        - env:</span><br><span class=\"line\">            - name: MYSQL_USER</span><br><span class=\"line\">              value: confluence</span><br><span class=\"line\">            - name: MYSQL_PASSWORD</span><br><span class=\"line\">              value: confluence</span><br><span class=\"line\">            - name: MYSQL_DATABASE</span><br><span class=\"line\">              value: confluencedb</span><br><span class=\"line\">            - name: MYSQL_ROOT_PASSWORD</span><br><span class=\"line\">              value: root</span><br><span class=\"line\">          image: &apos;mysql:5.6&apos;</span><br><span class=\"line\">          imagePullPolicy: IfNotPresent</span><br><span class=\"line\">          name: mysql-confluence</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            limits:</span><br><span class=\"line\">              cpu: &apos;2&apos;</span><br><span class=\"line\">              memory: 4Gi</span><br><span class=\"line\">          terminationMessagePath: /dev/termination-log</span><br><span class=\"line\">          terminationMessagePolicy: File</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">            - mountPath: /var/lib/mysql</span><br><span class=\"line\">              name: mysql-data</span><br><span class=\"line\">            - mountPath: /etc/mysql/my.cnf</span><br><span class=\"line\">              name: new-volume</span><br><span class=\"line\">              readOnly: true</span><br><span class=\"line\">              subPath: my.cnf</span><br><span class=\"line\">      dnsPolicy: ClusterFirst</span><br><span class=\"line\">      nodeSelector:</span><br><span class=\"line\">        kubernetes.io/hostname: slave-2</span><br><span class=\"line\">      restartPolicy: Always</span><br><span class=\"line\">      schedulerName: default-scheduler</span><br><span class=\"line\">      securityContext: &#123;&#125;</span><br><span class=\"line\">      terminationGracePeriodSeconds: 30</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">        - operator: Exists</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">        - hostPath:</span><br><span class=\"line\">            path: /data/mysql/data</span><br><span class=\"line\">            type: &apos;&apos;</span><br><span class=\"line\">          name: mysql-data</span><br><span class=\"line\">        - configMap:</span><br><span class=\"line\">            defaultMode: 420</span><br><span class=\"line\">            items:</span><br><span class=\"line\">              - key: my.cnf</span><br><span class=\"line\">                path: my.cnf</span><br><span class=\"line\">            name: confluence-mysql</span><br><span class=\"line\">          name: new-volume</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: test-mysql-confluence.production-business-confluence</span><br><span class=\"line\">  name: test-mysql-confluence</span><br><span class=\"line\">  namespace: production-business-confluence</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /api/v1/namespaces/production-business-confluence/services/test-mysql-confluence</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">    - name: tcp-3306-3306</span><br><span class=\"line\">      port: 3306</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 3306</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app.test.io/name: test-mysql-confluence.production-business-confluence</span><br><span class=\"line\">    service.test.io/name: deployment-test-mysql-confluence-mysql-confluence</span><br><span class=\"line\">  sessionAffinity: ClientIP</span><br><span class=\"line\">  sessionAffinityConfig:</span><br><span class=\"line\">    clientIP:</span><br><span class=\"line\">      timeoutSeconds: 10800</span><br><span class=\"line\">  type: ClusterIP</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"启动Confluence\"><a href=\"#启动Confluence\" class=\"headerlink\" title=\"启动Confluence\"></a>启动Confluence</h3><p>Confluence启动也是分为两种，一种是docker run另外一种是Kubelete方式启动<br>docker run方式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d --restart=always --name confluence -p 8090:8090 \\</span><br><span class=\"line\">  -e JVM_MAXIMUM_MEMORY=8196m \\</span><br><span class=\"line\">  -e JAVA_OPTS=&quot;-javaagent:/opt/atlassian-agent.jar&quot; \\</span><br><span class=\"line\">  -v /data/confluence/data:/var/atlassian/application-data/confluence \\</span><br><span class=\"line\">  -v /root/atlassian-agent.jar:/opt/atlassian-agent.jar \\</span><br><span class=\"line\">  -v /data/confluence/logs:/opt/atlassian/confluence/logs \\</span><br><span class=\"line\">docker.io/atlassian/confluence-server</span><br></pre></td></tr></table></figure></p>\n<p>Kubelete方式启动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: confluence.production-business-confluence</span><br><span class=\"line\">  name: confluence-confluence</span><br><span class=\"line\">  namespace: production-business-confluence</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /apis/extensions/v1beta1/namespaces/production-business-confluence/deployments/confluence-confluence</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  progressDeadlineSeconds: 600</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  revisionHistoryLimit: 10</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app.test.io/name: confluence.production-business-confluence</span><br><span class=\"line\">      project.test.io/name: production-business</span><br><span class=\"line\">      service.test.io/name: deployment-confluence-confluence</span><br><span class=\"line\">  strategy:</span><br><span class=\"line\">    rollingUpdate:</span><br><span class=\"line\">      maxSurge: 25%</span><br><span class=\"line\">      maxUnavailable: 25%</span><br><span class=\"line\">    type: RollingUpdate</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      creationTimestamp: null</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: deployment-confluence-confluence</span><br><span class=\"line\">        app.test.io/name: confluence.production-business-confluence</span><br><span class=\"line\">        project.test.io/name: production-business</span><br><span class=\"line\">        service.test.io/name: deployment-confluence-confluence</span><br><span class=\"line\">        version: v1</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">        - env:</span><br><span class=\"line\">            - name: JAVA_OPTS</span><br><span class=\"line\">              value: &apos;-javaagent:/opt/atlassian-agent.jar&apos;</span><br><span class=\"line\">          image: &apos;docker.io/atlassian/confluence-server&apos;</span><br><span class=\"line\">          imagePullPolicy: IfNotPresent</span><br><span class=\"line\">          name: confluence</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            limits:</span><br><span class=\"line\">              cpu: &apos;4&apos;</span><br><span class=\"line\">              memory: 16Gi</span><br><span class=\"line\">          terminationMessagePath: /dev/termination-log</span><br><span class=\"line\">          terminationMessagePolicy: File</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">            - mountPath: /var/atlassian/application-data/confluence</span><br><span class=\"line\">              name: confluence-data</span><br><span class=\"line\">            - mountPath: /opt/atlassian/confluence/logs</span><br><span class=\"line\">              name: confluence-log</span><br><span class=\"line\">      dnsPolicy: ClusterFirst</span><br><span class=\"line\">      nodeSelector:</span><br><span class=\"line\">        kubernetes.io/hostname: slave-2</span><br><span class=\"line\">      restartPolicy: Always</span><br><span class=\"line\">      schedulerName: default-scheduler</span><br><span class=\"line\">      securityContext: &#123;&#125;</span><br><span class=\"line\">      terminationGracePeriodSeconds: 30</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">        - operator: Exists</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">        - hostPath:</span><br><span class=\"line\">            path: /data/confluence/data</span><br><span class=\"line\">            type: &apos;&apos;</span><br><span class=\"line\">          name: confluence-data</span><br><span class=\"line\">        - hostPath:</span><br><span class=\"line\">            path: /data/confluence/logs</span><br><span class=\"line\">            type: &apos;&apos;</span><br><span class=\"line\">          name: confluence-log</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: confluence.production-business-confluence</span><br><span class=\"line\">  name: confluence-confluence</span><br><span class=\"line\">  namespace: production-business-confluence</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /api/v1/namespaces/production-business-confluence/services/confluence-confluence</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">    - name: tcp-8090-8090</span><br><span class=\"line\">      port: 8090</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 8090</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app.test.io/name: confluence.production-business-confluence</span><br><span class=\"line\">    service.test.io/name: deployment-confluence-confluence</span><br><span class=\"line\">  sessionAffinity: ClientIP</span><br><span class=\"line\">  sessionAffinityConfig:</span><br><span class=\"line\">    clientIP:</span><br><span class=\"line\">      timeoutSeconds: 10800</span><br><span class=\"line\">  type: ClusterIP</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"登录Confluence开始对Confluence进行初始化\"><a href=\"#登录Confluence开始对Confluence进行初始化\" class=\"headerlink\" title=\"登录Confluence开始对Confluence进行初始化\"></a>登录Confluence开始对Confluence进行初始化</h4><p>选择Confluence Team Calendars<br>复制Server ID<br>登录Confluence机器中的Confluence容器内</p>\n<blockquote>\n<p>docker exec -it confluence bash<br> cd /opt/<br> ls<br> <code>bash-4.4$ ls\natlassian            atlassian-agent.jar</code><br>java -jar atlassian-agent.jar -p conf -m <a href=\"mailto:aaa@bbb.com\" target=\"_blank\" rel=\"noopener\">aaa@bbb.com</a> -n my_name -o <a href=\"http://datura.top\">http://datura.top</a> -s XXXXXX<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">====================================================</span><br><span class=\"line\">=======        Atlassian Crack Agent         =======</span><br><span class=\"line\">=======           https://zhile.io           =======</span><br><span class=\"line\">=======          QQ Group: 30347511          =======</span><br><span class=\"line\">====================================================</span><br><span class=\"line\">Your license code(Don&apos;t copy this line!!!):</span><br><span class=\"line\">AAABQQ0ODAoPeJxtUNFOgzAUfe9XNPEZXDc3xpImTkCdgWFkm76ZC7tzTaCQtizOr7cDfDFLmjQ9p</span><br><span class=\"line\">/fcc87NpkWaYUOZR0f+YjJfTDz6lGzoeMR8EigEI2oZgkF+QZyR7zCPRCco247hByg1khB1oUTTI</span><br><span class=\"line\">VtZikoY3NNSFCg10vxMj8Y0enF7+3MUJbqiJqn6Ail0L3JhLbkH0ypwTd2QopYHFwojTsiNapEEt</span><br><span class=\"line\">TT2HSUgSg4A93meu0Vd9T8zA8qgGtx0UNwv35wbXEOFPEiTJHoLVsuYWA1pUIIsMPpuhDoP+eY2n</span><br><span class=\"line\">2cPGWZXIY9XYRatnZhNZ3OPTRjzpnczkqE6obL0w/vOc7wPljqP/vLFmYXPyd/wdeXXVhVH0Pi/0</span><br><span class=\"line\">aGqHSp9KWTcZ1i3VY4qPWy1xbnDiPXCr/gZyulyVudPae9f57CZMDAsAhRpli3TWhHdAL0fOkAeh</span><br><span class=\"line\">38ZCSuf+QIUfBreVMIH4k/6isdn0HptYXvU608=X02g0</span><br></pre></td></tr></table></figure></p>\n</blockquote>\n<p>Server ID： XXXXX<br>Confluence：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AAABQQ0ODAoPeJxtUNFOgzAUfe9XNPEZXDc3xpImTkCdgWFkm76ZC7tzTaCQtizOr7cDfDFLmjQ9p</span><br><span class=\"line\">/fcc87NpkWaYUOZR0f+YjJfTDz6lGzoeMR8EigEI2oZgkF+QZyR7zCPRCco247hByg1khB1oUTTI</span><br><span class=\"line\">VtZikoY3NNSFCg10vxMj8Y0enF7+3MUJbqiJqn6Ail0L3JhLbkH0ypwTd2QopYHFwojTsiNapEEt</span><br><span class=\"line\">TT2HSUgSg4A93meu0Vd9T8zA8qgGtx0UNwv35wbXEOFPEiTJHoLVsuYWA1pUIIsMPpuhDoP+eY2n</span><br><span class=\"line\">2cPGWZXIY9XYRatnZhNZ3OPTRjzpnczkqE6obL0w/vOc7wPljqP/vLFmYXPyd/wdeXXVhVH0Pi/0</span><br><span class=\"line\">aGqHSp9KWTcZ1i3VY4qPWy1xbnDiPXCr/gZyulyVudPae9f57CZMDAsAhRpli3TWhHdAL0fOkAeh</span><br><span class=\"line\">38ZCSuf+QIUfBreVMIH4k/6isdn0HptYXvU608=X02g0</span><br></pre></td></tr></table></figure></p>\n<p>选择My own database</p>\n<blockquote>\n<p>Database type: MySQL<br>Setup type: Simple<br>Hostname: mysql-confluence<br>PortThis: 3306<br>Database name: confluencedb<br>Username: confluence<br>Password: confluence</p>\n</blockquote>\n<p>点击Test connection 后可能会出现<br><code>Collation error\nThe database collation &#39;utf8_general_ci&#39; is not supported by Confluence. You need to use &#39;utf8_bin&#39;.</code><br>错误<br>进入mysql容器</p>\n<blockquote>\n<p>docker exec -it mysql bash<br>mysql -uroot -proot<br><code>alter database confluencedb character set utf8 COLLATE utf8_bin;\nSET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED;</code></p>\n</blockquote>\n<p>然后在点击Test connection，提示Success! Database connected successfully.<br>然后点击Next 等待数据库初始化<br>然后选择Restore From Backup<br>将备份的包拷贝到本机的 <code>/data/confluence/data/restore/</code> 目录下<br>此时页面上就会有相应的包，选择之后点击import后，等待导入完数据，此时Confluence迁移完成</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"jira和confluence迁移简介\"><a href=\"#jira和confluence迁移简介\" class=\"headerlink\" title=\"jira和confluence迁移简介\"></a>jira和confluence迁移简介</h1><blockquote>\n<p>环境说明：<br>1.mysql5.6。<br>2.全部使用Kubelete和docker启动。<br>3.挂载方式为本地目录。</p>\n</blockquote>","more":"<h2 id=\"Jira迁移\"><a href=\"#Jira迁移\" class=\"headerlink\" title=\"Jira迁移\"></a>Jira迁移</h2><h3 id=\"备份老jira机器上的数据\"><a href=\"#备份老jira机器上的数据\" class=\"headerlink\" title=\"备份老jira机器上的数据\"></a>备份老jira机器上的数据</h3><p>老环境的web页面中数据进行备份，页面选择Setting&gt;System&gt;Backup system&gt;<br>备份目录为<code>/var/atlassian/jira/export</code><br>将备份的zip包拷贝到新的机器<br>同时将jira目录拷贝到新的机器上，jira目录为<code>/var/atlassian/jira/data/attachments</code>     (此目录是jira上面存储的图片和附件信息)</p>\n<h3 id=\"启动Jira跟Mysql\"><a href=\"#启动Jira跟Mysql\" class=\"headerlink\" title=\"启动Jira跟Mysql\"></a>启动Jira跟Mysql</h3><p>mysql配置文件my.cnf<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[client]</span><br><span class=\"line\">port            = 3306</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\">socket          = /var/run/mysqld/mysqld.sock</span><br><span class=\"line\"></span><br><span class=\"line\">[mysql]</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld_safe]</span><br><span class=\"line\">pid-file        = /var/run/mysqld/mysqld.pid</span><br><span class=\"line\">socket          = /var/run/mysqld/mysqld.sock</span><br><span class=\"line\">nice            = 0</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld]</span><br><span class=\"line\">skip-host-cache</span><br><span class=\"line\">skip-name-resolve</span><br><span class=\"line\">user            = mysql</span><br><span class=\"line\">pid-file        = /var/run/mysqld/mysqld.pid</span><br><span class=\"line\">socket          = /var/run/mysqld/mysqld.sock</span><br><span class=\"line\">port            = 3306</span><br><span class=\"line\">basedir         = /usr</span><br><span class=\"line\">datadir         = /var/lib/mysql</span><br><span class=\"line\">tmpdir          = /tmp</span><br><span class=\"line\">lc-messages-dir = /usr/share/mysql</span><br><span class=\"line\">explicit_defaults_for_timestamp</span><br><span class=\"line\">character-set-server=utf8</span><br><span class=\"line\">default-storage-engine=INNODB</span><br><span class=\"line\">max_allowed_packet=256M</span><br><span class=\"line\">innodb_log_file_size=256M</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#sql_mode = NO_AUTO_VALUE_ON_ZERO</span><br><span class=\"line\">sql_mode = &quot;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">symbolic-links=0</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld.safe]</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\">[mysql.server]</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\"></span><br><span class=\"line\">#</span><br><span class=\"line\">!includedir /etc/mysql/conf.d/</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"启动Mysql有两种方法，一种是docker-run-一种是使用Kubelete启动\"><a href=\"#启动Mysql有两种方法，一种是docker-run-一种是使用Kubelete启动\" class=\"headerlink\" title=\"启动Mysql有两种方法，一种是docker run 一种是使用Kubelete启动\"></a>启动Mysql有两种方法，一种是docker run 一种是使用Kubelete启动</h3><p>docker run方式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d --restart=always --name mysql \\</span><br><span class=\"line\">  -e MYSQL_ROOT_PASSWORD=root \\</span><br><span class=\"line\">  -e MYSQL_USER=jira \\</span><br><span class=\"line\">  -e MYSQL_PASSWORD=jira \\</span><br><span class=\"line\">  -e MYSQL_DATABASE=jiradb \\</span><br><span class=\"line\">  -v /data/mysql/config/my.cnf:/etc/mysql/my.cnf \\</span><br><span class=\"line\">  -v /data/mysql/data:/var/lib/mysql \\</span><br><span class=\"line\">  -p 3306:3306 \\</span><br><span class=\"line\">  mysql:5.6</span><br></pre></td></tr></table></figure></p>\n<p>Kubelete方式启动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: test-mysql-jira.production-business-jira</span><br><span class=\"line\">  name: test-mysql-jira-mysql</span><br><span class=\"line\">  namespace: production-business-jira</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /apis/extensions/v1beta1/namespaces/production-business-jira/deployments/test-mysql-jira-mysql</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  progressDeadlineSeconds: 600</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  revisionHistoryLimit: 10</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app.test.io/name: test-mysql-jira.production-business-jira</span><br><span class=\"line\">      project.test.io/name: production-business</span><br><span class=\"line\">      service.test.io/name: deployment-test-mysql-jira-mysql</span><br><span class=\"line\">  strategy:</span><br><span class=\"line\">    rollingUpdate:</span><br><span class=\"line\">      maxSurge: 25%</span><br><span class=\"line\">      maxUnavailable: 25%</span><br><span class=\"line\">    type: RollingUpdate</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      creationTimestamp: null</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: deployment-test-mysql-jira-mysql</span><br><span class=\"line\">        app.test.io/name: test-mysql-jira.production-business-jira</span><br><span class=\"line\">        project.test.io/name: production-business</span><br><span class=\"line\">        service.test.io/name: deployment-test-mysql-jira-mysql</span><br><span class=\"line\">        version: v1</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">        - env:</span><br><span class=\"line\">            - name: MYSQL_ROOT_PASSWORD</span><br><span class=\"line\">              value: root</span><br><span class=\"line\">            - name: MYSQL_USER</span><br><span class=\"line\">              value: jira</span><br><span class=\"line\">            - name: MYSQL_PASSWORD</span><br><span class=\"line\">              value: jira</span><br><span class=\"line\">            - name: MYSQL_DATABASE</span><br><span class=\"line\">              value: jiradb</span><br><span class=\"line\">          image: &apos;mysql:5.6&apos;</span><br><span class=\"line\">          imagePullPolicy: IfNotPresent</span><br><span class=\"line\">          name: mysql</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            limits:</span><br><span class=\"line\">              cpu: &apos;4&apos;</span><br><span class=\"line\">              memory: 4Gi</span><br><span class=\"line\">          terminationMessagePath: /dev/termination-log</span><br><span class=\"line\">          terminationMessagePolicy: File</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">            - mountPath: /var/lib/mysql</span><br><span class=\"line\">              name: mysql-data</span><br><span class=\"line\">            - mountPath: /etc/mysql/my.cnf</span><br><span class=\"line\">              name: mysql-cnf</span><br><span class=\"line\">              readOnly: true</span><br><span class=\"line\">              subPath: my.cnf</span><br><span class=\"line\">      dnsPolicy: ClusterFirst</span><br><span class=\"line\">      nodeSelector:</span><br><span class=\"line\">        kubernetes.io/hostname: slave-4</span><br><span class=\"line\">      restartPolicy: Always</span><br><span class=\"line\">      schedulerName: default-scheduler</span><br><span class=\"line\">      securityContext: &#123;&#125;</span><br><span class=\"line\">      terminationGracePeriodSeconds: 30</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">        - operator: Exists</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">        - hostPath:</span><br><span class=\"line\">            path: /data/mysql/data</span><br><span class=\"line\">            type: &apos;&apos;</span><br><span class=\"line\">          name: mysql-data</span><br><span class=\"line\">        - configMap:</span><br><span class=\"line\">            defaultMode: 420</span><br><span class=\"line\">            items:</span><br><span class=\"line\">              - key: my.cnf</span><br><span class=\"line\">                path: my.cnf</span><br><span class=\"line\">            name: mysql</span><br><span class=\"line\">          name: mysql-cnf</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    test.io/creator: admin@test.io</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: test-mysql-jira.production-business-jira</span><br><span class=\"line\">  name: test-mysql-jira-mysql</span><br><span class=\"line\">  namespace: production-business-jira</span><br><span class=\"line\">  ownerReferences:</span><br><span class=\"line\">    - apiVersion: app.k8s.io/v1beta1</span><br><span class=\"line\">      blockOwnerDeletion: true</span><br><span class=\"line\">      controller: true</span><br><span class=\"line\">      kind: Application</span><br><span class=\"line\">      name: test-mysql-jira</span><br><span class=\"line\">  resourceVersion: &apos;2489793&apos;</span><br><span class=\"line\">  selfLink: /api/v1/namespaces/production-business-jira/services/test-mysql-jira-mysql</span><br><span class=\"line\">  uid: f8ea4a3c-d507-11e9-a5de-525400ed59d9</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">    - name: tcp-3306-3306</span><br><span class=\"line\">      port: 3306</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 3306</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app.test.io/name: test-mysql-jira.production-business-jira</span><br><span class=\"line\">    service.test.io/name: deployment-test-mysql-jira-mysql</span><br><span class=\"line\">  sessionAffinity: ClientIP</span><br><span class=\"line\">  sessionAffinityConfig:</span><br><span class=\"line\">    clientIP:</span><br><span class=\"line\">      timeoutSeconds: 10800</span><br><span class=\"line\">  type: ClusterIP</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"启动Jira\"><a href=\"#启动Jira\" class=\"headerlink\" title=\"启动Jira\"></a>启动Jira</h3><p>Jira启动也是分为两种，一种是docker run另外一种是Kubelete方式启动<br>docker run方式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d  --restart=always --name jira -p 8080:8080 \\</span><br><span class=\"line\">  -e JVM_MAXIMUM_MEMORY=6144m \\</span><br><span class=\"line\">  -e JAVA_OPTS=&quot;-javaagent:/opt/atlassian-agent.jar&quot; \\</span><br><span class=\"line\">  -v /root/atlassian-agent.jar:/opt/atlassian-agent.jar \\</span><br><span class=\"line\">  -v /data/jira/data:/var/atlassian/jira \\</span><br><span class=\"line\">  -v /data/jira/logs:/opt/atlassian/jira/logs \\</span><br><span class=\"line\">  cptactionhank/atlassian-jira</span><br></pre></td></tr></table></figure></p>\n<p>atlassian-agent.jar是破解包，详情请见<a href=\"https://gitee.com/pengzhile/atlassian-agent\" target=\"_blank\" rel=\"noopener\">https://gitee.com/pengzhile/atlassian-agent</a></p>\n<p>Kubelete方式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: test-jira.production-business-jira</span><br><span class=\"line\">  name: test-jira-atlassian-jira</span><br><span class=\"line\">  namespace: production-business-jira</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /apis/extensions/v1beta1/namespaces/production-business-jira/deployments/test-jira-atlassian-jira</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  progressDeadlineSeconds: 600</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  revisionHistoryLimit: 10</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app.test.io/name: test-jira.production-business-jira</span><br><span class=\"line\">      project.test.io/name: production-business</span><br><span class=\"line\">      service.test.io/name: deployment-test-jira-atlassian-jira</span><br><span class=\"line\">  strategy:</span><br><span class=\"line\">    rollingUpdate:</span><br><span class=\"line\">      maxSurge: 25%</span><br><span class=\"line\">      maxUnavailable: 25%</span><br><span class=\"line\">    type: RollingUpdate</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      creationTimestamp: null</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: deployment-test-jira-atlassian-jira</span><br><span class=\"line\">        app.test.io/name: test-jira.production-business-jira</span><br><span class=\"line\">        project.test.io/name: production-business</span><br><span class=\"line\">        service.test.io/name: deployment-test-jira-atlassian-jira</span><br><span class=\"line\">        version: v1</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">        - env:</span><br><span class=\"line\">            - name: JAVA_OPTS</span><br><span class=\"line\">              value: &apos;-javaagent:/opt/atlassian-agent.jar&apos;</span><br><span class=\"line\">          image: &apos;cptactionhank/atlassian-jira&apos;</span><br><span class=\"line\">          imagePullPolicy: IfNotPresent</span><br><span class=\"line\">          name: atlassian-jira</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            limits:</span><br><span class=\"line\">              cpu: &apos;8&apos;</span><br><span class=\"line\">              memory: 16Gi</span><br><span class=\"line\">          terminationMessagePath: /dev/termination-log</span><br><span class=\"line\">          terminationMessagePolicy: File</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">            - mountPath: /var/atlassian/jira</span><br><span class=\"line\">              name: new-volume</span><br><span class=\"line\">            - mountPath: /opt/atlassian/jira/logs</span><br><span class=\"line\">              name: new-volume1</span><br><span class=\"line\">      dnsPolicy: ClusterFirst</span><br><span class=\"line\">      nodeSelector:</span><br><span class=\"line\">        kubernetes.io/hostname: slave-4</span><br><span class=\"line\">      restartPolicy: Always</span><br><span class=\"line\">      schedulerName: default-scheduler</span><br><span class=\"line\">      securityContext: &#123;&#125;</span><br><span class=\"line\">      terminationGracePeriodSeconds: 30</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">        - operator: Exists</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">        - hostPath:</span><br><span class=\"line\">            path: /data/jira/data</span><br><span class=\"line\">            type: &apos;&apos;</span><br><span class=\"line\">          name: new-volume</span><br><span class=\"line\">        - hostPath:</span><br><span class=\"line\">            path: /data/jira/logs</span><br><span class=\"line\">            type: &apos;&apos;</span><br><span class=\"line\">          name: new-volume1</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: test-jira.production-business-jira</span><br><span class=\"line\">  name: test-jira-atlassian-jira</span><br><span class=\"line\">  namespace: production-business-jira</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /api/v1/namespaces/production-business-jira/services/test-jira-atlassian-jira</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">    - name: tcp-8080-8080</span><br><span class=\"line\">      port: 8080</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 8080</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app.test.io/name: test-jira.production-business-jira</span><br><span class=\"line\">    service.test.io/name: deployment-test-jira-atlassian-jira</span><br><span class=\"line\">  sessionAffinity: None</span><br><span class=\"line\">  type: ClusterIP</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"登录Jira开始对Jira进行初始化\"><a href=\"#登录Jira开始对Jira进行初始化\" class=\"headerlink\" title=\"登录Jira开始对Jira进行初始化\"></a>登录Jira开始对Jira进行初始化</h4><p>1.选择I’ll set it up myself     Next<br>2.选择My Own Database (recommended for production environments)</p>\n<blockquote>\n<p>Database Type:   MySQL 5.6<br>Hostname: mysql-jira-mysql<br>Port: 3306<br>Database: jiradb<br>Username: jira<br>Password: jira</p>\n</blockquote>\n<p>选择Test Connection，测试链接成功后点击  Next  然后等待数据库初始化完成<br>3.填写jira项目信息</p>\n<blockquote>\n<p>Application Title: jiar<br>Mode:Private<br>Base URL:<a href=\"http://192.168.8.27:8081\" target=\"_blank\" rel=\"noopener\">http://192.168.8.27:8081</a></p>\n</blockquote>\n<p>4.破解Jira<br>复制Server ID内容<br>然后进入jira容器内</p>\n<blockquote>\n<p>docker exec -it jira bash<br> cd /opt/<br> ls<br> <code>bash-4.4$ ls\natlassian            atlassian-agent.jar</code><br>java -jar atlassian-agent.jar -p jira -m <a href=\"mailto:aaa@bbb.com\" target=\"_blank\" rel=\"noopener\">aaa@bbb.com</a> -n my_name -o <a href=\"http://datura.top\">http://datura.top</a> -s XXXXXX<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">====================================================</span><br><span class=\"line\">=======        Atlassian Crack Agent         =======</span><br><span class=\"line\">=======           https://zhile.io           =======</span><br><span class=\"line\">=======          QQ Group: 30347511          =======</span><br><span class=\"line\">====================================================</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;Your license code(Don&apos;t copy this line!!!):</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;AAABjQ0ODAoPeJx9klFr2zAUhd/1Kwx7tmuFpXEDgm222TzsJNRpHvYyrp2bRsOWxZWcNvv1lRsX0</span><br><span class=\"line\">&gt;jYEBEJC59xP594v6x69ErXHZ14Yzfl0ziPvZ7H2JiG/Y4+EqPad1khBLmtUBtdHjQtoUcTLokjv4</span><br><span class=\"line\">&gt;+x7zmJCsLJTCVgUg9AP73w+Y1ckCZqapB5U4kE1spUWt15zEnjV0dtbq8385ub/XjYYyI4VIJVFB</span><br><span class=\"line\">&gt;arG9FlLOo7VIldt5hb7JwneKNOtPFkv8qzI1mnCFn1bIS13DwbJCJ+/wV3x0tRt+9oGw8E33c4+A</span><br><span class=\"line\">&gt;WHwyejKW6itPKCw1OO7LM/vxz9vnNtAPGHpAZr+NU+xg8YgW9IjKGlOV0MuLpYt2N6VtZ1mcaesM</span><br><span class=\"line\">&gt;0xdQI0AgG9VVQV1157ALuOeA1zhLy2QRRo5xsSyRORZUqYLP+fT22gWRpxH0+nkXQMu9bxEOiA5+</span><br><span class=\"line\">&gt;Y/4a+yv/mx++2m+ufV/rcrw0qh9buKqp3oPBj8O2rkY3ZSQJmnG7zlQcQF2TO2VsT3+VW5/AS2KC</span><br><span class=\"line\">&gt; fkwLAIUYgOdQfGYSq/19VKXo54j+OohnFoCFDNIF/aherXDRLivmm2xF3bE8S47X02j7</span><br></pre></td></tr></table></figure></p>\n</blockquote>\n<p>Server ID：XXXXXXX<br>Your License Key:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AAABjQ0ODAoPeJx9klFr2zAUhd/1Kwx7tmuFpXEDgm222TzsJNRpHvYyrp2bRsOWxZWcNvv1lRsX0</span><br><span class=\"line\">jYEBEJC59xP594v6x69ErXHZ14Yzfl0ziPvZ7H2JiG/Y4+EqPad1khBLmtUBtdHjQtoUcTLokjv4</span><br><span class=\"line\">+x7zmJCsLJTCVgUg9AP73w+Y1ckCZqapB5U4kE1spUWt15zEnjV0dtbq8385ub/XjYYyI4VIJVFB</span><br><span class=\"line\">arG9FlLOo7VIldt5hb7JwneKNOtPFkv8qzI1mnCFn1bIS13DwbJCJ+/wV3x0tRt+9oGw8E33c4+A</span><br><span class=\"line\">WHwyejKW6itPKCw1OO7LM/vxz9vnNtAPGHpAZr+NU+xg8YgW9IjKGlOV0MuLpYt2N6VtZ1mcaesM</span><br><span class=\"line\">0xdQI0AgG9VVQV1157ALuOeA1zhLy2QRRo5xsSyRORZUqYLP+fT22gWRpxH0+nkXQMu9bxEOiA5+</span><br><span class=\"line\">Y/4a+yv/mx++2m+ufV/rcrw0qh9buKqp3oPBj8O2rkY3ZSQJmnG7zlQcQF2TO2VsT3+VW5/AS2KC</span><br><span class=\"line\">fkwLAIUYgOdQfGYSq/19VKXo54j+OohnFoCFDNIF/aherXDRLivmm2xF3bE8S47X02j7</span><br></pre></td></tr></table></figure></p>\n<p>等待初始化Jira</p>\n<p>5.创建Jira用户信息</p>\n<blockquote>\n<p>Full name ：jiraadmin<br>Email Address :<a href=\"mailto:jiraadmin@123.com\" target=\"_blank\" rel=\"noopener\">jiraadmin@123.com</a><br>Username: jiraadmin<br>Password: jiraadmin<br>Confirm Password : jiraadmin<br>选择 Next<br>Configure Email Notifications ：Later<br>选择 Finish<br>选择语言<br>之后创建Jira项目</p>\n</blockquote>\n<p>6.恢复Jira数据<br>将备份的zip包拷贝到新的Jira目录中，目录位置为<br><code>/var/atlassian/jira/import</code><br>返回jira页面，Setting&gt;System&gt;Restore system<br>将备份包信息填写到相应位置，License输入上面的key信息<br>然后点击Restore<br>等待数据恢复，数据恢复后回到命令行<br>将老Jira<code>/var/atlassian/jira/data/attachments</code>  的目录拷贝到本机的/data/jira/data/data/attachments目录中<br>拷贝完成后重启Jira容器<br>重启完成后，此时将可以使用老Jira的用户登录新Jira，到此Jira迁移完成。</p>\n<h2 id=\"Confluence-迁移简介\"><a href=\"#Confluence-迁移简介\" class=\"headerlink\" title=\"Confluence 迁移简介\"></a>Confluence 迁移简介</h2><h3 id=\"备份老Confluence数据\"><a href=\"#备份老Confluence数据\" class=\"headerlink\" title=\"备份老Confluence数据\"></a>备份老Confluence数据</h3><p>登录Confluence，Setting&gt;General Configuration&gt;Backup &amp; Restore<br>选择Include attachments然后导出或者直接使用Confluence每日自动备份的zip包进行恢复，我这里使用的是每日自动备份的zip包进行恢复的<br>包路径为<code>$CONFLUENCE_HOME/backups</code><br>将zip包拷贝到新的Confluence机器上</p>\n<h3 id=\"启动Confluence和Mysql\"><a href=\"#启动Confluence和Mysql\" class=\"headerlink\" title=\"启动Confluence和Mysql\"></a>启动Confluence和Mysql</h3><p>mysql配置文件my.cnf<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[client]</span><br><span class=\"line\">port            = 3306</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\">socket          = /var/run/mysqld/mysqld.sock</span><br><span class=\"line\"></span><br><span class=\"line\">[mysql]</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld_safe]</span><br><span class=\"line\">pid-file        = /var/run/mysqld/mysqld.pid</span><br><span class=\"line\">socket          = /var/run/mysqld/mysqld.sock</span><br><span class=\"line\">nice            = 0</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld]</span><br><span class=\"line\">skip-host-cache</span><br><span class=\"line\">skip-name-resolve</span><br><span class=\"line\">user            = mysql</span><br><span class=\"line\">pid-file        = /var/run/mysqld/mysqld.pid</span><br><span class=\"line\">socket          = /var/run/mysqld/mysqld.sock</span><br><span class=\"line\">port            = 3306</span><br><span class=\"line\">basedir         = /usr</span><br><span class=\"line\">datadir         = /var/lib/mysql</span><br><span class=\"line\">tmpdir          = /tmp</span><br><span class=\"line\">lc-messages-dir = /usr/share/mysql</span><br><span class=\"line\">explicit_defaults_for_timestamp</span><br><span class=\"line\">character-set-server=utf8</span><br><span class=\"line\">default-storage-engine=INNODB</span><br><span class=\"line\">max_allowed_packet=256M</span><br><span class=\"line\">innodb_log_file_size=256M</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#sql_mode = NO_AUTO_VALUE_ON_ZERO</span><br><span class=\"line\">sql_mode = &quot;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">symbolic-links=0</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld.safe]</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\">[mysql.server]</span><br><span class=\"line\">default-character-set=utf8</span><br><span class=\"line\"></span><br><span class=\"line\">#</span><br><span class=\"line\">!includedir /etc/mysql/conf.d/</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"启动mysql有两种方法，一种是docker-run-一种是使用Kubelete启动\"><a href=\"#启动mysql有两种方法，一种是docker-run-一种是使用Kubelete启动\" class=\"headerlink\" title=\"启动mysql有两种方法，一种是docker run 一种是使用Kubelete启动\"></a>启动mysql有两种方法，一种是docker run 一种是使用Kubelete启动</h3><p>docker run方式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d --restart=always --name mysql \\</span><br><span class=\"line\">  -e MYSQL_ROOT_PASSWORD=root \\</span><br><span class=\"line\">  -e MYSQL_USER=confluence \\</span><br><span class=\"line\">  -e MYSQL_PASSWORD=confluence \\</span><br><span class=\"line\">  -e MYSQL_DATABASE=confluencedb \\  </span><br><span class=\"line\">  -v /data/mysql/data:/var/lib/mysql \\</span><br><span class=\"line\">  -v /data/mysql/config/my.cnf:/etc/mysql/my.cnf \\</span><br><span class=\"line\">  -p 3306:3306 \\</span><br><span class=\"line\">  mysql:5.6</span><br></pre></td></tr></table></figure></p>\n<p>Kubelete方式启动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  generation: 26</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: test-mysql-confluence.production-business-confluence</span><br><span class=\"line\">  name: test-mysql-confluence-mysql-confluence</span><br><span class=\"line\">  namespace: production-business-confluence</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /apis/extensions/v1beta1/namespaces/production-business-confluence/deployments/test-mysql-confluence-mysql-confluence</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  progressDeadlineSeconds: 600</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  revisionHistoryLimit: 10</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app.test.io/name: test-mysql-confluence.production-business-confluence</span><br><span class=\"line\">      project.test.io/name: production-business</span><br><span class=\"line\">      service.test.io/name: deployment-test-mysql-confluence-mysql-confluence</span><br><span class=\"line\">  strategy:</span><br><span class=\"line\">    rollingUpdate:</span><br><span class=\"line\">      maxSurge: 25%</span><br><span class=\"line\">      maxUnavailable: 25%</span><br><span class=\"line\">    type: RollingUpdate</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      creationTimestamp: null</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: deployment-test-mysql-confluence-mysql-confluence</span><br><span class=\"line\">        app.test.io/name: test-mysql-confluence.production-business-confluence</span><br><span class=\"line\">        project.test.io/name: production-business</span><br><span class=\"line\">        service.test.io/name: deployment-test-mysql-confluence-mysql-confluence</span><br><span class=\"line\">        version: v1</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">        - env:</span><br><span class=\"line\">            - name: MYSQL_USER</span><br><span class=\"line\">              value: confluence</span><br><span class=\"line\">            - name: MYSQL_PASSWORD</span><br><span class=\"line\">              value: confluence</span><br><span class=\"line\">            - name: MYSQL_DATABASE</span><br><span class=\"line\">              value: confluencedb</span><br><span class=\"line\">            - name: MYSQL_ROOT_PASSWORD</span><br><span class=\"line\">              value: root</span><br><span class=\"line\">          image: &apos;mysql:5.6&apos;</span><br><span class=\"line\">          imagePullPolicy: IfNotPresent</span><br><span class=\"line\">          name: mysql-confluence</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            limits:</span><br><span class=\"line\">              cpu: &apos;2&apos;</span><br><span class=\"line\">              memory: 4Gi</span><br><span class=\"line\">          terminationMessagePath: /dev/termination-log</span><br><span class=\"line\">          terminationMessagePolicy: File</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">            - mountPath: /var/lib/mysql</span><br><span class=\"line\">              name: mysql-data</span><br><span class=\"line\">            - mountPath: /etc/mysql/my.cnf</span><br><span class=\"line\">              name: new-volume</span><br><span class=\"line\">              readOnly: true</span><br><span class=\"line\">              subPath: my.cnf</span><br><span class=\"line\">      dnsPolicy: ClusterFirst</span><br><span class=\"line\">      nodeSelector:</span><br><span class=\"line\">        kubernetes.io/hostname: slave-2</span><br><span class=\"line\">      restartPolicy: Always</span><br><span class=\"line\">      schedulerName: default-scheduler</span><br><span class=\"line\">      securityContext: &#123;&#125;</span><br><span class=\"line\">      terminationGracePeriodSeconds: 30</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">        - operator: Exists</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">        - hostPath:</span><br><span class=\"line\">            path: /data/mysql/data</span><br><span class=\"line\">            type: &apos;&apos;</span><br><span class=\"line\">          name: mysql-data</span><br><span class=\"line\">        - configMap:</span><br><span class=\"line\">            defaultMode: 420</span><br><span class=\"line\">            items:</span><br><span class=\"line\">              - key: my.cnf</span><br><span class=\"line\">                path: my.cnf</span><br><span class=\"line\">            name: confluence-mysql</span><br><span class=\"line\">          name: new-volume</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: test-mysql-confluence.production-business-confluence</span><br><span class=\"line\">  name: test-mysql-confluence</span><br><span class=\"line\">  namespace: production-business-confluence</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /api/v1/namespaces/production-business-confluence/services/test-mysql-confluence</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">    - name: tcp-3306-3306</span><br><span class=\"line\">      port: 3306</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 3306</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app.test.io/name: test-mysql-confluence.production-business-confluence</span><br><span class=\"line\">    service.test.io/name: deployment-test-mysql-confluence-mysql-confluence</span><br><span class=\"line\">  sessionAffinity: ClientIP</span><br><span class=\"line\">  sessionAffinityConfig:</span><br><span class=\"line\">    clientIP:</span><br><span class=\"line\">      timeoutSeconds: 10800</span><br><span class=\"line\">  type: ClusterIP</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"启动Confluence\"><a href=\"#启动Confluence\" class=\"headerlink\" title=\"启动Confluence\"></a>启动Confluence</h3><p>Confluence启动也是分为两种，一种是docker run另外一种是Kubelete方式启动<br>docker run方式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d --restart=always --name confluence -p 8090:8090 \\</span><br><span class=\"line\">  -e JVM_MAXIMUM_MEMORY=8196m \\</span><br><span class=\"line\">  -e JAVA_OPTS=&quot;-javaagent:/opt/atlassian-agent.jar&quot; \\</span><br><span class=\"line\">  -v /data/confluence/data:/var/atlassian/application-data/confluence \\</span><br><span class=\"line\">  -v /root/atlassian-agent.jar:/opt/atlassian-agent.jar \\</span><br><span class=\"line\">  -v /data/confluence/logs:/opt/atlassian/confluence/logs \\</span><br><span class=\"line\">docker.io/atlassian/confluence-server</span><br></pre></td></tr></table></figure></p>\n<p>Kubelete方式启动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: extensions/v1beta1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: confluence.production-business-confluence</span><br><span class=\"line\">  name: confluence-confluence</span><br><span class=\"line\">  namespace: production-business-confluence</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /apis/extensions/v1beta1/namespaces/production-business-confluence/deployments/confluence-confluence</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  progressDeadlineSeconds: 600</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  revisionHistoryLimit: 10</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app.test.io/name: confluence.production-business-confluence</span><br><span class=\"line\">      project.test.io/name: production-business</span><br><span class=\"line\">      service.test.io/name: deployment-confluence-confluence</span><br><span class=\"line\">  strategy:</span><br><span class=\"line\">    rollingUpdate:</span><br><span class=\"line\">      maxSurge: 25%</span><br><span class=\"line\">      maxUnavailable: 25%</span><br><span class=\"line\">    type: RollingUpdate</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      creationTimestamp: null</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: deployment-confluence-confluence</span><br><span class=\"line\">        app.test.io/name: confluence.production-business-confluence</span><br><span class=\"line\">        project.test.io/name: production-business</span><br><span class=\"line\">        service.test.io/name: deployment-confluence-confluence</span><br><span class=\"line\">        version: v1</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">        - env:</span><br><span class=\"line\">            - name: JAVA_OPTS</span><br><span class=\"line\">              value: &apos;-javaagent:/opt/atlassian-agent.jar&apos;</span><br><span class=\"line\">          image: &apos;docker.io/atlassian/confluence-server&apos;</span><br><span class=\"line\">          imagePullPolicy: IfNotPresent</span><br><span class=\"line\">          name: confluence</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            limits:</span><br><span class=\"line\">              cpu: &apos;4&apos;</span><br><span class=\"line\">              memory: 16Gi</span><br><span class=\"line\">          terminationMessagePath: /dev/termination-log</span><br><span class=\"line\">          terminationMessagePolicy: File</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">            - mountPath: /var/atlassian/application-data/confluence</span><br><span class=\"line\">              name: confluence-data</span><br><span class=\"line\">            - mountPath: /opt/atlassian/confluence/logs</span><br><span class=\"line\">              name: confluence-log</span><br><span class=\"line\">      dnsPolicy: ClusterFirst</span><br><span class=\"line\">      nodeSelector:</span><br><span class=\"line\">        kubernetes.io/hostname: slave-2</span><br><span class=\"line\">      restartPolicy: Always</span><br><span class=\"line\">      schedulerName: default-scheduler</span><br><span class=\"line\">      securityContext: &#123;&#125;</span><br><span class=\"line\">      terminationGracePeriodSeconds: 30</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">        - operator: Exists</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">        - hostPath:</span><br><span class=\"line\">            path: /data/confluence/data</span><br><span class=\"line\">            type: &apos;&apos;</span><br><span class=\"line\">          name: confluence-data</span><br><span class=\"line\">        - hostPath:</span><br><span class=\"line\">            path: /data/confluence/logs</span><br><span class=\"line\">            type: &apos;&apos;</span><br><span class=\"line\">          name: confluence-log</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.test.io/name: confluence.production-business-confluence</span><br><span class=\"line\">  name: confluence-confluence</span><br><span class=\"line\">  namespace: production-business-confluence</span><br><span class=\"line\">  selfLink: &gt;-</span><br><span class=\"line\">    /api/v1/namespaces/production-business-confluence/services/confluence-confluence</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">    - name: tcp-8090-8090</span><br><span class=\"line\">      port: 8090</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 8090</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app.test.io/name: confluence.production-business-confluence</span><br><span class=\"line\">    service.test.io/name: deployment-confluence-confluence</span><br><span class=\"line\">  sessionAffinity: ClientIP</span><br><span class=\"line\">  sessionAffinityConfig:</span><br><span class=\"line\">    clientIP:</span><br><span class=\"line\">      timeoutSeconds: 10800</span><br><span class=\"line\">  type: ClusterIP</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"登录Confluence开始对Confluence进行初始化\"><a href=\"#登录Confluence开始对Confluence进行初始化\" class=\"headerlink\" title=\"登录Confluence开始对Confluence进行初始化\"></a>登录Confluence开始对Confluence进行初始化</h4><p>选择Confluence Team Calendars<br>复制Server ID<br>登录Confluence机器中的Confluence容器内</p>\n<blockquote>\n<p>docker exec -it confluence bash<br> cd /opt/<br> ls<br> <code>bash-4.4$ ls\natlassian            atlassian-agent.jar</code><br>java -jar atlassian-agent.jar -p conf -m <a href=\"mailto:aaa@bbb.com\" target=\"_blank\" rel=\"noopener\">aaa@bbb.com</a> -n my_name -o <a href=\"http://datura.top\">http://datura.top</a> -s XXXXXX<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">====================================================</span><br><span class=\"line\">=======        Atlassian Crack Agent         =======</span><br><span class=\"line\">=======           https://zhile.io           =======</span><br><span class=\"line\">=======          QQ Group: 30347511          =======</span><br><span class=\"line\">====================================================</span><br><span class=\"line\">Your license code(Don&apos;t copy this line!!!):</span><br><span class=\"line\">AAABQQ0ODAoPeJxtUNFOgzAUfe9XNPEZXDc3xpImTkCdgWFkm76ZC7tzTaCQtizOr7cDfDFLmjQ9p</span><br><span class=\"line\">/fcc87NpkWaYUOZR0f+YjJfTDz6lGzoeMR8EigEI2oZgkF+QZyR7zCPRCco247hByg1khB1oUTTI</span><br><span class=\"line\">VtZikoY3NNSFCg10vxMj8Y0enF7+3MUJbqiJqn6Ail0L3JhLbkH0ypwTd2QopYHFwojTsiNapEEt</span><br><span class=\"line\">TT2HSUgSg4A93meu0Vd9T8zA8qgGtx0UNwv35wbXEOFPEiTJHoLVsuYWA1pUIIsMPpuhDoP+eY2n</span><br><span class=\"line\">2cPGWZXIY9XYRatnZhNZ3OPTRjzpnczkqE6obL0w/vOc7wPljqP/vLFmYXPyd/wdeXXVhVH0Pi/0</span><br><span class=\"line\">aGqHSp9KWTcZ1i3VY4qPWy1xbnDiPXCr/gZyulyVudPae9f57CZMDAsAhRpli3TWhHdAL0fOkAeh</span><br><span class=\"line\">38ZCSuf+QIUfBreVMIH4k/6isdn0HptYXvU608=X02g0</span><br></pre></td></tr></table></figure></p>\n</blockquote>\n<p>Server ID： XXXXX<br>Confluence：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AAABQQ0ODAoPeJxtUNFOgzAUfe9XNPEZXDc3xpImTkCdgWFkm76ZC7tzTaCQtizOr7cDfDFLmjQ9p</span><br><span class=\"line\">/fcc87NpkWaYUOZR0f+YjJfTDz6lGzoeMR8EigEI2oZgkF+QZyR7zCPRCco247hByg1khB1oUTTI</span><br><span class=\"line\">VtZikoY3NNSFCg10vxMj8Y0enF7+3MUJbqiJqn6Ail0L3JhLbkH0ypwTd2QopYHFwojTsiNapEEt</span><br><span class=\"line\">TT2HSUgSg4A93meu0Vd9T8zA8qgGtx0UNwv35wbXEOFPEiTJHoLVsuYWA1pUIIsMPpuhDoP+eY2n</span><br><span class=\"line\">2cPGWZXIY9XYRatnZhNZ3OPTRjzpnczkqE6obL0w/vOc7wPljqP/vLFmYXPyd/wdeXXVhVH0Pi/0</span><br><span class=\"line\">aGqHSp9KWTcZ1i3VY4qPWy1xbnDiPXCr/gZyulyVudPae9f57CZMDAsAhRpli3TWhHdAL0fOkAeh</span><br><span class=\"line\">38ZCSuf+QIUfBreVMIH4k/6isdn0HptYXvU608=X02g0</span><br></pre></td></tr></table></figure></p>\n<p>选择My own database</p>\n<blockquote>\n<p>Database type: MySQL<br>Setup type: Simple<br>Hostname: mysql-confluence<br>PortThis: 3306<br>Database name: confluencedb<br>Username: confluence<br>Password: confluence</p>\n</blockquote>\n<p>点击Test connection 后可能会出现<br><code>Collation error\nThe database collation &#39;utf8_general_ci&#39; is not supported by Confluence. You need to use &#39;utf8_bin&#39;.</code><br>错误<br>进入mysql容器</p>\n<blockquote>\n<p>docker exec -it mysql bash<br>mysql -uroot -proot<br><code>alter database confluencedb character set utf8 COLLATE utf8_bin;\nSET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED;</code></p>\n</blockquote>\n<p>然后在点击Test connection，提示Success! Database connected successfully.<br>然后点击Next 等待数据库初始化<br>然后选择Restore From Backup<br>将备份的包拷贝到本机的 <code>/data/confluence/data/restore/</code> 目录下<br>此时页面上就会有相应的包，选择之后点击import后，等待导入完数据，此时Confluence迁移完成</p>"},{"title":"keepalive+nginx实现高可用","date":"2016-09-02T04:00:00.000Z","_content":"1安装相应基础服务\n\n    yum install openssl-devel\n    yum install popt-devel\n2下载并安装keepalive安装包\n    wget http://www.keepalived.org/software/keepalived-1.2.12.tar.gz\n    tar xzf keepalived-1.2.12.tar.gz;\n    cd keepalived-1.2.12\n    ./configure –prefix=/usr/local/keepalived-1.2.12;\n    make && make install\n<!--more-->\n3制作keepalive服务\n    cp /usr/local/keepalived-1.2.12/etc/rc.d/init.d/keepalived /etc/init.d/\n    cp /usr/local/keepalived-1.2.12/etc/sysconfig/keepalived /etc/sysconfig/\n    chmod +x /etc/init.d/keepalived;\n    chkconfig –add keepalived;\n    mkdir -p /etc/keepalived\n    ln -s /usr/local/keepalived-1.2.12/sbin/keepalived /usr/sbin/\n    cp /usr/local/keepalived-1.2.12/etc/keepalived/keepalived.conf /etc/keepalived/\n    ln -s /usr/local/keepalived-1.2.12/sbin/keepalived /sbin/\n    service keepalived restart\n4更改keepalive的配置文件\n    vim /etc/keepalived/keepalived.conf\n    keepalive主\n    ! Configuration File for keepalived\n    \n    global_defs {\n    \n       router_id nginx_master\n    \n    }\n    \n    #监控服务.NGINX mysql等\n    \n    vrrp_script chk_nginx {\n    \n    script “/usr/local/nginx/check_nginx.sh”\n    \n    interval 2\n    \n    weight 2\n    \n    }\n    \n    vrrp_instance VI_1 {\n    \n    state MASTER\n    \n    interface eth0\n    \n    virtual_router_id 51   #通道\n    \n    priority 101#优先级，数值越高优先级越高\n    \n    advert_int 1\n    \n    authentication {\n    \n    auth_type PASS\n    \n    auth_pass 1111\n    \n    }\n    \n    virtual_ipaddress {\n    \n    192.168.1.254   #虚拟IP\n    \n    }\n    \n    track_script {\n    \n    chk_nginx  #检测脚本 上面配置的\n    \n    }\n\n \n\nkeepalive从\n\n    ! Configuration File for keepalived\n     \n    global_defs {\n       router_id nginx_backup\n    }\n    #监控服务.NGINX mysql等\n    vrrp_script chk_nginx {\n    script “/usr/local/nginx/check_nginx.sh”\n    interval 2\n    weight 2\n    }\n     \n    vrrp_instance VI_1 {\n    state BACKUP\n    interface eth0\n    virtual_router_id 51#通道\n    priority 99#优先级，数值越高优先级越高\n    advert_int 1\n    authentication {\n    auth_type PASS\n    auth_pass 1111\n    }\n    virtual_ipaddress {\n    192.168.1.254   #虚拟IP\n    }\n    track_script {\n    chk_nginx  #检测脚本 上面配置的\n    }\n    }\n5脚本/usr/local/nginx/check_nginx.sh”内容：\n    #!/bin/bash\n    \n    if [ “$(ps -ef | grep “nginx: master process“| grep -v grep )” == “” ]\n    \n    then\n    \n    /usr/local/nginx/sbin/nginx\n    \n    sleep 5\n    \n    if [ “$(ps -ef | grep “nginx: master process“| grep -v grep )” == “” ]\n    \n    then\n    \n    killall keepalived\n    \n    fi\n    \n    fi\n\n6编写keepalive和nginx共存脚本\n\n    vim /data/apps/jiance.sh\n    \n    #!/bin/bash\n    while :\n    do\n    nginxpid=`ps -C nginx –no-header |wc -l`\n    if [ $nginxpid -eq 0 ];then\n       /etc/init.d/nginx restart\n      sleep 5\n    nginxpid=`ps -C nginx –no-header |wc -l`\n      if [ $nginxpid -eq 0 ];then\n      /etc/init.d/keepalived stop\n      fi\n    fi\n    sleep 5\n    done\n    }\n7把该脚本制作成系统服务并且开机启动\n    chmod 755 /data/apps/jiance.sh\n    vim /etc/init.d/jiance\n    #!/bin/bash\n    # chkconfig: 2345 10 90\n    # description: jiance ….\n    start() {\n    echo “Starting my process “\n    cd /data/apps/\n    ./jiance.sh\n    }\n    stop() {\n    killall jiance.sh\n    echo “Stoped”\n    }\n    chmod a+wrx /etc/init.d/jiance\n    /etc/init.d/jiance start\n    chmod +x jiance   #增加执行权限\n    chkconfig –add jiance #把jiance添加到系统服务列表\n    chkconfig jiance on #设定jiance的开关（on/off）\n    chkconfig –list jiance   #就可以看到已经注册了jiance的服务\n完成如上步骤keepalive+nginx高可用即搭建完成。\n","source":"_posts/keepalive+nginx实现高可用.md","raw":"---\ntitle: keepalive+nginx实现高可用\ndate: 2016-09-02\ntags: nginx\ncategories: nginx\n---\n1安装相应基础服务\n\n    yum install openssl-devel\n    yum install popt-devel\n2下载并安装keepalive安装包\n    wget http://www.keepalived.org/software/keepalived-1.2.12.tar.gz\n    tar xzf keepalived-1.2.12.tar.gz;\n    cd keepalived-1.2.12\n    ./configure –prefix=/usr/local/keepalived-1.2.12;\n    make && make install\n<!--more-->\n3制作keepalive服务\n    cp /usr/local/keepalived-1.2.12/etc/rc.d/init.d/keepalived /etc/init.d/\n    cp /usr/local/keepalived-1.2.12/etc/sysconfig/keepalived /etc/sysconfig/\n    chmod +x /etc/init.d/keepalived;\n    chkconfig –add keepalived;\n    mkdir -p /etc/keepalived\n    ln -s /usr/local/keepalived-1.2.12/sbin/keepalived /usr/sbin/\n    cp /usr/local/keepalived-1.2.12/etc/keepalived/keepalived.conf /etc/keepalived/\n    ln -s /usr/local/keepalived-1.2.12/sbin/keepalived /sbin/\n    service keepalived restart\n4更改keepalive的配置文件\n    vim /etc/keepalived/keepalived.conf\n    keepalive主\n    ! Configuration File for keepalived\n    \n    global_defs {\n    \n       router_id nginx_master\n    \n    }\n    \n    #监控服务.NGINX mysql等\n    \n    vrrp_script chk_nginx {\n    \n    script “/usr/local/nginx/check_nginx.sh”\n    \n    interval 2\n    \n    weight 2\n    \n    }\n    \n    vrrp_instance VI_1 {\n    \n    state MASTER\n    \n    interface eth0\n    \n    virtual_router_id 51   #通道\n    \n    priority 101#优先级，数值越高优先级越高\n    \n    advert_int 1\n    \n    authentication {\n    \n    auth_type PASS\n    \n    auth_pass 1111\n    \n    }\n    \n    virtual_ipaddress {\n    \n    192.168.1.254   #虚拟IP\n    \n    }\n    \n    track_script {\n    \n    chk_nginx  #检测脚本 上面配置的\n    \n    }\n\n \n\nkeepalive从\n\n    ! Configuration File for keepalived\n     \n    global_defs {\n       router_id nginx_backup\n    }\n    #监控服务.NGINX mysql等\n    vrrp_script chk_nginx {\n    script “/usr/local/nginx/check_nginx.sh”\n    interval 2\n    weight 2\n    }\n     \n    vrrp_instance VI_1 {\n    state BACKUP\n    interface eth0\n    virtual_router_id 51#通道\n    priority 99#优先级，数值越高优先级越高\n    advert_int 1\n    authentication {\n    auth_type PASS\n    auth_pass 1111\n    }\n    virtual_ipaddress {\n    192.168.1.254   #虚拟IP\n    }\n    track_script {\n    chk_nginx  #检测脚本 上面配置的\n    }\n    }\n5脚本/usr/local/nginx/check_nginx.sh”内容：\n    #!/bin/bash\n    \n    if [ “$(ps -ef | grep “nginx: master process“| grep -v grep )” == “” ]\n    \n    then\n    \n    /usr/local/nginx/sbin/nginx\n    \n    sleep 5\n    \n    if [ “$(ps -ef | grep “nginx: master process“| grep -v grep )” == “” ]\n    \n    then\n    \n    killall keepalived\n    \n    fi\n    \n    fi\n\n6编写keepalive和nginx共存脚本\n\n    vim /data/apps/jiance.sh\n    \n    #!/bin/bash\n    while :\n    do\n    nginxpid=`ps -C nginx –no-header |wc -l`\n    if [ $nginxpid -eq 0 ];then\n       /etc/init.d/nginx restart\n      sleep 5\n    nginxpid=`ps -C nginx –no-header |wc -l`\n      if [ $nginxpid -eq 0 ];then\n      /etc/init.d/keepalived stop\n      fi\n    fi\n    sleep 5\n    done\n    }\n7把该脚本制作成系统服务并且开机启动\n    chmod 755 /data/apps/jiance.sh\n    vim /etc/init.d/jiance\n    #!/bin/bash\n    # chkconfig: 2345 10 90\n    # description: jiance ….\n    start() {\n    echo “Starting my process “\n    cd /data/apps/\n    ./jiance.sh\n    }\n    stop() {\n    killall jiance.sh\n    echo “Stoped”\n    }\n    chmod a+wrx /etc/init.d/jiance\n    /etc/init.d/jiance start\n    chmod +x jiance   #增加执行权限\n    chkconfig –add jiance #把jiance添加到系统服务列表\n    chkconfig jiance on #设定jiance的开关（on/off）\n    chkconfig –list jiance   #就可以看到已经注册了jiance的服务\n完成如上步骤keepalive+nginx高可用即搭建完成。\n","slug":"keepalive+nginx实现高可用","published":1,"updated":"2019-06-18T08:07:01.114Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sjz000thcb7jvik8ieh","content":"<p>1安装相应基础服务</p>\n<pre><code>yum install openssl-devel\nyum install popt-devel\n</code></pre><p>2下载并安装keepalive安装包<br>    wget <a href=\"http://www.keepalived.org/software/keepalived-1.2.12.tar.gz\" target=\"_blank\" rel=\"noopener\">http://www.keepalived.org/software/keepalived-1.2.12.tar.gz</a><br>    tar xzf keepalived-1.2.12.tar.gz;<br>    cd keepalived-1.2.12<br>    ./configure –prefix=/usr/local/keepalived-1.2.12;<br>    make &amp;&amp; make install<br><a id=\"more\"></a><br>3制作keepalive服务<br>    cp /usr/local/keepalived-1.2.12/etc/rc.d/init.d/keepalived /etc/init.d/<br>    cp /usr/local/keepalived-1.2.12/etc/sysconfig/keepalived /etc/sysconfig/<br>    chmod +x /etc/init.d/keepalived;<br>    chkconfig –add keepalived;<br>    mkdir -p /etc/keepalived<br>    ln -s /usr/local/keepalived-1.2.12/sbin/keepalived /usr/sbin/<br>    cp /usr/local/keepalived-1.2.12/etc/keepalived/keepalived.conf /etc/keepalived/<br>    ln -s /usr/local/keepalived-1.2.12/sbin/keepalived /sbin/<br>    service keepalived restart<br>4更改keepalive的配置文件<br>    vim /etc/keepalived/keepalived.conf<br>    keepalive主<br>    ! Configuration File for keepalived</p>\n<pre><code>global_defs {\n\n   router_id nginx_master\n\n}\n\n#监控服务.NGINX mysql等\n\nvrrp_script chk_nginx {\n\nscript “/usr/local/nginx/check_nginx.sh”\n\ninterval 2\n\nweight 2\n\n}\n\nvrrp_instance VI_1 {\n\nstate MASTER\n\ninterface eth0\n\nvirtual_router_id 51   #通道\n\npriority 101#优先级，数值越高优先级越高\n\nadvert_int 1\n\nauthentication {\n\nauth_type PASS\n\nauth_pass 1111\n\n}\n\nvirtual_ipaddress {\n\n192.168.1.254   #虚拟IP\n\n}\n\ntrack_script {\n\nchk_nginx  #检测脚本 上面配置的\n\n}\n</code></pre><p>keepalive从</p>\n<pre><code>! Configuration File for keepalived\n\nglobal_defs {\n   router_id nginx_backup\n}\n#监控服务.NGINX mysql等\nvrrp_script chk_nginx {\nscript “/usr/local/nginx/check_nginx.sh”\ninterval 2\nweight 2\n}\n\nvrrp_instance VI_1 {\nstate BACKUP\ninterface eth0\nvirtual_router_id 51#通道\npriority 99#优先级，数值越高优先级越高\nadvert_int 1\nauthentication {\nauth_type PASS\nauth_pass 1111\n}\nvirtual_ipaddress {\n192.168.1.254   #虚拟IP\n}\ntrack_script {\nchk_nginx  #检测脚本 上面配置的\n}\n}\n</code></pre><p>5脚本/usr/local/nginx/check_nginx.sh”内容：</p>\n<pre><code>#!/bin/bash\n\nif [ “$(ps -ef | grep “nginx: master process“| grep -v grep )” == “” ]\n\nthen\n\n/usr/local/nginx/sbin/nginx\n\nsleep 5\n\nif [ “$(ps -ef | grep “nginx: master process“| grep -v grep )” == “” ]\n\nthen\n\nkillall keepalived\n\nfi\n\nfi\n</code></pre><p>6编写keepalive和nginx共存脚本</p>\n<pre><code>vim /data/apps/jiance.sh\n\n#!/bin/bash\nwhile :\ndo\nnginxpid=`ps -C nginx –no-header |wc -l`\nif [ $nginxpid -eq 0 ];then\n   /etc/init.d/nginx restart\n  sleep 5\nnginxpid=`ps -C nginx –no-header |wc -l`\n  if [ $nginxpid -eq 0 ];then\n  /etc/init.d/keepalived stop\n  fi\nfi\nsleep 5\ndone\n}\n</code></pre><p>7把该脚本制作成系统服务并且开机启动<br>    chmod 755 /data/apps/jiance.sh<br>    vim /etc/init.d/jiance</p>\n<pre><code>#!/bin/bash\n# chkconfig: 2345 10 90\n# description: jiance ….\nstart() {\necho “Starting my process “\ncd /data/apps/\n./jiance.sh\n}\nstop() {\nkillall jiance.sh\necho “Stoped”\n}\nchmod a+wrx /etc/init.d/jiance\n/etc/init.d/jiance start\nchmod +x jiance   #增加执行权限\nchkconfig –add jiance #把jiance添加到系统服务列表\nchkconfig jiance on #设定jiance的开关（on/off）\nchkconfig –list jiance   #就可以看到已经注册了jiance的服务\n</code></pre><p>完成如上步骤keepalive+nginx高可用即搭建完成。</p>\n","site":{"data":{}},"excerpt":"<p>1安装相应基础服务</p>\n<pre><code>yum install openssl-devel\nyum install popt-devel\n</code></pre><p>2下载并安装keepalive安装包<br>    wget <a href=\"http://www.keepalived.org/software/keepalived-1.2.12.tar.gz\" target=\"_blank\" rel=\"noopener\">http://www.keepalived.org/software/keepalived-1.2.12.tar.gz</a><br>    tar xzf keepalived-1.2.12.tar.gz;<br>    cd keepalived-1.2.12<br>    ./configure –prefix=/usr/local/keepalived-1.2.12;<br>    make &amp;&amp; make install<br>","more":"<br>3制作keepalive服务<br>    cp /usr/local/keepalived-1.2.12/etc/rc.d/init.d/keepalived /etc/init.d/<br>    cp /usr/local/keepalived-1.2.12/etc/sysconfig/keepalived /etc/sysconfig/<br>    chmod +x /etc/init.d/keepalived;<br>    chkconfig –add keepalived;<br>    mkdir -p /etc/keepalived<br>    ln -s /usr/local/keepalived-1.2.12/sbin/keepalived /usr/sbin/<br>    cp /usr/local/keepalived-1.2.12/etc/keepalived/keepalived.conf /etc/keepalived/<br>    ln -s /usr/local/keepalived-1.2.12/sbin/keepalived /sbin/<br>    service keepalived restart<br>4更改keepalive的配置文件<br>    vim /etc/keepalived/keepalived.conf<br>    keepalive主<br>    ! Configuration File for keepalived</p>\n<pre><code>global_defs {\n\n   router_id nginx_master\n\n}\n\n#监控服务.NGINX mysql等\n\nvrrp_script chk_nginx {\n\nscript “/usr/local/nginx/check_nginx.sh”\n\ninterval 2\n\nweight 2\n\n}\n\nvrrp_instance VI_1 {\n\nstate MASTER\n\ninterface eth0\n\nvirtual_router_id 51   #通道\n\npriority 101#优先级，数值越高优先级越高\n\nadvert_int 1\n\nauthentication {\n\nauth_type PASS\n\nauth_pass 1111\n\n}\n\nvirtual_ipaddress {\n\n192.168.1.254   #虚拟IP\n\n}\n\ntrack_script {\n\nchk_nginx  #检测脚本 上面配置的\n\n}\n</code></pre><p>keepalive从</p>\n<pre><code>! Configuration File for keepalived\n\nglobal_defs {\n   router_id nginx_backup\n}\n#监控服务.NGINX mysql等\nvrrp_script chk_nginx {\nscript “/usr/local/nginx/check_nginx.sh”\ninterval 2\nweight 2\n}\n\nvrrp_instance VI_1 {\nstate BACKUP\ninterface eth0\nvirtual_router_id 51#通道\npriority 99#优先级，数值越高优先级越高\nadvert_int 1\nauthentication {\nauth_type PASS\nauth_pass 1111\n}\nvirtual_ipaddress {\n192.168.1.254   #虚拟IP\n}\ntrack_script {\nchk_nginx  #检测脚本 上面配置的\n}\n}\n</code></pre><p>5脚本/usr/local/nginx/check_nginx.sh”内容：</p>\n<pre><code>#!/bin/bash\n\nif [ “$(ps -ef | grep “nginx: master process“| grep -v grep )” == “” ]\n\nthen\n\n/usr/local/nginx/sbin/nginx\n\nsleep 5\n\nif [ “$(ps -ef | grep “nginx: master process“| grep -v grep )” == “” ]\n\nthen\n\nkillall keepalived\n\nfi\n\nfi\n</code></pre><p>6编写keepalive和nginx共存脚本</p>\n<pre><code>vim /data/apps/jiance.sh\n\n#!/bin/bash\nwhile :\ndo\nnginxpid=`ps -C nginx –no-header |wc -l`\nif [ $nginxpid -eq 0 ];then\n   /etc/init.d/nginx restart\n  sleep 5\nnginxpid=`ps -C nginx –no-header |wc -l`\n  if [ $nginxpid -eq 0 ];then\n  /etc/init.d/keepalived stop\n  fi\nfi\nsleep 5\ndone\n}\n</code></pre><p>7把该脚本制作成系统服务并且开机启动<br>    chmod 755 /data/apps/jiance.sh<br>    vim /etc/init.d/jiance</p>\n<pre><code>#!/bin/bash\n# chkconfig: 2345 10 90\n# description: jiance ….\nstart() {\necho “Starting my process “\ncd /data/apps/\n./jiance.sh\n}\nstop() {\nkillall jiance.sh\necho “Stoped”\n}\nchmod a+wrx /etc/init.d/jiance\n/etc/init.d/jiance start\nchmod +x jiance   #增加执行权限\nchkconfig –add jiance #把jiance添加到系统服务列表\nchkconfig jiance on #设定jiance的开关（on/off）\nchkconfig –list jiance   #就可以看到已经注册了jiance的服务\n</code></pre><p>完成如上步骤keepalive+nginx高可用即搭建完成。</p>"},{"title":"路由跟踪指令traceroute","date":"2016-11-03T04:00:00.000Z","_content":"通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的\n<!--more-->\nlinux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。\n在大多数情况下，我们会在linux主机系统下，直接执行命令行：traceroute hostname\n而在Windows系统下是执行tracert的命令： tracert hostname\n1.命令格式：\ntraceroute[参数][主机]\n2.命令功能：\ntraceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。\n具体参数格式：traceroute [-dFlnrvx][-f<存活数值>][-g<网关>...][-i<网络界面>][-m<存活数值>][-p<通信端口>][-s<来源地址>][-t<服务类型>][-w<超时秒数>][主机名称或IP地址][数据包大小]\n3.命令参数：\n-d 使用Socket层级的排错功能。\n-f 设置第一个检测数据包的存活数值TTL的大小。\n-F 设置勿离断位。\n-g 设置来源路由网关，最多可设置8个。\n-i 使用指定的网络界面送出数据包。\n-I 使用ICMP回应取代UDP资料信息。\n-m 设置检测数据包的最大存活数值TTL的大小。\n-n 直接使用IP地址而非主机名称。\n-p 设置UDP传输协议的通信端口。\n-r 忽略普通的Routing Table，直接将数据包送到远端主机上。\n-s 设置本地主机送出数据包的IP地址。\n-t 设置检测数据包的TOS数值。\n-v 详细显示指令的执行过程。\n-w 设置等待远端主机回报的时间。\n-x 开启或关闭数据包的正确性检验。\n4.使用实例：\n实例1：traceroute 用法简单、最常用的用法\n命令：traceroute www.baidu.com \n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 192.168.74.2 (192.168.74.2) 2.606 ms 2.771 ms 2.950 ms\n2 211.151.56.57 (211.151.56.57) 0.596 ms 0.598 ms 0.591 ms\n3 211.151.227.206 (211.151.227.206) 0.546 ms 0.544 ms 0.538 ms\n4 210.77.139.145 (210.77.139.145) 0.710 ms 0.748 ms 0.801 ms\n5 202.106.42.101 (202.106.42.101) 6.759 ms 6.945 ms 7.107 ms\n6 61.148.154.97 (61.148.154.97) 718.908 ms * bt-228-025.bta.net.cn (202.106.228.25) 5.177 ms\n7 124.65.58.213 (124.65.58.213) 4.343 ms 4.336 ms 4.367 ms\n8 202.106.35.190 (202.106.35.190) 1.795 ms 61.148.156.138 (61.148.156.138) 1.899 ms 1.951 ms\n9 * * *\n30 * * *\n[root@localhost ~]# \n说明：\n记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。\n有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。\n有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。\n如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。\n实例2：跳数设置\n命令：traceroute -m 10 www.baidu.com\n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -m 10 www.baidu.com\ntraceroute to www.baidu.com (61.135.169.105), 10 hops max, 40 byte packets\n1 192.168.74.2 (192.168.74.2) 1.534 ms 1.775 ms 1.961 ms\n2 211.151.56.1 (211.151.56.1) 0.508 ms 0.514 ms 0.507 ms\n3 211.151.227.206 (211.151.227.206) 0.571 ms 0.558 ms 0.550 ms\n4 210.77.139.145 (210.77.139.145) 0.708 ms 0.729 ms 0.785 ms\n5 202.106.42.101 (202.106.42.101) 7.978 ms 8.155 ms 8.311 ms\n6 bt-228-037.bta.net.cn (202.106.228.37) 772.460 ms bt-228-025.bta.net.cn (202.106.228.25) 2.152 ms 61.148.154.97 (61.148.154.97) 772.107 ms\n7 124.65.58.221 (124.65.58.221) 4.875 ms 61.148.146.29 (61.148.146.29) 2.124 ms 124.65.58.221 (124.65.58.221) 4.854 ms\n8 123.126.6.198 (123.126.6.198) 2.944 ms 61.148.156.6 (61.148.156.6) 3.505 ms 123.126.6.198 (123.126.6.198) 2.885 ms\n9 * * *\n10 * * *\n[root@localhost ~]#\n\n \n实例3：显示IP地址，不查主机名\n命令：traceroute -n www.baidu.com\n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -n www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 211.151.74.2 5.430 ms 5.636 ms 5.802 ms\n2 211.151.56.57 0.627 ms 0.625 ms 0.617 ms\n3 211.151.227.206 0.575 ms 0.584 ms 0.576 ms\n4 210.77.139.145 0.703 ms 0.754 ms 0.806 ms\n5 202.106.42.101 23.683 ms 23.869 ms 23.998 ms\n6 202.106.228.37 247.101 ms * *\n7 61.148.146.29 5.256 ms 124.65.58.213 4.386 ms 4.373 ms\n8 202.106.35.190 1.610 ms 61.148.156.138 1.786 ms 61.148.3.34 2.089 ms\n9 * * *\n30 * * *\n[root@localhost ~]# traceroute www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 4.671 ms 4.865 ms 5.055 ms\n2 211.151.56.57 (211.151.56.57) 0.619 ms 0.618 ms 0.612 ms\n3 211.151.227.206 (211.151.227.206) 0.620 ms 0.642 ms 0.636 ms\n4 210.77.139.145 (210.77.139.145) 0.720 ms 0.772 ms 0.816 ms\n5 202.106.42.101 (202.106.42.101) 7.667 ms 7.910 ms 8.012 ms\n6 bt-228-025.bta.net.cn (202.106.228.25) 2.965 ms 2.440 ms 61.148.154.97 (61.148.154.97) 431.337 ms\n7 124.65.58.213 (124.65.58.213) 5.134 ms 5.124 ms 5.044 ms\n8 202.106.35.190 (202.106.35.190) 1.917 ms 2.052 ms 2.059 ms\n9 * * *\n30 * * *\n[root@localhost ~]# \n实例4：探测包使用的基本UDP端口设置6888\n命令：traceroute -p 6888 www.baidu.com\n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -p 6888 www.baidu.com\ntraceroute to www.baidu.com (220.181.111.147), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 4.927 ms 5.121 ms 5.298 ms\n2 211.151.56.1 (211.151.56.1) 0.500 ms 0.499 ms 0.509 ms\n3 211.151.224.90 (211.151.224.90) 0.637 ms 0.631 ms 0.641 ms\n4 * * *\n5 220.181.70.98 (220.181.70.98) 5.050 ms 5.313 ms 5.596 ms\n6 220.181.17.94 (220.181.17.94) 1.665 ms !X * *\n[root@localhost ~]# \n实例5：把探测包的个数设置为值4\n命令：traceroute -q 4 www.baidu.com\n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -q 4 www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 40.633 ms 40.819 ms 41.004 ms 41.188 ms\n2 211.151.56.57 (211.151.56.57) 0.637 ms 0.633 ms 0.627 ms 0.619 ms\n3 211.151.227.206 (211.151.227.206) 0.505 ms 0.580 ms 0.571 ms 0.569 ms\n4 210.77.139.145 (210.77.139.145) 0.753 ms 0.800 ms 0.853 ms 0.904 ms\n5 202.106.42.101 (202.106.42.101) 7.449 ms 7.543 ms 7.738 ms 7.893 ms\n6 61.148.154.97 (61.148.154.97) 316.817 ms bt-228-025.bta.net.cn (202.106.228.25) 3.695 ms 3.672 ms *\n7 124.65.58.213 (124.65.58.213) 3.056 ms 2.993 ms 2.960 ms 61.148.146.29 (61.148.146.29) 2.837 ms\n8 61.148.3.34 (61.148.3.34) 2.179 ms 2.295 ms 2.442 ms 202.106.35.190 (202.106.35.190) 7.136 ms\n9 * * * *\n30 * * * *\n[root@localhost ~]# \n\n实例6：绕过正常的路由表，直接发送到网络相连的主机\n命令：traceroute -r www.baidu.com\n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -r www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\nconnect: 网络不可达\n[root@localhost ~]# \n实例7：把对外发探测包的等待响应时间设置为3秒\n命令：traceroute -w 3 www.baidu.com\n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -w 3 www.baidu.com\ntraceroute to www.baidu.com (61.135.169.105), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 2.306 ms 2.469 ms 2.650 ms\n2 211.151.56.1 (211.151.56.1) 0.621 ms 0.613 ms 0.603 ms\n3 211.151.227.206 (211.151.227.206) 0.557 ms 0.560 ms 0.552 ms\n4 210.77.139.145 (210.77.139.145) 0.708 ms 0.761 ms 0.817 ms\n5 202.106.42.101 (202.106.42.101) 7.520 ms 7.774 ms 7.902 ms\n6 bt-228-025.bta.net.cn (202.106.228.25) 2.890 ms 2.369 ms 61.148.154.97 (61.148.154.97) 471.961 ms\n7 124.65.58.221 (124.65.58.221) 4.490 ms 4.483 ms 4.472 ms\n8 123.126.6.198 (123.126.6.198) 2.948 ms 61.148.156.6 (61.148.156.6) 7.688 ms 7.756 ms\n9 * * *\n30 * * *\n[root@localhost ~]# \n\nTraceroute的工作原理：\nTraceroute最简单的基本用法是：traceroute hostname\nTraceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器...... traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？\nTraceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。\nTraceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。\nwindows之tracert:\n格式：\ntracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name\n参数说明：\ntracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name\n该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间 (TLS) 过期的报文并且对 tracert 无效。\n参数：\n-d 指定不对计算机名解析地址。\n-h maximum_hops 指定查找目标的跳转的最大数目。\n-jcomputer-list 指定在 computer-list 中松散源路由。\n-w timeout 等待由 timeout 对每个应答指定的毫秒数。\ntarget_name 目标计算机的名称。\n实例：\n\n复制代码\n代码如下:\n\nC:\\Users\\Administrator>tracert www.58.com\nTracing route to www.58.com [221.187.111.30]\nover a maximum of 30 hops:\n1 1 ms 1 ms 1 ms 10.58.156.1\n2 1 ms <1 ms <1 ms 10.10.10.1\n3 1 ms 1 ms 1 ms 211.103.193.129\n4 2 ms 2 ms 2 ms 10.255.109.129\n5 1 ms 1 ms 3 ms 124.205.98.205\n6 2 ms 2 ms 2 ms 124.205.98.253\n7 2 ms 6 ms 1 ms 202.99.1.125\n8 5 ms 6 ms 5 ms 118.186.0.113\n9 207 ms * * 118.186.0.106\n10 8 ms 6 ms 11 ms 124.238.226.201\n11 6 ms 7 ms 6 ms 219.148.19.177\n12 12 ms 12 ms 16 ms 219.148.18.117\n13 14 ms 17 ms 16 ms 219.148.19.125\n14 13 ms 13 ms 12 ms 202.97.80.113\n15 * * * Request timed out.\n16 12 ms 12 ms 17 ms bj141-147-82.bjtelecom.net [219.141.147.82]\n17 13 ms 13 ms 12 ms 202.97.48.2\n18 * * * Request timed out.\n19 14 ms 14 ms 12 ms 221.187.224.85\n20 15 ms 13 ms 12 ms 221.187.104.2\n21 * * * Request timed out.\n22 15 ms 17 ms 18 ms 221.187.111.30\nTrace complete.","source":"_posts/linux traceroute 命令详解.md","raw":"---\ntitle: 路由跟踪指令traceroute\ndate: 2016-11-03\ntags:\n---\n通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的\n<!--more-->\nlinux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。\n在大多数情况下，我们会在linux主机系统下，直接执行命令行：traceroute hostname\n而在Windows系统下是执行tracert的命令： tracert hostname\n1.命令格式：\ntraceroute[参数][主机]\n2.命令功能：\ntraceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。\n具体参数格式：traceroute [-dFlnrvx][-f<存活数值>][-g<网关>...][-i<网络界面>][-m<存活数值>][-p<通信端口>][-s<来源地址>][-t<服务类型>][-w<超时秒数>][主机名称或IP地址][数据包大小]\n3.命令参数：\n-d 使用Socket层级的排错功能。\n-f 设置第一个检测数据包的存活数值TTL的大小。\n-F 设置勿离断位。\n-g 设置来源路由网关，最多可设置8个。\n-i 使用指定的网络界面送出数据包。\n-I 使用ICMP回应取代UDP资料信息。\n-m 设置检测数据包的最大存活数值TTL的大小。\n-n 直接使用IP地址而非主机名称。\n-p 设置UDP传输协议的通信端口。\n-r 忽略普通的Routing Table，直接将数据包送到远端主机上。\n-s 设置本地主机送出数据包的IP地址。\n-t 设置检测数据包的TOS数值。\n-v 详细显示指令的执行过程。\n-w 设置等待远端主机回报的时间。\n-x 开启或关闭数据包的正确性检验。\n4.使用实例：\n实例1：traceroute 用法简单、最常用的用法\n命令：traceroute www.baidu.com \n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 192.168.74.2 (192.168.74.2) 2.606 ms 2.771 ms 2.950 ms\n2 211.151.56.57 (211.151.56.57) 0.596 ms 0.598 ms 0.591 ms\n3 211.151.227.206 (211.151.227.206) 0.546 ms 0.544 ms 0.538 ms\n4 210.77.139.145 (210.77.139.145) 0.710 ms 0.748 ms 0.801 ms\n5 202.106.42.101 (202.106.42.101) 6.759 ms 6.945 ms 7.107 ms\n6 61.148.154.97 (61.148.154.97) 718.908 ms * bt-228-025.bta.net.cn (202.106.228.25) 5.177 ms\n7 124.65.58.213 (124.65.58.213) 4.343 ms 4.336 ms 4.367 ms\n8 202.106.35.190 (202.106.35.190) 1.795 ms 61.148.156.138 (61.148.156.138) 1.899 ms 1.951 ms\n9 * * *\n30 * * *\n[root@localhost ~]# \n说明：\n记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。\n有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。\n有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。\n如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。\n实例2：跳数设置\n命令：traceroute -m 10 www.baidu.com\n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -m 10 www.baidu.com\ntraceroute to www.baidu.com (61.135.169.105), 10 hops max, 40 byte packets\n1 192.168.74.2 (192.168.74.2) 1.534 ms 1.775 ms 1.961 ms\n2 211.151.56.1 (211.151.56.1) 0.508 ms 0.514 ms 0.507 ms\n3 211.151.227.206 (211.151.227.206) 0.571 ms 0.558 ms 0.550 ms\n4 210.77.139.145 (210.77.139.145) 0.708 ms 0.729 ms 0.785 ms\n5 202.106.42.101 (202.106.42.101) 7.978 ms 8.155 ms 8.311 ms\n6 bt-228-037.bta.net.cn (202.106.228.37) 772.460 ms bt-228-025.bta.net.cn (202.106.228.25) 2.152 ms 61.148.154.97 (61.148.154.97) 772.107 ms\n7 124.65.58.221 (124.65.58.221) 4.875 ms 61.148.146.29 (61.148.146.29) 2.124 ms 124.65.58.221 (124.65.58.221) 4.854 ms\n8 123.126.6.198 (123.126.6.198) 2.944 ms 61.148.156.6 (61.148.156.6) 3.505 ms 123.126.6.198 (123.126.6.198) 2.885 ms\n9 * * *\n10 * * *\n[root@localhost ~]#\n\n \n实例3：显示IP地址，不查主机名\n命令：traceroute -n www.baidu.com\n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -n www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 211.151.74.2 5.430 ms 5.636 ms 5.802 ms\n2 211.151.56.57 0.627 ms 0.625 ms 0.617 ms\n3 211.151.227.206 0.575 ms 0.584 ms 0.576 ms\n4 210.77.139.145 0.703 ms 0.754 ms 0.806 ms\n5 202.106.42.101 23.683 ms 23.869 ms 23.998 ms\n6 202.106.228.37 247.101 ms * *\n7 61.148.146.29 5.256 ms 124.65.58.213 4.386 ms 4.373 ms\n8 202.106.35.190 1.610 ms 61.148.156.138 1.786 ms 61.148.3.34 2.089 ms\n9 * * *\n30 * * *\n[root@localhost ~]# traceroute www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 4.671 ms 4.865 ms 5.055 ms\n2 211.151.56.57 (211.151.56.57) 0.619 ms 0.618 ms 0.612 ms\n3 211.151.227.206 (211.151.227.206) 0.620 ms 0.642 ms 0.636 ms\n4 210.77.139.145 (210.77.139.145) 0.720 ms 0.772 ms 0.816 ms\n5 202.106.42.101 (202.106.42.101) 7.667 ms 7.910 ms 8.012 ms\n6 bt-228-025.bta.net.cn (202.106.228.25) 2.965 ms 2.440 ms 61.148.154.97 (61.148.154.97) 431.337 ms\n7 124.65.58.213 (124.65.58.213) 5.134 ms 5.124 ms 5.044 ms\n8 202.106.35.190 (202.106.35.190) 1.917 ms 2.052 ms 2.059 ms\n9 * * *\n30 * * *\n[root@localhost ~]# \n实例4：探测包使用的基本UDP端口设置6888\n命令：traceroute -p 6888 www.baidu.com\n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -p 6888 www.baidu.com\ntraceroute to www.baidu.com (220.181.111.147), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 4.927 ms 5.121 ms 5.298 ms\n2 211.151.56.1 (211.151.56.1) 0.500 ms 0.499 ms 0.509 ms\n3 211.151.224.90 (211.151.224.90) 0.637 ms 0.631 ms 0.641 ms\n4 * * *\n5 220.181.70.98 (220.181.70.98) 5.050 ms 5.313 ms 5.596 ms\n6 220.181.17.94 (220.181.17.94) 1.665 ms !X * *\n[root@localhost ~]# \n实例5：把探测包的个数设置为值4\n命令：traceroute -q 4 www.baidu.com\n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -q 4 www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 40.633 ms 40.819 ms 41.004 ms 41.188 ms\n2 211.151.56.57 (211.151.56.57) 0.637 ms 0.633 ms 0.627 ms 0.619 ms\n3 211.151.227.206 (211.151.227.206) 0.505 ms 0.580 ms 0.571 ms 0.569 ms\n4 210.77.139.145 (210.77.139.145) 0.753 ms 0.800 ms 0.853 ms 0.904 ms\n5 202.106.42.101 (202.106.42.101) 7.449 ms 7.543 ms 7.738 ms 7.893 ms\n6 61.148.154.97 (61.148.154.97) 316.817 ms bt-228-025.bta.net.cn (202.106.228.25) 3.695 ms 3.672 ms *\n7 124.65.58.213 (124.65.58.213) 3.056 ms 2.993 ms 2.960 ms 61.148.146.29 (61.148.146.29) 2.837 ms\n8 61.148.3.34 (61.148.3.34) 2.179 ms 2.295 ms 2.442 ms 202.106.35.190 (202.106.35.190) 7.136 ms\n9 * * * *\n30 * * * *\n[root@localhost ~]# \n\n实例6：绕过正常的路由表，直接发送到网络相连的主机\n命令：traceroute -r www.baidu.com\n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -r www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\nconnect: 网络不可达\n[root@localhost ~]# \n实例7：把对外发探测包的等待响应时间设置为3秒\n命令：traceroute -w 3 www.baidu.com\n输出：\n\n复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -w 3 www.baidu.com\ntraceroute to www.baidu.com (61.135.169.105), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 2.306 ms 2.469 ms 2.650 ms\n2 211.151.56.1 (211.151.56.1) 0.621 ms 0.613 ms 0.603 ms\n3 211.151.227.206 (211.151.227.206) 0.557 ms 0.560 ms 0.552 ms\n4 210.77.139.145 (210.77.139.145) 0.708 ms 0.761 ms 0.817 ms\n5 202.106.42.101 (202.106.42.101) 7.520 ms 7.774 ms 7.902 ms\n6 bt-228-025.bta.net.cn (202.106.228.25) 2.890 ms 2.369 ms 61.148.154.97 (61.148.154.97) 471.961 ms\n7 124.65.58.221 (124.65.58.221) 4.490 ms 4.483 ms 4.472 ms\n8 123.126.6.198 (123.126.6.198) 2.948 ms 61.148.156.6 (61.148.156.6) 7.688 ms 7.756 ms\n9 * * *\n30 * * *\n[root@localhost ~]# \n\nTraceroute的工作原理：\nTraceroute最简单的基本用法是：traceroute hostname\nTraceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器...... traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？\nTraceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。\nTraceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。\nwindows之tracert:\n格式：\ntracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name\n参数说明：\ntracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name\n该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间 (TLS) 过期的报文并且对 tracert 无效。\n参数：\n-d 指定不对计算机名解析地址。\n-h maximum_hops 指定查找目标的跳转的最大数目。\n-jcomputer-list 指定在 computer-list 中松散源路由。\n-w timeout 等待由 timeout 对每个应答指定的毫秒数。\ntarget_name 目标计算机的名称。\n实例：\n\n复制代码\n代码如下:\n\nC:\\Users\\Administrator>tracert www.58.com\nTracing route to www.58.com [221.187.111.30]\nover a maximum of 30 hops:\n1 1 ms 1 ms 1 ms 10.58.156.1\n2 1 ms <1 ms <1 ms 10.10.10.1\n3 1 ms 1 ms 1 ms 211.103.193.129\n4 2 ms 2 ms 2 ms 10.255.109.129\n5 1 ms 1 ms 3 ms 124.205.98.205\n6 2 ms 2 ms 2 ms 124.205.98.253\n7 2 ms 6 ms 1 ms 202.99.1.125\n8 5 ms 6 ms 5 ms 118.186.0.113\n9 207 ms * * 118.186.0.106\n10 8 ms 6 ms 11 ms 124.238.226.201\n11 6 ms 7 ms 6 ms 219.148.19.177\n12 12 ms 12 ms 16 ms 219.148.18.117\n13 14 ms 17 ms 16 ms 219.148.19.125\n14 13 ms 13 ms 12 ms 202.97.80.113\n15 * * * Request timed out.\n16 12 ms 12 ms 17 ms bj141-147-82.bjtelecom.net [219.141.147.82]\n17 13 ms 13 ms 12 ms 202.97.48.2\n18 * * * Request timed out.\n19 14 ms 14 ms 12 ms 221.187.224.85\n20 15 ms 13 ms 12 ms 221.187.104.2\n21 * * * Request timed out.\n22 15 ms 17 ms 18 ms 221.187.111.30\nTrace complete.","slug":"linux traceroute 命令详解","published":1,"updated":"2019-06-18T08:07:01.114Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sk3000vhcb7ywv8ykfx","content":"<p>通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的<br><a id=\"more\"></a><br>linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。<br>在大多数情况下，我们会在linux主机系统下，直接执行命令行：traceroute hostname<br>而在Windows系统下是执行tracert的命令： tracert hostname<br>1.命令格式：<br>traceroute[参数][主机]<br>2.命令功能：<br>traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。<br>具体参数格式：traceroute [-dFlnrvx][-f&lt;存活数值&gt;][-g&lt;网关&gt;…][-i&lt;网络界面&gt;][-m&lt;存活数值&gt;][-p&lt;通信端口&gt;][-s&lt;来源地址&gt;][-t&lt;服务类型&gt;][-w&lt;超时秒数&gt;][主机名称或IP地址][数据包大小]<br>3.命令参数：<br>-d 使用Socket层级的排错功能。<br>-f 设置第一个检测数据包的存活数值TTL的大小。<br>-F 设置勿离断位。<br>-g 设置来源路由网关，最多可设置8个。<br>-i 使用指定的网络界面送出数据包。<br>-I 使用ICMP回应取代UDP资料信息。<br>-m 设置检测数据包的最大存活数值TTL的大小。<br>-n 直接使用IP地址而非主机名称。<br>-p 设置UDP传输协议的通信端口。<br>-r 忽略普通的Routing Table，直接将数据包送到远端主机上。<br>-s 设置本地主机送出数据包的IP地址。<br>-t 设置检测数据包的TOS数值。<br>-v 详细显示指令的执行过程。<br>-w 设置等待远端主机回报的时间。<br>-x 开启或关闭数据包的正确性检验。<br>4.使用实例：<br>实例1：traceroute 用法简单、最常用的用法<br>命令：traceroute <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>1 192.168.74.2 (192.168.74.2) 2.606 ms 2.771 ms 2.950 ms<br>2 211.151.56.57 (211.151.56.57) 0.596 ms 0.598 ms 0.591 ms<br>3 211.151.227.206 (211.151.227.206) 0.546 ms 0.544 ms 0.538 ms<br>4 210.77.139.145 (210.77.139.145) 0.710 ms 0.748 ms 0.801 ms<br>5 202.106.42.101 (202.106.42.101) 6.759 ms 6.945 ms 7.107 ms<br>6 61.148.154.97 (61.148.154.97) 718.908 ms <em> bt-228-025.bta.net.cn (202.106.228.25) 5.177 ms<br>7 124.65.58.213 (124.65.58.213) 4.343 ms 4.336 ms 4.367 ms<br>8 202.106.35.190 (202.106.35.190) 1.795 ms 61.148.156.138 (61.148.156.138) 1.899 ms 1.951 ms<br>9 </em> <em> </em><br>30 <em> </em> *<br>[root@localhost ~]#<br>说明：<br>记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 <a href=\"http://www.58.com\" target=\"_blank\" rel=\"noopener\">www.58.com</a> ，表示向每个网关发送4个数据包。<br>有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。<br>有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。<br>如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。<br>实例2：跳数设置<br>命令：traceroute -m 10 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute -m 10 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.105), 10 hops max, 40 byte packets<br>1 192.168.74.2 (192.168.74.2) 1.534 ms 1.775 ms 1.961 ms<br>2 211.151.56.1 (211.151.56.1) 0.508 ms 0.514 ms 0.507 ms<br>3 211.151.227.206 (211.151.227.206) 0.571 ms 0.558 ms 0.550 ms<br>4 210.77.139.145 (210.77.139.145) 0.708 ms 0.729 ms 0.785 ms<br>5 202.106.42.101 (202.106.42.101) 7.978 ms 8.155 ms 8.311 ms<br>6 bt-228-037.bta.net.cn (202.106.228.37) 772.460 ms bt-228-025.bta.net.cn (202.106.228.25) 2.152 ms 61.148.154.97 (61.148.154.97) 772.107 ms<br>7 124.65.58.221 (124.65.58.221) 4.875 ms 61.148.146.29 (61.148.146.29) 2.124 ms 124.65.58.221 (124.65.58.221) 4.854 ms<br>8 123.126.6.198 (123.126.6.198) 2.944 ms 61.148.156.6 (61.148.156.6) 3.505 ms 123.126.6.198 (123.126.6.198) 2.885 ms<br>9 <em> </em> <em><br>10 </em> <em> </em><br>[root@localhost ~]#</p>\n<p>实例3：显示IP地址，不查主机名<br>命令：traceroute -n <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute -n <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>1 211.151.74.2 5.430 ms 5.636 ms 5.802 ms<br>2 211.151.56.57 0.627 ms 0.625 ms 0.617 ms<br>3 211.151.227.206 0.575 ms 0.584 ms 0.576 ms<br>4 210.77.139.145 0.703 ms 0.754 ms 0.806 ms<br>5 202.106.42.101 23.683 ms 23.869 ms 23.998 ms<br>6 202.106.228.37 247.101 ms <em> </em><br>7 61.148.146.29 5.256 ms 124.65.58.213 4.386 ms 4.373 ms<br>8 202.106.35.190 1.610 ms 61.148.156.138 1.786 ms 61.148.3.34 2.089 ms<br>9 <em> </em> <em><br>30 </em> <em> </em><br>[root@localhost ~]# traceroute <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>1 211.151.74.2 (211.151.74.2) 4.671 ms 4.865 ms 5.055 ms<br>2 211.151.56.57 (211.151.56.57) 0.619 ms 0.618 ms 0.612 ms<br>3 211.151.227.206 (211.151.227.206) 0.620 ms 0.642 ms 0.636 ms<br>4 210.77.139.145 (210.77.139.145) 0.720 ms 0.772 ms 0.816 ms<br>5 202.106.42.101 (202.106.42.101) 7.667 ms 7.910 ms 8.012 ms<br>6 bt-228-025.bta.net.cn (202.106.228.25) 2.965 ms 2.440 ms 61.148.154.97 (61.148.154.97) 431.337 ms<br>7 124.65.58.213 (124.65.58.213) 5.134 ms 5.124 ms 5.044 ms<br>8 202.106.35.190 (202.106.35.190) 1.917 ms 2.052 ms 2.059 ms<br>9 <em> </em> <em><br>30 </em> <em> </em><br>[root@localhost ~]#<br>实例4：探测包使用的基本UDP端口设置6888<br>命令：traceroute -p 6888 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute -p 6888 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (220.181.111.147), 30 hops max, 40 byte packets<br>1 211.151.74.2 (211.151.74.2) 4.927 ms 5.121 ms 5.298 ms<br>2 211.151.56.1 (211.151.56.1) 0.500 ms 0.499 ms 0.509 ms<br>3 211.151.224.90 (211.151.224.90) 0.637 ms 0.631 ms 0.641 ms<br>4 <em> </em> <em><br>5 220.181.70.98 (220.181.70.98) 5.050 ms 5.313 ms 5.596 ms<br>6 220.181.17.94 (220.181.17.94) 1.665 ms !X </em> *<br>[root@localhost ~]#<br>实例5：把探测包的个数设置为值4<br>命令：traceroute -q 4 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute -q 4 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>1 211.151.74.2 (211.151.74.2) 40.633 ms 40.819 ms 41.004 ms 41.188 ms<br>2 211.151.56.57 (211.151.56.57) 0.637 ms 0.633 ms 0.627 ms 0.619 ms<br>3 211.151.227.206 (211.151.227.206) 0.505 ms 0.580 ms 0.571 ms 0.569 ms<br>4 210.77.139.145 (210.77.139.145) 0.753 ms 0.800 ms 0.853 ms 0.904 ms<br>5 202.106.42.101 (202.106.42.101) 7.449 ms 7.543 ms 7.738 ms 7.893 ms<br>6 61.148.154.97 (61.148.154.97) 316.817 ms bt-228-025.bta.net.cn (202.106.228.25) 3.695 ms 3.672 ms <em><br>7 124.65.58.213 (124.65.58.213) 3.056 ms 2.993 ms 2.960 ms 61.148.146.29 (61.148.146.29) 2.837 ms<br>8 61.148.3.34 (61.148.3.34) 2.179 ms 2.295 ms 2.442 ms 202.106.35.190 (202.106.35.190) 7.136 ms<br>9 </em> <em> </em> <em><br>30 </em> <em> </em> *<br>[root@localhost ~]# </p>\n<p>实例6：绕过正常的路由表，直接发送到网络相连的主机<br>命令：traceroute -r <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute -r <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>connect: 网络不可达<br>[root@localhost ~]#<br>实例7：把对外发探测包的等待响应时间设置为3秒<br>命令：traceroute -w 3 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute -w 3 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.105), 30 hops max, 40 byte packets<br>1 211.151.74.2 (211.151.74.2) 2.306 ms 2.469 ms 2.650 ms<br>2 211.151.56.1 (211.151.56.1) 0.621 ms 0.613 ms 0.603 ms<br>3 211.151.227.206 (211.151.227.206) 0.557 ms 0.560 ms 0.552 ms<br>4 210.77.139.145 (210.77.139.145) 0.708 ms 0.761 ms 0.817 ms<br>5 202.106.42.101 (202.106.42.101) 7.520 ms 7.774 ms 7.902 ms<br>6 bt-228-025.bta.net.cn (202.106.228.25) 2.890 ms 2.369 ms 61.148.154.97 (61.148.154.97) 471.961 ms<br>7 124.65.58.221 (124.65.58.221) 4.490 ms 4.483 ms 4.472 ms<br>8 123.126.6.198 (123.126.6.198) 2.948 ms 61.148.156.6 (61.148.156.6) 7.688 ms 7.756 ms<br>9 <em> </em> <em><br>30 </em> <em> </em><br>[root@localhost ~]# </p>\n<p>Traceroute的工作原理：<br>Traceroute最简单的基本用法是：traceroute hostname<br>Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器…… traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？<br>Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。<br>Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。<br>windows之tracert:<br>格式：<br>tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name<br>参数说明：<br>tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name<br>该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间 (TLS) 过期的报文并且对 tracert 无效。<br>参数：<br>-d 指定不对计算机名解析地址。<br>-h maximum_hops 指定查找目标的跳转的最大数目。<br>-jcomputer-list 指定在 computer-list 中松散源路由。<br>-w timeout 等待由 timeout 对每个应答指定的毫秒数。<br>target_name 目标计算机的名称。<br>实例：</p>\n<p>复制代码<br>代码如下:</p>\n<p>C:\\Users\\Administrator&gt;tracert <a href=\"http://www.58.com\" target=\"_blank\" rel=\"noopener\">www.58.com</a><br>Tracing route to <a href=\"http://www.58.com\" target=\"_blank\" rel=\"noopener\">www.58.com</a> [221.187.111.30]<br>over a maximum of 30 hops:<br>1 1 ms 1 ms 1 ms 10.58.156.1<br>2 1 ms &lt;1 ms &lt;1 ms 10.10.10.1<br>3 1 ms 1 ms 1 ms 211.103.193.129<br>4 2 ms 2 ms 2 ms 10.255.109.129<br>5 1 ms 1 ms 3 ms 124.205.98.205<br>6 2 ms 2 ms 2 ms 124.205.98.253<br>7 2 ms 6 ms 1 ms 202.99.1.125<br>8 5 ms 6 ms 5 ms 118.186.0.113<br>9 207 ms <em> </em> 118.186.0.106<br>10 8 ms 6 ms 11 ms 124.238.226.201<br>11 6 ms 7 ms 6 ms 219.148.19.177<br>12 12 ms 12 ms 16 ms 219.148.18.117<br>13 14 ms 17 ms 16 ms 219.148.19.125<br>14 13 ms 13 ms 12 ms 202.97.80.113<br>15 <em> </em> <em> Request timed out.<br>16 12 ms 12 ms 17 ms bj141-147-82.bjtelecom.net [219.141.147.82]<br>17 13 ms 13 ms 12 ms 202.97.48.2<br>18 </em> <em> </em> Request timed out.<br>19 14 ms 14 ms 12 ms 221.187.224.85<br>20 15 ms 13 ms 12 ms 221.187.104.2<br>21 <em> </em> * Request timed out.<br>22 15 ms 17 ms 18 ms 221.187.111.30<br>Trace complete.</p>\n","site":{"data":{}},"excerpt":"<p>通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的<br>","more":"<br>linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。<br>在大多数情况下，我们会在linux主机系统下，直接执行命令行：traceroute hostname<br>而在Windows系统下是执行tracert的命令： tracert hostname<br>1.命令格式：<br>traceroute[参数][主机]<br>2.命令功能：<br>traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。<br>具体参数格式：traceroute [-dFlnrvx][-f&lt;存活数值&gt;][-g&lt;网关&gt;…][-i&lt;网络界面&gt;][-m&lt;存活数值&gt;][-p&lt;通信端口&gt;][-s&lt;来源地址&gt;][-t&lt;服务类型&gt;][-w&lt;超时秒数&gt;][主机名称或IP地址][数据包大小]<br>3.命令参数：<br>-d 使用Socket层级的排错功能。<br>-f 设置第一个检测数据包的存活数值TTL的大小。<br>-F 设置勿离断位。<br>-g 设置来源路由网关，最多可设置8个。<br>-i 使用指定的网络界面送出数据包。<br>-I 使用ICMP回应取代UDP资料信息。<br>-m 设置检测数据包的最大存活数值TTL的大小。<br>-n 直接使用IP地址而非主机名称。<br>-p 设置UDP传输协议的通信端口。<br>-r 忽略普通的Routing Table，直接将数据包送到远端主机上。<br>-s 设置本地主机送出数据包的IP地址。<br>-t 设置检测数据包的TOS数值。<br>-v 详细显示指令的执行过程。<br>-w 设置等待远端主机回报的时间。<br>-x 开启或关闭数据包的正确性检验。<br>4.使用实例：<br>实例1：traceroute 用法简单、最常用的用法<br>命令：traceroute <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>1 192.168.74.2 (192.168.74.2) 2.606 ms 2.771 ms 2.950 ms<br>2 211.151.56.57 (211.151.56.57) 0.596 ms 0.598 ms 0.591 ms<br>3 211.151.227.206 (211.151.227.206) 0.546 ms 0.544 ms 0.538 ms<br>4 210.77.139.145 (210.77.139.145) 0.710 ms 0.748 ms 0.801 ms<br>5 202.106.42.101 (202.106.42.101) 6.759 ms 6.945 ms 7.107 ms<br>6 61.148.154.97 (61.148.154.97) 718.908 ms <em> bt-228-025.bta.net.cn (202.106.228.25) 5.177 ms<br>7 124.65.58.213 (124.65.58.213) 4.343 ms 4.336 ms 4.367 ms<br>8 202.106.35.190 (202.106.35.190) 1.795 ms 61.148.156.138 (61.148.156.138) 1.899 ms 1.951 ms<br>9 </em> <em> </em><br>30 <em> </em> *<br>[root@localhost ~]#<br>说明：<br>记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 <a href=\"http://www.58.com\" target=\"_blank\" rel=\"noopener\">www.58.com</a> ，表示向每个网关发送4个数据包。<br>有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。<br>有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。<br>如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。<br>实例2：跳数设置<br>命令：traceroute -m 10 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute -m 10 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.105), 10 hops max, 40 byte packets<br>1 192.168.74.2 (192.168.74.2) 1.534 ms 1.775 ms 1.961 ms<br>2 211.151.56.1 (211.151.56.1) 0.508 ms 0.514 ms 0.507 ms<br>3 211.151.227.206 (211.151.227.206) 0.571 ms 0.558 ms 0.550 ms<br>4 210.77.139.145 (210.77.139.145) 0.708 ms 0.729 ms 0.785 ms<br>5 202.106.42.101 (202.106.42.101) 7.978 ms 8.155 ms 8.311 ms<br>6 bt-228-037.bta.net.cn (202.106.228.37) 772.460 ms bt-228-025.bta.net.cn (202.106.228.25) 2.152 ms 61.148.154.97 (61.148.154.97) 772.107 ms<br>7 124.65.58.221 (124.65.58.221) 4.875 ms 61.148.146.29 (61.148.146.29) 2.124 ms 124.65.58.221 (124.65.58.221) 4.854 ms<br>8 123.126.6.198 (123.126.6.198) 2.944 ms 61.148.156.6 (61.148.156.6) 3.505 ms 123.126.6.198 (123.126.6.198) 2.885 ms<br>9 <em> </em> <em><br>10 </em> <em> </em><br>[root@localhost ~]#</p>\n<p>实例3：显示IP地址，不查主机名<br>命令：traceroute -n <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute -n <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>1 211.151.74.2 5.430 ms 5.636 ms 5.802 ms<br>2 211.151.56.57 0.627 ms 0.625 ms 0.617 ms<br>3 211.151.227.206 0.575 ms 0.584 ms 0.576 ms<br>4 210.77.139.145 0.703 ms 0.754 ms 0.806 ms<br>5 202.106.42.101 23.683 ms 23.869 ms 23.998 ms<br>6 202.106.228.37 247.101 ms <em> </em><br>7 61.148.146.29 5.256 ms 124.65.58.213 4.386 ms 4.373 ms<br>8 202.106.35.190 1.610 ms 61.148.156.138 1.786 ms 61.148.3.34 2.089 ms<br>9 <em> </em> <em><br>30 </em> <em> </em><br>[root@localhost ~]# traceroute <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>1 211.151.74.2 (211.151.74.2) 4.671 ms 4.865 ms 5.055 ms<br>2 211.151.56.57 (211.151.56.57) 0.619 ms 0.618 ms 0.612 ms<br>3 211.151.227.206 (211.151.227.206) 0.620 ms 0.642 ms 0.636 ms<br>4 210.77.139.145 (210.77.139.145) 0.720 ms 0.772 ms 0.816 ms<br>5 202.106.42.101 (202.106.42.101) 7.667 ms 7.910 ms 8.012 ms<br>6 bt-228-025.bta.net.cn (202.106.228.25) 2.965 ms 2.440 ms 61.148.154.97 (61.148.154.97) 431.337 ms<br>7 124.65.58.213 (124.65.58.213) 5.134 ms 5.124 ms 5.044 ms<br>8 202.106.35.190 (202.106.35.190) 1.917 ms 2.052 ms 2.059 ms<br>9 <em> </em> <em><br>30 </em> <em> </em><br>[root@localhost ~]#<br>实例4：探测包使用的基本UDP端口设置6888<br>命令：traceroute -p 6888 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute -p 6888 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (220.181.111.147), 30 hops max, 40 byte packets<br>1 211.151.74.2 (211.151.74.2) 4.927 ms 5.121 ms 5.298 ms<br>2 211.151.56.1 (211.151.56.1) 0.500 ms 0.499 ms 0.509 ms<br>3 211.151.224.90 (211.151.224.90) 0.637 ms 0.631 ms 0.641 ms<br>4 <em> </em> <em><br>5 220.181.70.98 (220.181.70.98) 5.050 ms 5.313 ms 5.596 ms<br>6 220.181.17.94 (220.181.17.94) 1.665 ms !X </em> *<br>[root@localhost ~]#<br>实例5：把探测包的个数设置为值4<br>命令：traceroute -q 4 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute -q 4 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>1 211.151.74.2 (211.151.74.2) 40.633 ms 40.819 ms 41.004 ms 41.188 ms<br>2 211.151.56.57 (211.151.56.57) 0.637 ms 0.633 ms 0.627 ms 0.619 ms<br>3 211.151.227.206 (211.151.227.206) 0.505 ms 0.580 ms 0.571 ms 0.569 ms<br>4 210.77.139.145 (210.77.139.145) 0.753 ms 0.800 ms 0.853 ms 0.904 ms<br>5 202.106.42.101 (202.106.42.101) 7.449 ms 7.543 ms 7.738 ms 7.893 ms<br>6 61.148.154.97 (61.148.154.97) 316.817 ms bt-228-025.bta.net.cn (202.106.228.25) 3.695 ms 3.672 ms <em><br>7 124.65.58.213 (124.65.58.213) 3.056 ms 2.993 ms 2.960 ms 61.148.146.29 (61.148.146.29) 2.837 ms<br>8 61.148.3.34 (61.148.3.34) 2.179 ms 2.295 ms 2.442 ms 202.106.35.190 (202.106.35.190) 7.136 ms<br>9 </em> <em> </em> <em><br>30 </em> <em> </em> *<br>[root@localhost ~]# </p>\n<p>实例6：绕过正常的路由表，直接发送到网络相连的主机<br>命令：traceroute -r <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute -r <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>connect: 网络不可达<br>[root@localhost ~]#<br>实例7：把对外发探测包的等待响应时间设置为3秒<br>命令：traceroute -w 3 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<p>[root@localhost ~]# traceroute -w 3 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>traceroute to <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a> (61.135.169.105), 30 hops max, 40 byte packets<br>1 211.151.74.2 (211.151.74.2) 2.306 ms 2.469 ms 2.650 ms<br>2 211.151.56.1 (211.151.56.1) 0.621 ms 0.613 ms 0.603 ms<br>3 211.151.227.206 (211.151.227.206) 0.557 ms 0.560 ms 0.552 ms<br>4 210.77.139.145 (210.77.139.145) 0.708 ms 0.761 ms 0.817 ms<br>5 202.106.42.101 (202.106.42.101) 7.520 ms 7.774 ms 7.902 ms<br>6 bt-228-025.bta.net.cn (202.106.228.25) 2.890 ms 2.369 ms 61.148.154.97 (61.148.154.97) 471.961 ms<br>7 124.65.58.221 (124.65.58.221) 4.490 ms 4.483 ms 4.472 ms<br>8 123.126.6.198 (123.126.6.198) 2.948 ms 61.148.156.6 (61.148.156.6) 7.688 ms 7.756 ms<br>9 <em> </em> <em><br>30 </em> <em> </em><br>[root@localhost ~]# </p>\n<p>Traceroute的工作原理：<br>Traceroute最简单的基本用法是：traceroute hostname<br>Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器…… traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？<br>Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。<br>Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。<br>windows之tracert:<br>格式：<br>tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name<br>参数说明：<br>tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name<br>该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间 (TLS) 过期的报文并且对 tracert 无效。<br>参数：<br>-d 指定不对计算机名解析地址。<br>-h maximum_hops 指定查找目标的跳转的最大数目。<br>-jcomputer-list 指定在 computer-list 中松散源路由。<br>-w timeout 等待由 timeout 对每个应答指定的毫秒数。<br>target_name 目标计算机的名称。<br>实例：</p>\n<p>复制代码<br>代码如下:</p>\n<p>C:\\Users\\Administrator&gt;tracert <a href=\"http://www.58.com\" target=\"_blank\" rel=\"noopener\">www.58.com</a><br>Tracing route to <a href=\"http://www.58.com\" target=\"_blank\" rel=\"noopener\">www.58.com</a> [221.187.111.30]<br>over a maximum of 30 hops:<br>1 1 ms 1 ms 1 ms 10.58.156.1<br>2 1 ms &lt;1 ms &lt;1 ms 10.10.10.1<br>3 1 ms 1 ms 1 ms 211.103.193.129<br>4 2 ms 2 ms 2 ms 10.255.109.129<br>5 1 ms 1 ms 3 ms 124.205.98.205<br>6 2 ms 2 ms 2 ms 124.205.98.253<br>7 2 ms 6 ms 1 ms 202.99.1.125<br>8 5 ms 6 ms 5 ms 118.186.0.113<br>9 207 ms <em> </em> 118.186.0.106<br>10 8 ms 6 ms 11 ms 124.238.226.201<br>11 6 ms 7 ms 6 ms 219.148.19.177<br>12 12 ms 12 ms 16 ms 219.148.18.117<br>13 14 ms 17 ms 16 ms 219.148.19.125<br>14 13 ms 13 ms 12 ms 202.97.80.113<br>15 <em> </em> <em> Request timed out.<br>16 12 ms 12 ms 17 ms bj141-147-82.bjtelecom.net [219.141.147.82]<br>17 13 ms 13 ms 12 ms 202.97.48.2<br>18 </em> <em> </em> Request timed out.<br>19 14 ms 14 ms 12 ms 221.187.224.85<br>20 15 ms 13 ms 12 ms 221.187.104.2<br>21 <em> </em> * Request timed out.<br>22 15 ms 17 ms 18 ms 221.187.111.30<br>Trace complete.</p>"},{"title":"路由跟踪指令traceroute","date":"2016-11-03T04:00:00.000Z","_content":"通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的\n<!--more-->\nlinux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。\n在大多数情况下，我们会在linux主机系统下，直接执行命令行：traceroute hostname\n而在Windows系统下是执行tracert的命令： tracert hostname  \n###1.命令格式：\n  \n    traceroute[参数][主机]\n###2.命令功能：\ntraceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。  \n具体参数格式：  \ntraceroute [-dFlnrvx][-f<存活数值>][-g<网关>...][-i<网络界面>][-m<存活数值>][-p<通信端口>][-s<来源地址>][-t<服务类型>][-w<超时秒数>][主机名称或IP地址][数据包大小]  \n###3.命令参数：\n    -d 使用Socket层级的排错功能。  \n    -f 设置第一个检测数据包的存活数值TTL的大小。  \n    -F 设置勿离断位。  \n    -g 设置来源路由网关，最多可设置8个。  \n    -i 使用指定的网络界面送出数据包。  \n    -I 使用ICMP回应取代UDP资料信息。  \n    -m 设置检测数据包的最大存活数值TTL的大小。  \n    -n 直接使用IP地址而非主机名称。  \n    -p 设置UDP传输协议的通信端口。  \n    -r 忽略普通的Routing Table，直接将数据包送到远端主机上。  \n    -s 设置本地主机送出数据包的IP地址。  \n    -t 设置检测数据包的TOS数值。  \n    -v 详细显示指令的执行过程。  \n    -w 设置等待远端主机回报的时间。  \n    -x 开启或关闭数据包的正确性检验。  \n###4.使用实例：\n实例1：traceroute 用法简单、最常用的用法\n命令：traceroute www.baidu.com \n输出：\n\n复制代码\n代码如下:\n\n    [root@localhost ~]# traceroute www.baidu.com  \n    traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets  \n    1 192.168.74.2 (192.168.74.2) 2.606 ms 2.771 ms 2.950 ms\n    2 211.151.56.57 (211.151.56.57) 0.596 ms 0.598 ms 0.591 ms\n    3 211.151.227.206 (211.151.227.206) 0.546 ms 0.544 ms 0.538 ms\n    4 210.77.139.145 (210.77.139.145) 0.710 ms 0.748 ms 0.801 ms\n    5 202.106.42.101 (202.106.42.101) 6.759 ms 6.945 ms 7.107 ms\n    6 61.148.154.97 (61.148.154.97) 718.908 ms * bt-228-025.bta.net.cn (202.106.228.25) 5.177 ms\n    7 124.65.58.213 (124.65.58.213) 4.343 ms 4.336 ms 4.367 ms\n    8 202.106.35.190 (202.106.35.190) 1.795 ms 61.148.156.138 (61.148.156.138) 1.899 ms 1.951 ms\n    9 * * *\n    30 * * *\n    [root@localhost ~]# \n    说明：  \n    记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。      \n    有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。\n    有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。\n    如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。\n\n实例2：跳数设置\n    命令：traceroute -m 10 www.baidu.com\n    输出：\n    \n    复制代码\n    代码如下:\n    \n    [root@localhost ~]# traceroute -m 10 www.baidu.com\n    traceroute to www.baidu.com (61.135.169.105), 10 hops max, 40 byte packets\n    1 192.168.74.2 (192.168.74.2) 1.534 ms 1.775 ms 1.961 ms\n    2 211.151.56.1 (211.151.56.1) 0.508 ms 0.514 ms 0.507 ms\n    3 211.151.227.206 (211.151.227.206) 0.571 ms 0.558 ms 0.550 ms\n    4 210.77.139.145 (210.77.139.145) 0.708 ms 0.729 ms 0.785 ms\n    5 202.106.42.101 (202.106.42.101) 7.978 ms 8.155 ms 8.311 ms\n    6 bt-228-037.bta.net.cn (202.106.228.37) 772.460 ms bt-228-025.bta.net.cn (202.106.228.25) 2.152 ms 61.148.154.97 (61.148.154.97) 772.107 ms\n    7 124.65.58.221 (124.65.58.221) 4.875 ms 61.148.146.29 (61.148.146.29) 2.124 ms 124.65.58.221 (124.65.58.221) 4.854 ms\n    8 123.126.6.198 (123.126.6.198) 2.944 ms 61.148.156.6 (61.148.156.6) 3.505 ms 123.126.6.198 (123.126.6.198) 2.885 ms\n    9 * * *\n    10 * * *\n    [root@localhost ~]#\n\n \n实例3：显示IP地址，不查主机名\n    命令：traceroute -n www.baidu.com\n    输出：\n    \n    复制代码\n    代码如下:\n    \n    [root@localhost ~]# traceroute -n www.baidu.com\n    traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n    1 211.151.74.2 5.430 ms 5.636 ms 5.802 ms\n    2 211.151.56.57 0.627 ms 0.625 ms 0.617 ms\n    3 211.151.227.206 0.575 ms 0.584 ms 0.576 ms\n    4 210.77.139.145 0.703 ms 0.754 ms 0.806 ms\n    5 202.106.42.101 23.683 ms 23.869 ms 23.998 ms\n    6 202.106.228.37 247.101 ms * *\n    7 61.148.146.29 5.256 ms 124.65.58.213 4.386 ms 4.373 ms\n    8 202.106.35.190 1.610 ms 61.148.156.138 1.786 ms 61.148.3.34 2.089 ms\n    9 * * *\n    30 * * *\n    [root@localhost ~]# traceroute www.baidu.com\n    traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n    1 211.151.74.2 (211.151.74.2) 4.671 ms 4.865 ms 5.055 ms\n    2 211.151.56.57 (211.151.56.57) 0.619 ms 0.618 ms 0.612 ms\n    3 211.151.227.206 (211.151.227.206) 0.620 ms 0.642 ms 0.636 ms\n    4 210.77.139.145 (210.77.139.145) 0.720 ms 0.772 ms 0.816 ms\n    5 202.106.42.101 (202.106.42.101) 7.667 ms 7.910 ms 8.012 ms\n    6 bt-228-025.bta.net.cn (202.106.228.25) 2.965 ms 2.440 ms 61.148.154.97 (61.148.154.97) 431.337 ms\n    7 124.65.58.213 (124.65.58.213) 5.134 ms 5.124 ms 5.044 ms\n    8 202.106.35.190 (202.106.35.190) 1.917 ms 2.052 ms 2.059 ms\n    9 * * *\n    30 * * *\n    [root@localhost ~]# \n实例4：探测包使用的基本UDP端口设置6888\n    命令：traceroute -p 6888 www.baidu.com\n    输出：\n    \n    复制代码\n    代码如下:\n    \n    [root@localhost ~]# traceroute -p 6888 www.baidu.com\n    traceroute to www.baidu.com (220.181.111.147), 30 hops max, 40 byte packets\n    1 211.151.74.2 (211.151.74.2) 4.927 ms 5.121 ms 5.298 ms\n    2 211.151.56.1 (211.151.56.1) 0.500 ms 0.499 ms 0.509 ms\n    3 211.151.224.90 (211.151.224.90) 0.637 ms 0.631 ms 0.641 ms\n    4 * * *\n    5 220.181.70.98 (220.181.70.98) 5.050 ms 5.313 ms 5.596 ms\n    6 220.181.17.94 (220.181.17.94) 1.665 ms !X * *\n    [root@localhost ~]# \n实例5：把探测包的个数设置为值4\n    命令：traceroute -q 4 www.baidu.com\n    输出：\n    \n    复制代码\n    代码如下:\n    \n    [root@localhost ~]# traceroute -q 4 www.baidu.com\n    traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n    1 211.151.74.2 (211.151.74.2) 40.633 ms 40.819 ms 41.004 ms 41.188 ms\n    2 211.151.56.57 (211.151.56.57) 0.637 ms 0.633 ms 0.627 ms 0.619 ms\n    3 211.151.227.206 (211.151.227.206) 0.505 ms 0.580 ms 0.571 ms 0.569 ms\n    4 210.77.139.145 (210.77.139.145) 0.753 ms 0.800 ms 0.853 ms 0.904 ms\n    5 202.106.42.101 (202.106.42.101) 7.449 ms 7.543 ms 7.738 ms 7.893 ms\n    6 61.148.154.97 (61.148.154.97) 316.817 ms bt-228-025.bta.net.cn (202.106.228.25) 3.695 ms 3.672 ms *\n    7 124.65.58.213 (124.65.58.213) 3.056 ms 2.993 ms 2.960 ms 61.148.146.29 (61.148.146.29) 2.837 ms\n    8 61.148.3.34 (61.148.3.34) 2.179 ms 2.295 ms 2.442 ms 202.106.35.190 (202.106.35.190) 7.136 ms\n    9 * * * *\n    30 * * * *\n    [root@localhost ~]# \n    \n实例6：绕过正常的路由表，直接发送到网络相连的主机\n    命令：traceroute -r www.baidu.com\n    输出：\n    \n    复制代码\n    代码如下:\n    \n    [root@localhost ~]# traceroute -r www.baidu.com\n    traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n    connect: 网络不可达\n    [root@localhost ~]# \n实例7：把对外发探测包的等待响应时间设置为3秒\n    命令：traceroute -w 3 www.baidu.com\n    输出：\n    \n    复制代码\n    代码如下:\n    \n    [root@localhost ~]# traceroute -w 3 www.baidu.com\n    traceroute to www.baidu.com (61.135.169.105), 30 hops max, 40 byte packets\n    1 211.151.74.2 (211.151.74.2) 2.306 ms 2.469 ms 2.650 ms\n    2 211.151.56.1 (211.151.56.1) 0.621 ms 0.613 ms 0.603 ms\n    3 211.151.227.206 (211.151.227.206) 0.557 ms 0.560 ms 0.552 ms\n    4 210.77.139.145 (210.77.139.145) 0.708 ms 0.761 ms 0.817 ms\n    5 202.106.42.101 (202.106.42.101) 7.520 ms 7.774 ms 7.902 ms\n    6 bt-228-025.bta.net.cn (202.106.228.25) 2.890 ms 2.369 ms 61.148.154.97 (61.148.154.97) 471.961 ms\n    7 124.65.58.221 (124.65.58.221) 4.490 ms 4.483 ms 4.472 ms\n    8 123.126.6.198 (123.126.6.198) 2.948 ms 61.148.156.6 (61.148.156.6) 7.688 ms 7.756 ms\n    9 * * *\n    30 * * *\n    [root@localhost ~]# \n\n###Traceroute的工作原理：  \nTraceroute最简单的基本用法是：traceroute hostname  \nTraceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器...... traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？  \nTraceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。\nTraceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。  \nwindows之tracert:  \n格式：  \n\n    tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name  \n参数说明：  \n\n    tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name  \n该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间     (TLS) 过期的报文并且对 tracert 无效。  \n\n    参数：  \n    -d 指定不对计算机名解析地址。  \n    -h maximum_hops 指定查找目标的跳转的最大数目。  \n    -jcomputer-list 指定在 computer-list 中松散源路由。  \n    -w timeout 等待由 timeout 对每个应答指定的毫秒数。  \n    target_name 目标计算机的名称。  \n实例：  \n\n复制代码  \n代码如下:  \n\n    C:\\Users\\Administrator>tracert www.58.com\n    Tracing route to www.58.com [221.187.111.30]\n    over a maximum of 30 hops:\n    1 1 ms 1 ms 1 ms 10.58.156.1\n    2 1 ms <1 ms <1 ms 10.10.10.1\n    3 1 ms 1 ms 1 ms 211.103.193.129\n    4 2 ms 2 ms 2 ms 10.255.109.129\n    5 1 ms 1 ms 3 ms 124.205.98.205\n    6 2 ms 2 ms 2 ms 124.205.98.253\n    7 2 ms 6 ms 1 ms 202.99.1.125\n    8 5 ms 6 ms 5 ms 118.186.0.113\n    9 207 ms * * 118.186.0.106\n    10 8 ms 6 ms 11 ms 124.238.226.201\n    11 6 ms 7 ms 6 ms 219.148.19.177\n    12 12 ms 12 ms 16 ms 219.148.18.117\n    13 14 ms 17 ms 16 ms 219.148.19.125\n    14 13 ms 13 ms 12 ms 202.97.80.113\n    15 * * * Request timed out.\n    16 12 ms 12 ms 17 ms bj141-147-82.bjtelecom.net [219.141.147.82]\n    17 13 ms 13 ms 12 ms 202.97.48.2\n    18 * * * Request timed out.\n    19 14 ms 14 ms 12 ms 221.187.224.85\n    20 15 ms 13 ms 12 ms 221.187.104.2\n    21 * * * Request timed out.\n    22 15 ms 17 ms 18 ms 221.187.111.30\n    Trace complete.\n","source":"_posts/linux_traceroute_命令详解.md","raw":"---\ntitle: 路由跟踪指令traceroute\ndate: 2016-11-03\ntags: traceroute\ncategories: linux\n---\n通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的\n<!--more-->\nlinux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。\n在大多数情况下，我们会在linux主机系统下，直接执行命令行：traceroute hostname\n而在Windows系统下是执行tracert的命令： tracert hostname  \n###1.命令格式：\n  \n    traceroute[参数][主机]\n###2.命令功能：\ntraceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。  \n具体参数格式：  \ntraceroute [-dFlnrvx][-f<存活数值>][-g<网关>...][-i<网络界面>][-m<存活数值>][-p<通信端口>][-s<来源地址>][-t<服务类型>][-w<超时秒数>][主机名称或IP地址][数据包大小]  \n###3.命令参数：\n    -d 使用Socket层级的排错功能。  \n    -f 设置第一个检测数据包的存活数值TTL的大小。  \n    -F 设置勿离断位。  \n    -g 设置来源路由网关，最多可设置8个。  \n    -i 使用指定的网络界面送出数据包。  \n    -I 使用ICMP回应取代UDP资料信息。  \n    -m 设置检测数据包的最大存活数值TTL的大小。  \n    -n 直接使用IP地址而非主机名称。  \n    -p 设置UDP传输协议的通信端口。  \n    -r 忽略普通的Routing Table，直接将数据包送到远端主机上。  \n    -s 设置本地主机送出数据包的IP地址。  \n    -t 设置检测数据包的TOS数值。  \n    -v 详细显示指令的执行过程。  \n    -w 设置等待远端主机回报的时间。  \n    -x 开启或关闭数据包的正确性检验。  \n###4.使用实例：\n实例1：traceroute 用法简单、最常用的用法\n命令：traceroute www.baidu.com \n输出：\n\n复制代码\n代码如下:\n\n    [root@localhost ~]# traceroute www.baidu.com  \n    traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets  \n    1 192.168.74.2 (192.168.74.2) 2.606 ms 2.771 ms 2.950 ms\n    2 211.151.56.57 (211.151.56.57) 0.596 ms 0.598 ms 0.591 ms\n    3 211.151.227.206 (211.151.227.206) 0.546 ms 0.544 ms 0.538 ms\n    4 210.77.139.145 (210.77.139.145) 0.710 ms 0.748 ms 0.801 ms\n    5 202.106.42.101 (202.106.42.101) 6.759 ms 6.945 ms 7.107 ms\n    6 61.148.154.97 (61.148.154.97) 718.908 ms * bt-228-025.bta.net.cn (202.106.228.25) 5.177 ms\n    7 124.65.58.213 (124.65.58.213) 4.343 ms 4.336 ms 4.367 ms\n    8 202.106.35.190 (202.106.35.190) 1.795 ms 61.148.156.138 (61.148.156.138) 1.899 ms 1.951 ms\n    9 * * *\n    30 * * *\n    [root@localhost ~]# \n    说明：  \n    记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。      \n    有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。\n    有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。\n    如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。\n\n实例2：跳数设置\n    命令：traceroute -m 10 www.baidu.com\n    输出：\n    \n    复制代码\n    代码如下:\n    \n    [root@localhost ~]# traceroute -m 10 www.baidu.com\n    traceroute to www.baidu.com (61.135.169.105), 10 hops max, 40 byte packets\n    1 192.168.74.2 (192.168.74.2) 1.534 ms 1.775 ms 1.961 ms\n    2 211.151.56.1 (211.151.56.1) 0.508 ms 0.514 ms 0.507 ms\n    3 211.151.227.206 (211.151.227.206) 0.571 ms 0.558 ms 0.550 ms\n    4 210.77.139.145 (210.77.139.145) 0.708 ms 0.729 ms 0.785 ms\n    5 202.106.42.101 (202.106.42.101) 7.978 ms 8.155 ms 8.311 ms\n    6 bt-228-037.bta.net.cn (202.106.228.37) 772.460 ms bt-228-025.bta.net.cn (202.106.228.25) 2.152 ms 61.148.154.97 (61.148.154.97) 772.107 ms\n    7 124.65.58.221 (124.65.58.221) 4.875 ms 61.148.146.29 (61.148.146.29) 2.124 ms 124.65.58.221 (124.65.58.221) 4.854 ms\n    8 123.126.6.198 (123.126.6.198) 2.944 ms 61.148.156.6 (61.148.156.6) 3.505 ms 123.126.6.198 (123.126.6.198) 2.885 ms\n    9 * * *\n    10 * * *\n    [root@localhost ~]#\n\n \n实例3：显示IP地址，不查主机名\n    命令：traceroute -n www.baidu.com\n    输出：\n    \n    复制代码\n    代码如下:\n    \n    [root@localhost ~]# traceroute -n www.baidu.com\n    traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n    1 211.151.74.2 5.430 ms 5.636 ms 5.802 ms\n    2 211.151.56.57 0.627 ms 0.625 ms 0.617 ms\n    3 211.151.227.206 0.575 ms 0.584 ms 0.576 ms\n    4 210.77.139.145 0.703 ms 0.754 ms 0.806 ms\n    5 202.106.42.101 23.683 ms 23.869 ms 23.998 ms\n    6 202.106.228.37 247.101 ms * *\n    7 61.148.146.29 5.256 ms 124.65.58.213 4.386 ms 4.373 ms\n    8 202.106.35.190 1.610 ms 61.148.156.138 1.786 ms 61.148.3.34 2.089 ms\n    9 * * *\n    30 * * *\n    [root@localhost ~]# traceroute www.baidu.com\n    traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n    1 211.151.74.2 (211.151.74.2) 4.671 ms 4.865 ms 5.055 ms\n    2 211.151.56.57 (211.151.56.57) 0.619 ms 0.618 ms 0.612 ms\n    3 211.151.227.206 (211.151.227.206) 0.620 ms 0.642 ms 0.636 ms\n    4 210.77.139.145 (210.77.139.145) 0.720 ms 0.772 ms 0.816 ms\n    5 202.106.42.101 (202.106.42.101) 7.667 ms 7.910 ms 8.012 ms\n    6 bt-228-025.bta.net.cn (202.106.228.25) 2.965 ms 2.440 ms 61.148.154.97 (61.148.154.97) 431.337 ms\n    7 124.65.58.213 (124.65.58.213) 5.134 ms 5.124 ms 5.044 ms\n    8 202.106.35.190 (202.106.35.190) 1.917 ms 2.052 ms 2.059 ms\n    9 * * *\n    30 * * *\n    [root@localhost ~]# \n实例4：探测包使用的基本UDP端口设置6888\n    命令：traceroute -p 6888 www.baidu.com\n    输出：\n    \n    复制代码\n    代码如下:\n    \n    [root@localhost ~]# traceroute -p 6888 www.baidu.com\n    traceroute to www.baidu.com (220.181.111.147), 30 hops max, 40 byte packets\n    1 211.151.74.2 (211.151.74.2) 4.927 ms 5.121 ms 5.298 ms\n    2 211.151.56.1 (211.151.56.1) 0.500 ms 0.499 ms 0.509 ms\n    3 211.151.224.90 (211.151.224.90) 0.637 ms 0.631 ms 0.641 ms\n    4 * * *\n    5 220.181.70.98 (220.181.70.98) 5.050 ms 5.313 ms 5.596 ms\n    6 220.181.17.94 (220.181.17.94) 1.665 ms !X * *\n    [root@localhost ~]# \n实例5：把探测包的个数设置为值4\n    命令：traceroute -q 4 www.baidu.com\n    输出：\n    \n    复制代码\n    代码如下:\n    \n    [root@localhost ~]# traceroute -q 4 www.baidu.com\n    traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n    1 211.151.74.2 (211.151.74.2) 40.633 ms 40.819 ms 41.004 ms 41.188 ms\n    2 211.151.56.57 (211.151.56.57) 0.637 ms 0.633 ms 0.627 ms 0.619 ms\n    3 211.151.227.206 (211.151.227.206) 0.505 ms 0.580 ms 0.571 ms 0.569 ms\n    4 210.77.139.145 (210.77.139.145) 0.753 ms 0.800 ms 0.853 ms 0.904 ms\n    5 202.106.42.101 (202.106.42.101) 7.449 ms 7.543 ms 7.738 ms 7.893 ms\n    6 61.148.154.97 (61.148.154.97) 316.817 ms bt-228-025.bta.net.cn (202.106.228.25) 3.695 ms 3.672 ms *\n    7 124.65.58.213 (124.65.58.213) 3.056 ms 2.993 ms 2.960 ms 61.148.146.29 (61.148.146.29) 2.837 ms\n    8 61.148.3.34 (61.148.3.34) 2.179 ms 2.295 ms 2.442 ms 202.106.35.190 (202.106.35.190) 7.136 ms\n    9 * * * *\n    30 * * * *\n    [root@localhost ~]# \n    \n实例6：绕过正常的路由表，直接发送到网络相连的主机\n    命令：traceroute -r www.baidu.com\n    输出：\n    \n    复制代码\n    代码如下:\n    \n    [root@localhost ~]# traceroute -r www.baidu.com\n    traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n    connect: 网络不可达\n    [root@localhost ~]# \n实例7：把对外发探测包的等待响应时间设置为3秒\n    命令：traceroute -w 3 www.baidu.com\n    输出：\n    \n    复制代码\n    代码如下:\n    \n    [root@localhost ~]# traceroute -w 3 www.baidu.com\n    traceroute to www.baidu.com (61.135.169.105), 30 hops max, 40 byte packets\n    1 211.151.74.2 (211.151.74.2) 2.306 ms 2.469 ms 2.650 ms\n    2 211.151.56.1 (211.151.56.1) 0.621 ms 0.613 ms 0.603 ms\n    3 211.151.227.206 (211.151.227.206) 0.557 ms 0.560 ms 0.552 ms\n    4 210.77.139.145 (210.77.139.145) 0.708 ms 0.761 ms 0.817 ms\n    5 202.106.42.101 (202.106.42.101) 7.520 ms 7.774 ms 7.902 ms\n    6 bt-228-025.bta.net.cn (202.106.228.25) 2.890 ms 2.369 ms 61.148.154.97 (61.148.154.97) 471.961 ms\n    7 124.65.58.221 (124.65.58.221) 4.490 ms 4.483 ms 4.472 ms\n    8 123.126.6.198 (123.126.6.198) 2.948 ms 61.148.156.6 (61.148.156.6) 7.688 ms 7.756 ms\n    9 * * *\n    30 * * *\n    [root@localhost ~]# \n\n###Traceroute的工作原理：  \nTraceroute最简单的基本用法是：traceroute hostname  \nTraceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器...... traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？  \nTraceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。\nTraceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。  \nwindows之tracert:  \n格式：  \n\n    tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name  \n参数说明：  \n\n    tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name  \n该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间     (TLS) 过期的报文并且对 tracert 无效。  \n\n    参数：  \n    -d 指定不对计算机名解析地址。  \n    -h maximum_hops 指定查找目标的跳转的最大数目。  \n    -jcomputer-list 指定在 computer-list 中松散源路由。  \n    -w timeout 等待由 timeout 对每个应答指定的毫秒数。  \n    target_name 目标计算机的名称。  \n实例：  \n\n复制代码  \n代码如下:  \n\n    C:\\Users\\Administrator>tracert www.58.com\n    Tracing route to www.58.com [221.187.111.30]\n    over a maximum of 30 hops:\n    1 1 ms 1 ms 1 ms 10.58.156.1\n    2 1 ms <1 ms <1 ms 10.10.10.1\n    3 1 ms 1 ms 1 ms 211.103.193.129\n    4 2 ms 2 ms 2 ms 10.255.109.129\n    5 1 ms 1 ms 3 ms 124.205.98.205\n    6 2 ms 2 ms 2 ms 124.205.98.253\n    7 2 ms 6 ms 1 ms 202.99.1.125\n    8 5 ms 6 ms 5 ms 118.186.0.113\n    9 207 ms * * 118.186.0.106\n    10 8 ms 6 ms 11 ms 124.238.226.201\n    11 6 ms 7 ms 6 ms 219.148.19.177\n    12 12 ms 12 ms 16 ms 219.148.18.117\n    13 14 ms 17 ms 16 ms 219.148.19.125\n    14 13 ms 13 ms 12 ms 202.97.80.113\n    15 * * * Request timed out.\n    16 12 ms 12 ms 17 ms bj141-147-82.bjtelecom.net [219.141.147.82]\n    17 13 ms 13 ms 12 ms 202.97.48.2\n    18 * * * Request timed out.\n    19 14 ms 14 ms 12 ms 221.187.224.85\n    20 15 ms 13 ms 12 ms 221.187.104.2\n    21 * * * Request timed out.\n    22 15 ms 17 ms 18 ms 221.187.111.30\n    Trace complete.\n","slug":"linux_traceroute_命令详解","published":1,"updated":"2019-06-18T08:07:01.114Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sk7000xhcb76ot0mwl2","content":"<p>通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的<br><a id=\"more\"></a><br>linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。<br>在大多数情况下，我们会在linux主机系统下，直接执行命令行：traceroute hostname<br>而在Windows系统下是执行tracert的命令： tracert hostname  </p>\n<p>###1.命令格式：</p>\n<pre><code>traceroute[参数][主机]\n</code></pre><p>###2.命令功能：<br>traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。<br>具体参数格式：<br>traceroute [-dFlnrvx][-f&lt;存活数值&gt;][-g&lt;网关&gt;…][-i&lt;网络界面&gt;][-m&lt;存活数值&gt;][-p&lt;通信端口&gt;][-s&lt;来源地址&gt;][-t&lt;服务类型&gt;][-w&lt;超时秒数&gt;][主机名称或IP地址][数据包大小]  </p>\n<p>###3.命令参数：<br>    -d 使用Socket层级的排错功能。<br>    -f 设置第一个检测数据包的存活数值TTL的大小。<br>    -F 设置勿离断位。<br>    -g 设置来源路由网关，最多可设置8个。<br>    -i 使用指定的网络界面送出数据包。<br>    -I 使用ICMP回应取代UDP资料信息。<br>    -m 设置检测数据包的最大存活数值TTL的大小。<br>    -n 直接使用IP地址而非主机名称。<br>    -p 设置UDP传输协议的通信端口。<br>    -r 忽略普通的Routing Table，直接将数据包送到远端主机上。<br>    -s 设置本地主机送出数据包的IP地址。<br>    -t 设置检测数据包的TOS数值。<br>    -v 详细显示指令的执行过程。<br>    -w 设置等待远端主机回报的时间。<br>    -x 开启或关闭数据包的正确性检验。  </p>\n<p>###4.使用实例：<br>实例1：traceroute 用法简单、最常用的用法<br>命令：traceroute <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<pre><code>[root@localhost ~]# traceroute www.baidu.com  \ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets  \n1 192.168.74.2 (192.168.74.2) 2.606 ms 2.771 ms 2.950 ms\n2 211.151.56.57 (211.151.56.57) 0.596 ms 0.598 ms 0.591 ms\n3 211.151.227.206 (211.151.227.206) 0.546 ms 0.544 ms 0.538 ms\n4 210.77.139.145 (210.77.139.145) 0.710 ms 0.748 ms 0.801 ms\n5 202.106.42.101 (202.106.42.101) 6.759 ms 6.945 ms 7.107 ms\n6 61.148.154.97 (61.148.154.97) 718.908 ms * bt-228-025.bta.net.cn (202.106.228.25) 5.177 ms\n7 124.65.58.213 (124.65.58.213) 4.343 ms 4.336 ms 4.367 ms\n8 202.106.35.190 (202.106.35.190) 1.795 ms 61.148.156.138 (61.148.156.138) 1.899 ms 1.951 ms\n9 * * *\n30 * * *\n[root@localhost ~]# \n说明：  \n记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。      \n有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。\n有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。\n如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。\n</code></pre><p>实例2：跳数设置<br>    命令：traceroute -m 10 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>    输出：</p>\n<pre><code>复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -m 10 www.baidu.com\ntraceroute to www.baidu.com (61.135.169.105), 10 hops max, 40 byte packets\n1 192.168.74.2 (192.168.74.2) 1.534 ms 1.775 ms 1.961 ms\n2 211.151.56.1 (211.151.56.1) 0.508 ms 0.514 ms 0.507 ms\n3 211.151.227.206 (211.151.227.206) 0.571 ms 0.558 ms 0.550 ms\n4 210.77.139.145 (210.77.139.145) 0.708 ms 0.729 ms 0.785 ms\n5 202.106.42.101 (202.106.42.101) 7.978 ms 8.155 ms 8.311 ms\n6 bt-228-037.bta.net.cn (202.106.228.37) 772.460 ms bt-228-025.bta.net.cn (202.106.228.25) 2.152 ms 61.148.154.97 (61.148.154.97) 772.107 ms\n7 124.65.58.221 (124.65.58.221) 4.875 ms 61.148.146.29 (61.148.146.29) 2.124 ms 124.65.58.221 (124.65.58.221) 4.854 ms\n8 123.126.6.198 (123.126.6.198) 2.944 ms 61.148.156.6 (61.148.156.6) 3.505 ms 123.126.6.198 (123.126.6.198) 2.885 ms\n9 * * *\n10 * * *\n[root@localhost ~]#\n</code></pre><p>实例3：显示IP地址，不查主机名<br>    命令：traceroute -n <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>    输出：</p>\n<pre><code>复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -n www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 211.151.74.2 5.430 ms 5.636 ms 5.802 ms\n2 211.151.56.57 0.627 ms 0.625 ms 0.617 ms\n3 211.151.227.206 0.575 ms 0.584 ms 0.576 ms\n4 210.77.139.145 0.703 ms 0.754 ms 0.806 ms\n5 202.106.42.101 23.683 ms 23.869 ms 23.998 ms\n6 202.106.228.37 247.101 ms * *\n7 61.148.146.29 5.256 ms 124.65.58.213 4.386 ms 4.373 ms\n8 202.106.35.190 1.610 ms 61.148.156.138 1.786 ms 61.148.3.34 2.089 ms\n9 * * *\n30 * * *\n[root@localhost ~]# traceroute www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 4.671 ms 4.865 ms 5.055 ms\n2 211.151.56.57 (211.151.56.57) 0.619 ms 0.618 ms 0.612 ms\n3 211.151.227.206 (211.151.227.206) 0.620 ms 0.642 ms 0.636 ms\n4 210.77.139.145 (210.77.139.145) 0.720 ms 0.772 ms 0.816 ms\n5 202.106.42.101 (202.106.42.101) 7.667 ms 7.910 ms 8.012 ms\n6 bt-228-025.bta.net.cn (202.106.228.25) 2.965 ms 2.440 ms 61.148.154.97 (61.148.154.97) 431.337 ms\n7 124.65.58.213 (124.65.58.213) 5.134 ms 5.124 ms 5.044 ms\n8 202.106.35.190 (202.106.35.190) 1.917 ms 2.052 ms 2.059 ms\n9 * * *\n30 * * *\n[root@localhost ~]# \n</code></pre><p>实例4：探测包使用的基本UDP端口设置6888<br>    命令：traceroute -p 6888 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>    输出：</p>\n<pre><code>复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -p 6888 www.baidu.com\ntraceroute to www.baidu.com (220.181.111.147), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 4.927 ms 5.121 ms 5.298 ms\n2 211.151.56.1 (211.151.56.1) 0.500 ms 0.499 ms 0.509 ms\n3 211.151.224.90 (211.151.224.90) 0.637 ms 0.631 ms 0.641 ms\n4 * * *\n5 220.181.70.98 (220.181.70.98) 5.050 ms 5.313 ms 5.596 ms\n6 220.181.17.94 (220.181.17.94) 1.665 ms !X * *\n[root@localhost ~]# \n</code></pre><p>实例5：把探测包的个数设置为值4<br>    命令：traceroute -q 4 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>    输出：</p>\n<pre><code>复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -q 4 www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 40.633 ms 40.819 ms 41.004 ms 41.188 ms\n2 211.151.56.57 (211.151.56.57) 0.637 ms 0.633 ms 0.627 ms 0.619 ms\n3 211.151.227.206 (211.151.227.206) 0.505 ms 0.580 ms 0.571 ms 0.569 ms\n4 210.77.139.145 (210.77.139.145) 0.753 ms 0.800 ms 0.853 ms 0.904 ms\n5 202.106.42.101 (202.106.42.101) 7.449 ms 7.543 ms 7.738 ms 7.893 ms\n6 61.148.154.97 (61.148.154.97) 316.817 ms bt-228-025.bta.net.cn (202.106.228.25) 3.695 ms 3.672 ms *\n7 124.65.58.213 (124.65.58.213) 3.056 ms 2.993 ms 2.960 ms 61.148.146.29 (61.148.146.29) 2.837 ms\n8 61.148.3.34 (61.148.3.34) 2.179 ms 2.295 ms 2.442 ms 202.106.35.190 (202.106.35.190) 7.136 ms\n9 * * * *\n30 * * * *\n[root@localhost ~]# \n</code></pre><p>实例6：绕过正常的路由表，直接发送到网络相连的主机<br>    命令：traceroute -r <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>    输出：</p>\n<pre><code>复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -r www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\nconnect: 网络不可达\n[root@localhost ~]# \n</code></pre><p>实例7：把对外发探测包的等待响应时间设置为3秒<br>    命令：traceroute -w 3 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>    输出：</p>\n<pre><code>复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -w 3 www.baidu.com\ntraceroute to www.baidu.com (61.135.169.105), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 2.306 ms 2.469 ms 2.650 ms\n2 211.151.56.1 (211.151.56.1) 0.621 ms 0.613 ms 0.603 ms\n3 211.151.227.206 (211.151.227.206) 0.557 ms 0.560 ms 0.552 ms\n4 210.77.139.145 (210.77.139.145) 0.708 ms 0.761 ms 0.817 ms\n5 202.106.42.101 (202.106.42.101) 7.520 ms 7.774 ms 7.902 ms\n6 bt-228-025.bta.net.cn (202.106.228.25) 2.890 ms 2.369 ms 61.148.154.97 (61.148.154.97) 471.961 ms\n7 124.65.58.221 (124.65.58.221) 4.490 ms 4.483 ms 4.472 ms\n8 123.126.6.198 (123.126.6.198) 2.948 ms 61.148.156.6 (61.148.156.6) 7.688 ms 7.756 ms\n9 * * *\n30 * * *\n[root@localhost ~]# \n</code></pre><p>###Traceroute的工作原理：<br>Traceroute最简单的基本用法是：traceroute hostname<br>Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器…… traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？<br>Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。<br>Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。<br>windows之tracert:<br>格式：  </p>\n<pre><code>tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name  \n</code></pre><p>参数说明：  </p>\n<pre><code>tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name  \n</code></pre><p>该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间     (TLS) 过期的报文并且对 tracert 无效。  </p>\n<pre><code>参数：  \n-d 指定不对计算机名解析地址。  \n-h maximum_hops 指定查找目标的跳转的最大数目。  \n-jcomputer-list 指定在 computer-list 中松散源路由。  \n-w timeout 等待由 timeout 对每个应答指定的毫秒数。  \ntarget_name 目标计算机的名称。  \n</code></pre><p>实例：  </p>\n<p>复制代码<br>代码如下:  </p>\n<pre><code>C:\\Users\\Administrator&gt;tracert www.58.com\nTracing route to www.58.com [221.187.111.30]\nover a maximum of 30 hops:\n1 1 ms 1 ms 1 ms 10.58.156.1\n2 1 ms &lt;1 ms &lt;1 ms 10.10.10.1\n3 1 ms 1 ms 1 ms 211.103.193.129\n4 2 ms 2 ms 2 ms 10.255.109.129\n5 1 ms 1 ms 3 ms 124.205.98.205\n6 2 ms 2 ms 2 ms 124.205.98.253\n7 2 ms 6 ms 1 ms 202.99.1.125\n8 5 ms 6 ms 5 ms 118.186.0.113\n9 207 ms * * 118.186.0.106\n10 8 ms 6 ms 11 ms 124.238.226.201\n11 6 ms 7 ms 6 ms 219.148.19.177\n12 12 ms 12 ms 16 ms 219.148.18.117\n13 14 ms 17 ms 16 ms 219.148.19.125\n14 13 ms 13 ms 12 ms 202.97.80.113\n15 * * * Request timed out.\n16 12 ms 12 ms 17 ms bj141-147-82.bjtelecom.net [219.141.147.82]\n17 13 ms 13 ms 12 ms 202.97.48.2\n18 * * * Request timed out.\n19 14 ms 14 ms 12 ms 221.187.224.85\n20 15 ms 13 ms 12 ms 221.187.104.2\n21 * * * Request timed out.\n22 15 ms 17 ms 18 ms 221.187.111.30\nTrace complete.\n</code></pre>","site":{"data":{}},"excerpt":"<p>通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的<br>","more":"<br>linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。<br>在大多数情况下，我们会在linux主机系统下，直接执行命令行：traceroute hostname<br>而在Windows系统下是执行tracert的命令： tracert hostname  </p>\n<p>###1.命令格式：</p>\n<pre><code>traceroute[参数][主机]\n</code></pre><p>###2.命令功能：<br>traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。<br>具体参数格式：<br>traceroute [-dFlnrvx][-f&lt;存活数值&gt;][-g&lt;网关&gt;…][-i&lt;网络界面&gt;][-m&lt;存活数值&gt;][-p&lt;通信端口&gt;][-s&lt;来源地址&gt;][-t&lt;服务类型&gt;][-w&lt;超时秒数&gt;][主机名称或IP地址][数据包大小]  </p>\n<p>###3.命令参数：<br>    -d 使用Socket层级的排错功能。<br>    -f 设置第一个检测数据包的存活数值TTL的大小。<br>    -F 设置勿离断位。<br>    -g 设置来源路由网关，最多可设置8个。<br>    -i 使用指定的网络界面送出数据包。<br>    -I 使用ICMP回应取代UDP资料信息。<br>    -m 设置检测数据包的最大存活数值TTL的大小。<br>    -n 直接使用IP地址而非主机名称。<br>    -p 设置UDP传输协议的通信端口。<br>    -r 忽略普通的Routing Table，直接将数据包送到远端主机上。<br>    -s 设置本地主机送出数据包的IP地址。<br>    -t 设置检测数据包的TOS数值。<br>    -v 详细显示指令的执行过程。<br>    -w 设置等待远端主机回报的时间。<br>    -x 开启或关闭数据包的正确性检验。  </p>\n<p>###4.使用实例：<br>实例1：traceroute 用法简单、最常用的用法<br>命令：traceroute <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>输出：</p>\n<p>复制代码<br>代码如下:</p>\n<pre><code>[root@localhost ~]# traceroute www.baidu.com  \ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets  \n1 192.168.74.2 (192.168.74.2) 2.606 ms 2.771 ms 2.950 ms\n2 211.151.56.57 (211.151.56.57) 0.596 ms 0.598 ms 0.591 ms\n3 211.151.227.206 (211.151.227.206) 0.546 ms 0.544 ms 0.538 ms\n4 210.77.139.145 (210.77.139.145) 0.710 ms 0.748 ms 0.801 ms\n5 202.106.42.101 (202.106.42.101) 6.759 ms 6.945 ms 7.107 ms\n6 61.148.154.97 (61.148.154.97) 718.908 ms * bt-228-025.bta.net.cn (202.106.228.25) 5.177 ms\n7 124.65.58.213 (124.65.58.213) 4.343 ms 4.336 ms 4.367 ms\n8 202.106.35.190 (202.106.35.190) 1.795 ms 61.148.156.138 (61.148.156.138) 1.899 ms 1.951 ms\n9 * * *\n30 * * *\n[root@localhost ~]# \n说明：  \n记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。      \n有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。\n有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。\n如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。\n</code></pre><p>实例2：跳数设置<br>    命令：traceroute -m 10 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>    输出：</p>\n<pre><code>复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -m 10 www.baidu.com\ntraceroute to www.baidu.com (61.135.169.105), 10 hops max, 40 byte packets\n1 192.168.74.2 (192.168.74.2) 1.534 ms 1.775 ms 1.961 ms\n2 211.151.56.1 (211.151.56.1) 0.508 ms 0.514 ms 0.507 ms\n3 211.151.227.206 (211.151.227.206) 0.571 ms 0.558 ms 0.550 ms\n4 210.77.139.145 (210.77.139.145) 0.708 ms 0.729 ms 0.785 ms\n5 202.106.42.101 (202.106.42.101) 7.978 ms 8.155 ms 8.311 ms\n6 bt-228-037.bta.net.cn (202.106.228.37) 772.460 ms bt-228-025.bta.net.cn (202.106.228.25) 2.152 ms 61.148.154.97 (61.148.154.97) 772.107 ms\n7 124.65.58.221 (124.65.58.221) 4.875 ms 61.148.146.29 (61.148.146.29) 2.124 ms 124.65.58.221 (124.65.58.221) 4.854 ms\n8 123.126.6.198 (123.126.6.198) 2.944 ms 61.148.156.6 (61.148.156.6) 3.505 ms 123.126.6.198 (123.126.6.198) 2.885 ms\n9 * * *\n10 * * *\n[root@localhost ~]#\n</code></pre><p>实例3：显示IP地址，不查主机名<br>    命令：traceroute -n <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>    输出：</p>\n<pre><code>复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -n www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 211.151.74.2 5.430 ms 5.636 ms 5.802 ms\n2 211.151.56.57 0.627 ms 0.625 ms 0.617 ms\n3 211.151.227.206 0.575 ms 0.584 ms 0.576 ms\n4 210.77.139.145 0.703 ms 0.754 ms 0.806 ms\n5 202.106.42.101 23.683 ms 23.869 ms 23.998 ms\n6 202.106.228.37 247.101 ms * *\n7 61.148.146.29 5.256 ms 124.65.58.213 4.386 ms 4.373 ms\n8 202.106.35.190 1.610 ms 61.148.156.138 1.786 ms 61.148.3.34 2.089 ms\n9 * * *\n30 * * *\n[root@localhost ~]# traceroute www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 4.671 ms 4.865 ms 5.055 ms\n2 211.151.56.57 (211.151.56.57) 0.619 ms 0.618 ms 0.612 ms\n3 211.151.227.206 (211.151.227.206) 0.620 ms 0.642 ms 0.636 ms\n4 210.77.139.145 (210.77.139.145) 0.720 ms 0.772 ms 0.816 ms\n5 202.106.42.101 (202.106.42.101) 7.667 ms 7.910 ms 8.012 ms\n6 bt-228-025.bta.net.cn (202.106.228.25) 2.965 ms 2.440 ms 61.148.154.97 (61.148.154.97) 431.337 ms\n7 124.65.58.213 (124.65.58.213) 5.134 ms 5.124 ms 5.044 ms\n8 202.106.35.190 (202.106.35.190) 1.917 ms 2.052 ms 2.059 ms\n9 * * *\n30 * * *\n[root@localhost ~]# \n</code></pre><p>实例4：探测包使用的基本UDP端口设置6888<br>    命令：traceroute -p 6888 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>    输出：</p>\n<pre><code>复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -p 6888 www.baidu.com\ntraceroute to www.baidu.com (220.181.111.147), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 4.927 ms 5.121 ms 5.298 ms\n2 211.151.56.1 (211.151.56.1) 0.500 ms 0.499 ms 0.509 ms\n3 211.151.224.90 (211.151.224.90) 0.637 ms 0.631 ms 0.641 ms\n4 * * *\n5 220.181.70.98 (220.181.70.98) 5.050 ms 5.313 ms 5.596 ms\n6 220.181.17.94 (220.181.17.94) 1.665 ms !X * *\n[root@localhost ~]# \n</code></pre><p>实例5：把探测包的个数设置为值4<br>    命令：traceroute -q 4 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>    输出：</p>\n<pre><code>复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -q 4 www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 40.633 ms 40.819 ms 41.004 ms 41.188 ms\n2 211.151.56.57 (211.151.56.57) 0.637 ms 0.633 ms 0.627 ms 0.619 ms\n3 211.151.227.206 (211.151.227.206) 0.505 ms 0.580 ms 0.571 ms 0.569 ms\n4 210.77.139.145 (210.77.139.145) 0.753 ms 0.800 ms 0.853 ms 0.904 ms\n5 202.106.42.101 (202.106.42.101) 7.449 ms 7.543 ms 7.738 ms 7.893 ms\n6 61.148.154.97 (61.148.154.97) 316.817 ms bt-228-025.bta.net.cn (202.106.228.25) 3.695 ms 3.672 ms *\n7 124.65.58.213 (124.65.58.213) 3.056 ms 2.993 ms 2.960 ms 61.148.146.29 (61.148.146.29) 2.837 ms\n8 61.148.3.34 (61.148.3.34) 2.179 ms 2.295 ms 2.442 ms 202.106.35.190 (202.106.35.190) 7.136 ms\n9 * * * *\n30 * * * *\n[root@localhost ~]# \n</code></pre><p>实例6：绕过正常的路由表，直接发送到网络相连的主机<br>    命令：traceroute -r <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>    输出：</p>\n<pre><code>复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -r www.baidu.com\ntraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets\nconnect: 网络不可达\n[root@localhost ~]# \n</code></pre><p>实例7：把对外发探测包的等待响应时间设置为3秒<br>    命令：traceroute -w 3 <a href=\"http://www.baidu.com\" target=\"_blank\" rel=\"noopener\">www.baidu.com</a><br>    输出：</p>\n<pre><code>复制代码\n代码如下:\n\n[root@localhost ~]# traceroute -w 3 www.baidu.com\ntraceroute to www.baidu.com (61.135.169.105), 30 hops max, 40 byte packets\n1 211.151.74.2 (211.151.74.2) 2.306 ms 2.469 ms 2.650 ms\n2 211.151.56.1 (211.151.56.1) 0.621 ms 0.613 ms 0.603 ms\n3 211.151.227.206 (211.151.227.206) 0.557 ms 0.560 ms 0.552 ms\n4 210.77.139.145 (210.77.139.145) 0.708 ms 0.761 ms 0.817 ms\n5 202.106.42.101 (202.106.42.101) 7.520 ms 7.774 ms 7.902 ms\n6 bt-228-025.bta.net.cn (202.106.228.25) 2.890 ms 2.369 ms 61.148.154.97 (61.148.154.97) 471.961 ms\n7 124.65.58.221 (124.65.58.221) 4.490 ms 4.483 ms 4.472 ms\n8 123.126.6.198 (123.126.6.198) 2.948 ms 61.148.156.6 (61.148.156.6) 7.688 ms 7.756 ms\n9 * * *\n30 * * *\n[root@localhost ~]# \n</code></pre><p>###Traceroute的工作原理：<br>Traceroute最简单的基本用法是：traceroute hostname<br>Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器…… traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？<br>Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。<br>Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。<br>windows之tracert:<br>格式：  </p>\n<pre><code>tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name  \n</code></pre><p>参数说明：  </p>\n<pre><code>tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name  \n</code></pre><p>该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间     (TLS) 过期的报文并且对 tracert 无效。  </p>\n<pre><code>参数：  \n-d 指定不对计算机名解析地址。  \n-h maximum_hops 指定查找目标的跳转的最大数目。  \n-jcomputer-list 指定在 computer-list 中松散源路由。  \n-w timeout 等待由 timeout 对每个应答指定的毫秒数。  \ntarget_name 目标计算机的名称。  \n</code></pre><p>实例：  </p>\n<p>复制代码<br>代码如下:  </p>\n<pre><code>C:\\Users\\Administrator&gt;tracert www.58.com\nTracing route to www.58.com [221.187.111.30]\nover a maximum of 30 hops:\n1 1 ms 1 ms 1 ms 10.58.156.1\n2 1 ms &lt;1 ms &lt;1 ms 10.10.10.1\n3 1 ms 1 ms 1 ms 211.103.193.129\n4 2 ms 2 ms 2 ms 10.255.109.129\n5 1 ms 1 ms 3 ms 124.205.98.205\n6 2 ms 2 ms 2 ms 124.205.98.253\n7 2 ms 6 ms 1 ms 202.99.1.125\n8 5 ms 6 ms 5 ms 118.186.0.113\n9 207 ms * * 118.186.0.106\n10 8 ms 6 ms 11 ms 124.238.226.201\n11 6 ms 7 ms 6 ms 219.148.19.177\n12 12 ms 12 ms 16 ms 219.148.18.117\n13 14 ms 17 ms 16 ms 219.148.19.125\n14 13 ms 13 ms 12 ms 202.97.80.113\n15 * * * Request timed out.\n16 12 ms 12 ms 17 ms bj141-147-82.bjtelecom.net [219.141.147.82]\n17 13 ms 13 ms 12 ms 202.97.48.2\n18 * * * Request timed out.\n19 14 ms 14 ms 12 ms 221.187.224.85\n20 15 ms 13 ms 12 ms 221.187.104.2\n21 * * * Request timed out.\n22 15 ms 17 ms 18 ms 221.187.111.30\nTrace complete.\n</code></pre>"},{"title":"linux 下同步工具inotify + rsync 使用详解","date":"2017-09-13T04:00:00.000Z","_content":"## rsynv\n<!--more-->\n\n### 什么是rsync\n\nrsync是一个远程数据同步工具，可以通过LAN/WAN快速同步多台主机之间的文件。它使用所谓的“Rsync演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。所以通常可以作为备份工具来使用。\n\n运行Rsync server的机器也叫backup server，一个Rsync server可同时备份多个client的数据；也可以多个Rsync server备份一个client的数据。Rsync可以搭配ssh甚至使用daemon模式。Rsync server会打开一个873的服务通道（port），等待对方rsync连接。连接时，Rsync server会检查口令是否相符，若通过口令查核，则可以开始进行文件传输。第一次联通完成时，会把整份文件传输一次，下一次就只会传送两个文件之间不同的部分。\n\n#### 基本特点：\n\n1.可以镜像保存整个目录树和文件系统；\n\n2.可以很容易做到保持原来文件的权限、时间、软硬连接等；\n\n3.无需特殊权限即可安装；\n\n4.优化的流程，文件传输效率高；\n\n5.可以使用rcp，ssh等方式来传输文件，当然也可以通过直接的socket连接；\n\n6.支持匿名传输。\n\n#### 命令语法：\n\nrsync的命令格式可以分为以下六种：\n\n\trsync [OPTION]... SRC DEST\n\trsync [OPTION]... SRC [USER@]HOST:DEST\n\trsync [OPTION]... [USER@]HOST:SRC DEST\n\trsync [OPTION]... [USER@]HOST::SRC DEST\n\trsync [OPTION]... SRC [USER@]HOST::DEST\n\trsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]\n\n对应于以上六种命令格式，我们可以总结rsync有两种不同工作模式：\n>1. shell模式：使用远程shell程序（如ssh或rsh）进行连接。当源路径或目的路径的主机名后面包含一个冒号分隔符是使用这种模式，rsync安装完成后可以使用了，无所谓启动。\n>2. daemon模式：使用TCP直接连接rsync daemon。当源路径的主机名后面包含两个冒号，或使用rsync：//URL时使用这种模式，无需远程shell，但必须在一台机器上启动rsync daemon，默认端口873，这里可以通过rsyn --daemon使用独立进程方式，或者通过xinetd超级进程来管理rsync后台进程。\n\n当rsync作为daemon运行时。他需要一个用户身份。如果你希望启用chroot，则必须以root身份来运行daemon，监听端口，或设定文件属主；如果不启用chroot，也可以不使用root用户来运行daemon，但该用户必须对相应的模块拥有读写数据、日志和lock file的权限。当rsync以daemon模式运行时，他还需要一个配置文件--rsync.conf。修改这个配置后不必重启rsync daemon，因为每一次的client连接都会去重新读取该文件。\n\n我们一般DEST远程服务器端称为rsync server，运行rsync命令的一端SRC称为client。\n\n#### 安装\n\nrsync在Centos 6上是默认已经安装，如果没有则可以使用\n\tyum install rsync -y\n服务端和客户端是同一个安装包。rsync命令帮助\n\trsync -h\n\n## 同步测试\n\n### 本机文件夹同步\n\trsync -auvrtzopgP --progress /root/ /tmp/rsync_bak/\n\n会看到从/root/传输到/tmp/rsync_bak/的列表和速率，在运行一次会看到dending incremental file list下没有复制的内容，可以在/root/下 touch 某一个文件在运行看到只同步了修改过的文件。\n\n上面需要考虑以下问题：\n>删除/root/下的文件不会同步删除/tmp/rsync_bak，除非加入--delete选项\n>文件访问时间等属性、读写等权限、文件内容等有任何变动，都会被认为修改\n>目标目录下如果文件比源目录还新，则不会同步\n>源路径的最后是否有斜杠有不同的含义：有斜杠，只是复制目录中的文件；没有斜杠的话，不但要复制目录中的文件，还要复制目录本身\n\n### 同步到远程服务器\n\n在服务器间rsync传输文件，需要有一个是开着rsync的服务，而这一服务需要两个配置文件，说明当运行的用户和用户组，这个用户名和用户组在改变文件权限和相关内容的时候有用，否则有时候会出现提示权限问题。配置文件也说明了模块、模块化管理服务的安全性，每个模块的名称都是自己定义的，可以添加用户密码验证，也可以验证IP，设置目录是否可以写等，不同模块用于同步不同需求的目录。\n\n#### 服务端的配置文件\n\n/etc/rsyncd.conf\n\n>uid=root  \n>gid=root  \n>use chroot=no  \n>max connections=10  \n>timeout=600  \n>strict modes=yes  \n>port=873  \n>pid file=/var/run/rsyncd.pid  \n>lock file=/var/run/rsyncd.lock  \n>log file=/var/log/rsyncd.log  \n\n>[module_test]  \n>path=/tmp/rsync_bak2  \n>comment=rsync test logs  \n>auth users=sean  \n>uid=test  \n>gid=test  \n>secrets file=/etc/rsyncd.secrets  \n>read only=no  \n>list=no  \n>hosts allow=IP  \n>hosts deny=0.0.0.0/32 \n\n这里配置soket方式传输文件，端口873，[module_test]开始定义一个模块，指定要同步的目录（接收）path ，授权用户，密码文件，允许那台服务器IP同步（发送）等。\n\n经测试，上述配置文件每行后面不能使用#来注释\n\n/etc/rsyncd.secrets\n>test:test\n\n一行一个用户，用户名：密码。请注意这里的用户名和密码与操作系统的用户名密码无关，可以随意指定，与/etc/rsyncd.conf中的auth users对应。\n\n修改权限：\n\tchmod 600 /etc/rsyncd.d/rsync_server.pwd\n\n#### 服务器启动rsync后台服务\n\n修改 /etc/xinetd.d/rsync 文件，disable 改为no\n>service rsync  \n>{  \n>    disable = no  \n>    flags       = IPv6  \n>    socket_type     = stream  \n>    wait            = no  \n>    user            = root  \n>    server          = /usr/bin/rsync  \n>    server_args     = --daemon  \n>    log_on_failure  += USERID  \n>}  \n\n执行service xinetd restart会一起重启rsync后台进程，默认使用配置文件/etc/rsyncd.conf。也可以使用/usr/bin/rsync --daemon --config=/etc/rsyncd.conf。\n\n为了以防rsync写入过多的无用日志到/var/log/message（容易塞满从而错过重要的信息），建议注释掉/etc/xinetd.conf的success：\n\n\t# log_on_success  = PID HOST DURATION EXIT\n\n如果使用了防火墙，要添加允许IP到873端口的规则。\n\n\t# iptables -A INPUT -p tcp -m state --state NEW  -m tcp --dport 873 -j ACCEPT\n\t# iptables -L  查看一下防火墙是不是打开了 873端口\n\t# netstat -anp|grep 873\n\n建议关闭selinux，可能会由于强访问控制导致同步报错。\n\n#### 客户端测试同步\n\n单向同步时，客户端只需要一个包含密码的文件。\n/etc/rsync_client.pwd：\n\n>\ttest  \n\n\tchmod 600 /etc/rsync_client.pwd\n\n\n命令：  \n将本地/root/目录同步到远程172.29.88.223的/tmp/rsync_bak2目录（module_test指定）：  \n\n\t/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd /root/ sean@172.29.88.223::module_test \n\n当然你也可以将远程的/tmp/rsync_bak2目录同步到本地目录/root/tmp：\n\n\t/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd sean@172.29.88.223::module_test /root/ \n\n从上面两个命令可以看到，其实这里的服务器与客户端的概念是很模糊的，rsync daemon都运行在远程172.29.88.223上，第一条命令是本地主动推送目录到远程，远程服务器是用来备份的；第二条命令是本地主动向远程索取文件，本地服务器用来备份，也可以认为是本地服务器恢复的一个过程。\n\n### rsync不足\n\n与传统的cp、tar备份方式相比，rsync具有安全性高、备份迅速、支持增量备份等优点，通过rsync可以解决对实时性要求不高的数据备份需求，例如定期的备份文件服务器数据到远端服务器，对本地磁盘定期做数据镜像等。\n\n随着应用系统规模的不断扩大，对数据的安全性和可靠性也提出的更好的要求，rsync在高端业务系统中也逐渐暴露出了很多不足，首先，rsync同步数据时，需要扫描所有文件后进行比对，进行差量传输。如果文件数量达到了百万甚至千万量级，扫描所有文件将是非常耗时的。而且正在发生变化的往往是其中很少的一部分，这是非常低效的方式。其次，rsync不能实时的去监测、同步数据，虽然它可以通过crontab方式进行触发同步，但是两次触发动作一定会有时间差，这样就导致了服务端和客户端数据可能出现不一致，无法在应用故障时完全的恢复数据。基于以上原因，rsync+inotify组合出现了！\n\n## inotify-tools\n\n### 什么是inotify\n\ninotify是一种强大的、细粒度的、异步的文件系统事件监控机制，Linux内核从2.6.13开始引入，允许监控程序打开一个独立文件描述符，并针对事件集监控一个或者多个文件，例如打开、关闭、移动/重命名、删除、创建或者改变属性。\n\nCentOS6自然已经支持：\n\n使用ll /proc/sys/fs/inotify命令，是否有以下三条信息输出，如果没有表示不支持。\n>total 0\n>-rw-r--r-- 1 root root 0 Dec 11 15:23 max_queued_events\n>-rw-r--r-- 1 root root 0 Dec 11 15:23 max_user_instances\n>-rw-r--r-- 1 root root 0 Dec 11 15:23 max_user_watches\n\n\n1./proc/sys/fs/inotify/max_queued_evnets表示调用inotify_init时分配给inotify instance中可排队的event的数目的最大值，超出这个值的事件被丢弃，但会触发IN_Q_OVERFLOW事件。\n\n2./proc/sys/fs/inotify/max_user_instances表示每一个real user ID可创建的inotify instatnces的数量上限。\n\n3./proc/sys/fs/inotify/max_user_watches表示每个inotify instatnces可监控的最大目录数量。如果监控的文件数目巨大，需要根据情况，适当增加此值的大小。\n\ninotify-tools：\n\ninotify-tools是为linux下inotify文件监控工具提供的一套C的开发接口库函数，同时还提供了一系列的命令行工具，这些工具可以用来监控文件系统的事件。 inotify-tools是用c编写的，除了要求内核支持inotify外，不依赖于其他。inotify-tools提供两种工具，一是inotifywait，它是用来监控文件或目录的变化，二是inotifywatch，它是用来统计文件系统访问的次数。\n\n下载inotify-tools-3.14-1.el6.x86_64.rpm，通过rpm包安装：\n\n\t# rpm -ivh /apps/crm/soft_src/inotify-tools-3.14-1.el6.x86_64.rpm \n\twarning: /apps/crm/soft_src/inotify-tools-3.14-1.el6.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 4026433f: NOKEY  \n\tPreparing...                ########################################### [100%]\n\t1:inotify-tools          ########################################### [100%]\n\t# rpm -qa|grep inotify\n\tinotify-tools-3.14-1.el5.x86_64\n\n### inotifywait使用示例\n\n监控/root/tmp目录文件的变化：\n\n\t/usr/bin/inotifywait -mrq --timefmt '%Y/%m/%d-%H:%M:%S' --format '%T %w %f' -e modify,delete,create,move,attrib /root/tmp/\n\n上面的命令表示，持续监听/root/tmp目录及其子目录的文件变化，监听事件包括文件被修改、删除、创建、移动、属性更改，显示到屏幕。执行完上面的命令后，在/root/tmp下创建或修改文件都会有信息输出：\n\n\t2014/12/11-15:40:04 /root/tmp/ new.txt\n\t2014/12/11-15:40:22 /root/tmp/ .new.txt.swp\n\t2014/12/11-15:40:22 /root/tmp/ .new.txt.swx\n\t2014/12/11-15:40:22 /root/tmp/ .new.txt.swx\n\t2014/12/11-15:40:22 /root/tmp/ .new.txt.swp\n\t2014/12/11-15:40:22 /root/tmp/ .new.txt.swp\n\t2014/12/11-15:40:23 /root/tmp/ .new.txt.swp\n\t2014/12/11-15:40:31 /root/tmp/ .new.txt.swp\n\t2014/12/11-15:40:32 /root/tmp/ 4913\n\t2014/12/11-15:40:32 /root/tmp/ 4913\n\t2014/12/11-15:40:32 /root/tmp/ 4913\n\t2014/12/11-15:40:32 /root/tmp/ new.txt\n\t2014/12/11-15:40:32 /root/tmp/ new.txt~\n\t2014/12/11-15:40:32 /root/tmp/ new.txt\n\t...\n\n## rsync组合inotify-tools完成实时同步\n\n这一步的核心其实就是在客户端创建一个脚本rsync.sh，适用inotifywait监控本地目录的变化，触发rsync将变化的文件传输到远程备份服务器上。为了更接近实战，我们要求一部分子目录不同步，如/root/tmp/log和临时文件。\n\n### 创建排除在外不同步的文件列表\n\n排除不需要同步的文件或目录有两种做法，第一种是inotify监控整个目录，在rsync中加入排除选项，简单；第二种是inotify排除部分不监控的目录，同时rsync中也要加入排除选项，可以减少不必要的网络带宽和CPU消耗。我们选择第二种。\n\n#### inotifywait排除\n\n这个操作在客户端进行，假设/tmp/src/mail/2014/以及/tmp/src/mail/2015/cache/目录下的所有文件不用同步，所以不需要监控，/tmp/src/下的其他文件和目录都同步。（其实对于打开的临时文件，可以不监听modify时间而改成监听close_write）\n\ninotifywait排除监控目录有--exclude <pattern>和--fromfile <file>两种格式，并且可以同时使用，但主要前者可以用正则，而后者只能是具体的目录或文件。\n\t\n\t# vi /etc/inotify_exclude.lst：\n\t/tmp/src/pdf\n\t@/tmp/src/2014\n\n\n使用fromfile格式只能用绝对路径，不能使用诸如*正则表达式去匹配，@表示排除。\n\n如果要排除的格式比较复杂，必须使用正则，那只能在inotifywait中加入选项，如--exclude '(.*/*\\.log|.*/*\\.swp)$|^/tmp/src/mail/(2014|201.*/cache.*)'，表示排除/tmp/src/mail/以下的2014目录，和所有201*目录下的带cache的文件或目录，以及/tmp/src目录下所有的以.log或.swp结尾的文件。\n\n#### rsync排除\n使用inotifywait排除监控目录的情况下，必须同时使用rsync排除对应的目录，否则只要有触发同步操作，必然会导致不该同步的目录也会同步。与inotifywait类似，rsync的同步也有--exclude和--exclude-from两种写法。\n\n个人还是习惯将要排除同步的目录卸载单独的文件列表里，便于管理。使用--include-from=FILE时，排除文件列表用绝对路径，但FILE里面的内容请用相对路径，如：\n\n\n/etc/rsyncd.d/rsync_exclude.lst\n>mail/2014/\n>mail/201*/201*/201*/.??*\n>mail??*\n>src/*.html*\n>src/js/\n>src/ext3/\n>src/2014/20140[1-9]/\n>src/201*/201*/201*/.??*\n>membermail/\n>membermail??*\n>membermail/201*/201*/201*/.??*\n\n排除同步的内容包括，mail下的2014目录，类似2015/201501/20150101/下的临时或隐藏文件，等\n\n### 客户端同步到远程的脚本rsync.sh\n下面是一个完整的同步脚本，请根据需要进行裁剪，rsync.sh：\n\n\n\tcurrent_date=$(date +%Y%m%d_%H%M%S)\n\tsource_path=/tmp/src/\n\tlog_file=/var/log/rsync_client.log\n\n\t#rsync\n\trsync_server=172.29.88.223\n\trsync_user=sean\n\trsync_pwd=/etc/rsync_client.pwd\n\trsync_module=module_test\n\tINOTIFY_EXCLUDE='(.*/*\\.log|.*/*\\.swp)$|^/tmp/src/mail/(2014|20.*/.*che.*)'\n\tRSYNC_EXCLUDE='/etc/rsyncd.d/rsync_exclude.lst'\n\n\t#rsync client pwd check\n\tif [ ! -e ${rsync_pwd} ];then\n    echo -e \"rsync client passwod file ${rsync_pwd} does not exist!\"\n    exit 0\n\tfi\n\n\t#inotify_function\n\tinotify_fun(){\n    /usr/bin/inotifywait -mrq --timefmt '%Y/%m/%d-%H:%M:%S' --format '%T %w %f' \\\n          --exclude ${INOTIFY_EXCLUDE}  -e modify,delete,create,move,attrib ${source_path} \\\n          | while read file\n      do\n          /usr/bin/rsync -auvrtzopgP --exclude-from=${RSYNC_EXCLUDE} --progress --bwlimit=200 --password-file=${rsync_pwd} ${source_path} ${rsync_user}@${rsync_server}::${rsync_module} \n      done\n\t}\n\n\t#inotify log\n\tinotify_fun >> ${log_file} 2>&1 &\n\t\n--bwlimit=200用于限制传输速率最大200kb，因为在实际应用中发现如果不做速率限制，会导致巨大的CPU消耗。\n\n在客户端运行脚本# ./rsync.sh即可实时同步目录。\n\n","source":"_posts/linux_下同步工具inotify_+_rsync_使用详解.md","raw":"---\ntitle: linux 下同步工具inotify + rsync 使用详解\ndate: 2017-09-13\ntags: rsync\ncategories: rsync\n---\n## rsynv\n<!--more-->\n\n### 什么是rsync\n\nrsync是一个远程数据同步工具，可以通过LAN/WAN快速同步多台主机之间的文件。它使用所谓的“Rsync演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。所以通常可以作为备份工具来使用。\n\n运行Rsync server的机器也叫backup server，一个Rsync server可同时备份多个client的数据；也可以多个Rsync server备份一个client的数据。Rsync可以搭配ssh甚至使用daemon模式。Rsync server会打开一个873的服务通道（port），等待对方rsync连接。连接时，Rsync server会检查口令是否相符，若通过口令查核，则可以开始进行文件传输。第一次联通完成时，会把整份文件传输一次，下一次就只会传送两个文件之间不同的部分。\n\n#### 基本特点：\n\n1.可以镜像保存整个目录树和文件系统；\n\n2.可以很容易做到保持原来文件的权限、时间、软硬连接等；\n\n3.无需特殊权限即可安装；\n\n4.优化的流程，文件传输效率高；\n\n5.可以使用rcp，ssh等方式来传输文件，当然也可以通过直接的socket连接；\n\n6.支持匿名传输。\n\n#### 命令语法：\n\nrsync的命令格式可以分为以下六种：\n\n\trsync [OPTION]... SRC DEST\n\trsync [OPTION]... SRC [USER@]HOST:DEST\n\trsync [OPTION]... [USER@]HOST:SRC DEST\n\trsync [OPTION]... [USER@]HOST::SRC DEST\n\trsync [OPTION]... SRC [USER@]HOST::DEST\n\trsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]\n\n对应于以上六种命令格式，我们可以总结rsync有两种不同工作模式：\n>1. shell模式：使用远程shell程序（如ssh或rsh）进行连接。当源路径或目的路径的主机名后面包含一个冒号分隔符是使用这种模式，rsync安装完成后可以使用了，无所谓启动。\n>2. daemon模式：使用TCP直接连接rsync daemon。当源路径的主机名后面包含两个冒号，或使用rsync：//URL时使用这种模式，无需远程shell，但必须在一台机器上启动rsync daemon，默认端口873，这里可以通过rsyn --daemon使用独立进程方式，或者通过xinetd超级进程来管理rsync后台进程。\n\n当rsync作为daemon运行时。他需要一个用户身份。如果你希望启用chroot，则必须以root身份来运行daemon，监听端口，或设定文件属主；如果不启用chroot，也可以不使用root用户来运行daemon，但该用户必须对相应的模块拥有读写数据、日志和lock file的权限。当rsync以daemon模式运行时，他还需要一个配置文件--rsync.conf。修改这个配置后不必重启rsync daemon，因为每一次的client连接都会去重新读取该文件。\n\n我们一般DEST远程服务器端称为rsync server，运行rsync命令的一端SRC称为client。\n\n#### 安装\n\nrsync在Centos 6上是默认已经安装，如果没有则可以使用\n\tyum install rsync -y\n服务端和客户端是同一个安装包。rsync命令帮助\n\trsync -h\n\n## 同步测试\n\n### 本机文件夹同步\n\trsync -auvrtzopgP --progress /root/ /tmp/rsync_bak/\n\n会看到从/root/传输到/tmp/rsync_bak/的列表和速率，在运行一次会看到dending incremental file list下没有复制的内容，可以在/root/下 touch 某一个文件在运行看到只同步了修改过的文件。\n\n上面需要考虑以下问题：\n>删除/root/下的文件不会同步删除/tmp/rsync_bak，除非加入--delete选项\n>文件访问时间等属性、读写等权限、文件内容等有任何变动，都会被认为修改\n>目标目录下如果文件比源目录还新，则不会同步\n>源路径的最后是否有斜杠有不同的含义：有斜杠，只是复制目录中的文件；没有斜杠的话，不但要复制目录中的文件，还要复制目录本身\n\n### 同步到远程服务器\n\n在服务器间rsync传输文件，需要有一个是开着rsync的服务，而这一服务需要两个配置文件，说明当运行的用户和用户组，这个用户名和用户组在改变文件权限和相关内容的时候有用，否则有时候会出现提示权限问题。配置文件也说明了模块、模块化管理服务的安全性，每个模块的名称都是自己定义的，可以添加用户密码验证，也可以验证IP，设置目录是否可以写等，不同模块用于同步不同需求的目录。\n\n#### 服务端的配置文件\n\n/etc/rsyncd.conf\n\n>uid=root  \n>gid=root  \n>use chroot=no  \n>max connections=10  \n>timeout=600  \n>strict modes=yes  \n>port=873  \n>pid file=/var/run/rsyncd.pid  \n>lock file=/var/run/rsyncd.lock  \n>log file=/var/log/rsyncd.log  \n\n>[module_test]  \n>path=/tmp/rsync_bak2  \n>comment=rsync test logs  \n>auth users=sean  \n>uid=test  \n>gid=test  \n>secrets file=/etc/rsyncd.secrets  \n>read only=no  \n>list=no  \n>hosts allow=IP  \n>hosts deny=0.0.0.0/32 \n\n这里配置soket方式传输文件，端口873，[module_test]开始定义一个模块，指定要同步的目录（接收）path ，授权用户，密码文件，允许那台服务器IP同步（发送）等。\n\n经测试，上述配置文件每行后面不能使用#来注释\n\n/etc/rsyncd.secrets\n>test:test\n\n一行一个用户，用户名：密码。请注意这里的用户名和密码与操作系统的用户名密码无关，可以随意指定，与/etc/rsyncd.conf中的auth users对应。\n\n修改权限：\n\tchmod 600 /etc/rsyncd.d/rsync_server.pwd\n\n#### 服务器启动rsync后台服务\n\n修改 /etc/xinetd.d/rsync 文件，disable 改为no\n>service rsync  \n>{  \n>    disable = no  \n>    flags       = IPv6  \n>    socket_type     = stream  \n>    wait            = no  \n>    user            = root  \n>    server          = /usr/bin/rsync  \n>    server_args     = --daemon  \n>    log_on_failure  += USERID  \n>}  \n\n执行service xinetd restart会一起重启rsync后台进程，默认使用配置文件/etc/rsyncd.conf。也可以使用/usr/bin/rsync --daemon --config=/etc/rsyncd.conf。\n\n为了以防rsync写入过多的无用日志到/var/log/message（容易塞满从而错过重要的信息），建议注释掉/etc/xinetd.conf的success：\n\n\t# log_on_success  = PID HOST DURATION EXIT\n\n如果使用了防火墙，要添加允许IP到873端口的规则。\n\n\t# iptables -A INPUT -p tcp -m state --state NEW  -m tcp --dport 873 -j ACCEPT\n\t# iptables -L  查看一下防火墙是不是打开了 873端口\n\t# netstat -anp|grep 873\n\n建议关闭selinux，可能会由于强访问控制导致同步报错。\n\n#### 客户端测试同步\n\n单向同步时，客户端只需要一个包含密码的文件。\n/etc/rsync_client.pwd：\n\n>\ttest  \n\n\tchmod 600 /etc/rsync_client.pwd\n\n\n命令：  \n将本地/root/目录同步到远程172.29.88.223的/tmp/rsync_bak2目录（module_test指定）：  \n\n\t/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd /root/ sean@172.29.88.223::module_test \n\n当然你也可以将远程的/tmp/rsync_bak2目录同步到本地目录/root/tmp：\n\n\t/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd sean@172.29.88.223::module_test /root/ \n\n从上面两个命令可以看到，其实这里的服务器与客户端的概念是很模糊的，rsync daemon都运行在远程172.29.88.223上，第一条命令是本地主动推送目录到远程，远程服务器是用来备份的；第二条命令是本地主动向远程索取文件，本地服务器用来备份，也可以认为是本地服务器恢复的一个过程。\n\n### rsync不足\n\n与传统的cp、tar备份方式相比，rsync具有安全性高、备份迅速、支持增量备份等优点，通过rsync可以解决对实时性要求不高的数据备份需求，例如定期的备份文件服务器数据到远端服务器，对本地磁盘定期做数据镜像等。\n\n随着应用系统规模的不断扩大，对数据的安全性和可靠性也提出的更好的要求，rsync在高端业务系统中也逐渐暴露出了很多不足，首先，rsync同步数据时，需要扫描所有文件后进行比对，进行差量传输。如果文件数量达到了百万甚至千万量级，扫描所有文件将是非常耗时的。而且正在发生变化的往往是其中很少的一部分，这是非常低效的方式。其次，rsync不能实时的去监测、同步数据，虽然它可以通过crontab方式进行触发同步，但是两次触发动作一定会有时间差，这样就导致了服务端和客户端数据可能出现不一致，无法在应用故障时完全的恢复数据。基于以上原因，rsync+inotify组合出现了！\n\n## inotify-tools\n\n### 什么是inotify\n\ninotify是一种强大的、细粒度的、异步的文件系统事件监控机制，Linux内核从2.6.13开始引入，允许监控程序打开一个独立文件描述符，并针对事件集监控一个或者多个文件，例如打开、关闭、移动/重命名、删除、创建或者改变属性。\n\nCentOS6自然已经支持：\n\n使用ll /proc/sys/fs/inotify命令，是否有以下三条信息输出，如果没有表示不支持。\n>total 0\n>-rw-r--r-- 1 root root 0 Dec 11 15:23 max_queued_events\n>-rw-r--r-- 1 root root 0 Dec 11 15:23 max_user_instances\n>-rw-r--r-- 1 root root 0 Dec 11 15:23 max_user_watches\n\n\n1./proc/sys/fs/inotify/max_queued_evnets表示调用inotify_init时分配给inotify instance中可排队的event的数目的最大值，超出这个值的事件被丢弃，但会触发IN_Q_OVERFLOW事件。\n\n2./proc/sys/fs/inotify/max_user_instances表示每一个real user ID可创建的inotify instatnces的数量上限。\n\n3./proc/sys/fs/inotify/max_user_watches表示每个inotify instatnces可监控的最大目录数量。如果监控的文件数目巨大，需要根据情况，适当增加此值的大小。\n\ninotify-tools：\n\ninotify-tools是为linux下inotify文件监控工具提供的一套C的开发接口库函数，同时还提供了一系列的命令行工具，这些工具可以用来监控文件系统的事件。 inotify-tools是用c编写的，除了要求内核支持inotify外，不依赖于其他。inotify-tools提供两种工具，一是inotifywait，它是用来监控文件或目录的变化，二是inotifywatch，它是用来统计文件系统访问的次数。\n\n下载inotify-tools-3.14-1.el6.x86_64.rpm，通过rpm包安装：\n\n\t# rpm -ivh /apps/crm/soft_src/inotify-tools-3.14-1.el6.x86_64.rpm \n\twarning: /apps/crm/soft_src/inotify-tools-3.14-1.el6.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 4026433f: NOKEY  \n\tPreparing...                ########################################### [100%]\n\t1:inotify-tools          ########################################### [100%]\n\t# rpm -qa|grep inotify\n\tinotify-tools-3.14-1.el5.x86_64\n\n### inotifywait使用示例\n\n监控/root/tmp目录文件的变化：\n\n\t/usr/bin/inotifywait -mrq --timefmt '%Y/%m/%d-%H:%M:%S' --format '%T %w %f' -e modify,delete,create,move,attrib /root/tmp/\n\n上面的命令表示，持续监听/root/tmp目录及其子目录的文件变化，监听事件包括文件被修改、删除、创建、移动、属性更改，显示到屏幕。执行完上面的命令后，在/root/tmp下创建或修改文件都会有信息输出：\n\n\t2014/12/11-15:40:04 /root/tmp/ new.txt\n\t2014/12/11-15:40:22 /root/tmp/ .new.txt.swp\n\t2014/12/11-15:40:22 /root/tmp/ .new.txt.swx\n\t2014/12/11-15:40:22 /root/tmp/ .new.txt.swx\n\t2014/12/11-15:40:22 /root/tmp/ .new.txt.swp\n\t2014/12/11-15:40:22 /root/tmp/ .new.txt.swp\n\t2014/12/11-15:40:23 /root/tmp/ .new.txt.swp\n\t2014/12/11-15:40:31 /root/tmp/ .new.txt.swp\n\t2014/12/11-15:40:32 /root/tmp/ 4913\n\t2014/12/11-15:40:32 /root/tmp/ 4913\n\t2014/12/11-15:40:32 /root/tmp/ 4913\n\t2014/12/11-15:40:32 /root/tmp/ new.txt\n\t2014/12/11-15:40:32 /root/tmp/ new.txt~\n\t2014/12/11-15:40:32 /root/tmp/ new.txt\n\t...\n\n## rsync组合inotify-tools完成实时同步\n\n这一步的核心其实就是在客户端创建一个脚本rsync.sh，适用inotifywait监控本地目录的变化，触发rsync将变化的文件传输到远程备份服务器上。为了更接近实战，我们要求一部分子目录不同步，如/root/tmp/log和临时文件。\n\n### 创建排除在外不同步的文件列表\n\n排除不需要同步的文件或目录有两种做法，第一种是inotify监控整个目录，在rsync中加入排除选项，简单；第二种是inotify排除部分不监控的目录，同时rsync中也要加入排除选项，可以减少不必要的网络带宽和CPU消耗。我们选择第二种。\n\n#### inotifywait排除\n\n这个操作在客户端进行，假设/tmp/src/mail/2014/以及/tmp/src/mail/2015/cache/目录下的所有文件不用同步，所以不需要监控，/tmp/src/下的其他文件和目录都同步。（其实对于打开的临时文件，可以不监听modify时间而改成监听close_write）\n\ninotifywait排除监控目录有--exclude <pattern>和--fromfile <file>两种格式，并且可以同时使用，但主要前者可以用正则，而后者只能是具体的目录或文件。\n\t\n\t# vi /etc/inotify_exclude.lst：\n\t/tmp/src/pdf\n\t@/tmp/src/2014\n\n\n使用fromfile格式只能用绝对路径，不能使用诸如*正则表达式去匹配，@表示排除。\n\n如果要排除的格式比较复杂，必须使用正则，那只能在inotifywait中加入选项，如--exclude '(.*/*\\.log|.*/*\\.swp)$|^/tmp/src/mail/(2014|201.*/cache.*)'，表示排除/tmp/src/mail/以下的2014目录，和所有201*目录下的带cache的文件或目录，以及/tmp/src目录下所有的以.log或.swp结尾的文件。\n\n#### rsync排除\n使用inotifywait排除监控目录的情况下，必须同时使用rsync排除对应的目录，否则只要有触发同步操作，必然会导致不该同步的目录也会同步。与inotifywait类似，rsync的同步也有--exclude和--exclude-from两种写法。\n\n个人还是习惯将要排除同步的目录卸载单独的文件列表里，便于管理。使用--include-from=FILE时，排除文件列表用绝对路径，但FILE里面的内容请用相对路径，如：\n\n\n/etc/rsyncd.d/rsync_exclude.lst\n>mail/2014/\n>mail/201*/201*/201*/.??*\n>mail??*\n>src/*.html*\n>src/js/\n>src/ext3/\n>src/2014/20140[1-9]/\n>src/201*/201*/201*/.??*\n>membermail/\n>membermail??*\n>membermail/201*/201*/201*/.??*\n\n排除同步的内容包括，mail下的2014目录，类似2015/201501/20150101/下的临时或隐藏文件，等\n\n### 客户端同步到远程的脚本rsync.sh\n下面是一个完整的同步脚本，请根据需要进行裁剪，rsync.sh：\n\n\n\tcurrent_date=$(date +%Y%m%d_%H%M%S)\n\tsource_path=/tmp/src/\n\tlog_file=/var/log/rsync_client.log\n\n\t#rsync\n\trsync_server=172.29.88.223\n\trsync_user=sean\n\trsync_pwd=/etc/rsync_client.pwd\n\trsync_module=module_test\n\tINOTIFY_EXCLUDE='(.*/*\\.log|.*/*\\.swp)$|^/tmp/src/mail/(2014|20.*/.*che.*)'\n\tRSYNC_EXCLUDE='/etc/rsyncd.d/rsync_exclude.lst'\n\n\t#rsync client pwd check\n\tif [ ! -e ${rsync_pwd} ];then\n    echo -e \"rsync client passwod file ${rsync_pwd} does not exist!\"\n    exit 0\n\tfi\n\n\t#inotify_function\n\tinotify_fun(){\n    /usr/bin/inotifywait -mrq --timefmt '%Y/%m/%d-%H:%M:%S' --format '%T %w %f' \\\n          --exclude ${INOTIFY_EXCLUDE}  -e modify,delete,create,move,attrib ${source_path} \\\n          | while read file\n      do\n          /usr/bin/rsync -auvrtzopgP --exclude-from=${RSYNC_EXCLUDE} --progress --bwlimit=200 --password-file=${rsync_pwd} ${source_path} ${rsync_user}@${rsync_server}::${rsync_module} \n      done\n\t}\n\n\t#inotify log\n\tinotify_fun >> ${log_file} 2>&1 &\n\t\n--bwlimit=200用于限制传输速率最大200kb，因为在实际应用中发现如果不做速率限制，会导致巨大的CPU消耗。\n\n在客户端运行脚本# ./rsync.sh即可实时同步目录。\n\n","slug":"linux_下同步工具inotify_+_rsync_使用详解","published":1,"updated":"2019-06-18T08:07:01.114Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9skf0011hcb7v6503ksg","content":"<h2 id=\"rsynv\"><a href=\"#rsynv\" class=\"headerlink\" title=\"rsynv\"></a>rsynv</h2><a id=\"more\"></a>\n<h3 id=\"什么是rsync\"><a href=\"#什么是rsync\" class=\"headerlink\" title=\"什么是rsync\"></a>什么是rsync</h3><p>rsync是一个远程数据同步工具，可以通过LAN/WAN快速同步多台主机之间的文件。它使用所谓的“Rsync演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。所以通常可以作为备份工具来使用。</p>\n<p>运行Rsync server的机器也叫backup server，一个Rsync server可同时备份多个client的数据；也可以多个Rsync server备份一个client的数据。Rsync可以搭配ssh甚至使用daemon模式。Rsync server会打开一个873的服务通道（port），等待对方rsync连接。连接时，Rsync server会检查口令是否相符，若通过口令查核，则可以开始进行文件传输。第一次联通完成时，会把整份文件传输一次，下一次就只会传送两个文件之间不同的部分。</p>\n<h4 id=\"基本特点：\"><a href=\"#基本特点：\" class=\"headerlink\" title=\"基本特点：\"></a>基本特点：</h4><p>1.可以镜像保存整个目录树和文件系统；</p>\n<p>2.可以很容易做到保持原来文件的权限、时间、软硬连接等；</p>\n<p>3.无需特殊权限即可安装；</p>\n<p>4.优化的流程，文件传输效率高；</p>\n<p>5.可以使用rcp，ssh等方式来传输文件，当然也可以通过直接的socket连接；</p>\n<p>6.支持匿名传输。</p>\n<h4 id=\"命令语法：\"><a href=\"#命令语法：\" class=\"headerlink\" title=\"命令语法：\"></a>命令语法：</h4><p>rsync的命令格式可以分为以下六种：</p>\n<pre><code>rsync [OPTION]... SRC DEST\nrsync [OPTION]... SRC [USER@]HOST:DEST\nrsync [OPTION]... [USER@]HOST:SRC DEST\nrsync [OPTION]... [USER@]HOST::SRC DEST\nrsync [OPTION]... SRC [USER@]HOST::DEST\nrsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]\n</code></pre><p>对应于以上六种命令格式，我们可以总结rsync有两种不同工作模式：</p>\n<blockquote>\n<ol>\n<li>shell模式：使用远程shell程序（如ssh或rsh）进行连接。当源路径或目的路径的主机名后面包含一个冒号分隔符是使用这种模式，rsync安装完成后可以使用了，无所谓启动。</li>\n<li>daemon模式：使用TCP直接连接rsync daemon。当源路径的主机名后面包含两个冒号，或使用rsync：//URL时使用这种模式，无需远程shell，但必须在一台机器上启动rsync daemon，默认端口873，这里可以通过rsyn –daemon使用独立进程方式，或者通过xinetd超级进程来管理rsync后台进程。</li>\n</ol>\n</blockquote>\n<p>当rsync作为daemon运行时。他需要一个用户身份。如果你希望启用chroot，则必须以root身份来运行daemon，监听端口，或设定文件属主；如果不启用chroot，也可以不使用root用户来运行daemon，但该用户必须对相应的模块拥有读写数据、日志和lock file的权限。当rsync以daemon模式运行时，他还需要一个配置文件–rsync.conf。修改这个配置后不必重启rsync daemon，因为每一次的client连接都会去重新读取该文件。</p>\n<p>我们一般DEST远程服务器端称为rsync server，运行rsync命令的一端SRC称为client。</p>\n<h4 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h4><p>rsync在Centos 6上是默认已经安装，如果没有则可以使用<br>    yum install rsync -y<br>服务端和客户端是同一个安装包。rsync命令帮助<br>    rsync -h</p>\n<h2 id=\"同步测试\"><a href=\"#同步测试\" class=\"headerlink\" title=\"同步测试\"></a>同步测试</h2><h3 id=\"本机文件夹同步\"><a href=\"#本机文件夹同步\" class=\"headerlink\" title=\"本机文件夹同步\"></a>本机文件夹同步</h3><pre><code>rsync -auvrtzopgP --progress /root/ /tmp/rsync_bak/\n</code></pre><p>会看到从/root/传输到/tmp/rsync_bak/的列表和速率，在运行一次会看到dending incremental file list下没有复制的内容，可以在/root/下 touch 某一个文件在运行看到只同步了修改过的文件。</p>\n<p>上面需要考虑以下问题：</p>\n<blockquote>\n<p>删除/root/下的文件不会同步删除/tmp/rsync_bak，除非加入–delete选项<br>文件访问时间等属性、读写等权限、文件内容等有任何变动，都会被认为修改<br>目标目录下如果文件比源目录还新，则不会同步<br>源路径的最后是否有斜杠有不同的含义：有斜杠，只是复制目录中的文件；没有斜杠的话，不但要复制目录中的文件，还要复制目录本身</p>\n</blockquote>\n<h3 id=\"同步到远程服务器\"><a href=\"#同步到远程服务器\" class=\"headerlink\" title=\"同步到远程服务器\"></a>同步到远程服务器</h3><p>在服务器间rsync传输文件，需要有一个是开着rsync的服务，而这一服务需要两个配置文件，说明当运行的用户和用户组，这个用户名和用户组在改变文件权限和相关内容的时候有用，否则有时候会出现提示权限问题。配置文件也说明了模块、模块化管理服务的安全性，每个模块的名称都是自己定义的，可以添加用户密码验证，也可以验证IP，设置目录是否可以写等，不同模块用于同步不同需求的目录。</p>\n<h4 id=\"服务端的配置文件\"><a href=\"#服务端的配置文件\" class=\"headerlink\" title=\"服务端的配置文件\"></a>服务端的配置文件</h4><p>/etc/rsyncd.conf</p>\n<blockquote>\n<p>uid=root<br>gid=root<br>use chroot=no<br>max connections=10<br>timeout=600<br>strict modes=yes<br>port=873<br>pid file=/var/run/rsyncd.pid<br>lock file=/var/run/rsyncd.lock<br>log file=/var/log/rsyncd.log  </p>\n</blockquote>\n<blockquote>\n<p>[module_test]<br>path=/tmp/rsync_bak2<br>comment=rsync test logs<br>auth users=sean<br>uid=test<br>gid=test<br>secrets file=/etc/rsyncd.secrets<br>read only=no<br>list=no<br>hosts allow=IP<br>hosts deny=0.0.0.0/32 </p>\n</blockquote>\n<p>这里配置soket方式传输文件，端口873，[module_test]开始定义一个模块，指定要同步的目录（接收）path ，授权用户，密码文件，允许那台服务器IP同步（发送）等。</p>\n<p>经测试，上述配置文件每行后面不能使用#来注释</p>\n<p>/etc/rsyncd.secrets</p>\n<blockquote>\n<p>test:test</p>\n</blockquote>\n<p>一行一个用户，用户名：密码。请注意这里的用户名和密码与操作系统的用户名密码无关，可以随意指定，与/etc/rsyncd.conf中的auth users对应。</p>\n<p>修改权限：<br>    chmod 600 /etc/rsyncd.d/rsync_server.pwd</p>\n<h4 id=\"服务器启动rsync后台服务\"><a href=\"#服务器启动rsync后台服务\" class=\"headerlink\" title=\"服务器启动rsync后台服务\"></a>服务器启动rsync后台服务</h4><p>修改 /etc/xinetd.d/rsync 文件，disable 改为no</p>\n<blockquote>\n<p>service rsync<br>{<br>   disable = no<br>   flags       = IPv6<br>   socket_type     = stream<br>   wait            = no<br>   user            = root<br>   server          = /usr/bin/rsync<br>   server_args     = –daemon<br>   log_on_failure  += USERID<br>}  </p>\n</blockquote>\n<p>执行service xinetd restart会一起重启rsync后台进程，默认使用配置文件/etc/rsyncd.conf。也可以使用/usr/bin/rsync –daemon –config=/etc/rsyncd.conf。</p>\n<p>为了以防rsync写入过多的无用日志到/var/log/message（容易塞满从而错过重要的信息），建议注释掉/etc/xinetd.conf的success：</p>\n<pre><code># log_on_success  = PID HOST DURATION EXIT\n</code></pre><p>如果使用了防火墙，要添加允许IP到873端口的规则。</p>\n<pre><code># iptables -A INPUT -p tcp -m state --state NEW  -m tcp --dport 873 -j ACCEPT\n# iptables -L  查看一下防火墙是不是打开了 873端口\n# netstat -anp|grep 873\n</code></pre><p>建议关闭selinux，可能会由于强访问控制导致同步报错。</p>\n<h4 id=\"客户端测试同步\"><a href=\"#客户端测试同步\" class=\"headerlink\" title=\"客户端测试同步\"></a>客户端测试同步</h4><p>单向同步时，客户端只需要一个包含密码的文件。<br>/etc/rsync_client.pwd：</p>\n<blockquote>\n<p>   test  </p>\n</blockquote>\n<pre><code>chmod 600 /etc/rsync_client.pwd\n</code></pre><p>命令：<br>将本地/root/目录同步到远程172.29.88.223的/tmp/rsync_bak2目录（module_test指定）：  </p>\n<pre><code>/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd /root/ sean@172.29.88.223::module_test \n</code></pre><p>当然你也可以将远程的/tmp/rsync_bak2目录同步到本地目录/root/tmp：</p>\n<pre><code>/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd sean@172.29.88.223::module_test /root/ \n</code></pre><p>从上面两个命令可以看到，其实这里的服务器与客户端的概念是很模糊的，rsync daemon都运行在远程172.29.88.223上，第一条命令是本地主动推送目录到远程，远程服务器是用来备份的；第二条命令是本地主动向远程索取文件，本地服务器用来备份，也可以认为是本地服务器恢复的一个过程。</p>\n<h3 id=\"rsync不足\"><a href=\"#rsync不足\" class=\"headerlink\" title=\"rsync不足\"></a>rsync不足</h3><p>与传统的cp、tar备份方式相比，rsync具有安全性高、备份迅速、支持增量备份等优点，通过rsync可以解决对实时性要求不高的数据备份需求，例如定期的备份文件服务器数据到远端服务器，对本地磁盘定期做数据镜像等。</p>\n<p>随着应用系统规模的不断扩大，对数据的安全性和可靠性也提出的更好的要求，rsync在高端业务系统中也逐渐暴露出了很多不足，首先，rsync同步数据时，需要扫描所有文件后进行比对，进行差量传输。如果文件数量达到了百万甚至千万量级，扫描所有文件将是非常耗时的。而且正在发生变化的往往是其中很少的一部分，这是非常低效的方式。其次，rsync不能实时的去监测、同步数据，虽然它可以通过crontab方式进行触发同步，但是两次触发动作一定会有时间差，这样就导致了服务端和客户端数据可能出现不一致，无法在应用故障时完全的恢复数据。基于以上原因，rsync+inotify组合出现了！</p>\n<h2 id=\"inotify-tools\"><a href=\"#inotify-tools\" class=\"headerlink\" title=\"inotify-tools\"></a>inotify-tools</h2><h3 id=\"什么是inotify\"><a href=\"#什么是inotify\" class=\"headerlink\" title=\"什么是inotify\"></a>什么是inotify</h3><p>inotify是一种强大的、细粒度的、异步的文件系统事件监控机制，Linux内核从2.6.13开始引入，允许监控程序打开一个独立文件描述符，并针对事件集监控一个或者多个文件，例如打开、关闭、移动/重命名、删除、创建或者改变属性。</p>\n<p>CentOS6自然已经支持：</p>\n<p>使用ll /proc/sys/fs/inotify命令，是否有以下三条信息输出，如果没有表示不支持。</p>\n<blockquote>\n<p>total 0<br>-rw-r–r– 1 root root 0 Dec 11 15:23 max_queued_events<br>-rw-r–r– 1 root root 0 Dec 11 15:23 max_user_instances<br>-rw-r–r– 1 root root 0 Dec 11 15:23 max_user_watches</p>\n</blockquote>\n<p>1./proc/sys/fs/inotify/max_queued_evnets表示调用inotify_init时分配给inotify instance中可排队的event的数目的最大值，超出这个值的事件被丢弃，但会触发IN_Q_OVERFLOW事件。</p>\n<p>2./proc/sys/fs/inotify/max_user_instances表示每一个real user ID可创建的inotify instatnces的数量上限。</p>\n<p>3./proc/sys/fs/inotify/max_user_watches表示每个inotify instatnces可监控的最大目录数量。如果监控的文件数目巨大，需要根据情况，适当增加此值的大小。</p>\n<p>inotify-tools：</p>\n<p>inotify-tools是为linux下inotify文件监控工具提供的一套C的开发接口库函数，同时还提供了一系列的命令行工具，这些工具可以用来监控文件系统的事件。 inotify-tools是用c编写的，除了要求内核支持inotify外，不依赖于其他。inotify-tools提供两种工具，一是inotifywait，它是用来监控文件或目录的变化，二是inotifywatch，它是用来统计文件系统访问的次数。</p>\n<p>下载inotify-tools-3.14-1.el6.x86_64.rpm，通过rpm包安装：</p>\n<pre><code># rpm -ivh /apps/crm/soft_src/inotify-tools-3.14-1.el6.x86_64.rpm \nwarning: /apps/crm/soft_src/inotify-tools-3.14-1.el6.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 4026433f: NOKEY  \nPreparing...                ########################################### [100%]\n1:inotify-tools          ########################################### [100%]\n# rpm -qa|grep inotify\ninotify-tools-3.14-1.el5.x86_64\n</code></pre><h3 id=\"inotifywait使用示例\"><a href=\"#inotifywait使用示例\" class=\"headerlink\" title=\"inotifywait使用示例\"></a>inotifywait使用示例</h3><p>监控/root/tmp目录文件的变化：</p>\n<pre><code>/usr/bin/inotifywait -mrq --timefmt &apos;%Y/%m/%d-%H:%M:%S&apos; --format &apos;%T %w %f&apos; -e modify,delete,create,move,attrib /root/tmp/\n</code></pre><p>上面的命令表示，持续监听/root/tmp目录及其子目录的文件变化，监听事件包括文件被修改、删除、创建、移动、属性更改，显示到屏幕。执行完上面的命令后，在/root/tmp下创建或修改文件都会有信息输出：</p>\n<pre><code>2014/12/11-15:40:04 /root/tmp/ new.txt\n2014/12/11-15:40:22 /root/tmp/ .new.txt.swp\n2014/12/11-15:40:22 /root/tmp/ .new.txt.swx\n2014/12/11-15:40:22 /root/tmp/ .new.txt.swx\n2014/12/11-15:40:22 /root/tmp/ .new.txt.swp\n2014/12/11-15:40:22 /root/tmp/ .new.txt.swp\n2014/12/11-15:40:23 /root/tmp/ .new.txt.swp\n2014/12/11-15:40:31 /root/tmp/ .new.txt.swp\n2014/12/11-15:40:32 /root/tmp/ 4913\n2014/12/11-15:40:32 /root/tmp/ 4913\n2014/12/11-15:40:32 /root/tmp/ 4913\n2014/12/11-15:40:32 /root/tmp/ new.txt\n2014/12/11-15:40:32 /root/tmp/ new.txt~\n2014/12/11-15:40:32 /root/tmp/ new.txt\n...\n</code></pre><h2 id=\"rsync组合inotify-tools完成实时同步\"><a href=\"#rsync组合inotify-tools完成实时同步\" class=\"headerlink\" title=\"rsync组合inotify-tools完成实时同步\"></a>rsync组合inotify-tools完成实时同步</h2><p>这一步的核心其实就是在客户端创建一个脚本rsync.sh，适用inotifywait监控本地目录的变化，触发rsync将变化的文件传输到远程备份服务器上。为了更接近实战，我们要求一部分子目录不同步，如/root/tmp/log和临时文件。</p>\n<h3 id=\"创建排除在外不同步的文件列表\"><a href=\"#创建排除在外不同步的文件列表\" class=\"headerlink\" title=\"创建排除在外不同步的文件列表\"></a>创建排除在外不同步的文件列表</h3><p>排除不需要同步的文件或目录有两种做法，第一种是inotify监控整个目录，在rsync中加入排除选项，简单；第二种是inotify排除部分不监控的目录，同时rsync中也要加入排除选项，可以减少不必要的网络带宽和CPU消耗。我们选择第二种。</p>\n<h4 id=\"inotifywait排除\"><a href=\"#inotifywait排除\" class=\"headerlink\" title=\"inotifywait排除\"></a>inotifywait排除</h4><p>这个操作在客户端进行，假设/tmp/src/mail/2014/以及/tmp/src/mail/2015/cache/目录下的所有文件不用同步，所以不需要监控，/tmp/src/下的其他文件和目录都同步。（其实对于打开的临时文件，可以不监听modify时间而改成监听close_write）</p>\n<p>inotifywait排除监控目录有–exclude <pattern>和–fromfile <file>两种格式，并且可以同时使用，但主要前者可以用正则，而后者只能是具体的目录或文件。</file></pattern></p>\n<pre><code># vi /etc/inotify_exclude.lst：\n/tmp/src/pdf\n@/tmp/src/2014\n</code></pre><p>使用fromfile格式只能用绝对路径，不能使用诸如*正则表达式去匹配，@表示排除。</p>\n<p>如果要排除的格式比较复杂，必须使用正则，那只能在inotifywait中加入选项，如–exclude ‘(.<em>/</em>.log|.<em>/</em>.swp)$|^/tmp/src/mail/(2014|201.<em>/cache.</em>)’，表示排除/tmp/src/mail/以下的2014目录，和所有201*目录下的带cache的文件或目录，以及/tmp/src目录下所有的以.log或.swp结尾的文件。</p>\n<h4 id=\"rsync排除\"><a href=\"#rsync排除\" class=\"headerlink\" title=\"rsync排除\"></a>rsync排除</h4><p>使用inotifywait排除监控目录的情况下，必须同时使用rsync排除对应的目录，否则只要有触发同步操作，必然会导致不该同步的目录也会同步。与inotifywait类似，rsync的同步也有–exclude和–exclude-from两种写法。</p>\n<p>个人还是习惯将要排除同步的目录卸载单独的文件列表里，便于管理。使用–include-from=FILE时，排除文件列表用绝对路径，但FILE里面的内容请用相对路径，如：</p>\n<p>/etc/rsyncd.d/rsync_exclude.lst</p>\n<blockquote>\n<p>mail/2014/<br>mail/201<em>/201</em>/201<em>/.??</em><br>mail??<em><br>src/</em>.html<em><br>src/js/<br>src/ext3/<br>src/2014/20140[1-9]/<br>src/201</em>/201<em>/201</em>/.??<em><br>membermail/<br>membermail??</em><br>membermail/201<em>/201</em>/201<em>/.??</em></p>\n</blockquote>\n<p>排除同步的内容包括，mail下的2014目录，类似2015/201501/20150101/下的临时或隐藏文件，等</p>\n<h3 id=\"客户端同步到远程的脚本rsync-sh\"><a href=\"#客户端同步到远程的脚本rsync-sh\" class=\"headerlink\" title=\"客户端同步到远程的脚本rsync.sh\"></a>客户端同步到远程的脚本rsync.sh</h3><p>下面是一个完整的同步脚本，请根据需要进行裁剪，rsync.sh：</p>\n<pre><code>current_date=$(date +%Y%m%d_%H%M%S)\nsource_path=/tmp/src/\nlog_file=/var/log/rsync_client.log\n\n#rsync\nrsync_server=172.29.88.223\nrsync_user=sean\nrsync_pwd=/etc/rsync_client.pwd\nrsync_module=module_test\nINOTIFY_EXCLUDE=&apos;(.*/*\\.log|.*/*\\.swp)$|^/tmp/src/mail/(2014|20.*/.*che.*)&apos;\nRSYNC_EXCLUDE=&apos;/etc/rsyncd.d/rsync_exclude.lst&apos;\n\n#rsync client pwd check\nif [ ! -e ${rsync_pwd} ];then\necho -e &quot;rsync client passwod file ${rsync_pwd} does not exist!&quot;\nexit 0\nfi\n\n#inotify_function\ninotify_fun(){\n/usr/bin/inotifywait -mrq --timefmt &apos;%Y/%m/%d-%H:%M:%S&apos; --format &apos;%T %w %f&apos; \\\n      --exclude ${INOTIFY_EXCLUDE}  -e modify,delete,create,move,attrib ${source_path} \\\n      | while read file\n  do\n      /usr/bin/rsync -auvrtzopgP --exclude-from=${RSYNC_EXCLUDE} --progress --bwlimit=200 --password-file=${rsync_pwd} ${source_path} ${rsync_user}@${rsync_server}::${rsync_module} \n  done\n}\n\n#inotify log\ninotify_fun &gt;&gt; ${log_file} 2&gt;&amp;1 &amp;\n</code></pre><p>–bwlimit=200用于限制传输速率最大200kb，因为在实际应用中发现如果不做速率限制，会导致巨大的CPU消耗。</p>\n<p>在客户端运行脚本# ./rsync.sh即可实时同步目录。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"rsynv\"><a href=\"#rsynv\" class=\"headerlink\" title=\"rsynv\"></a>rsynv</h2>","more":"<h3 id=\"什么是rsync\"><a href=\"#什么是rsync\" class=\"headerlink\" title=\"什么是rsync\"></a>什么是rsync</h3><p>rsync是一个远程数据同步工具，可以通过LAN/WAN快速同步多台主机之间的文件。它使用所谓的“Rsync演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。所以通常可以作为备份工具来使用。</p>\n<p>运行Rsync server的机器也叫backup server，一个Rsync server可同时备份多个client的数据；也可以多个Rsync server备份一个client的数据。Rsync可以搭配ssh甚至使用daemon模式。Rsync server会打开一个873的服务通道（port），等待对方rsync连接。连接时，Rsync server会检查口令是否相符，若通过口令查核，则可以开始进行文件传输。第一次联通完成时，会把整份文件传输一次，下一次就只会传送两个文件之间不同的部分。</p>\n<h4 id=\"基本特点：\"><a href=\"#基本特点：\" class=\"headerlink\" title=\"基本特点：\"></a>基本特点：</h4><p>1.可以镜像保存整个目录树和文件系统；</p>\n<p>2.可以很容易做到保持原来文件的权限、时间、软硬连接等；</p>\n<p>3.无需特殊权限即可安装；</p>\n<p>4.优化的流程，文件传输效率高；</p>\n<p>5.可以使用rcp，ssh等方式来传输文件，当然也可以通过直接的socket连接；</p>\n<p>6.支持匿名传输。</p>\n<h4 id=\"命令语法：\"><a href=\"#命令语法：\" class=\"headerlink\" title=\"命令语法：\"></a>命令语法：</h4><p>rsync的命令格式可以分为以下六种：</p>\n<pre><code>rsync [OPTION]... SRC DEST\nrsync [OPTION]... SRC [USER@]HOST:DEST\nrsync [OPTION]... [USER@]HOST:SRC DEST\nrsync [OPTION]... [USER@]HOST::SRC DEST\nrsync [OPTION]... SRC [USER@]HOST::DEST\nrsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]\n</code></pre><p>对应于以上六种命令格式，我们可以总结rsync有两种不同工作模式：</p>\n<blockquote>\n<ol>\n<li>shell模式：使用远程shell程序（如ssh或rsh）进行连接。当源路径或目的路径的主机名后面包含一个冒号分隔符是使用这种模式，rsync安装完成后可以使用了，无所谓启动。</li>\n<li>daemon模式：使用TCP直接连接rsync daemon。当源路径的主机名后面包含两个冒号，或使用rsync：//URL时使用这种模式，无需远程shell，但必须在一台机器上启动rsync daemon，默认端口873，这里可以通过rsyn –daemon使用独立进程方式，或者通过xinetd超级进程来管理rsync后台进程。</li>\n</ol>\n</blockquote>\n<p>当rsync作为daemon运行时。他需要一个用户身份。如果你希望启用chroot，则必须以root身份来运行daemon，监听端口，或设定文件属主；如果不启用chroot，也可以不使用root用户来运行daemon，但该用户必须对相应的模块拥有读写数据、日志和lock file的权限。当rsync以daemon模式运行时，他还需要一个配置文件–rsync.conf。修改这个配置后不必重启rsync daemon，因为每一次的client连接都会去重新读取该文件。</p>\n<p>我们一般DEST远程服务器端称为rsync server，运行rsync命令的一端SRC称为client。</p>\n<h4 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h4><p>rsync在Centos 6上是默认已经安装，如果没有则可以使用<br>    yum install rsync -y<br>服务端和客户端是同一个安装包。rsync命令帮助<br>    rsync -h</p>\n<h2 id=\"同步测试\"><a href=\"#同步测试\" class=\"headerlink\" title=\"同步测试\"></a>同步测试</h2><h3 id=\"本机文件夹同步\"><a href=\"#本机文件夹同步\" class=\"headerlink\" title=\"本机文件夹同步\"></a>本机文件夹同步</h3><pre><code>rsync -auvrtzopgP --progress /root/ /tmp/rsync_bak/\n</code></pre><p>会看到从/root/传输到/tmp/rsync_bak/的列表和速率，在运行一次会看到dending incremental file list下没有复制的内容，可以在/root/下 touch 某一个文件在运行看到只同步了修改过的文件。</p>\n<p>上面需要考虑以下问题：</p>\n<blockquote>\n<p>删除/root/下的文件不会同步删除/tmp/rsync_bak，除非加入–delete选项<br>文件访问时间等属性、读写等权限、文件内容等有任何变动，都会被认为修改<br>目标目录下如果文件比源目录还新，则不会同步<br>源路径的最后是否有斜杠有不同的含义：有斜杠，只是复制目录中的文件；没有斜杠的话，不但要复制目录中的文件，还要复制目录本身</p>\n</blockquote>\n<h3 id=\"同步到远程服务器\"><a href=\"#同步到远程服务器\" class=\"headerlink\" title=\"同步到远程服务器\"></a>同步到远程服务器</h3><p>在服务器间rsync传输文件，需要有一个是开着rsync的服务，而这一服务需要两个配置文件，说明当运行的用户和用户组，这个用户名和用户组在改变文件权限和相关内容的时候有用，否则有时候会出现提示权限问题。配置文件也说明了模块、模块化管理服务的安全性，每个模块的名称都是自己定义的，可以添加用户密码验证，也可以验证IP，设置目录是否可以写等，不同模块用于同步不同需求的目录。</p>\n<h4 id=\"服务端的配置文件\"><a href=\"#服务端的配置文件\" class=\"headerlink\" title=\"服务端的配置文件\"></a>服务端的配置文件</h4><p>/etc/rsyncd.conf</p>\n<blockquote>\n<p>uid=root<br>gid=root<br>use chroot=no<br>max connections=10<br>timeout=600<br>strict modes=yes<br>port=873<br>pid file=/var/run/rsyncd.pid<br>lock file=/var/run/rsyncd.lock<br>log file=/var/log/rsyncd.log  </p>\n</blockquote>\n<blockquote>\n<p>[module_test]<br>path=/tmp/rsync_bak2<br>comment=rsync test logs<br>auth users=sean<br>uid=test<br>gid=test<br>secrets file=/etc/rsyncd.secrets<br>read only=no<br>list=no<br>hosts allow=IP<br>hosts deny=0.0.0.0/32 </p>\n</blockquote>\n<p>这里配置soket方式传输文件，端口873，[module_test]开始定义一个模块，指定要同步的目录（接收）path ，授权用户，密码文件，允许那台服务器IP同步（发送）等。</p>\n<p>经测试，上述配置文件每行后面不能使用#来注释</p>\n<p>/etc/rsyncd.secrets</p>\n<blockquote>\n<p>test:test</p>\n</blockquote>\n<p>一行一个用户，用户名：密码。请注意这里的用户名和密码与操作系统的用户名密码无关，可以随意指定，与/etc/rsyncd.conf中的auth users对应。</p>\n<p>修改权限：<br>    chmod 600 /etc/rsyncd.d/rsync_server.pwd</p>\n<h4 id=\"服务器启动rsync后台服务\"><a href=\"#服务器启动rsync后台服务\" class=\"headerlink\" title=\"服务器启动rsync后台服务\"></a>服务器启动rsync后台服务</h4><p>修改 /etc/xinetd.d/rsync 文件，disable 改为no</p>\n<blockquote>\n<p>service rsync<br>{<br>   disable = no<br>   flags       = IPv6<br>   socket_type     = stream<br>   wait            = no<br>   user            = root<br>   server          = /usr/bin/rsync<br>   server_args     = –daemon<br>   log_on_failure  += USERID<br>}  </p>\n</blockquote>\n<p>执行service xinetd restart会一起重启rsync后台进程，默认使用配置文件/etc/rsyncd.conf。也可以使用/usr/bin/rsync –daemon –config=/etc/rsyncd.conf。</p>\n<p>为了以防rsync写入过多的无用日志到/var/log/message（容易塞满从而错过重要的信息），建议注释掉/etc/xinetd.conf的success：</p>\n<pre><code># log_on_success  = PID HOST DURATION EXIT\n</code></pre><p>如果使用了防火墙，要添加允许IP到873端口的规则。</p>\n<pre><code># iptables -A INPUT -p tcp -m state --state NEW  -m tcp --dport 873 -j ACCEPT\n# iptables -L  查看一下防火墙是不是打开了 873端口\n# netstat -anp|grep 873\n</code></pre><p>建议关闭selinux，可能会由于强访问控制导致同步报错。</p>\n<h4 id=\"客户端测试同步\"><a href=\"#客户端测试同步\" class=\"headerlink\" title=\"客户端测试同步\"></a>客户端测试同步</h4><p>单向同步时，客户端只需要一个包含密码的文件。<br>/etc/rsync_client.pwd：</p>\n<blockquote>\n<p>   test  </p>\n</blockquote>\n<pre><code>chmod 600 /etc/rsync_client.pwd\n</code></pre><p>命令：<br>将本地/root/目录同步到远程172.29.88.223的/tmp/rsync_bak2目录（module_test指定）：  </p>\n<pre><code>/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd /root/ sean@172.29.88.223::module_test \n</code></pre><p>当然你也可以将远程的/tmp/rsync_bak2目录同步到本地目录/root/tmp：</p>\n<pre><code>/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd sean@172.29.88.223::module_test /root/ \n</code></pre><p>从上面两个命令可以看到，其实这里的服务器与客户端的概念是很模糊的，rsync daemon都运行在远程172.29.88.223上，第一条命令是本地主动推送目录到远程，远程服务器是用来备份的；第二条命令是本地主动向远程索取文件，本地服务器用来备份，也可以认为是本地服务器恢复的一个过程。</p>\n<h3 id=\"rsync不足\"><a href=\"#rsync不足\" class=\"headerlink\" title=\"rsync不足\"></a>rsync不足</h3><p>与传统的cp、tar备份方式相比，rsync具有安全性高、备份迅速、支持增量备份等优点，通过rsync可以解决对实时性要求不高的数据备份需求，例如定期的备份文件服务器数据到远端服务器，对本地磁盘定期做数据镜像等。</p>\n<p>随着应用系统规模的不断扩大，对数据的安全性和可靠性也提出的更好的要求，rsync在高端业务系统中也逐渐暴露出了很多不足，首先，rsync同步数据时，需要扫描所有文件后进行比对，进行差量传输。如果文件数量达到了百万甚至千万量级，扫描所有文件将是非常耗时的。而且正在发生变化的往往是其中很少的一部分，这是非常低效的方式。其次，rsync不能实时的去监测、同步数据，虽然它可以通过crontab方式进行触发同步，但是两次触发动作一定会有时间差，这样就导致了服务端和客户端数据可能出现不一致，无法在应用故障时完全的恢复数据。基于以上原因，rsync+inotify组合出现了！</p>\n<h2 id=\"inotify-tools\"><a href=\"#inotify-tools\" class=\"headerlink\" title=\"inotify-tools\"></a>inotify-tools</h2><h3 id=\"什么是inotify\"><a href=\"#什么是inotify\" class=\"headerlink\" title=\"什么是inotify\"></a>什么是inotify</h3><p>inotify是一种强大的、细粒度的、异步的文件系统事件监控机制，Linux内核从2.6.13开始引入，允许监控程序打开一个独立文件描述符，并针对事件集监控一个或者多个文件，例如打开、关闭、移动/重命名、删除、创建或者改变属性。</p>\n<p>CentOS6自然已经支持：</p>\n<p>使用ll /proc/sys/fs/inotify命令，是否有以下三条信息输出，如果没有表示不支持。</p>\n<blockquote>\n<p>total 0<br>-rw-r–r– 1 root root 0 Dec 11 15:23 max_queued_events<br>-rw-r–r– 1 root root 0 Dec 11 15:23 max_user_instances<br>-rw-r–r– 1 root root 0 Dec 11 15:23 max_user_watches</p>\n</blockquote>\n<p>1./proc/sys/fs/inotify/max_queued_evnets表示调用inotify_init时分配给inotify instance中可排队的event的数目的最大值，超出这个值的事件被丢弃，但会触发IN_Q_OVERFLOW事件。</p>\n<p>2./proc/sys/fs/inotify/max_user_instances表示每一个real user ID可创建的inotify instatnces的数量上限。</p>\n<p>3./proc/sys/fs/inotify/max_user_watches表示每个inotify instatnces可监控的最大目录数量。如果监控的文件数目巨大，需要根据情况，适当增加此值的大小。</p>\n<p>inotify-tools：</p>\n<p>inotify-tools是为linux下inotify文件监控工具提供的一套C的开发接口库函数，同时还提供了一系列的命令行工具，这些工具可以用来监控文件系统的事件。 inotify-tools是用c编写的，除了要求内核支持inotify外，不依赖于其他。inotify-tools提供两种工具，一是inotifywait，它是用来监控文件或目录的变化，二是inotifywatch，它是用来统计文件系统访问的次数。</p>\n<p>下载inotify-tools-3.14-1.el6.x86_64.rpm，通过rpm包安装：</p>\n<pre><code># rpm -ivh /apps/crm/soft_src/inotify-tools-3.14-1.el6.x86_64.rpm \nwarning: /apps/crm/soft_src/inotify-tools-3.14-1.el6.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 4026433f: NOKEY  \nPreparing...                ########################################### [100%]\n1:inotify-tools          ########################################### [100%]\n# rpm -qa|grep inotify\ninotify-tools-3.14-1.el5.x86_64\n</code></pre><h3 id=\"inotifywait使用示例\"><a href=\"#inotifywait使用示例\" class=\"headerlink\" title=\"inotifywait使用示例\"></a>inotifywait使用示例</h3><p>监控/root/tmp目录文件的变化：</p>\n<pre><code>/usr/bin/inotifywait -mrq --timefmt &apos;%Y/%m/%d-%H:%M:%S&apos; --format &apos;%T %w %f&apos; -e modify,delete,create,move,attrib /root/tmp/\n</code></pre><p>上面的命令表示，持续监听/root/tmp目录及其子目录的文件变化，监听事件包括文件被修改、删除、创建、移动、属性更改，显示到屏幕。执行完上面的命令后，在/root/tmp下创建或修改文件都会有信息输出：</p>\n<pre><code>2014/12/11-15:40:04 /root/tmp/ new.txt\n2014/12/11-15:40:22 /root/tmp/ .new.txt.swp\n2014/12/11-15:40:22 /root/tmp/ .new.txt.swx\n2014/12/11-15:40:22 /root/tmp/ .new.txt.swx\n2014/12/11-15:40:22 /root/tmp/ .new.txt.swp\n2014/12/11-15:40:22 /root/tmp/ .new.txt.swp\n2014/12/11-15:40:23 /root/tmp/ .new.txt.swp\n2014/12/11-15:40:31 /root/tmp/ .new.txt.swp\n2014/12/11-15:40:32 /root/tmp/ 4913\n2014/12/11-15:40:32 /root/tmp/ 4913\n2014/12/11-15:40:32 /root/tmp/ 4913\n2014/12/11-15:40:32 /root/tmp/ new.txt\n2014/12/11-15:40:32 /root/tmp/ new.txt~\n2014/12/11-15:40:32 /root/tmp/ new.txt\n...\n</code></pre><h2 id=\"rsync组合inotify-tools完成实时同步\"><a href=\"#rsync组合inotify-tools完成实时同步\" class=\"headerlink\" title=\"rsync组合inotify-tools完成实时同步\"></a>rsync组合inotify-tools完成实时同步</h2><p>这一步的核心其实就是在客户端创建一个脚本rsync.sh，适用inotifywait监控本地目录的变化，触发rsync将变化的文件传输到远程备份服务器上。为了更接近实战，我们要求一部分子目录不同步，如/root/tmp/log和临时文件。</p>\n<h3 id=\"创建排除在外不同步的文件列表\"><a href=\"#创建排除在外不同步的文件列表\" class=\"headerlink\" title=\"创建排除在外不同步的文件列表\"></a>创建排除在外不同步的文件列表</h3><p>排除不需要同步的文件或目录有两种做法，第一种是inotify监控整个目录，在rsync中加入排除选项，简单；第二种是inotify排除部分不监控的目录，同时rsync中也要加入排除选项，可以减少不必要的网络带宽和CPU消耗。我们选择第二种。</p>\n<h4 id=\"inotifywait排除\"><a href=\"#inotifywait排除\" class=\"headerlink\" title=\"inotifywait排除\"></a>inotifywait排除</h4><p>这个操作在客户端进行，假设/tmp/src/mail/2014/以及/tmp/src/mail/2015/cache/目录下的所有文件不用同步，所以不需要监控，/tmp/src/下的其他文件和目录都同步。（其实对于打开的临时文件，可以不监听modify时间而改成监听close_write）</p>\n<p>inotifywait排除监控目录有–exclude <pattern>和–fromfile <file>两种格式，并且可以同时使用，但主要前者可以用正则，而后者只能是具体的目录或文件。</file></pattern></p>\n<pre><code># vi /etc/inotify_exclude.lst：\n/tmp/src/pdf\n@/tmp/src/2014\n</code></pre><p>使用fromfile格式只能用绝对路径，不能使用诸如*正则表达式去匹配，@表示排除。</p>\n<p>如果要排除的格式比较复杂，必须使用正则，那只能在inotifywait中加入选项，如–exclude ‘(.<em>/</em>.log|.<em>/</em>.swp)$|^/tmp/src/mail/(2014|201.<em>/cache.</em>)’，表示排除/tmp/src/mail/以下的2014目录，和所有201*目录下的带cache的文件或目录，以及/tmp/src目录下所有的以.log或.swp结尾的文件。</p>\n<h4 id=\"rsync排除\"><a href=\"#rsync排除\" class=\"headerlink\" title=\"rsync排除\"></a>rsync排除</h4><p>使用inotifywait排除监控目录的情况下，必须同时使用rsync排除对应的目录，否则只要有触发同步操作，必然会导致不该同步的目录也会同步。与inotifywait类似，rsync的同步也有–exclude和–exclude-from两种写法。</p>\n<p>个人还是习惯将要排除同步的目录卸载单独的文件列表里，便于管理。使用–include-from=FILE时，排除文件列表用绝对路径，但FILE里面的内容请用相对路径，如：</p>\n<p>/etc/rsyncd.d/rsync_exclude.lst</p>\n<blockquote>\n<p>mail/2014/<br>mail/201<em>/201</em>/201<em>/.??</em><br>mail??<em><br>src/</em>.html<em><br>src/js/<br>src/ext3/<br>src/2014/20140[1-9]/<br>src/201</em>/201<em>/201</em>/.??<em><br>membermail/<br>membermail??</em><br>membermail/201<em>/201</em>/201<em>/.??</em></p>\n</blockquote>\n<p>排除同步的内容包括，mail下的2014目录，类似2015/201501/20150101/下的临时或隐藏文件，等</p>\n<h3 id=\"客户端同步到远程的脚本rsync-sh\"><a href=\"#客户端同步到远程的脚本rsync-sh\" class=\"headerlink\" title=\"客户端同步到远程的脚本rsync.sh\"></a>客户端同步到远程的脚本rsync.sh</h3><p>下面是一个完整的同步脚本，请根据需要进行裁剪，rsync.sh：</p>\n<pre><code>current_date=$(date +%Y%m%d_%H%M%S)\nsource_path=/tmp/src/\nlog_file=/var/log/rsync_client.log\n\n#rsync\nrsync_server=172.29.88.223\nrsync_user=sean\nrsync_pwd=/etc/rsync_client.pwd\nrsync_module=module_test\nINOTIFY_EXCLUDE=&apos;(.*/*\\.log|.*/*\\.swp)$|^/tmp/src/mail/(2014|20.*/.*che.*)&apos;\nRSYNC_EXCLUDE=&apos;/etc/rsyncd.d/rsync_exclude.lst&apos;\n\n#rsync client pwd check\nif [ ! -e ${rsync_pwd} ];then\necho -e &quot;rsync client passwod file ${rsync_pwd} does not exist!&quot;\nexit 0\nfi\n\n#inotify_function\ninotify_fun(){\n/usr/bin/inotifywait -mrq --timefmt &apos;%Y/%m/%d-%H:%M:%S&apos; --format &apos;%T %w %f&apos; \\\n      --exclude ${INOTIFY_EXCLUDE}  -e modify,delete,create,move,attrib ${source_path} \\\n      | while read file\n  do\n      /usr/bin/rsync -auvrtzopgP --exclude-from=${RSYNC_EXCLUDE} --progress --bwlimit=200 --password-file=${rsync_pwd} ${source_path} ${rsync_user}@${rsync_server}::${rsync_module} \n  done\n}\n\n#inotify log\ninotify_fun &gt;&gt; ${log_file} 2&gt;&amp;1 &amp;\n</code></pre><p>–bwlimit=200用于限制传输速率最大200kb，因为在实际应用中发现如果不做速率限制，会导致巨大的CPU消耗。</p>\n<p>在客户端运行脚本# ./rsync.sh即可实时同步目录。</p>"},{"title":"linux 命令rsync+crontab实现自动同步","date":"2016-10-05T04:00:00.000Z","_content":"linux 命令rsync+crontab实现自动同步,这个技术现在已经用得很广泛了,比起第三方的软件要可靠好使,所以得到系统管理员的广泛应用;在此,我给大伙来分享一下;请指教.\n\n首先,我们来了解一下这个命令:\n\nrsync命令格式:rsync [option] 源路径 目标路径;\n<!--more-->\n其中:  \n\n[option]:  \n\n    a:使用archive模式,等于-rlptgoD,即保持原有的文件权限;\n    \n    z:表示传输时压缩数据;\n    \n    v:显示到屏幕中;\n    \n    e:使用远程shell程序(可以使用rsh或ssh;\n    \n    --delete:精确保存副本,源主机删除的文件,目标主机也会同步删除;\n    \n    --include=PATTERN:不排除符合PATTERN的文件或目录;\n    \n    --exclude=PATTERN:排除所有符合PATTERN的文件或目录;\n    \n    --password-file:指定用于rsync服务器的用户验证密码;\n    \n源路径和目标路径可以使用如下格式:\n\n\n    rsync://[USER@]Host[:Port]/Path #--rsync服务器路径;\n    \n    [USER@]Host::Path   #--rsync服务器的另一种表示形式;\n    \n    [USER@]Host:Path#--远程路径;\n    \n    LocalPath   #--本地路径;\n    \n知道上述命令的基本格式了吗?\n\n下面我们来讲安装rsyn命令;\n\n\n    [root@dbserver ~]#yum list rsync*\n    \n    Loaded plugins: fastestmirror, refresh-packagekit, security\n    \n    Loading mirror speeds from cached hostfile\n    \n     * rpmforge: mirrors.neusoft.edu.cn\n    \n    Installed Packages\n    \n    rsync.i686  3.0.6-9.el6   @anaconda-CentOS-201207051201.i386/6.3\n    \n    [root@dbserver ~]#yum -y install rsync*\n    \n前面是查看rsync RPM包,后面是安装rsync这个命令;\n\n安装完后,我们便可以来配置rsync服务器与客服端了;\n\n实例:\n\nA服务器:192.168.1.213\n\nB客户端:192.168.1.210\n\n首先人们配置服务器,look,\n\n在配置服务器之前要先生成密钥,ssh-keygen -t rsa,生成密钥如下:\n\n\n    [root@masternagios .ssh]# ls\n    \n    id_rsa  id_rsa.pub\n    \n    [root@masternagios .ssh]#  scp id_rsa_pub root@192.168.1.210:/root/.ssh/authorized_keys\n\n在客户端也要如下操作:\n\n\n    [root@masternagios .ssh]# ssh-keygen -t rsa\n    \n    [root@masternagios .ssh]# ls\n    \n    id_rsa  id_rsa.pub  authorized_keys(213的公钥)\n    \n    [root@masternagios.ssh]#\n    \n    scp id_rsa_pub root@192.168.1.213:/root/.ssh/authorized_keys\n\n这样两台机可以无密码SSH登陆,以便后面我们同步方便;当然,不要上述的操作也能实现;那么如下操作:\n\n服务端:\n\n    vi /etc/sery.pass  权限:600(chmod 600 /etc/sery.pass)\n    \n    root:123456\n\n客服端:\n    \n    vi /etc/sery_client.pass  权限:600(chmod 600 /etc/sery_client.pass)\n    \n    123456\n\n生成的这两件文件后面有用处的;\n\n然后新建配置文件vi /etc/rsyncd.conf,内容如下图示:\n![](http://hiphotos.baidu.com/exp/pic/item/d872d695d143ad4b038f881c83025aafa50f060e.jpg)\n解析如下:\n\n    uid = root           #root用户访问(我这里用ROOT用户,也可以用其他新建的用户)\n\n    gid = root           #root组用户访问\n\n    use chroot = no      #不能使用chroot\n\n    max connections = 10  #最大连接数\n\n    list = yes           #允许列出文件清单\n\n    pid file = /var/run/rsyncd.pid\n\n    lock file = /var/run/rsyncd.lock\n\n    log file = /var/log/rsyncd.log\n\n    hosts allow  = 192.168.1.2      #只允许这个主机访问\n\n   [data]                    #发布项(注意这个命名)\n\n    path = /webapps/IDManage         #发布的路径\n\n    ignore errors\n\n    read only = yes            #只读\n\n    auth users = root                #认证用户为root\n\n    secrets file = /etc/sery.pass    #密码文件\n\n然后我们来启动:\n\n[root@masternagios ~]# rsync --daemon --config=/etc/rsyncd.conf\n\n    [root@masternagios ~]# ps -ef |grep rsync\n\n    root     21359     1  0 Aug24 ?        00:00:00 rsync --daemon --     config=/etc/rsyncd.conf\n\n    root     24018 23885  0 10:38 pts/0    00:00:00 grep rsync\n\n    [root@masternagios ~]#lsof -i:873\n\n    COMMAND   PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n\n    rsync   21359 root    4u  IPv4 1558266      0t0  TCP *:rsync (LISTEN)\n\n    rsync   21359 root    5u  IPv6 1558267      0t0  TCP *:rsync (LISTEN)\n\n然后在客户端测试:\n    \n    [root@dbserver ~]# telnet 192.168.1.213 873\n    \n    Trying 192.168.1.213...\n    \n    Connected to 192.168.1.213.\n    \n    Escape character is '^]'.\n    \n    @RSYNCD: 30.0\n    \n    ^]\n    \n    telnet> q\n    \n    Connection closed.\n\n说明网络端口开放,没有问题;通常在这配置时会发现一些问题,比如报错(111)--说明服务器端口未开启,就检查一下rsync服务有没有开启;\n\n报错(1503)(1536)--说明无 [data] #发布项(注意这个命名),这里命令一定要对应上同步::[data];\n\n我们再来把服务端rsync加自动启动;\n\n    echo \"/usr/bin/rsync --daemon --config=/etc/rsyncd.conf\" >>/etc/rc.local\n\n配置客户端;\n\n客户端只要安装rsync这个命令便可以实现,所以,我们来测试同步实现;\n\n    [root@dbserver ~]#rsync -aSvH /webapps/IDManage/ root@192.168.1.213::data --password-file=/etc/sery_client.pass\n    \n可以看到:\n![](http://hiphotos.baidu.com/exp/pic/item/346bd85c10385343bd094ffd9213b07ec88088ed.jpg)\n命令执行成功;说明服务端与客户端都没有问题;\n\n如何自实rsync客户端自动与rsync服务器端同步呢?这里我们用到计划任务命令:crontab;\n\n首先,我们来做一个shell脚本,\n\n    [root@dbserver ~]#vi /tmp/rsyncd.sh\n    \n    #!/bin/bash\n    \n    rsync -aSvH /webapps/IDManage/ root@192.168.1.213::data --password-file=/etc/sery_client.pass\n    \n    wq!   ##保存退出\n    \n    [root@dbserver ~]#crontab -e\n    \n    */5 * * * * sh /tmp/rsyncd.sh #第5分钟执行一次同步;\n    \n    wq!   ##保存退出\n\n看了,到此分享linux 命令rsync+crontab实现自动同步,已经结束;总结一点:rsync命令格式一定要知道:rsync [option] 源路径目标路径,目标路径的格式有几种,大家只要记得一两种便可以了;\n","source":"_posts/linux_命令rsync+crontab实现自动同步.md","raw":"---\ntitle: linux 命令rsync+crontab实现自动同步\ndate: 2016-10-05\ntags: rsync\ncategories: rsync\n---\nlinux 命令rsync+crontab实现自动同步,这个技术现在已经用得很广泛了,比起第三方的软件要可靠好使,所以得到系统管理员的广泛应用;在此,我给大伙来分享一下;请指教.\n\n首先,我们来了解一下这个命令:\n\nrsync命令格式:rsync [option] 源路径 目标路径;\n<!--more-->\n其中:  \n\n[option]:  \n\n    a:使用archive模式,等于-rlptgoD,即保持原有的文件权限;\n    \n    z:表示传输时压缩数据;\n    \n    v:显示到屏幕中;\n    \n    e:使用远程shell程序(可以使用rsh或ssh;\n    \n    --delete:精确保存副本,源主机删除的文件,目标主机也会同步删除;\n    \n    --include=PATTERN:不排除符合PATTERN的文件或目录;\n    \n    --exclude=PATTERN:排除所有符合PATTERN的文件或目录;\n    \n    --password-file:指定用于rsync服务器的用户验证密码;\n    \n源路径和目标路径可以使用如下格式:\n\n\n    rsync://[USER@]Host[:Port]/Path #--rsync服务器路径;\n    \n    [USER@]Host::Path   #--rsync服务器的另一种表示形式;\n    \n    [USER@]Host:Path#--远程路径;\n    \n    LocalPath   #--本地路径;\n    \n知道上述命令的基本格式了吗?\n\n下面我们来讲安装rsyn命令;\n\n\n    [root@dbserver ~]#yum list rsync*\n    \n    Loaded plugins: fastestmirror, refresh-packagekit, security\n    \n    Loading mirror speeds from cached hostfile\n    \n     * rpmforge: mirrors.neusoft.edu.cn\n    \n    Installed Packages\n    \n    rsync.i686  3.0.6-9.el6   @anaconda-CentOS-201207051201.i386/6.3\n    \n    [root@dbserver ~]#yum -y install rsync*\n    \n前面是查看rsync RPM包,后面是安装rsync这个命令;\n\n安装完后,我们便可以来配置rsync服务器与客服端了;\n\n实例:\n\nA服务器:192.168.1.213\n\nB客户端:192.168.1.210\n\n首先人们配置服务器,look,\n\n在配置服务器之前要先生成密钥,ssh-keygen -t rsa,生成密钥如下:\n\n\n    [root@masternagios .ssh]# ls\n    \n    id_rsa  id_rsa.pub\n    \n    [root@masternagios .ssh]#  scp id_rsa_pub root@192.168.1.210:/root/.ssh/authorized_keys\n\n在客户端也要如下操作:\n\n\n    [root@masternagios .ssh]# ssh-keygen -t rsa\n    \n    [root@masternagios .ssh]# ls\n    \n    id_rsa  id_rsa.pub  authorized_keys(213的公钥)\n    \n    [root@masternagios.ssh]#\n    \n    scp id_rsa_pub root@192.168.1.213:/root/.ssh/authorized_keys\n\n这样两台机可以无密码SSH登陆,以便后面我们同步方便;当然,不要上述的操作也能实现;那么如下操作:\n\n服务端:\n\n    vi /etc/sery.pass  权限:600(chmod 600 /etc/sery.pass)\n    \n    root:123456\n\n客服端:\n    \n    vi /etc/sery_client.pass  权限:600(chmod 600 /etc/sery_client.pass)\n    \n    123456\n\n生成的这两件文件后面有用处的;\n\n然后新建配置文件vi /etc/rsyncd.conf,内容如下图示:\n![](http://hiphotos.baidu.com/exp/pic/item/d872d695d143ad4b038f881c83025aafa50f060e.jpg)\n解析如下:\n\n    uid = root           #root用户访问(我这里用ROOT用户,也可以用其他新建的用户)\n\n    gid = root           #root组用户访问\n\n    use chroot = no      #不能使用chroot\n\n    max connections = 10  #最大连接数\n\n    list = yes           #允许列出文件清单\n\n    pid file = /var/run/rsyncd.pid\n\n    lock file = /var/run/rsyncd.lock\n\n    log file = /var/log/rsyncd.log\n\n    hosts allow  = 192.168.1.2      #只允许这个主机访问\n\n   [data]                    #发布项(注意这个命名)\n\n    path = /webapps/IDManage         #发布的路径\n\n    ignore errors\n\n    read only = yes            #只读\n\n    auth users = root                #认证用户为root\n\n    secrets file = /etc/sery.pass    #密码文件\n\n然后我们来启动:\n\n[root@masternagios ~]# rsync --daemon --config=/etc/rsyncd.conf\n\n    [root@masternagios ~]# ps -ef |grep rsync\n\n    root     21359     1  0 Aug24 ?        00:00:00 rsync --daemon --     config=/etc/rsyncd.conf\n\n    root     24018 23885  0 10:38 pts/0    00:00:00 grep rsync\n\n    [root@masternagios ~]#lsof -i:873\n\n    COMMAND   PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n\n    rsync   21359 root    4u  IPv4 1558266      0t0  TCP *:rsync (LISTEN)\n\n    rsync   21359 root    5u  IPv6 1558267      0t0  TCP *:rsync (LISTEN)\n\n然后在客户端测试:\n    \n    [root@dbserver ~]# telnet 192.168.1.213 873\n    \n    Trying 192.168.1.213...\n    \n    Connected to 192.168.1.213.\n    \n    Escape character is '^]'.\n    \n    @RSYNCD: 30.0\n    \n    ^]\n    \n    telnet> q\n    \n    Connection closed.\n\n说明网络端口开放,没有问题;通常在这配置时会发现一些问题,比如报错(111)--说明服务器端口未开启,就检查一下rsync服务有没有开启;\n\n报错(1503)(1536)--说明无 [data] #发布项(注意这个命名),这里命令一定要对应上同步::[data];\n\n我们再来把服务端rsync加自动启动;\n\n    echo \"/usr/bin/rsync --daemon --config=/etc/rsyncd.conf\" >>/etc/rc.local\n\n配置客户端;\n\n客户端只要安装rsync这个命令便可以实现,所以,我们来测试同步实现;\n\n    [root@dbserver ~]#rsync -aSvH /webapps/IDManage/ root@192.168.1.213::data --password-file=/etc/sery_client.pass\n    \n可以看到:\n![](http://hiphotos.baidu.com/exp/pic/item/346bd85c10385343bd094ffd9213b07ec88088ed.jpg)\n命令执行成功;说明服务端与客户端都没有问题;\n\n如何自实rsync客户端自动与rsync服务器端同步呢?这里我们用到计划任务命令:crontab;\n\n首先,我们来做一个shell脚本,\n\n    [root@dbserver ~]#vi /tmp/rsyncd.sh\n    \n    #!/bin/bash\n    \n    rsync -aSvH /webapps/IDManage/ root@192.168.1.213::data --password-file=/etc/sery_client.pass\n    \n    wq!   ##保存退出\n    \n    [root@dbserver ~]#crontab -e\n    \n    */5 * * * * sh /tmp/rsyncd.sh #第5分钟执行一次同步;\n    \n    wq!   ##保存退出\n\n看了,到此分享linux 命令rsync+crontab实现自动同步,已经结束;总结一点:rsync命令格式一定要知道:rsync [option] 源路径目标路径,目标路径的格式有几种,大家只要记得一两种便可以了;\n","slug":"linux_命令rsync+crontab实现自动同步","published":1,"updated":"2019-06-18T08:07:01.115Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9skj0012hcb7klwf0dba","content":"<p>linux 命令rsync+crontab实现自动同步,这个技术现在已经用得很广泛了,比起第三方的软件要可靠好使,所以得到系统管理员的广泛应用;在此,我给大伙来分享一下;请指教.</p>\n<p>首先,我们来了解一下这个命令:</p>\n<p>rsync命令格式:rsync [option] 源路径 目标路径;<br><a id=\"more\"></a><br>其中:  </p>\n<p>[option]:  </p>\n<pre><code>a:使用archive模式,等于-rlptgoD,即保持原有的文件权限;\n\nz:表示传输时压缩数据;\n\nv:显示到屏幕中;\n\ne:使用远程shell程序(可以使用rsh或ssh;\n\n--delete:精确保存副本,源主机删除的文件,目标主机也会同步删除;\n\n--include=PATTERN:不排除符合PATTERN的文件或目录;\n\n--exclude=PATTERN:排除所有符合PATTERN的文件或目录;\n\n--password-file:指定用于rsync服务器的用户验证密码;\n</code></pre><p>源路径和目标路径可以使用如下格式:</p>\n<pre><code>rsync://[USER@]Host[:Port]/Path #--rsync服务器路径;\n\n[USER@]Host::Path   #--rsync服务器的另一种表示形式;\n\n[USER@]Host:Path#--远程路径;\n\nLocalPath   #--本地路径;\n</code></pre><p>知道上述命令的基本格式了吗?</p>\n<p>下面我们来讲安装rsyn命令;</p>\n<pre><code>[root@dbserver ~]#yum list rsync*\n\nLoaded plugins: fastestmirror, refresh-packagekit, security\n\nLoading mirror speeds from cached hostfile\n\n * rpmforge: mirrors.neusoft.edu.cn\n\nInstalled Packages\n\nrsync.i686  3.0.6-9.el6   @anaconda-CentOS-201207051201.i386/6.3\n\n[root@dbserver ~]#yum -y install rsync*\n</code></pre><p>前面是查看rsync RPM包,后面是安装rsync这个命令;</p>\n<p>安装完后,我们便可以来配置rsync服务器与客服端了;</p>\n<p>实例:</p>\n<p>A服务器:192.168.1.213</p>\n<p>B客户端:192.168.1.210</p>\n<p>首先人们配置服务器,look,</p>\n<p>在配置服务器之前要先生成密钥,ssh-keygen -t rsa,生成密钥如下:</p>\n<pre><code>[root@masternagios .ssh]# ls\n\nid_rsa  id_rsa.pub\n\n[root@masternagios .ssh]#  scp id_rsa_pub root@192.168.1.210:/root/.ssh/authorized_keys\n</code></pre><p>在客户端也要如下操作:</p>\n<pre><code>[root@masternagios .ssh]# ssh-keygen -t rsa\n\n[root@masternagios .ssh]# ls\n\nid_rsa  id_rsa.pub  authorized_keys(213的公钥)\n\n[root@masternagios.ssh]#\n\nscp id_rsa_pub root@192.168.1.213:/root/.ssh/authorized_keys\n</code></pre><p>这样两台机可以无密码SSH登陆,以便后面我们同步方便;当然,不要上述的操作也能实现;那么如下操作:</p>\n<p>服务端:</p>\n<pre><code>vi /etc/sery.pass  权限:600(chmod 600 /etc/sery.pass)\n\nroot:123456\n</code></pre><p>客服端:</p>\n<pre><code>vi /etc/sery_client.pass  权限:600(chmod 600 /etc/sery_client.pass)\n\n123456\n</code></pre><p>生成的这两件文件后面有用处的;</p>\n<p>然后新建配置文件vi /etc/rsyncd.conf,内容如下图示:<br><img src=\"http://hiphotos.baidu.com/exp/pic/item/d872d695d143ad4b038f881c83025aafa50f060e.jpg\" alt=\"\"><br>解析如下:</p>\n<pre><code>uid = root           #root用户访问(我这里用ROOT用户,也可以用其他新建的用户)\n\ngid = root           #root组用户访问\n\nuse chroot = no      #不能使用chroot\n\nmax connections = 10  #最大连接数\n\nlist = yes           #允许列出文件清单\n\npid file = /var/run/rsyncd.pid\n\nlock file = /var/run/rsyncd.lock\n\nlog file = /var/log/rsyncd.log\n\nhosts allow  = 192.168.1.2      #只允许这个主机访问\n</code></pre><p>   [data]                    #发布项(注意这个命名)</p>\n<pre><code>path = /webapps/IDManage         #发布的路径\n\nignore errors\n\nread only = yes            #只读\n\nauth users = root                #认证用户为root\n\nsecrets file = /etc/sery.pass    #密码文件\n</code></pre><p>然后我们来启动:</p>\n<p>[root@masternagios ~]# rsync –daemon –config=/etc/rsyncd.conf</p>\n<pre><code>[root@masternagios ~]# ps -ef |grep rsync\n\nroot     21359     1  0 Aug24 ?        00:00:00 rsync --daemon --     config=/etc/rsyncd.conf\n\nroot     24018 23885  0 10:38 pts/0    00:00:00 grep rsync\n\n[root@masternagios ~]#lsof -i:873\n\nCOMMAND   PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n\nrsync   21359 root    4u  IPv4 1558266      0t0  TCP *:rsync (LISTEN)\n\nrsync   21359 root    5u  IPv6 1558267      0t0  TCP *:rsync (LISTEN)\n</code></pre><p>然后在客户端测试:</p>\n<pre><code>[root@dbserver ~]# telnet 192.168.1.213 873\n\nTrying 192.168.1.213...\n\nConnected to 192.168.1.213.\n\nEscape character is &apos;^]&apos;.\n\n@RSYNCD: 30.0\n\n^]\n\ntelnet&gt; q\n\nConnection closed.\n</code></pre><p>说明网络端口开放,没有问题;通常在这配置时会发现一些问题,比如报错(111)–说明服务器端口未开启,就检查一下rsync服务有没有开启;</p>\n<p>报错(1503)(1536)–说明无 [data] #发布项(注意这个命名),这里命令一定要对应上同步::[data];</p>\n<p>我们再来把服务端rsync加自动启动;</p>\n<pre><code>echo &quot;/usr/bin/rsync --daemon --config=/etc/rsyncd.conf&quot; &gt;&gt;/etc/rc.local\n</code></pre><p>配置客户端;</p>\n<p>客户端只要安装rsync这个命令便可以实现,所以,我们来测试同步实现;</p>\n<pre><code>[root@dbserver ~]#rsync -aSvH /webapps/IDManage/ root@192.168.1.213::data --password-file=/etc/sery_client.pass\n</code></pre><p>可以看到:<br><img src=\"http://hiphotos.baidu.com/exp/pic/item/346bd85c10385343bd094ffd9213b07ec88088ed.jpg\" alt=\"\"><br>命令执行成功;说明服务端与客户端都没有问题;</p>\n<p>如何自实rsync客户端自动与rsync服务器端同步呢?这里我们用到计划任务命令:crontab;</p>\n<p>首先,我们来做一个shell脚本,</p>\n<pre><code>[root@dbserver ~]#vi /tmp/rsyncd.sh\n\n#!/bin/bash\n\nrsync -aSvH /webapps/IDManage/ root@192.168.1.213::data --password-file=/etc/sery_client.pass\n\nwq!   ##保存退出\n\n[root@dbserver ~]#crontab -e\n\n*/5 * * * * sh /tmp/rsyncd.sh #第5分钟执行一次同步;\n\nwq!   ##保存退出\n</code></pre><p>看了,到此分享linux 命令rsync+crontab实现自动同步,已经结束;总结一点:rsync命令格式一定要知道:rsync [option] 源路径目标路径,目标路径的格式有几种,大家只要记得一两种便可以了;</p>\n","site":{"data":{}},"excerpt":"<p>linux 命令rsync+crontab实现自动同步,这个技术现在已经用得很广泛了,比起第三方的软件要可靠好使,所以得到系统管理员的广泛应用;在此,我给大伙来分享一下;请指教.</p>\n<p>首先,我们来了解一下这个命令:</p>\n<p>rsync命令格式:rsync [option] 源路径 目标路径;<br>","more":"<br>其中:  </p>\n<p>[option]:  </p>\n<pre><code>a:使用archive模式,等于-rlptgoD,即保持原有的文件权限;\n\nz:表示传输时压缩数据;\n\nv:显示到屏幕中;\n\ne:使用远程shell程序(可以使用rsh或ssh;\n\n--delete:精确保存副本,源主机删除的文件,目标主机也会同步删除;\n\n--include=PATTERN:不排除符合PATTERN的文件或目录;\n\n--exclude=PATTERN:排除所有符合PATTERN的文件或目录;\n\n--password-file:指定用于rsync服务器的用户验证密码;\n</code></pre><p>源路径和目标路径可以使用如下格式:</p>\n<pre><code>rsync://[USER@]Host[:Port]/Path #--rsync服务器路径;\n\n[USER@]Host::Path   #--rsync服务器的另一种表示形式;\n\n[USER@]Host:Path#--远程路径;\n\nLocalPath   #--本地路径;\n</code></pre><p>知道上述命令的基本格式了吗?</p>\n<p>下面我们来讲安装rsyn命令;</p>\n<pre><code>[root@dbserver ~]#yum list rsync*\n\nLoaded plugins: fastestmirror, refresh-packagekit, security\n\nLoading mirror speeds from cached hostfile\n\n * rpmforge: mirrors.neusoft.edu.cn\n\nInstalled Packages\n\nrsync.i686  3.0.6-9.el6   @anaconda-CentOS-201207051201.i386/6.3\n\n[root@dbserver ~]#yum -y install rsync*\n</code></pre><p>前面是查看rsync RPM包,后面是安装rsync这个命令;</p>\n<p>安装完后,我们便可以来配置rsync服务器与客服端了;</p>\n<p>实例:</p>\n<p>A服务器:192.168.1.213</p>\n<p>B客户端:192.168.1.210</p>\n<p>首先人们配置服务器,look,</p>\n<p>在配置服务器之前要先生成密钥,ssh-keygen -t rsa,生成密钥如下:</p>\n<pre><code>[root@masternagios .ssh]# ls\n\nid_rsa  id_rsa.pub\n\n[root@masternagios .ssh]#  scp id_rsa_pub root@192.168.1.210:/root/.ssh/authorized_keys\n</code></pre><p>在客户端也要如下操作:</p>\n<pre><code>[root@masternagios .ssh]# ssh-keygen -t rsa\n\n[root@masternagios .ssh]# ls\n\nid_rsa  id_rsa.pub  authorized_keys(213的公钥)\n\n[root@masternagios.ssh]#\n\nscp id_rsa_pub root@192.168.1.213:/root/.ssh/authorized_keys\n</code></pre><p>这样两台机可以无密码SSH登陆,以便后面我们同步方便;当然,不要上述的操作也能实现;那么如下操作:</p>\n<p>服务端:</p>\n<pre><code>vi /etc/sery.pass  权限:600(chmod 600 /etc/sery.pass)\n\nroot:123456\n</code></pre><p>客服端:</p>\n<pre><code>vi /etc/sery_client.pass  权限:600(chmod 600 /etc/sery_client.pass)\n\n123456\n</code></pre><p>生成的这两件文件后面有用处的;</p>\n<p>然后新建配置文件vi /etc/rsyncd.conf,内容如下图示:<br><img src=\"http://hiphotos.baidu.com/exp/pic/item/d872d695d143ad4b038f881c83025aafa50f060e.jpg\" alt=\"\"><br>解析如下:</p>\n<pre><code>uid = root           #root用户访问(我这里用ROOT用户,也可以用其他新建的用户)\n\ngid = root           #root组用户访问\n\nuse chroot = no      #不能使用chroot\n\nmax connections = 10  #最大连接数\n\nlist = yes           #允许列出文件清单\n\npid file = /var/run/rsyncd.pid\n\nlock file = /var/run/rsyncd.lock\n\nlog file = /var/log/rsyncd.log\n\nhosts allow  = 192.168.1.2      #只允许这个主机访问\n</code></pre><p>   [data]                    #发布项(注意这个命名)</p>\n<pre><code>path = /webapps/IDManage         #发布的路径\n\nignore errors\n\nread only = yes            #只读\n\nauth users = root                #认证用户为root\n\nsecrets file = /etc/sery.pass    #密码文件\n</code></pre><p>然后我们来启动:</p>\n<p>[root@masternagios ~]# rsync –daemon –config=/etc/rsyncd.conf</p>\n<pre><code>[root@masternagios ~]# ps -ef |grep rsync\n\nroot     21359     1  0 Aug24 ?        00:00:00 rsync --daemon --     config=/etc/rsyncd.conf\n\nroot     24018 23885  0 10:38 pts/0    00:00:00 grep rsync\n\n[root@masternagios ~]#lsof -i:873\n\nCOMMAND   PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n\nrsync   21359 root    4u  IPv4 1558266      0t0  TCP *:rsync (LISTEN)\n\nrsync   21359 root    5u  IPv6 1558267      0t0  TCP *:rsync (LISTEN)\n</code></pre><p>然后在客户端测试:</p>\n<pre><code>[root@dbserver ~]# telnet 192.168.1.213 873\n\nTrying 192.168.1.213...\n\nConnected to 192.168.1.213.\n\nEscape character is &apos;^]&apos;.\n\n@RSYNCD: 30.0\n\n^]\n\ntelnet&gt; q\n\nConnection closed.\n</code></pre><p>说明网络端口开放,没有问题;通常在这配置时会发现一些问题,比如报错(111)–说明服务器端口未开启,就检查一下rsync服务有没有开启;</p>\n<p>报错(1503)(1536)–说明无 [data] #发布项(注意这个命名),这里命令一定要对应上同步::[data];</p>\n<p>我们再来把服务端rsync加自动启动;</p>\n<pre><code>echo &quot;/usr/bin/rsync --daemon --config=/etc/rsyncd.conf&quot; &gt;&gt;/etc/rc.local\n</code></pre><p>配置客户端;</p>\n<p>客户端只要安装rsync这个命令便可以实现,所以,我们来测试同步实现;</p>\n<pre><code>[root@dbserver ~]#rsync -aSvH /webapps/IDManage/ root@192.168.1.213::data --password-file=/etc/sery_client.pass\n</code></pre><p>可以看到:<br><img src=\"http://hiphotos.baidu.com/exp/pic/item/346bd85c10385343bd094ffd9213b07ec88088ed.jpg\" alt=\"\"><br>命令执行成功;说明服务端与客户端都没有问题;</p>\n<p>如何自实rsync客户端自动与rsync服务器端同步呢?这里我们用到计划任务命令:crontab;</p>\n<p>首先,我们来做一个shell脚本,</p>\n<pre><code>[root@dbserver ~]#vi /tmp/rsyncd.sh\n\n#!/bin/bash\n\nrsync -aSvH /webapps/IDManage/ root@192.168.1.213::data --password-file=/etc/sery_client.pass\n\nwq!   ##保存退出\n\n[root@dbserver ~]#crontab -e\n\n*/5 * * * * sh /tmp/rsyncd.sh #第5分钟执行一次同步;\n\nwq!   ##保存退出\n</code></pre><p>看了,到此分享linux 命令rsync+crontab实现自动同步,已经结束;总结一点:rsync命令格式一定要知道:rsync [option] 源路径目标路径,目标路径的格式有几种,大家只要记得一两种便可以了;</p>"},{"title":"linux—SSH1","date":"2016-09-02T04:00:00.000Z","_content":"一、远程连接简介\n\nl  远程连接服务器\n\n远程连接服务器通过文字或图形接口的方式来远程登陆系统，在远程的终端前面登陆linux主机并取得操作主机的接口shell，登陆后的操作就像在系统前面一样，这样可以进行系统管理的任务\n<!--more-->\nl  工作站\n\n工作站就是仅提供大量的运作能力给用户而不提供因特网服务的主机\n\nl  当前远程连接的登陆类型\n\n1、加密的远程连接\n\n主要是ssh，也是用到的最多最安全的，而且还可以使用rsync通过ssh协议来进行异地备份\n\n2、图形接口的远程连接\n\nXDMCP、VNC和XRDP，这些方式由于是传输图形所以速度慢，且安全性也不是很好\n\n二、远程连接之SSH\n\nSsh是secure shell protocol（安全的壳程序协议）的简写，可以通过数据包加密技术将传输的数据包加密后再传输到网络上，当前ssh有两个版本，其中version2加上了连接检测的机制，可以避免连接期间被插入恶意攻击码\n\nl  Ssh服务器提供的功能\n\n默认的ssh服务器提供两个服务器功能\n\n1、ssh服务\n\n类似telnet的远程连接，使用shell的服务器，可以用来管理服务器\n\n2、ftp服务\n\n类似ftp服务的sftp-server，可以用来远程上传和下载\n\nl  连接的加密技术\n\n当前常见的网络数据包加密技术主要是通过非对称秘钥系统来处理的，主要是通过两把不同的公钥（public key）和私钥（private key）来进行数据的加密与解密的，且在同一个方向上的连接中这两把钥匙是成对存在的。每台主机都应该有自己的秘钥（公钥和私钥），并且公钥用于加密而私钥用于解密\n\n1、公钥（public key）\n\n提供给远程主机进行数据加密的行为，所有客户端都能取得它进行数据加密\n\n2、私钥（private key）\n\n远程主机使用公钥加密的数据在本地就需要使用私钥进行解密了，其非常重要只能在自己的主机上\n\nl  Ssh服务器端与客户端的链接步骤\n\n1、服务器建立公钥文件\n\n系统安装完成时sshd会朱勇去计算出需要的公钥文件和自己需要的私钥文件，等下次再次启动sshd的时候该服务就会主动去找文件/etc/ssh/ssh_host*\n\n2、客户端主动链接\n\n需要使用客户端程序（如ssh）来连接\n\n3、服务器传送公钥文件给客户端\n\n服务器将将取得的公钥文件/etc/ssh/ssh_host*传送给客户端（由于公钥是给大家使用的，所以此时的传送是明文的）\n\n4、客户端记录并比对该公钥数据，然后计算出自己的公钥和私钥\n\n客户端在第一次连接该服务器后会将服务器的公钥数据记录到客户端的用户主目录下的~ /.ssh/known_hosts内，如果已经记录过该数据则客户端会去比对此次受到的公钥与之前的差异，若接受此次公钥数据那么会计算出客户端自己的公钥和私钥\n\n5、客户端将自己的公钥传送给服务器\n\n此时服务器端会有自己的私钥和客户端的公钥；而客户端会有服务器的公钥和自己的私钥，这时服务器与客户端的秘钥（公钥与私钥）是不一样的，所以才称之为非对称式秘钥系统\n\n6、服务器开始进行双向加解密\n\n1)   服务器传送数据到客户端\n\n将用户的公钥加密后进行发送，客户端接收后用自己的私钥解密\n\n2)   客户端传送数据到服务器\n\n将服务器的公钥加密后进行发送，服务器接受后用自己的私钥解密\n\nl  秘钥文件的建立\n\n1、服务器端启动ssh服务，以生成服务器端的公钥和私钥\n\n\n    [root@baobao ~]# /etc/init.d/sshd restart\n\n停止 sshd：                                                [确定]\n\n生成 SSH1 RSA 主机键：                                     [确定]\n\n生成 SSH2 RSA 主机键：                                     [确定]\n\n正在生成 SSH2 DSA 主机键：                                 [确定]\n\n正在启动 sshd：                                            [确定]\n\n2、客户端利用ssh连接服务器\n\n\n    [root@abao ~]# ssh 172.168.72.68\n\n    The authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n    \n    RSA key fingerprint is36:cf:9f:46:54:46:4b:b3:b0:48:4a:93:4d:14:81:56.\n    \n    Are you sure you want to continue connecting (yes/no)? yes\n    \n    Warning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n    \n    root@172.168.72.68’s password:\n    \n    Last login: Sun Sep 28 15:37:10 2014 from localhost\n    \n    [root@baobao ~]# exit\n    \n    logout\n    \n    Connection to 172.168.72.68 closed.\n\n3、删除客户端的秘钥文件\n\n    [root@abao ~]# rm /etc/ssh/ssh_host*\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key.pub”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_key”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_key.pub”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key.pub”？y\n\n4、重新启动客户端的sshd服务以查看秘钥文件的建立过程\n\n    [root@abao ~]# /etc/init.d/sshd restart\n    \n    停止 sshd：[确定]\n    \n    生成 SSH1 RSA 主机键： [确定]\n    \n    生成 SSH2 RSA 主机键： [确定]\n    \n    正在生成 SSH2 DSA 主机键： [确定]\n    \n    正在启动 sshd：[确定]\n    \nl  Sshd服务的启动\n\n    [root@baobao ~]# /etc/init.d/sshd restart\n    \n    停止 sshd：[确定]\n    \n    正在启动 sshd：[确定]\n    \n    [root@baobao ~]# netstat -tlnp | grep ssh #注意ssh服务是tcp端口22\n    \n    tcp 0  0 0.0.0.0:22  0.0.0.0:*LISTEN 9262/sshd\n    \n    tcp 0  0:::22:::* LISTEN 9262/sshd\n\n在linux系统中默认就有ssh所需要的软件了，包括可以产生密码等协议的OpenSSL软件和OpenSSH软件，而且在当前的linux系统中都是默认启动ssh的。这个sshd可以同时提供shell与ftp，而且都是在tcp端口22\n\nl  Linux用户ssh客户端的连接程序\n\nLinux客户端默认情况下是可以正常使用ssh的而不必安装额外的软件，而且其默认是启动的\n\n1、 直接登录远程主机的指令ssh（可用作服务器管理）\n\nSsh命令格式为：ssh [-f][-o参数项目][-p非标准端口][账号@]IP地址[命令]\n\n1)   Ssh命令参数介绍\n\n-f：     需要配合后面的[命令]，不登陆远程主机直接发送一个命令过去而已\n\n-o：     主要的参数有：ConnectTimeout=秒数：连接等到的秒数，减少等待的时间\n\nStrictHostKeyChecking=yes/no/ask：默认是ask，如果想要public key主动加入known_host这里设置为no\n\n-p：     如果sshd服务启动在非标准的端口需使用该项目[命令]，不登陆远程主机直接发送一个命令过去，但与-f意义不太相同\n\n2)   ssh使用范例\n\nA：直接登录到远程主机\n\n    [root@abao ~]# ssh 172.168.72.68\n    \n    The authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n    \n    RSA key fingerprint is36:cf:9f:46:54:46:4b:b3:b0:48:4a:93:4d:14:81:56.   #远程服务器的公钥指纹码\n    \n    Are you sure you want to continue connecting (yes/no)? yes   #将上述指纹码写入服务器公钥记录文件~ /.ssh/known_hosts，等再次登录时就不会出现该指纹码提示了。一定要yes而不是y\n    \n    Warning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n    \n    root@172.168.72.68’s password:#远程主机的root密码\n    \n    Last login: Sun Sep 28 15:37:10 2014 from localhost\n    \n    [root@baobao ~]# exit #退出远程连接\n    \n    logout\n    \n    Connection to 172.168.72.68 closed.\n\n一般我们使用“ssh 账号 主机IP地址”的登录方式，如果不写账号的话那么会以本地计算机的当前账号来尝试登录远程主机\n\nB：再次登录远程主机\n\n    [root@abao ~]# ssh 172.168.72.68\n    \n    root@172.168.72.68’s password:\n    \n    Last login: Sun Sep 28 16:42:05 2014 from aca84448.ipt.aol.com\n\nC：使用账号axing登录\n\n    [root@baobao ~]# ssh axing@172.168.72.68\n    \n    The authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n    \n    RSA key fingerprint is 36:cf:9f:46:54:46:4b:b3:b0:48:4a:93:4d:14:81:56.\n    \n    Are you sure you want to continue connecting (yes/no)? yes\n    \n    Warning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n    \n    axing@172.168.72.68’s password:\n    \n    [axing@baobao ~]$   #远程登陆后身份变为axing\n    \nD：远程登陆执行命令后立刻离开\n\n    [root@abao ~]# ssh axing@172.168.72.68 find / -name passwd  #既后面直接加命令\n    \n    axing@172.168.72.68’s password:\n    \n卡在这里等待命令的执行完毕\n\nE：让远程主机自动运行命令而立刻回到本地端继续工作\n    \n    [root@abao ~]# ssh -faxing@172.168.72.68 shutdown -h now\n    \n    axing@172.168.72.68’s password:\n\nF：自动加上公钥记录而不再询问\n\n    [root@abao ~]# rm ~/.ssh/known_hosts\n    \n    rm：是否删除普通文件 “/root/.ssh/known_hosts”？y\n    \n    [root@abao ~]# ssh -o StrictHostKeyChecking=no root@172.168.72.68#不在要求输入yes或no了\n    \n    Warning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n    \n    root@172.168.72.68’s password:\n    \n    Last login: Mon Sep 29 14:00:28 2014 from aca84448.ipt.aol.com\n    \n2、服务器公钥记录文件~ /.ssh/known_hosts\n\n当远程登陆服务器时本机会主动将从服务器收到的公钥服务器公钥记录文件~ /.ssh/known_hosts进行比对，如果服务器的公钥文件还没有记录那么就会主动询问是否记录（登陆时候的yes或no行为）；如果收到的公钥已经记录那么会比对记录是否相同，如果相同则继续登陆，如果不同就会离开登陆而返回。但是如果是服务器重新安装那么服务器的公钥就会经常变化，这样的话我们就无法正常远程登陆了\n\nA：模拟服务器重新安装后ssh登陆\n\n    [root@baobao ~]# rm /etc/ssh/ssh_host*\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key.pub”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_key”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_key.pub”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key.pub”？y\n    \n    [root@baobao ~]# /etc/init.d/sshd restart\n    \n    停止 sshd：[确定]\n    \n    生成 SSH1 RSA 主机键： [确定]\n    \n    生成 SSH2 RSA 主机键： [确定]\n    \n    正在生成 SSH2 DSA 主机键： [确定]\n    \n    正在启动 sshd：[确定]\n    \n    [root@baobao ~]# ssh 172.168.72.68\n    \n    @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n    \n    @WARNING: REMOTE HOSTIDENTIFICATION HAS CHANGED! @\n    \n    @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n    \n    IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\n    \n    Someone could be eavesdropping on you right now(man-in-the-middle attack)!\n    \n    It is also possible that the RSA host key has just been changed.\n    \n    The fingerprint for the RSA key sent by the remote host is\n    \n    17:7e:8e:e9:fd:df:1c:e5:c9:9d:cd:30:31:5e:a6:45.\n    \n    Please contact your system administrator.\n    \n    Add correct host key in /root/.ssh/known_hosts to get rid ofthis message.\n    \n    Offending key in /root/.ssh/known_hosts:2#有问题的数据行号\n    \n    RSA host key for 172.168.72.68 has changed and you haverequested strict checking.\n    \n    Host key verification failed.\n    \nB：上述现象解决方法\n    \n    [root@baobao ~]# vim /root/.ssh/known_hosts  #清空该文件\n    \n    [root@baobao ~]# ssh 172.168.72.68\n    \n    The authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n    \n    RSA key fingerprint is17:7e:8e:e9:fd:df:1c:e5:c9:9d:cd:30:31:5e:a6:45.\n    \n    Are you sure you want to continue connecting (yes/no)? yes#记录公钥\n    \n    Warning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n    \n    root@172.168.72.68’s password:\n    \n    Last login: Mon Sep 29 14:28:46 2014 from aca84448.ipt.aol.com\n\n3、模拟FTP的文件传输之SFTP\n\n如果想要从远程服务器下载或上传文件就不能使用ssh了，而必须使用sftp或scp，这两个指令也是使用ssh的端口22，只是模拟成ftp与复制的操作而已\n\n1)   SFTP使用的命令\n\nSftp使用的命令与ftp是一样的\n\nA：针对远程服务器的命令\n\n跟linux服务器命令相同\n\nB：针对本机的命令\n\n在基本命令前面加“l”即代表是针对本机的操作，例如sftp> lcd /tmp进入本机的该目录\n\nC：针对资料的上传或下载的命令\n\nput [本地目录或文件][远程]或put [本地目录或文件]（这样会存储到远程主机的目录下）\n\nget [远程目录或文件][本机]或get [远程目录或文件]（这样会存储到当前本机所在目录）\n\n2)   Sftp的使用范例\n\nA：sftp的登陆于退出\n\n    [root@baobao ~]# sftp 172.168.72.68\n    \n    Connecting to 172.168.72.68…\n    \n    root@172.168.72.68’s password:\n    \n    sftp>\n    \n    或\n    \n    [root@baobao ~]# sftp axing@172.168.72.68\n    \n    Connecting to 172.168.72.68…\n    \n    axing@172.168.72.68’s password:\n    \n    sftp> exit\n\nB：上传与下载\n\n    sftp> pwd#查看当前在服务器的目录\n    \n    Remote working directory: /home/axing\n    \n    sftp> lls /etc/hosts #查看本机是否有该文件\n    \n    /etc/hosts\n    \n    sftp> put /etc/hosts #上传该文件到远程服务器\n    \n    Uploading /etc/hosts to /home/axing/hosts#上传到服务器的默认目录\n    \n    /etc/hosts 100%  1580.2KB/s   00:00\n    \n    sftp> ls\n    \n    hosts\n    \n    sftp> ls –a  #查看服务器该目录下的隐藏文件\n    \n    .   ..  .bash_history   .bash_logout.bash_profile   .bashrc .emacs\n    \n    .gnome2.mozillahosts\n    \n    sftp> lcd /tmp#切换到本地的目录/tmp下\n    \n    sftp> get .bashrc #从服务器下载该文件\n    \n    Fetching /home/axing/.bashrc to .bashrc\n    \n    /home/axing/.bashrc   100%  124 0.1KB/s  00:00\n    \n    sftp> lls –a #确认是否下载成功\n    \n    ……………………………………………\n    \n    baoaj  .bashrc  guoal   guobe  guobx guocq  guodj  pulse-Fhzh5o9BSGRy\n    \n    sftp> exit\n\n4、文件异地直接复制SCP\n\n当已经知道服务器上的文件名时可以使用该命令，该命令的上传和下载使用格式如下：\n\n上传：scp [-pr] [-l 速率] file [账号@]主机：目录名（：后没有空格）\n\n下载：scp [-pr] [-l 速率] [账号@]主机：file 目录名（file后有空格）\n\n1)   命令参数介绍\n\n-p：     保留文件的原有权限\n\n-r：     复制整个目录\n\n-l：     传输速率\n\n2)   Scp使用范例\n\nA：上传本地文件到远程服务器\n\n`[root@baobao ~]# scp /etc/hosts* axing@172.168.72.68:~     ` #上传到服务器的用户主目录下\n\naxing@172.168.72.68’s password:\n\nhosts                100% 158     0.2KB/s   00:00\n\nhosts.allow          100% 370     0.4KB/s   00:00\n\nhosts.deny           100% 460     0.5KB/s   00:00\n\nB：从服务器下载文件到本地\n\n    [root@baobao ~]# scp axing@172.168.72.68:/etc/bashrc /tmp\n    \n    axing@172.168.72.68’s password:\n    \n    bashrc   100%2681 2.6KB/s   00:00\n    \nl  windows用户ssh客户端的连接程序\n\n默认的windows并没有ssh的客户端程序，所以需要下载第三方软件才行，常见的有pietty、psftp和filezilla\n\n1、直接连接的pietty（可用作服务器管理）\n\n下载后安装即可使用，不过由于编码的问题中文会显示乱码需要设置该软件才行option—more options—features（右第二个打钩打开键盘数字）—connection—-ssh（右2only选择版本）\n\noption—font（脚本gb2312调整字符集支持中文）\n\n2、psftp\n\n下载后安装并启动，输入open172.168.72.68后连接即可\n\n3、filezilla\n\n下载后安装运行即可，是普通的中文界面ftp软件\n\nl  windows用户远程登陆管理服务器工具xshell（当前最好用的工具）\n\n1、xshell界面\n\n它是windows下当前最好用的远程管理软件，只需要你下载后安装即可使用，一般还有中文版，非常好用，以下是链接后的画面\n\n    Connecting to 172.168.72.68:22…\n    \n    Connection established.\n    \n    To escape to local shell, press ‘Ctrl+Alt+]’.  #回到本地shell\n    \n    Last login: Tue Sep 30 08:55:23 2014 from aca80058.ipt.aol.com\n    \n    [root@baobao ~]# ls\n    \n    123baoae  cheng  last.list  lsrootaf   图片\n    \n    anaconda-ks.cfg  baoagguo.txt  lsrootaa regular_express.txt.1  下载\n    \n    baoaa baoah  homelsrootab   xinzi.txt  音乐\n    \n    baoab   baoai  homefile  lsrootac   公共的 桌面\n    \n    ………………………………………………………\n    \n    [root@baobao ~]#\n\n2、xshell中文乱码解决法案\n\nXshell是个非常不错的工具。但很多时候中文显示为乱码的问题，解决方法其实很简单的，即把xshell编码方式改成UTF-8即可：[文件]–>[打开]–>在打开的session中选择连接的那个然后右键点击[属性] -> [终端]，编码选择为：Unicode(UTF-8)，然后重新连接服务器即可\n\n3、ssh远程登陆日志（重要）\n\n    [root@baobao ~]# cat /var/log/secure\n    \n    thenticationAgent, locale zh_CN.UTF-8)\n    \n    Sep 30 08:55:23 baobao sshd[2916]: Accepted password for rootfrom 172.168.0.88 port 57853 ssh2\n    \n    Sep 30 08:55:23 baobao sshd[2916]: pam_unix(sshd:session):session opened for user root by (uid=0)\n    \n    Sep 30 09:21:21 baobao sshd[3331]: Accepted password for rootfrom 172.168.0.88 port 52386 ssh2\n    \n    Sep 30 09:21:21 baobao sshd[3331]: pam_unix(sshd:session):session opened for user root by (uid=0)\n    \n    Sep 30 09:21:55 baobao sshd[2916]: pam_unix(sshd:session):session closed for user root\n\nl  sshd服务器配置\n\nsshd服务器的详细配置都放在/etc/ssh/sshd_config配置文件里，只要是没有被注释的就是默认值\n\n        [root@baobao ~]# vim /etc/ssh/sshd_config\n    \n    ……………………………………………………\n    \n    #Port 22   #也可以设置多个端口只要添加一行然后重启即可（不建议）\n    \n    #ListenAddress 0.0.0.0 #默认监听所有网卡的接口，如果想指定后面直接写ip即可\n    \n    Protocol 2 #ssh的协议版本\n    \n    # HostKey for protocol version 1   #下面是不同协议版本的秘钥文件host key\n    \n    #HostKey /etc/ssh/ssh_host_key\n    \n    # HostKeys for protocol version 2\n    \n    #HostKey /etc/ssh/ssh_host_rsa_key\n    \n    #HostKey /etc/ssh/ssh_host_dsa_key\n    \n    SyslogFacility AUTHPRIV #ssh登陆记录，默认是/var/log/secure\n    \n    #LoginGraceTime 2m  #登陆超时设置\n    \n    #PermitRootLogin yes#是否允许root登陆，默认是允许的，建议设置为no\n    \n    #StrictModes yes#是否让sshd检查相关权限以免用户将某些权限设置错误\n    \n    PasswordAuthentication yes  #密码验证，当然需要了\n    \n    #PermitEmptyPasswords no#是否允许空密码登陆，当然是no了\n    \n    #IgnoreUserKnownHosts no#是否忽略用户主文件记录，当然是no了\n    \n    #IgnoreRhosts yes   #是否取消~/.ssh/.rhosts认证，当然yes了\n    \n    ChallengeResponseAuthentication no  #该认证不安全，设置为no即可\n    \n    UsePAM yes#最好使用该认证模块记录与管理，所以yes\n    \n    #PrintLastLog yes #显示上次登陆的信息\n    \n    #TCPKeepAlive yes #网络不稳定时为了连接不中断可以设置为no\n    \n    #UsePrivilegeSeparation yes   #使用权限较低的程序来给用户操作\n    \n    DenyUsers #拒绝登陆的用户\n    \n    DenyGroups#拒绝登陆的组\n\n基本上ssh的默认设置已经就很安全了，不过还是建议将root的登陆权限取消，并将ssh的版本设置为2，而且通常这个文件不需要修改，如果修改了需要重启sshd\n\nl  制作不用密码接口登陆的ssh用户\n\n将客户端产生的key复制到服务器中，以后客户端再次登录的时候由于两者在ssh要连接的信号传递中已经比对过key了，所以不再需要输入密码了\n\n1、步骤一，客户端建立两把钥匙\n\n    [root@abao ~]# useradd abao\n    \n    [root@abao ~]# passwd abao\n    \n    更改用户 abao 的密码 。\n    \n    新的 密码：\n    \n    重新输入新的 密码：\n    \n    passwd： 所有的身份验证令牌已经成功更新。\n    \n    服务器上也做上面相同的用户配置\n    \n    [root@abao ~]# su – abao\n    \n    [abao@abao ~]$ ssh-keygen#默认以RSA建立两把钥匙\n    \n    Generating public/private rsa key pair.\n    \n    Enter file in which to save the key (/home/abao/.ssh/id_rsa): 回车\n    \n    Created directory ‘/home/abao/.ssh’. #建立主目录\n    \n    Enter passphrase (empty for no passphrase): 回车\n    \n    Enter same passphrase again: 回车\n    \n    Your identification has been saved in /home/abao/.ssh/id_rsa.   #私钥文件\n    \n    Your public key has been saved in /home/abao/.ssh/id_rsa.pub.   #公钥文件\n    \n    The key fingerprint is:\n    \n    89:1e:87:c9:a8:68:69:df:bd:75:a4:df:54:37:70:f1 abao@abao\n    \n    The key’s randomart image is:\n    \n    +–[ RSA 2048]—-+\n    \n    |   . |\n    \n    |o|\n    \n    | . .E|\n    \n    | o + .o  |\n    \n    |. * S  .   o.|\n    \n    | … . o  o   . o|\n    \n    |.+.   .  o . .  |\n    \n    |o . . . . o o|\n    \n    |   . . o.  . .   |\n    \n    +—————–+\n    \n    [abao@abao ~]$ ls -ld ~/.ssh; ls -l ~/.ssh\n    \n    drwx——. 2 abao abao 4096 9月  30 11:56 /home/abao/.ssh\n    \n    总用量 8\n    \n    -rw——-. 1 abao abao1675 9月  30 11:56 id_rsa\n    \n    -rw-r–r–. 1 abao abao  391 9月  3011:56 id_rsa.pub\n\n默认情况下建立私钥后权限和文件名放置位置都是正确的。身份必须是abao，当执行ssh-keygen的时候才会在用户主目录下生成两把钥匙，需要注意的是~/.ssh/目录必有700的权限，而且私钥文件的权限必须是-rw——-且属于abao才行，否则在秘钥比对中会被误判为危险而无法成功的以公私钥成对文件的机制实现连接\n\n2、步骤二，将公钥文件数据上传到服务器\n\n    [root@baobao ~]# useradd abao  #先在ssh服务器端建立上传文件账户abao\n    [root@baobao ~]# passwd abao\n    更改用户 abao 的密码 。\n    新的 密码：\n    重新输入新的 密码：\n    passwd： 所有的身份验证令牌已经成功更新。\n    [abao@abao ~]$ scp ~/.ssh/id_rsa.pub abao@172.168.72.68:~\n    \n    abao@172.168.72.68’s password:\n    \n    id_rsa.pub100%  3910.4KB/s   00:00\n\n3、步骤三，蒋公钥放置到服务器端的正确目录与文件名\n\n1)   服务器上建立文件~/.ssh\n\n    [root@baobao ~]# su – abao\n    \n    [abao@baobao ~]$ ls -ld .ssh\n    \n    ls: 无法访问.ssh: 没有那个文件或目录\n    \n    [abao@baobao ~]$ mkdir .ssh; chmod 700 .ssh  #注意其权限必须是700\n    \n    [abao@baobao ~]$ ls -ld .ssh\n    \n    drwx——. 2 abao abao 4096 9月  3012:30 .ssh\n\n2)   将公钥文件内的数据使用cat转存到authorized_keys内\n\n    [abao@baobao ~]$ ls -l *pub\n    \n    -rw-r–r–. 1 abao abao 391 9月  3012:26 id_rsa.pub\n    \n    [abao@baobao ~]$ cat id_rsa.pub >> .ssh/authorized_keys\n    \n    [abao@baobao ~]$ chmod 644 .ssh/authorized_keys\n    \n    [abao@baobao ~]$ ls -l .ssh\n    \n    总用量 4\n    \n    -rw-r–r–. 1 abao abao 391 9月  3012:39 authorized_keys\n\n总结：客户端必须制作出两把钥匙，其中私钥必须放到~/.ssh内；而公钥必须上传到服务器端并且放置到用户主目录下的~/.ssh/authorized_keys，同时目录的权限必须是700,而文件权限必须是644\n\n4、步骤四，验证\n\n    [root@abao ~]# ssh abao@172.168.72.68\n    \n    @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n    \n    @WARNING: REMOTE HOSTIDENTIFICATION HAS CHANGED! @\n    \n    @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n    \n    IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\n    \n    Someone could be eavesdropping on you right now(man-in-the-middle attack)!\n    \n    It is also possible that the RSA host key has just been changed.\n    \n    The fingerprint for the RSA key sent by the remote host is\n    \n    17:7e:8e:e9:fd:df:1c:e5:c9:9d:cd:30:31:5e:a6:45.\n    \n    Please contact your system administrator.\n    \n    Add correct host key in /root/.ssh/known_hosts to get rid ofthis message.\n    \n    Offending key in /root/.ssh/known_hosts:1\n    \n    RSA host key for 172.168.72.68 has changed and you haverequested strict checking.\n    \n    Host key verification failed.\n    \n    [root@abao ~]##看不再需要密码了\n    \n    [root@abao ~]# ifconfig   #查看服务器IP地址\n    \n    eth0  Linkencap:Ethernet  HWaddr00:0C:29:59:D9:E6\n    \n    inet addr:172.168.68.72  Bcast:172.168.255.255  Mask:255.255.0.0\n    \n    inet6 addr:fe80::20c:29ff:fe59:d9e6/64 Scope:Link\n    \n    UP BROADCASTRUNNING MULTICAST  MTU:1500  Metric:1\n    \n    RXpackets:239668 errors:0 dropped:0 overruns:0 frame:0\n    \n    TX packets:855errors:0 dropped:0 overruns:0 carrier:0\n    \n    collisions:0txqueuelen:1000\n    \n    RXbytes:18091942 (17.2 MiB)  TX bytes:71093(69.4 KiB)\n\nl  Ssh的安全设置\n\nSshd所谓的安全其实指的是它的数据加密功能，而对于sshd本身这个服务来说是很不安全的，所以如果不是特别需要请尽量限制在小范围内的几个ip或主机名即可\n\n1、 服务器本身的设置强化/etc/ssh/sshd——config\n\n\n    [root@baobao ~]# vim /etc/ssh/sshd_config\n\n1)   禁止root账号使用sshd服务\n\n    PermitRootLogin no                         #去掉注释并修改为no\n\n2)   禁止nossh这个组的用户使用sshd服务\n\n    DenyGroups nosh\n    \n3)   禁止用户testssh使用sshd服务\n\n    DenyUsers testssh\n    \n    [root@abao ~]# /etc/init.d/sshd restart\n    \n    停止 sshd：[确定]\n    \n    正在启动 sshd：[确定]\n    \n    [root@abao ~]# cat /var/log/secure #验证上述用户不能登陆后查看其日志\n    \n2、TCP Wrapper的使用\n\n    [root@baobao ~]# vim /etc/host.allow  #只允许内网和本机可以远程登陆\n    \n    sshd: 127.0.0.1 192.168.1.0/255.255.255.0192.168.10.0/255.255.255.0\n    \n    [root@baobao ~]# vim /etc/host.deny\n    \n    sshd: all\n\n3、iptables数据包过滤防火墙\n\n    [root@baobao ~]# iptables -A INPUT -i eth0 -s 192.168.1.0/24 -p tcp –dport 22 -j ACCEPT\n    \n    [root@baobao ~]# iptables -A INPUT -i eth0 -s 192.168.10.0/24 -p tcp –dport 22 -j ACCEPT\n    \n    [root@baobao ~]# /etc/init.d/iptables save\n    \n    [root@baobao ~]# /etc/init.d/iptables restart\n\n注意不要开放ssh的登陆权限给Internet上面的所有用户或主机，只开放给适当的部分用户或主机即可，否则会很不安全\n","source":"_posts/linux—SSH1.md","raw":"---\ntitle: linux—SSH1\ndate: 2016-09-02\ntags: ssh\ncategories: linux\n---\n一、远程连接简介\n\nl  远程连接服务器\n\n远程连接服务器通过文字或图形接口的方式来远程登陆系统，在远程的终端前面登陆linux主机并取得操作主机的接口shell，登陆后的操作就像在系统前面一样，这样可以进行系统管理的任务\n<!--more-->\nl  工作站\n\n工作站就是仅提供大量的运作能力给用户而不提供因特网服务的主机\n\nl  当前远程连接的登陆类型\n\n1、加密的远程连接\n\n主要是ssh，也是用到的最多最安全的，而且还可以使用rsync通过ssh协议来进行异地备份\n\n2、图形接口的远程连接\n\nXDMCP、VNC和XRDP，这些方式由于是传输图形所以速度慢，且安全性也不是很好\n\n二、远程连接之SSH\n\nSsh是secure shell protocol（安全的壳程序协议）的简写，可以通过数据包加密技术将传输的数据包加密后再传输到网络上，当前ssh有两个版本，其中version2加上了连接检测的机制，可以避免连接期间被插入恶意攻击码\n\nl  Ssh服务器提供的功能\n\n默认的ssh服务器提供两个服务器功能\n\n1、ssh服务\n\n类似telnet的远程连接，使用shell的服务器，可以用来管理服务器\n\n2、ftp服务\n\n类似ftp服务的sftp-server，可以用来远程上传和下载\n\nl  连接的加密技术\n\n当前常见的网络数据包加密技术主要是通过非对称秘钥系统来处理的，主要是通过两把不同的公钥（public key）和私钥（private key）来进行数据的加密与解密的，且在同一个方向上的连接中这两把钥匙是成对存在的。每台主机都应该有自己的秘钥（公钥和私钥），并且公钥用于加密而私钥用于解密\n\n1、公钥（public key）\n\n提供给远程主机进行数据加密的行为，所有客户端都能取得它进行数据加密\n\n2、私钥（private key）\n\n远程主机使用公钥加密的数据在本地就需要使用私钥进行解密了，其非常重要只能在自己的主机上\n\nl  Ssh服务器端与客户端的链接步骤\n\n1、服务器建立公钥文件\n\n系统安装完成时sshd会朱勇去计算出需要的公钥文件和自己需要的私钥文件，等下次再次启动sshd的时候该服务就会主动去找文件/etc/ssh/ssh_host*\n\n2、客户端主动链接\n\n需要使用客户端程序（如ssh）来连接\n\n3、服务器传送公钥文件给客户端\n\n服务器将将取得的公钥文件/etc/ssh/ssh_host*传送给客户端（由于公钥是给大家使用的，所以此时的传送是明文的）\n\n4、客户端记录并比对该公钥数据，然后计算出自己的公钥和私钥\n\n客户端在第一次连接该服务器后会将服务器的公钥数据记录到客户端的用户主目录下的~ /.ssh/known_hosts内，如果已经记录过该数据则客户端会去比对此次受到的公钥与之前的差异，若接受此次公钥数据那么会计算出客户端自己的公钥和私钥\n\n5、客户端将自己的公钥传送给服务器\n\n此时服务器端会有自己的私钥和客户端的公钥；而客户端会有服务器的公钥和自己的私钥，这时服务器与客户端的秘钥（公钥与私钥）是不一样的，所以才称之为非对称式秘钥系统\n\n6、服务器开始进行双向加解密\n\n1)   服务器传送数据到客户端\n\n将用户的公钥加密后进行发送，客户端接收后用自己的私钥解密\n\n2)   客户端传送数据到服务器\n\n将服务器的公钥加密后进行发送，服务器接受后用自己的私钥解密\n\nl  秘钥文件的建立\n\n1、服务器端启动ssh服务，以生成服务器端的公钥和私钥\n\n\n    [root@baobao ~]# /etc/init.d/sshd restart\n\n停止 sshd：                                                [确定]\n\n生成 SSH1 RSA 主机键：                                     [确定]\n\n生成 SSH2 RSA 主机键：                                     [确定]\n\n正在生成 SSH2 DSA 主机键：                                 [确定]\n\n正在启动 sshd：                                            [确定]\n\n2、客户端利用ssh连接服务器\n\n\n    [root@abao ~]# ssh 172.168.72.68\n\n    The authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n    \n    RSA key fingerprint is36:cf:9f:46:54:46:4b:b3:b0:48:4a:93:4d:14:81:56.\n    \n    Are you sure you want to continue connecting (yes/no)? yes\n    \n    Warning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n    \n    root@172.168.72.68’s password:\n    \n    Last login: Sun Sep 28 15:37:10 2014 from localhost\n    \n    [root@baobao ~]# exit\n    \n    logout\n    \n    Connection to 172.168.72.68 closed.\n\n3、删除客户端的秘钥文件\n\n    [root@abao ~]# rm /etc/ssh/ssh_host*\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key.pub”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_key”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_key.pub”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key.pub”？y\n\n4、重新启动客户端的sshd服务以查看秘钥文件的建立过程\n\n    [root@abao ~]# /etc/init.d/sshd restart\n    \n    停止 sshd：[确定]\n    \n    生成 SSH1 RSA 主机键： [确定]\n    \n    生成 SSH2 RSA 主机键： [确定]\n    \n    正在生成 SSH2 DSA 主机键： [确定]\n    \n    正在启动 sshd：[确定]\n    \nl  Sshd服务的启动\n\n    [root@baobao ~]# /etc/init.d/sshd restart\n    \n    停止 sshd：[确定]\n    \n    正在启动 sshd：[确定]\n    \n    [root@baobao ~]# netstat -tlnp | grep ssh #注意ssh服务是tcp端口22\n    \n    tcp 0  0 0.0.0.0:22  0.0.0.0:*LISTEN 9262/sshd\n    \n    tcp 0  0:::22:::* LISTEN 9262/sshd\n\n在linux系统中默认就有ssh所需要的软件了，包括可以产生密码等协议的OpenSSL软件和OpenSSH软件，而且在当前的linux系统中都是默认启动ssh的。这个sshd可以同时提供shell与ftp，而且都是在tcp端口22\n\nl  Linux用户ssh客户端的连接程序\n\nLinux客户端默认情况下是可以正常使用ssh的而不必安装额外的软件，而且其默认是启动的\n\n1、 直接登录远程主机的指令ssh（可用作服务器管理）\n\nSsh命令格式为：ssh [-f][-o参数项目][-p非标准端口][账号@]IP地址[命令]\n\n1)   Ssh命令参数介绍\n\n-f：     需要配合后面的[命令]，不登陆远程主机直接发送一个命令过去而已\n\n-o：     主要的参数有：ConnectTimeout=秒数：连接等到的秒数，减少等待的时间\n\nStrictHostKeyChecking=yes/no/ask：默认是ask，如果想要public key主动加入known_host这里设置为no\n\n-p：     如果sshd服务启动在非标准的端口需使用该项目[命令]，不登陆远程主机直接发送一个命令过去，但与-f意义不太相同\n\n2)   ssh使用范例\n\nA：直接登录到远程主机\n\n    [root@abao ~]# ssh 172.168.72.68\n    \n    The authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n    \n    RSA key fingerprint is36:cf:9f:46:54:46:4b:b3:b0:48:4a:93:4d:14:81:56.   #远程服务器的公钥指纹码\n    \n    Are you sure you want to continue connecting (yes/no)? yes   #将上述指纹码写入服务器公钥记录文件~ /.ssh/known_hosts，等再次登录时就不会出现该指纹码提示了。一定要yes而不是y\n    \n    Warning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n    \n    root@172.168.72.68’s password:#远程主机的root密码\n    \n    Last login: Sun Sep 28 15:37:10 2014 from localhost\n    \n    [root@baobao ~]# exit #退出远程连接\n    \n    logout\n    \n    Connection to 172.168.72.68 closed.\n\n一般我们使用“ssh 账号 主机IP地址”的登录方式，如果不写账号的话那么会以本地计算机的当前账号来尝试登录远程主机\n\nB：再次登录远程主机\n\n    [root@abao ~]# ssh 172.168.72.68\n    \n    root@172.168.72.68’s password:\n    \n    Last login: Sun Sep 28 16:42:05 2014 from aca84448.ipt.aol.com\n\nC：使用账号axing登录\n\n    [root@baobao ~]# ssh axing@172.168.72.68\n    \n    The authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n    \n    RSA key fingerprint is 36:cf:9f:46:54:46:4b:b3:b0:48:4a:93:4d:14:81:56.\n    \n    Are you sure you want to continue connecting (yes/no)? yes\n    \n    Warning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n    \n    axing@172.168.72.68’s password:\n    \n    [axing@baobao ~]$   #远程登陆后身份变为axing\n    \nD：远程登陆执行命令后立刻离开\n\n    [root@abao ~]# ssh axing@172.168.72.68 find / -name passwd  #既后面直接加命令\n    \n    axing@172.168.72.68’s password:\n    \n卡在这里等待命令的执行完毕\n\nE：让远程主机自动运行命令而立刻回到本地端继续工作\n    \n    [root@abao ~]# ssh -faxing@172.168.72.68 shutdown -h now\n    \n    axing@172.168.72.68’s password:\n\nF：自动加上公钥记录而不再询问\n\n    [root@abao ~]# rm ~/.ssh/known_hosts\n    \n    rm：是否删除普通文件 “/root/.ssh/known_hosts”？y\n    \n    [root@abao ~]# ssh -o StrictHostKeyChecking=no root@172.168.72.68#不在要求输入yes或no了\n    \n    Warning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n    \n    root@172.168.72.68’s password:\n    \n    Last login: Mon Sep 29 14:00:28 2014 from aca84448.ipt.aol.com\n    \n2、服务器公钥记录文件~ /.ssh/known_hosts\n\n当远程登陆服务器时本机会主动将从服务器收到的公钥服务器公钥记录文件~ /.ssh/known_hosts进行比对，如果服务器的公钥文件还没有记录那么就会主动询问是否记录（登陆时候的yes或no行为）；如果收到的公钥已经记录那么会比对记录是否相同，如果相同则继续登陆，如果不同就会离开登陆而返回。但是如果是服务器重新安装那么服务器的公钥就会经常变化，这样的话我们就无法正常远程登陆了\n\nA：模拟服务器重新安装后ssh登陆\n\n    [root@baobao ~]# rm /etc/ssh/ssh_host*\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key.pub”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_key”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_key.pub”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key”？y\n    \n    rm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key.pub”？y\n    \n    [root@baobao ~]# /etc/init.d/sshd restart\n    \n    停止 sshd：[确定]\n    \n    生成 SSH1 RSA 主机键： [确定]\n    \n    生成 SSH2 RSA 主机键： [确定]\n    \n    正在生成 SSH2 DSA 主机键： [确定]\n    \n    正在启动 sshd：[确定]\n    \n    [root@baobao ~]# ssh 172.168.72.68\n    \n    @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n    \n    @WARNING: REMOTE HOSTIDENTIFICATION HAS CHANGED! @\n    \n    @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n    \n    IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\n    \n    Someone could be eavesdropping on you right now(man-in-the-middle attack)!\n    \n    It is also possible that the RSA host key has just been changed.\n    \n    The fingerprint for the RSA key sent by the remote host is\n    \n    17:7e:8e:e9:fd:df:1c:e5:c9:9d:cd:30:31:5e:a6:45.\n    \n    Please contact your system administrator.\n    \n    Add correct host key in /root/.ssh/known_hosts to get rid ofthis message.\n    \n    Offending key in /root/.ssh/known_hosts:2#有问题的数据行号\n    \n    RSA host key for 172.168.72.68 has changed and you haverequested strict checking.\n    \n    Host key verification failed.\n    \nB：上述现象解决方法\n    \n    [root@baobao ~]# vim /root/.ssh/known_hosts  #清空该文件\n    \n    [root@baobao ~]# ssh 172.168.72.68\n    \n    The authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n    \n    RSA key fingerprint is17:7e:8e:e9:fd:df:1c:e5:c9:9d:cd:30:31:5e:a6:45.\n    \n    Are you sure you want to continue connecting (yes/no)? yes#记录公钥\n    \n    Warning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n    \n    root@172.168.72.68’s password:\n    \n    Last login: Mon Sep 29 14:28:46 2014 from aca84448.ipt.aol.com\n\n3、模拟FTP的文件传输之SFTP\n\n如果想要从远程服务器下载或上传文件就不能使用ssh了，而必须使用sftp或scp，这两个指令也是使用ssh的端口22，只是模拟成ftp与复制的操作而已\n\n1)   SFTP使用的命令\n\nSftp使用的命令与ftp是一样的\n\nA：针对远程服务器的命令\n\n跟linux服务器命令相同\n\nB：针对本机的命令\n\n在基本命令前面加“l”即代表是针对本机的操作，例如sftp> lcd /tmp进入本机的该目录\n\nC：针对资料的上传或下载的命令\n\nput [本地目录或文件][远程]或put [本地目录或文件]（这样会存储到远程主机的目录下）\n\nget [远程目录或文件][本机]或get [远程目录或文件]（这样会存储到当前本机所在目录）\n\n2)   Sftp的使用范例\n\nA：sftp的登陆于退出\n\n    [root@baobao ~]# sftp 172.168.72.68\n    \n    Connecting to 172.168.72.68…\n    \n    root@172.168.72.68’s password:\n    \n    sftp>\n    \n    或\n    \n    [root@baobao ~]# sftp axing@172.168.72.68\n    \n    Connecting to 172.168.72.68…\n    \n    axing@172.168.72.68’s password:\n    \n    sftp> exit\n\nB：上传与下载\n\n    sftp> pwd#查看当前在服务器的目录\n    \n    Remote working directory: /home/axing\n    \n    sftp> lls /etc/hosts #查看本机是否有该文件\n    \n    /etc/hosts\n    \n    sftp> put /etc/hosts #上传该文件到远程服务器\n    \n    Uploading /etc/hosts to /home/axing/hosts#上传到服务器的默认目录\n    \n    /etc/hosts 100%  1580.2KB/s   00:00\n    \n    sftp> ls\n    \n    hosts\n    \n    sftp> ls –a  #查看服务器该目录下的隐藏文件\n    \n    .   ..  .bash_history   .bash_logout.bash_profile   .bashrc .emacs\n    \n    .gnome2.mozillahosts\n    \n    sftp> lcd /tmp#切换到本地的目录/tmp下\n    \n    sftp> get .bashrc #从服务器下载该文件\n    \n    Fetching /home/axing/.bashrc to .bashrc\n    \n    /home/axing/.bashrc   100%  124 0.1KB/s  00:00\n    \n    sftp> lls –a #确认是否下载成功\n    \n    ……………………………………………\n    \n    baoaj  .bashrc  guoal   guobe  guobx guocq  guodj  pulse-Fhzh5o9BSGRy\n    \n    sftp> exit\n\n4、文件异地直接复制SCP\n\n当已经知道服务器上的文件名时可以使用该命令，该命令的上传和下载使用格式如下：\n\n上传：scp [-pr] [-l 速率] file [账号@]主机：目录名（：后没有空格）\n\n下载：scp [-pr] [-l 速率] [账号@]主机：file 目录名（file后有空格）\n\n1)   命令参数介绍\n\n-p：     保留文件的原有权限\n\n-r：     复制整个目录\n\n-l：     传输速率\n\n2)   Scp使用范例\n\nA：上传本地文件到远程服务器\n\n`[root@baobao ~]# scp /etc/hosts* axing@172.168.72.68:~     ` #上传到服务器的用户主目录下\n\naxing@172.168.72.68’s password:\n\nhosts                100% 158     0.2KB/s   00:00\n\nhosts.allow          100% 370     0.4KB/s   00:00\n\nhosts.deny           100% 460     0.5KB/s   00:00\n\nB：从服务器下载文件到本地\n\n    [root@baobao ~]# scp axing@172.168.72.68:/etc/bashrc /tmp\n    \n    axing@172.168.72.68’s password:\n    \n    bashrc   100%2681 2.6KB/s   00:00\n    \nl  windows用户ssh客户端的连接程序\n\n默认的windows并没有ssh的客户端程序，所以需要下载第三方软件才行，常见的有pietty、psftp和filezilla\n\n1、直接连接的pietty（可用作服务器管理）\n\n下载后安装即可使用，不过由于编码的问题中文会显示乱码需要设置该软件才行option—more options—features（右第二个打钩打开键盘数字）—connection—-ssh（右2only选择版本）\n\noption—font（脚本gb2312调整字符集支持中文）\n\n2、psftp\n\n下载后安装并启动，输入open172.168.72.68后连接即可\n\n3、filezilla\n\n下载后安装运行即可，是普通的中文界面ftp软件\n\nl  windows用户远程登陆管理服务器工具xshell（当前最好用的工具）\n\n1、xshell界面\n\n它是windows下当前最好用的远程管理软件，只需要你下载后安装即可使用，一般还有中文版，非常好用，以下是链接后的画面\n\n    Connecting to 172.168.72.68:22…\n    \n    Connection established.\n    \n    To escape to local shell, press ‘Ctrl+Alt+]’.  #回到本地shell\n    \n    Last login: Tue Sep 30 08:55:23 2014 from aca80058.ipt.aol.com\n    \n    [root@baobao ~]# ls\n    \n    123baoae  cheng  last.list  lsrootaf   图片\n    \n    anaconda-ks.cfg  baoagguo.txt  lsrootaa regular_express.txt.1  下载\n    \n    baoaa baoah  homelsrootab   xinzi.txt  音乐\n    \n    baoab   baoai  homefile  lsrootac   公共的 桌面\n    \n    ………………………………………………………\n    \n    [root@baobao ~]#\n\n2、xshell中文乱码解决法案\n\nXshell是个非常不错的工具。但很多时候中文显示为乱码的问题，解决方法其实很简单的，即把xshell编码方式改成UTF-8即可：[文件]–>[打开]–>在打开的session中选择连接的那个然后右键点击[属性] -> [终端]，编码选择为：Unicode(UTF-8)，然后重新连接服务器即可\n\n3、ssh远程登陆日志（重要）\n\n    [root@baobao ~]# cat /var/log/secure\n    \n    thenticationAgent, locale zh_CN.UTF-8)\n    \n    Sep 30 08:55:23 baobao sshd[2916]: Accepted password for rootfrom 172.168.0.88 port 57853 ssh2\n    \n    Sep 30 08:55:23 baobao sshd[2916]: pam_unix(sshd:session):session opened for user root by (uid=0)\n    \n    Sep 30 09:21:21 baobao sshd[3331]: Accepted password for rootfrom 172.168.0.88 port 52386 ssh2\n    \n    Sep 30 09:21:21 baobao sshd[3331]: pam_unix(sshd:session):session opened for user root by (uid=0)\n    \n    Sep 30 09:21:55 baobao sshd[2916]: pam_unix(sshd:session):session closed for user root\n\nl  sshd服务器配置\n\nsshd服务器的详细配置都放在/etc/ssh/sshd_config配置文件里，只要是没有被注释的就是默认值\n\n        [root@baobao ~]# vim /etc/ssh/sshd_config\n    \n    ……………………………………………………\n    \n    #Port 22   #也可以设置多个端口只要添加一行然后重启即可（不建议）\n    \n    #ListenAddress 0.0.0.0 #默认监听所有网卡的接口，如果想指定后面直接写ip即可\n    \n    Protocol 2 #ssh的协议版本\n    \n    # HostKey for protocol version 1   #下面是不同协议版本的秘钥文件host key\n    \n    #HostKey /etc/ssh/ssh_host_key\n    \n    # HostKeys for protocol version 2\n    \n    #HostKey /etc/ssh/ssh_host_rsa_key\n    \n    #HostKey /etc/ssh/ssh_host_dsa_key\n    \n    SyslogFacility AUTHPRIV #ssh登陆记录，默认是/var/log/secure\n    \n    #LoginGraceTime 2m  #登陆超时设置\n    \n    #PermitRootLogin yes#是否允许root登陆，默认是允许的，建议设置为no\n    \n    #StrictModes yes#是否让sshd检查相关权限以免用户将某些权限设置错误\n    \n    PasswordAuthentication yes  #密码验证，当然需要了\n    \n    #PermitEmptyPasswords no#是否允许空密码登陆，当然是no了\n    \n    #IgnoreUserKnownHosts no#是否忽略用户主文件记录，当然是no了\n    \n    #IgnoreRhosts yes   #是否取消~/.ssh/.rhosts认证，当然yes了\n    \n    ChallengeResponseAuthentication no  #该认证不安全，设置为no即可\n    \n    UsePAM yes#最好使用该认证模块记录与管理，所以yes\n    \n    #PrintLastLog yes #显示上次登陆的信息\n    \n    #TCPKeepAlive yes #网络不稳定时为了连接不中断可以设置为no\n    \n    #UsePrivilegeSeparation yes   #使用权限较低的程序来给用户操作\n    \n    DenyUsers #拒绝登陆的用户\n    \n    DenyGroups#拒绝登陆的组\n\n基本上ssh的默认设置已经就很安全了，不过还是建议将root的登陆权限取消，并将ssh的版本设置为2，而且通常这个文件不需要修改，如果修改了需要重启sshd\n\nl  制作不用密码接口登陆的ssh用户\n\n将客户端产生的key复制到服务器中，以后客户端再次登录的时候由于两者在ssh要连接的信号传递中已经比对过key了，所以不再需要输入密码了\n\n1、步骤一，客户端建立两把钥匙\n\n    [root@abao ~]# useradd abao\n    \n    [root@abao ~]# passwd abao\n    \n    更改用户 abao 的密码 。\n    \n    新的 密码：\n    \n    重新输入新的 密码：\n    \n    passwd： 所有的身份验证令牌已经成功更新。\n    \n    服务器上也做上面相同的用户配置\n    \n    [root@abao ~]# su – abao\n    \n    [abao@abao ~]$ ssh-keygen#默认以RSA建立两把钥匙\n    \n    Generating public/private rsa key pair.\n    \n    Enter file in which to save the key (/home/abao/.ssh/id_rsa): 回车\n    \n    Created directory ‘/home/abao/.ssh’. #建立主目录\n    \n    Enter passphrase (empty for no passphrase): 回车\n    \n    Enter same passphrase again: 回车\n    \n    Your identification has been saved in /home/abao/.ssh/id_rsa.   #私钥文件\n    \n    Your public key has been saved in /home/abao/.ssh/id_rsa.pub.   #公钥文件\n    \n    The key fingerprint is:\n    \n    89:1e:87:c9:a8:68:69:df:bd:75:a4:df:54:37:70:f1 abao@abao\n    \n    The key’s randomart image is:\n    \n    +–[ RSA 2048]—-+\n    \n    |   . |\n    \n    |o|\n    \n    | . .E|\n    \n    | o + .o  |\n    \n    |. * S  .   o.|\n    \n    | … . o  o   . o|\n    \n    |.+.   .  o . .  |\n    \n    |o . . . . o o|\n    \n    |   . . o.  . .   |\n    \n    +—————–+\n    \n    [abao@abao ~]$ ls -ld ~/.ssh; ls -l ~/.ssh\n    \n    drwx——. 2 abao abao 4096 9月  30 11:56 /home/abao/.ssh\n    \n    总用量 8\n    \n    -rw——-. 1 abao abao1675 9月  30 11:56 id_rsa\n    \n    -rw-r–r–. 1 abao abao  391 9月  3011:56 id_rsa.pub\n\n默认情况下建立私钥后权限和文件名放置位置都是正确的。身份必须是abao，当执行ssh-keygen的时候才会在用户主目录下生成两把钥匙，需要注意的是~/.ssh/目录必有700的权限，而且私钥文件的权限必须是-rw——-且属于abao才行，否则在秘钥比对中会被误判为危险而无法成功的以公私钥成对文件的机制实现连接\n\n2、步骤二，将公钥文件数据上传到服务器\n\n    [root@baobao ~]# useradd abao  #先在ssh服务器端建立上传文件账户abao\n    [root@baobao ~]# passwd abao\n    更改用户 abao 的密码 。\n    新的 密码：\n    重新输入新的 密码：\n    passwd： 所有的身份验证令牌已经成功更新。\n    [abao@abao ~]$ scp ~/.ssh/id_rsa.pub abao@172.168.72.68:~\n    \n    abao@172.168.72.68’s password:\n    \n    id_rsa.pub100%  3910.4KB/s   00:00\n\n3、步骤三，蒋公钥放置到服务器端的正确目录与文件名\n\n1)   服务器上建立文件~/.ssh\n\n    [root@baobao ~]# su – abao\n    \n    [abao@baobao ~]$ ls -ld .ssh\n    \n    ls: 无法访问.ssh: 没有那个文件或目录\n    \n    [abao@baobao ~]$ mkdir .ssh; chmod 700 .ssh  #注意其权限必须是700\n    \n    [abao@baobao ~]$ ls -ld .ssh\n    \n    drwx——. 2 abao abao 4096 9月  3012:30 .ssh\n\n2)   将公钥文件内的数据使用cat转存到authorized_keys内\n\n    [abao@baobao ~]$ ls -l *pub\n    \n    -rw-r–r–. 1 abao abao 391 9月  3012:26 id_rsa.pub\n    \n    [abao@baobao ~]$ cat id_rsa.pub >> .ssh/authorized_keys\n    \n    [abao@baobao ~]$ chmod 644 .ssh/authorized_keys\n    \n    [abao@baobao ~]$ ls -l .ssh\n    \n    总用量 4\n    \n    -rw-r–r–. 1 abao abao 391 9月  3012:39 authorized_keys\n\n总结：客户端必须制作出两把钥匙，其中私钥必须放到~/.ssh内；而公钥必须上传到服务器端并且放置到用户主目录下的~/.ssh/authorized_keys，同时目录的权限必须是700,而文件权限必须是644\n\n4、步骤四，验证\n\n    [root@abao ~]# ssh abao@172.168.72.68\n    \n    @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n    \n    @WARNING: REMOTE HOSTIDENTIFICATION HAS CHANGED! @\n    \n    @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n    \n    IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\n    \n    Someone could be eavesdropping on you right now(man-in-the-middle attack)!\n    \n    It is also possible that the RSA host key has just been changed.\n    \n    The fingerprint for the RSA key sent by the remote host is\n    \n    17:7e:8e:e9:fd:df:1c:e5:c9:9d:cd:30:31:5e:a6:45.\n    \n    Please contact your system administrator.\n    \n    Add correct host key in /root/.ssh/known_hosts to get rid ofthis message.\n    \n    Offending key in /root/.ssh/known_hosts:1\n    \n    RSA host key for 172.168.72.68 has changed and you haverequested strict checking.\n    \n    Host key verification failed.\n    \n    [root@abao ~]##看不再需要密码了\n    \n    [root@abao ~]# ifconfig   #查看服务器IP地址\n    \n    eth0  Linkencap:Ethernet  HWaddr00:0C:29:59:D9:E6\n    \n    inet addr:172.168.68.72  Bcast:172.168.255.255  Mask:255.255.0.0\n    \n    inet6 addr:fe80::20c:29ff:fe59:d9e6/64 Scope:Link\n    \n    UP BROADCASTRUNNING MULTICAST  MTU:1500  Metric:1\n    \n    RXpackets:239668 errors:0 dropped:0 overruns:0 frame:0\n    \n    TX packets:855errors:0 dropped:0 overruns:0 carrier:0\n    \n    collisions:0txqueuelen:1000\n    \n    RXbytes:18091942 (17.2 MiB)  TX bytes:71093(69.4 KiB)\n\nl  Ssh的安全设置\n\nSshd所谓的安全其实指的是它的数据加密功能，而对于sshd本身这个服务来说是很不安全的，所以如果不是特别需要请尽量限制在小范围内的几个ip或主机名即可\n\n1、 服务器本身的设置强化/etc/ssh/sshd——config\n\n\n    [root@baobao ~]# vim /etc/ssh/sshd_config\n\n1)   禁止root账号使用sshd服务\n\n    PermitRootLogin no                         #去掉注释并修改为no\n\n2)   禁止nossh这个组的用户使用sshd服务\n\n    DenyGroups nosh\n    \n3)   禁止用户testssh使用sshd服务\n\n    DenyUsers testssh\n    \n    [root@abao ~]# /etc/init.d/sshd restart\n    \n    停止 sshd：[确定]\n    \n    正在启动 sshd：[确定]\n    \n    [root@abao ~]# cat /var/log/secure #验证上述用户不能登陆后查看其日志\n    \n2、TCP Wrapper的使用\n\n    [root@baobao ~]# vim /etc/host.allow  #只允许内网和本机可以远程登陆\n    \n    sshd: 127.0.0.1 192.168.1.0/255.255.255.0192.168.10.0/255.255.255.0\n    \n    [root@baobao ~]# vim /etc/host.deny\n    \n    sshd: all\n\n3、iptables数据包过滤防火墙\n\n    [root@baobao ~]# iptables -A INPUT -i eth0 -s 192.168.1.0/24 -p tcp –dport 22 -j ACCEPT\n    \n    [root@baobao ~]# iptables -A INPUT -i eth0 -s 192.168.10.0/24 -p tcp –dport 22 -j ACCEPT\n    \n    [root@baobao ~]# /etc/init.d/iptables save\n    \n    [root@baobao ~]# /etc/init.d/iptables restart\n\n注意不要开放ssh的登陆权限给Internet上面的所有用户或主机，只开放给适当的部分用户或主机即可，否则会很不安全\n","slug":"linux—SSH1","published":1,"updated":"2019-06-18T08:07:01.115Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9skq0017hcb7twki3xo5","content":"<p>一、远程连接简介</p>\n<p>l  远程连接服务器</p>\n<p>远程连接服务器通过文字或图形接口的方式来远程登陆系统，在远程的终端前面登陆linux主机并取得操作主机的接口shell，登陆后的操作就像在系统前面一样，这样可以进行系统管理的任务<br><a id=\"more\"></a><br>l  工作站</p>\n<p>工作站就是仅提供大量的运作能力给用户而不提供因特网服务的主机</p>\n<p>l  当前远程连接的登陆类型</p>\n<p>1、加密的远程连接</p>\n<p>主要是ssh，也是用到的最多最安全的，而且还可以使用rsync通过ssh协议来进行异地备份</p>\n<p>2、图形接口的远程连接</p>\n<p>XDMCP、VNC和XRDP，这些方式由于是传输图形所以速度慢，且安全性也不是很好</p>\n<p>二、远程连接之SSH</p>\n<p>Ssh是secure shell protocol（安全的壳程序协议）的简写，可以通过数据包加密技术将传输的数据包加密后再传输到网络上，当前ssh有两个版本，其中version2加上了连接检测的机制，可以避免连接期间被插入恶意攻击码</p>\n<p>l  Ssh服务器提供的功能</p>\n<p>默认的ssh服务器提供两个服务器功能</p>\n<p>1、ssh服务</p>\n<p>类似telnet的远程连接，使用shell的服务器，可以用来管理服务器</p>\n<p>2、ftp服务</p>\n<p>类似ftp服务的sftp-server，可以用来远程上传和下载</p>\n<p>l  连接的加密技术</p>\n<p>当前常见的网络数据包加密技术主要是通过非对称秘钥系统来处理的，主要是通过两把不同的公钥（public key）和私钥（private key）来进行数据的加密与解密的，且在同一个方向上的连接中这两把钥匙是成对存在的。每台主机都应该有自己的秘钥（公钥和私钥），并且公钥用于加密而私钥用于解密</p>\n<p>1、公钥（public key）</p>\n<p>提供给远程主机进行数据加密的行为，所有客户端都能取得它进行数据加密</p>\n<p>2、私钥（private key）</p>\n<p>远程主机使用公钥加密的数据在本地就需要使用私钥进行解密了，其非常重要只能在自己的主机上</p>\n<p>l  Ssh服务器端与客户端的链接步骤</p>\n<p>1、服务器建立公钥文件</p>\n<p>系统安装完成时sshd会朱勇去计算出需要的公钥文件和自己需要的私钥文件，等下次再次启动sshd的时候该服务就会主动去找文件/etc/ssh/ssh_host*</p>\n<p>2、客户端主动链接</p>\n<p>需要使用客户端程序（如ssh）来连接</p>\n<p>3、服务器传送公钥文件给客户端</p>\n<p>服务器将将取得的公钥文件/etc/ssh/ssh_host*传送给客户端（由于公钥是给大家使用的，所以此时的传送是明文的）</p>\n<p>4、客户端记录并比对该公钥数据，然后计算出自己的公钥和私钥</p>\n<p>客户端在第一次连接该服务器后会将服务器的公钥数据记录到客户端的用户主目录下的~ /.ssh/known_hosts内，如果已经记录过该数据则客户端会去比对此次受到的公钥与之前的差异，若接受此次公钥数据那么会计算出客户端自己的公钥和私钥</p>\n<p>5、客户端将自己的公钥传送给服务器</p>\n<p>此时服务器端会有自己的私钥和客户端的公钥；而客户端会有服务器的公钥和自己的私钥，这时服务器与客户端的秘钥（公钥与私钥）是不一样的，所以才称之为非对称式秘钥系统</p>\n<p>6、服务器开始进行双向加解密</p>\n<p>1)   服务器传送数据到客户端</p>\n<p>将用户的公钥加密后进行发送，客户端接收后用自己的私钥解密</p>\n<p>2)   客户端传送数据到服务器</p>\n<p>将服务器的公钥加密后进行发送，服务器接受后用自己的私钥解密</p>\n<p>l  秘钥文件的建立</p>\n<p>1、服务器端启动ssh服务，以生成服务器端的公钥和私钥</p>\n<pre><code>[root@baobao ~]# /etc/init.d/sshd restart\n</code></pre><p>停止 sshd：                                                [确定]</p>\n<p>生成 SSH1 RSA 主机键：                                     [确定]</p>\n<p>生成 SSH2 RSA 主机键：                                     [确定]</p>\n<p>正在生成 SSH2 DSA 主机键：                                 [确定]</p>\n<p>正在启动 sshd：                                            [确定]</p>\n<p>2、客户端利用ssh连接服务器</p>\n<pre><code>[root@abao ~]# ssh 172.168.72.68\n\nThe authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n\nRSA key fingerprint is36:cf:9f:46:54:46:4b:b3:b0:48:4a:93:4d:14:81:56.\n\nAre you sure you want to continue connecting (yes/no)? yes\n\nWarning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n\nroot@172.168.72.68’s password:\n\nLast login: Sun Sep 28 15:37:10 2014 from localhost\n\n[root@baobao ~]# exit\n\nlogout\n\nConnection to 172.168.72.68 closed.\n</code></pre><p>3、删除客户端的秘钥文件</p>\n<pre><code>[root@abao ~]# rm /etc/ssh/ssh_host*\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key.pub”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_key”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_key.pub”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key.pub”？y\n</code></pre><p>4、重新启动客户端的sshd服务以查看秘钥文件的建立过程</p>\n<pre><code>[root@abao ~]# /etc/init.d/sshd restart\n\n停止 sshd：[确定]\n\n生成 SSH1 RSA 主机键： [确定]\n\n生成 SSH2 RSA 主机键： [确定]\n\n正在生成 SSH2 DSA 主机键： [确定]\n\n正在启动 sshd：[确定]\n</code></pre><p>l  Sshd服务的启动</p>\n<pre><code>[root@baobao ~]# /etc/init.d/sshd restart\n\n停止 sshd：[确定]\n\n正在启动 sshd：[确定]\n\n[root@baobao ~]# netstat -tlnp | grep ssh #注意ssh服务是tcp端口22\n\ntcp 0  0 0.0.0.0:22  0.0.0.0:*LISTEN 9262/sshd\n\ntcp 0  0:::22:::* LISTEN 9262/sshd\n</code></pre><p>在linux系统中默认就有ssh所需要的软件了，包括可以产生密码等协议的OpenSSL软件和OpenSSH软件，而且在当前的linux系统中都是默认启动ssh的。这个sshd可以同时提供shell与ftp，而且都是在tcp端口22</p>\n<p>l  Linux用户ssh客户端的连接程序</p>\n<p>Linux客户端默认情况下是可以正常使用ssh的而不必安装额外的软件，而且其默认是启动的</p>\n<p>1、 直接登录远程主机的指令ssh（可用作服务器管理）</p>\n<p>Ssh命令格式为：ssh [-f][-o参数项目][-p非标准端口][账号@]IP地址[命令]</p>\n<p>1)   Ssh命令参数介绍</p>\n<p>-f：     需要配合后面的[命令]，不登陆远程主机直接发送一个命令过去而已</p>\n<p>-o：     主要的参数有：ConnectTimeout=秒数：连接等到的秒数，减少等待的时间</p>\n<p>StrictHostKeyChecking=yes/no/ask：默认是ask，如果想要public key主动加入known_host这里设置为no</p>\n<p>-p：     如果sshd服务启动在非标准的端口需使用该项目[命令]，不登陆远程主机直接发送一个命令过去，但与-f意义不太相同</p>\n<p>2)   ssh使用范例</p>\n<p>A：直接登录到远程主机</p>\n<pre><code>[root@abao ~]# ssh 172.168.72.68\n\nThe authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n\nRSA key fingerprint is36:cf:9f:46:54:46:4b:b3:b0:48:4a:93:4d:14:81:56.   #远程服务器的公钥指纹码\n\nAre you sure you want to continue connecting (yes/no)? yes   #将上述指纹码写入服务器公钥记录文件~ /.ssh/known_hosts，等再次登录时就不会出现该指纹码提示了。一定要yes而不是y\n\nWarning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n\nroot@172.168.72.68’s password:#远程主机的root密码\n\nLast login: Sun Sep 28 15:37:10 2014 from localhost\n\n[root@baobao ~]# exit #退出远程连接\n\nlogout\n\nConnection to 172.168.72.68 closed.\n</code></pre><p>一般我们使用“ssh 账号 主机IP地址”的登录方式，如果不写账号的话那么会以本地计算机的当前账号来尝试登录远程主机</p>\n<p>B：再次登录远程主机</p>\n<pre><code>[root@abao ~]# ssh 172.168.72.68\n\nroot@172.168.72.68’s password:\n\nLast login: Sun Sep 28 16:42:05 2014 from aca84448.ipt.aol.com\n</code></pre><p>C：使用账号axing登录</p>\n<pre><code>[root@baobao ~]# ssh axing@172.168.72.68\n\nThe authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n\nRSA key fingerprint is 36:cf:9f:46:54:46:4b:b3:b0:48:4a:93:4d:14:81:56.\n\nAre you sure you want to continue connecting (yes/no)? yes\n\nWarning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n\naxing@172.168.72.68’s password:\n\n[axing@baobao ~]$   #远程登陆后身份变为axing\n</code></pre><p>D：远程登陆执行命令后立刻离开</p>\n<pre><code>[root@abao ~]# ssh axing@172.168.72.68 find / -name passwd  #既后面直接加命令\n\naxing@172.168.72.68’s password:\n</code></pre><p>卡在这里等待命令的执行完毕</p>\n<p>E：让远程主机自动运行命令而立刻回到本地端继续工作</p>\n<pre><code>[root@abao ~]# ssh -faxing@172.168.72.68 shutdown -h now\n\naxing@172.168.72.68’s password:\n</code></pre><p>F：自动加上公钥记录而不再询问</p>\n<pre><code>[root@abao ~]# rm ~/.ssh/known_hosts\n\nrm：是否删除普通文件 “/root/.ssh/known_hosts”？y\n\n[root@abao ~]# ssh -o StrictHostKeyChecking=no root@172.168.72.68#不在要求输入yes或no了\n\nWarning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n\nroot@172.168.72.68’s password:\n\nLast login: Mon Sep 29 14:00:28 2014 from aca84448.ipt.aol.com\n</code></pre><p>2、服务器公钥记录文件~ /.ssh/known_hosts</p>\n<p>当远程登陆服务器时本机会主动将从服务器收到的公钥服务器公钥记录文件~ /.ssh/known_hosts进行比对，如果服务器的公钥文件还没有记录那么就会主动询问是否记录（登陆时候的yes或no行为）；如果收到的公钥已经记录那么会比对记录是否相同，如果相同则继续登陆，如果不同就会离开登陆而返回。但是如果是服务器重新安装那么服务器的公钥就会经常变化，这样的话我们就无法正常远程登陆了</p>\n<p>A：模拟服务器重新安装后ssh登陆</p>\n<pre><code>[root@baobao ~]# rm /etc/ssh/ssh_host*\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key.pub”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_key”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_key.pub”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key.pub”？y\n\n[root@baobao ~]# /etc/init.d/sshd restart\n\n停止 sshd：[确定]\n\n生成 SSH1 RSA 主机键： [确定]\n\n生成 SSH2 RSA 主机键： [确定]\n\n正在生成 SSH2 DSA 主机键： [确定]\n\n正在启动 sshd：[确定]\n\n[root@baobao ~]# ssh 172.168.72.68\n\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n\n@WARNING: REMOTE HOSTIDENTIFICATION HAS CHANGED! @\n\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\n\nSomeone could be eavesdropping on you right now(man-in-the-middle attack)!\n\nIt is also possible that the RSA host key has just been changed.\n\nThe fingerprint for the RSA key sent by the remote host is\n\n17:7e:8e:e9:fd:df:1c:e5:c9:9d:cd:30:31:5e:a6:45.\n\nPlease contact your system administrator.\n\nAdd correct host key in /root/.ssh/known_hosts to get rid ofthis message.\n\nOffending key in /root/.ssh/known_hosts:2#有问题的数据行号\n\nRSA host key for 172.168.72.68 has changed and you haverequested strict checking.\n\nHost key verification failed.\n</code></pre><p>B：上述现象解决方法</p>\n<pre><code>[root@baobao ~]# vim /root/.ssh/known_hosts  #清空该文件\n\n[root@baobao ~]# ssh 172.168.72.68\n\nThe authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n\nRSA key fingerprint is17:7e:8e:e9:fd:df:1c:e5:c9:9d:cd:30:31:5e:a6:45.\n\nAre you sure you want to continue connecting (yes/no)? yes#记录公钥\n\nWarning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n\nroot@172.168.72.68’s password:\n\nLast login: Mon Sep 29 14:28:46 2014 from aca84448.ipt.aol.com\n</code></pre><p>3、模拟FTP的文件传输之SFTP</p>\n<p>如果想要从远程服务器下载或上传文件就不能使用ssh了，而必须使用sftp或scp，这两个指令也是使用ssh的端口22，只是模拟成ftp与复制的操作而已</p>\n<p>1)   SFTP使用的命令</p>\n<p>Sftp使用的命令与ftp是一样的</p>\n<p>A：针对远程服务器的命令</p>\n<p>跟linux服务器命令相同</p>\n<p>B：针对本机的命令</p>\n<p>在基本命令前面加“l”即代表是针对本机的操作，例如sftp&gt; lcd /tmp进入本机的该目录</p>\n<p>C：针对资料的上传或下载的命令</p>\n<p>put [本地目录或文件][远程]或put [本地目录或文件]（这样会存储到远程主机的目录下）</p>\n<p>get [远程目录或文件][本机]或get [远程目录或文件]（这样会存储到当前本机所在目录）</p>\n<p>2)   Sftp的使用范例</p>\n<p>A：sftp的登陆于退出</p>\n<pre><code>[root@baobao ~]# sftp 172.168.72.68\n\nConnecting to 172.168.72.68…\n\nroot@172.168.72.68’s password:\n\nsftp&gt;\n\n或\n\n[root@baobao ~]# sftp axing@172.168.72.68\n\nConnecting to 172.168.72.68…\n\naxing@172.168.72.68’s password:\n\nsftp&gt; exit\n</code></pre><p>B：上传与下载</p>\n<pre><code>sftp&gt; pwd#查看当前在服务器的目录\n\nRemote working directory: /home/axing\n\nsftp&gt; lls /etc/hosts #查看本机是否有该文件\n\n/etc/hosts\n\nsftp&gt; put /etc/hosts #上传该文件到远程服务器\n\nUploading /etc/hosts to /home/axing/hosts#上传到服务器的默认目录\n\n/etc/hosts 100%  1580.2KB/s   00:00\n\nsftp&gt; ls\n\nhosts\n\nsftp&gt; ls –a  #查看服务器该目录下的隐藏文件\n\n.   ..  .bash_history   .bash_logout.bash_profile   .bashrc .emacs\n\n.gnome2.mozillahosts\n\nsftp&gt; lcd /tmp#切换到本地的目录/tmp下\n\nsftp&gt; get .bashrc #从服务器下载该文件\n\nFetching /home/axing/.bashrc to .bashrc\n\n/home/axing/.bashrc   100%  124 0.1KB/s  00:00\n\nsftp&gt; lls –a #确认是否下载成功\n\n……………………………………………\n\nbaoaj  .bashrc  guoal   guobe  guobx guocq  guodj  pulse-Fhzh5o9BSGRy\n\nsftp&gt; exit\n</code></pre><p>4、文件异地直接复制SCP</p>\n<p>当已经知道服务器上的文件名时可以使用该命令，该命令的上传和下载使用格式如下：</p>\n<p>上传：scp [-pr] [-l 速率] file [账号@]主机：目录名（：后没有空格）</p>\n<p>下载：scp [-pr] [-l 速率] [账号@]主机：file 目录名（file后有空格）</p>\n<p>1)   命令参数介绍</p>\n<p>-p：     保留文件的原有权限</p>\n<p>-r：     复制整个目录</p>\n<p>-l：     传输速率</p>\n<p>2)   Scp使用范例</p>\n<p>A：上传本地文件到远程服务器</p>\n<p><code>[root@baobao ~]# scp /etc/hosts* axing@172.168.72.68:~</code> #上传到服务器的用户主目录下</p>\n<p><a href=\"mailto:axing@172.168.72.68\" target=\"_blank\" rel=\"noopener\">axing@172.168.72.68</a>’s password:</p>\n<p>hosts                100% 158     0.2KB/s   00:00</p>\n<p>hosts.allow          100% 370     0.4KB/s   00:00</p>\n<p>hosts.deny           100% 460     0.5KB/s   00:00</p>\n<p>B：从服务器下载文件到本地</p>\n<pre><code>[root@baobao ~]# scp axing@172.168.72.68:/etc/bashrc /tmp\n\naxing@172.168.72.68’s password:\n\nbashrc   100%2681 2.6KB/s   00:00\n</code></pre><p>l  windows用户ssh客户端的连接程序</p>\n<p>默认的windows并没有ssh的客户端程序，所以需要下载第三方软件才行，常见的有pietty、psftp和filezilla</p>\n<p>1、直接连接的pietty（可用作服务器管理）</p>\n<p>下载后安装即可使用，不过由于编码的问题中文会显示乱码需要设置该软件才行option—more options—features（右第二个打钩打开键盘数字）—connection—-ssh（右2only选择版本）</p>\n<p>option—font（脚本gb2312调整字符集支持中文）</p>\n<p>2、psftp</p>\n<p>下载后安装并启动，输入open172.168.72.68后连接即可</p>\n<p>3、filezilla</p>\n<p>下载后安装运行即可，是普通的中文界面ftp软件</p>\n<p>l  windows用户远程登陆管理服务器工具xshell（当前最好用的工具）</p>\n<p>1、xshell界面</p>\n<p>它是windows下当前最好用的远程管理软件，只需要你下载后安装即可使用，一般还有中文版，非常好用，以下是链接后的画面</p>\n<pre><code>Connecting to 172.168.72.68:22…\n\nConnection established.\n\nTo escape to local shell, press ‘Ctrl+Alt+]’.  #回到本地shell\n\nLast login: Tue Sep 30 08:55:23 2014 from aca80058.ipt.aol.com\n\n[root@baobao ~]# ls\n\n123baoae  cheng  last.list  lsrootaf   图片\n\nanaconda-ks.cfg  baoagguo.txt  lsrootaa regular_express.txt.1  下载\n\nbaoaa baoah  homelsrootab   xinzi.txt  音乐\n\nbaoab   baoai  homefile  lsrootac   公共的 桌面\n\n………………………………………………………\n\n[root@baobao ~]#\n</code></pre><p>2、xshell中文乱码解决法案</p>\n<p>Xshell是个非常不错的工具。但很多时候中文显示为乱码的问题，解决方法其实很简单的，即把xshell编码方式改成UTF-8即可：[文件]–&gt;[打开]–&gt;在打开的session中选择连接的那个然后右键点击[属性] -&gt; [终端]，编码选择为：Unicode(UTF-8)，然后重新连接服务器即可</p>\n<p>3、ssh远程登陆日志（重要）</p>\n<pre><code>[root@baobao ~]# cat /var/log/secure\n\nthenticationAgent, locale zh_CN.UTF-8)\n\nSep 30 08:55:23 baobao sshd[2916]: Accepted password for rootfrom 172.168.0.88 port 57853 ssh2\n\nSep 30 08:55:23 baobao sshd[2916]: pam_unix(sshd:session):session opened for user root by (uid=0)\n\nSep 30 09:21:21 baobao sshd[3331]: Accepted password for rootfrom 172.168.0.88 port 52386 ssh2\n\nSep 30 09:21:21 baobao sshd[3331]: pam_unix(sshd:session):session opened for user root by (uid=0)\n\nSep 30 09:21:55 baobao sshd[2916]: pam_unix(sshd:session):session closed for user root\n</code></pre><p>l  sshd服务器配置</p>\n<p>sshd服务器的详细配置都放在/etc/ssh/sshd_config配置文件里，只要是没有被注释的就是默认值</p>\n<pre><code>    [root@baobao ~]# vim /etc/ssh/sshd_config\n\n……………………………………………………\n\n#Port 22   #也可以设置多个端口只要添加一行然后重启即可（不建议）\n\n#ListenAddress 0.0.0.0 #默认监听所有网卡的接口，如果想指定后面直接写ip即可\n\nProtocol 2 #ssh的协议版本\n\n# HostKey for protocol version 1   #下面是不同协议版本的秘钥文件host key\n\n#HostKey /etc/ssh/ssh_host_key\n\n# HostKeys for protocol version 2\n\n#HostKey /etc/ssh/ssh_host_rsa_key\n\n#HostKey /etc/ssh/ssh_host_dsa_key\n\nSyslogFacility AUTHPRIV #ssh登陆记录，默认是/var/log/secure\n\n#LoginGraceTime 2m  #登陆超时设置\n\n#PermitRootLogin yes#是否允许root登陆，默认是允许的，建议设置为no\n\n#StrictModes yes#是否让sshd检查相关权限以免用户将某些权限设置错误\n\nPasswordAuthentication yes  #密码验证，当然需要了\n\n#PermitEmptyPasswords no#是否允许空密码登陆，当然是no了\n\n#IgnoreUserKnownHosts no#是否忽略用户主文件记录，当然是no了\n\n#IgnoreRhosts yes   #是否取消~/.ssh/.rhosts认证，当然yes了\n\nChallengeResponseAuthentication no  #该认证不安全，设置为no即可\n\nUsePAM yes#最好使用该认证模块记录与管理，所以yes\n\n#PrintLastLog yes #显示上次登陆的信息\n\n#TCPKeepAlive yes #网络不稳定时为了连接不中断可以设置为no\n\n#UsePrivilegeSeparation yes   #使用权限较低的程序来给用户操作\n\nDenyUsers #拒绝登陆的用户\n\nDenyGroups#拒绝登陆的组\n</code></pre><p>基本上ssh的默认设置已经就很安全了，不过还是建议将root的登陆权限取消，并将ssh的版本设置为2，而且通常这个文件不需要修改，如果修改了需要重启sshd</p>\n<p>l  制作不用密码接口登陆的ssh用户</p>\n<p>将客户端产生的key复制到服务器中，以后客户端再次登录的时候由于两者在ssh要连接的信号传递中已经比对过key了，所以不再需要输入密码了</p>\n<p>1、步骤一，客户端建立两把钥匙</p>\n<pre><code>[root@abao ~]# useradd abao\n\n[root@abao ~]# passwd abao\n\n更改用户 abao 的密码 。\n\n新的 密码：\n\n重新输入新的 密码：\n\npasswd： 所有的身份验证令牌已经成功更新。\n\n服务器上也做上面相同的用户配置\n\n[root@abao ~]# su – abao\n\n[abao@abao ~]$ ssh-keygen#默认以RSA建立两把钥匙\n\nGenerating public/private rsa key pair.\n\nEnter file in which to save the key (/home/abao/.ssh/id_rsa): 回车\n\nCreated directory ‘/home/abao/.ssh’. #建立主目录\n\nEnter passphrase (empty for no passphrase): 回车\n\nEnter same passphrase again: 回车\n\nYour identification has been saved in /home/abao/.ssh/id_rsa.   #私钥文件\n\nYour public key has been saved in /home/abao/.ssh/id_rsa.pub.   #公钥文件\n\nThe key fingerprint is:\n\n89:1e:87:c9:a8:68:69:df:bd:75:a4:df:54:37:70:f1 abao@abao\n\nThe key’s randomart image is:\n\n+–[ RSA 2048]—-+\n\n|   . |\n\n|o|\n\n| . .E|\n\n| o + .o  |\n\n|. * S  .   o.|\n\n| … . o  o   . o|\n\n|.+.   .  o . .  |\n\n|o . . . . o o|\n\n|   . . o.  . .   |\n\n+—————–+\n\n[abao@abao ~]$ ls -ld ~/.ssh; ls -l ~/.ssh\n\ndrwx——. 2 abao abao 4096 9月  30 11:56 /home/abao/.ssh\n\n总用量 8\n\n-rw——-. 1 abao abao1675 9月  30 11:56 id_rsa\n\n-rw-r–r–. 1 abao abao  391 9月  3011:56 id_rsa.pub\n</code></pre><p>默认情况下建立私钥后权限和文件名放置位置都是正确的。身份必须是abao，当执行ssh-keygen的时候才会在用户主目录下生成两把钥匙，需要注意的是~/.ssh/目录必有700的权限，而且私钥文件的权限必须是-rw——-且属于abao才行，否则在秘钥比对中会被误判为危险而无法成功的以公私钥成对文件的机制实现连接</p>\n<p>2、步骤二，将公钥文件数据上传到服务器</p>\n<pre><code>[root@baobao ~]# useradd abao  #先在ssh服务器端建立上传文件账户abao\n[root@baobao ~]# passwd abao\n更改用户 abao 的密码 。\n新的 密码：\n重新输入新的 密码：\npasswd： 所有的身份验证令牌已经成功更新。\n[abao@abao ~]$ scp ~/.ssh/id_rsa.pub abao@172.168.72.68:~\n\nabao@172.168.72.68’s password:\n\nid_rsa.pub100%  3910.4KB/s   00:00\n</code></pre><p>3、步骤三，蒋公钥放置到服务器端的正确目录与文件名</p>\n<p>1)   服务器上建立文件~/.ssh</p>\n<pre><code>[root@baobao ~]# su – abao\n\n[abao@baobao ~]$ ls -ld .ssh\n\nls: 无法访问.ssh: 没有那个文件或目录\n\n[abao@baobao ~]$ mkdir .ssh; chmod 700 .ssh  #注意其权限必须是700\n\n[abao@baobao ~]$ ls -ld .ssh\n\ndrwx——. 2 abao abao 4096 9月  3012:30 .ssh\n</code></pre><p>2)   将公钥文件内的数据使用cat转存到authorized_keys内</p>\n<pre><code>[abao@baobao ~]$ ls -l *pub\n\n-rw-r–r–. 1 abao abao 391 9月  3012:26 id_rsa.pub\n\n[abao@baobao ~]$ cat id_rsa.pub &gt;&gt; .ssh/authorized_keys\n\n[abao@baobao ~]$ chmod 644 .ssh/authorized_keys\n\n[abao@baobao ~]$ ls -l .ssh\n\n总用量 4\n\n-rw-r–r–. 1 abao abao 391 9月  3012:39 authorized_keys\n</code></pre><p>总结：客户端必须制作出两把钥匙，其中私钥必须放到~/.ssh内；而公钥必须上传到服务器端并且放置到用户主目录下的~/.ssh/authorized_keys，同时目录的权限必须是700,而文件权限必须是644</p>\n<p>4、步骤四，验证</p>\n<pre><code>[root@abao ~]# ssh abao@172.168.72.68\n\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n\n@WARNING: REMOTE HOSTIDENTIFICATION HAS CHANGED! @\n\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\n\nSomeone could be eavesdropping on you right now(man-in-the-middle attack)!\n\nIt is also possible that the RSA host key has just been changed.\n\nThe fingerprint for the RSA key sent by the remote host is\n\n17:7e:8e:e9:fd:df:1c:e5:c9:9d:cd:30:31:5e:a6:45.\n\nPlease contact your system administrator.\n\nAdd correct host key in /root/.ssh/known_hosts to get rid ofthis message.\n\nOffending key in /root/.ssh/known_hosts:1\n\nRSA host key for 172.168.72.68 has changed and you haverequested strict checking.\n\nHost key verification failed.\n\n[root@abao ~]##看不再需要密码了\n\n[root@abao ~]# ifconfig   #查看服务器IP地址\n\neth0  Linkencap:Ethernet  HWaddr00:0C:29:59:D9:E6\n\ninet addr:172.168.68.72  Bcast:172.168.255.255  Mask:255.255.0.0\n\ninet6 addr:fe80::20c:29ff:fe59:d9e6/64 Scope:Link\n\nUP BROADCASTRUNNING MULTICAST  MTU:1500  Metric:1\n\nRXpackets:239668 errors:0 dropped:0 overruns:0 frame:0\n\nTX packets:855errors:0 dropped:0 overruns:0 carrier:0\n\ncollisions:0txqueuelen:1000\n\nRXbytes:18091942 (17.2 MiB)  TX bytes:71093(69.4 KiB)\n</code></pre><p>l  Ssh的安全设置</p>\n<p>Sshd所谓的安全其实指的是它的数据加密功能，而对于sshd本身这个服务来说是很不安全的，所以如果不是特别需要请尽量限制在小范围内的几个ip或主机名即可</p>\n<p>1、 服务器本身的设置强化/etc/ssh/sshd——config</p>\n<pre><code>[root@baobao ~]# vim /etc/ssh/sshd_config\n</code></pre><p>1)   禁止root账号使用sshd服务</p>\n<pre><code>PermitRootLogin no                         #去掉注释并修改为no\n</code></pre><p>2)   禁止nossh这个组的用户使用sshd服务</p>\n<pre><code>DenyGroups nosh\n</code></pre><p>3)   禁止用户testssh使用sshd服务</p>\n<pre><code>DenyUsers testssh\n\n[root@abao ~]# /etc/init.d/sshd restart\n\n停止 sshd：[确定]\n\n正在启动 sshd：[确定]\n\n[root@abao ~]# cat /var/log/secure #验证上述用户不能登陆后查看其日志\n</code></pre><p>2、TCP Wrapper的使用</p>\n<pre><code>[root@baobao ~]# vim /etc/host.allow  #只允许内网和本机可以远程登陆\n\nsshd: 127.0.0.1 192.168.1.0/255.255.255.0192.168.10.0/255.255.255.0\n\n[root@baobao ~]# vim /etc/host.deny\n\nsshd: all\n</code></pre><p>3、iptables数据包过滤防火墙</p>\n<pre><code>[root@baobao ~]# iptables -A INPUT -i eth0 -s 192.168.1.0/24 -p tcp –dport 22 -j ACCEPT\n\n[root@baobao ~]# iptables -A INPUT -i eth0 -s 192.168.10.0/24 -p tcp –dport 22 -j ACCEPT\n\n[root@baobao ~]# /etc/init.d/iptables save\n\n[root@baobao ~]# /etc/init.d/iptables restart\n</code></pre><p>注意不要开放ssh的登陆权限给Internet上面的所有用户或主机，只开放给适当的部分用户或主机即可，否则会很不安全</p>\n","site":{"data":{}},"excerpt":"<p>一、远程连接简介</p>\n<p>l  远程连接服务器</p>\n<p>远程连接服务器通过文字或图形接口的方式来远程登陆系统，在远程的终端前面登陆linux主机并取得操作主机的接口shell，登陆后的操作就像在系统前面一样，这样可以进行系统管理的任务<br>","more":"<br>l  工作站</p>\n<p>工作站就是仅提供大量的运作能力给用户而不提供因特网服务的主机</p>\n<p>l  当前远程连接的登陆类型</p>\n<p>1、加密的远程连接</p>\n<p>主要是ssh，也是用到的最多最安全的，而且还可以使用rsync通过ssh协议来进行异地备份</p>\n<p>2、图形接口的远程连接</p>\n<p>XDMCP、VNC和XRDP，这些方式由于是传输图形所以速度慢，且安全性也不是很好</p>\n<p>二、远程连接之SSH</p>\n<p>Ssh是secure shell protocol（安全的壳程序协议）的简写，可以通过数据包加密技术将传输的数据包加密后再传输到网络上，当前ssh有两个版本，其中version2加上了连接检测的机制，可以避免连接期间被插入恶意攻击码</p>\n<p>l  Ssh服务器提供的功能</p>\n<p>默认的ssh服务器提供两个服务器功能</p>\n<p>1、ssh服务</p>\n<p>类似telnet的远程连接，使用shell的服务器，可以用来管理服务器</p>\n<p>2、ftp服务</p>\n<p>类似ftp服务的sftp-server，可以用来远程上传和下载</p>\n<p>l  连接的加密技术</p>\n<p>当前常见的网络数据包加密技术主要是通过非对称秘钥系统来处理的，主要是通过两把不同的公钥（public key）和私钥（private key）来进行数据的加密与解密的，且在同一个方向上的连接中这两把钥匙是成对存在的。每台主机都应该有自己的秘钥（公钥和私钥），并且公钥用于加密而私钥用于解密</p>\n<p>1、公钥（public key）</p>\n<p>提供给远程主机进行数据加密的行为，所有客户端都能取得它进行数据加密</p>\n<p>2、私钥（private key）</p>\n<p>远程主机使用公钥加密的数据在本地就需要使用私钥进行解密了，其非常重要只能在自己的主机上</p>\n<p>l  Ssh服务器端与客户端的链接步骤</p>\n<p>1、服务器建立公钥文件</p>\n<p>系统安装完成时sshd会朱勇去计算出需要的公钥文件和自己需要的私钥文件，等下次再次启动sshd的时候该服务就会主动去找文件/etc/ssh/ssh_host*</p>\n<p>2、客户端主动链接</p>\n<p>需要使用客户端程序（如ssh）来连接</p>\n<p>3、服务器传送公钥文件给客户端</p>\n<p>服务器将将取得的公钥文件/etc/ssh/ssh_host*传送给客户端（由于公钥是给大家使用的，所以此时的传送是明文的）</p>\n<p>4、客户端记录并比对该公钥数据，然后计算出自己的公钥和私钥</p>\n<p>客户端在第一次连接该服务器后会将服务器的公钥数据记录到客户端的用户主目录下的~ /.ssh/known_hosts内，如果已经记录过该数据则客户端会去比对此次受到的公钥与之前的差异，若接受此次公钥数据那么会计算出客户端自己的公钥和私钥</p>\n<p>5、客户端将自己的公钥传送给服务器</p>\n<p>此时服务器端会有自己的私钥和客户端的公钥；而客户端会有服务器的公钥和自己的私钥，这时服务器与客户端的秘钥（公钥与私钥）是不一样的，所以才称之为非对称式秘钥系统</p>\n<p>6、服务器开始进行双向加解密</p>\n<p>1)   服务器传送数据到客户端</p>\n<p>将用户的公钥加密后进行发送，客户端接收后用自己的私钥解密</p>\n<p>2)   客户端传送数据到服务器</p>\n<p>将服务器的公钥加密后进行发送，服务器接受后用自己的私钥解密</p>\n<p>l  秘钥文件的建立</p>\n<p>1、服务器端启动ssh服务，以生成服务器端的公钥和私钥</p>\n<pre><code>[root@baobao ~]# /etc/init.d/sshd restart\n</code></pre><p>停止 sshd：                                                [确定]</p>\n<p>生成 SSH1 RSA 主机键：                                     [确定]</p>\n<p>生成 SSH2 RSA 主机键：                                     [确定]</p>\n<p>正在生成 SSH2 DSA 主机键：                                 [确定]</p>\n<p>正在启动 sshd：                                            [确定]</p>\n<p>2、客户端利用ssh连接服务器</p>\n<pre><code>[root@abao ~]# ssh 172.168.72.68\n\nThe authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n\nRSA key fingerprint is36:cf:9f:46:54:46:4b:b3:b0:48:4a:93:4d:14:81:56.\n\nAre you sure you want to continue connecting (yes/no)? yes\n\nWarning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n\nroot@172.168.72.68’s password:\n\nLast login: Sun Sep 28 15:37:10 2014 from localhost\n\n[root@baobao ~]# exit\n\nlogout\n\nConnection to 172.168.72.68 closed.\n</code></pre><p>3、删除客户端的秘钥文件</p>\n<pre><code>[root@abao ~]# rm /etc/ssh/ssh_host*\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key.pub”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_key”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_key.pub”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key.pub”？y\n</code></pre><p>4、重新启动客户端的sshd服务以查看秘钥文件的建立过程</p>\n<pre><code>[root@abao ~]# /etc/init.d/sshd restart\n\n停止 sshd：[确定]\n\n生成 SSH1 RSA 主机键： [确定]\n\n生成 SSH2 RSA 主机键： [确定]\n\n正在生成 SSH2 DSA 主机键： [确定]\n\n正在启动 sshd：[确定]\n</code></pre><p>l  Sshd服务的启动</p>\n<pre><code>[root@baobao ~]# /etc/init.d/sshd restart\n\n停止 sshd：[确定]\n\n正在启动 sshd：[确定]\n\n[root@baobao ~]# netstat -tlnp | grep ssh #注意ssh服务是tcp端口22\n\ntcp 0  0 0.0.0.0:22  0.0.0.0:*LISTEN 9262/sshd\n\ntcp 0  0:::22:::* LISTEN 9262/sshd\n</code></pre><p>在linux系统中默认就有ssh所需要的软件了，包括可以产生密码等协议的OpenSSL软件和OpenSSH软件，而且在当前的linux系统中都是默认启动ssh的。这个sshd可以同时提供shell与ftp，而且都是在tcp端口22</p>\n<p>l  Linux用户ssh客户端的连接程序</p>\n<p>Linux客户端默认情况下是可以正常使用ssh的而不必安装额外的软件，而且其默认是启动的</p>\n<p>1、 直接登录远程主机的指令ssh（可用作服务器管理）</p>\n<p>Ssh命令格式为：ssh [-f][-o参数项目][-p非标准端口][账号@]IP地址[命令]</p>\n<p>1)   Ssh命令参数介绍</p>\n<p>-f：     需要配合后面的[命令]，不登陆远程主机直接发送一个命令过去而已</p>\n<p>-o：     主要的参数有：ConnectTimeout=秒数：连接等到的秒数，减少等待的时间</p>\n<p>StrictHostKeyChecking=yes/no/ask：默认是ask，如果想要public key主动加入known_host这里设置为no</p>\n<p>-p：     如果sshd服务启动在非标准的端口需使用该项目[命令]，不登陆远程主机直接发送一个命令过去，但与-f意义不太相同</p>\n<p>2)   ssh使用范例</p>\n<p>A：直接登录到远程主机</p>\n<pre><code>[root@abao ~]# ssh 172.168.72.68\n\nThe authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n\nRSA key fingerprint is36:cf:9f:46:54:46:4b:b3:b0:48:4a:93:4d:14:81:56.   #远程服务器的公钥指纹码\n\nAre you sure you want to continue connecting (yes/no)? yes   #将上述指纹码写入服务器公钥记录文件~ /.ssh/known_hosts，等再次登录时就不会出现该指纹码提示了。一定要yes而不是y\n\nWarning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n\nroot@172.168.72.68’s password:#远程主机的root密码\n\nLast login: Sun Sep 28 15:37:10 2014 from localhost\n\n[root@baobao ~]# exit #退出远程连接\n\nlogout\n\nConnection to 172.168.72.68 closed.\n</code></pre><p>一般我们使用“ssh 账号 主机IP地址”的登录方式，如果不写账号的话那么会以本地计算机的当前账号来尝试登录远程主机</p>\n<p>B：再次登录远程主机</p>\n<pre><code>[root@abao ~]# ssh 172.168.72.68\n\nroot@172.168.72.68’s password:\n\nLast login: Sun Sep 28 16:42:05 2014 from aca84448.ipt.aol.com\n</code></pre><p>C：使用账号axing登录</p>\n<pre><code>[root@baobao ~]# ssh axing@172.168.72.68\n\nThe authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n\nRSA key fingerprint is 36:cf:9f:46:54:46:4b:b3:b0:48:4a:93:4d:14:81:56.\n\nAre you sure you want to continue connecting (yes/no)? yes\n\nWarning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n\naxing@172.168.72.68’s password:\n\n[axing@baobao ~]$   #远程登陆后身份变为axing\n</code></pre><p>D：远程登陆执行命令后立刻离开</p>\n<pre><code>[root@abao ~]# ssh axing@172.168.72.68 find / -name passwd  #既后面直接加命令\n\naxing@172.168.72.68’s password:\n</code></pre><p>卡在这里等待命令的执行完毕</p>\n<p>E：让远程主机自动运行命令而立刻回到本地端继续工作</p>\n<pre><code>[root@abao ~]# ssh -faxing@172.168.72.68 shutdown -h now\n\naxing@172.168.72.68’s password:\n</code></pre><p>F：自动加上公钥记录而不再询问</p>\n<pre><code>[root@abao ~]# rm ~/.ssh/known_hosts\n\nrm：是否删除普通文件 “/root/.ssh/known_hosts”？y\n\n[root@abao ~]# ssh -o StrictHostKeyChecking=no root@172.168.72.68#不在要求输入yes或no了\n\nWarning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n\nroot@172.168.72.68’s password:\n\nLast login: Mon Sep 29 14:00:28 2014 from aca84448.ipt.aol.com\n</code></pre><p>2、服务器公钥记录文件~ /.ssh/known_hosts</p>\n<p>当远程登陆服务器时本机会主动将从服务器收到的公钥服务器公钥记录文件~ /.ssh/known_hosts进行比对，如果服务器的公钥文件还没有记录那么就会主动询问是否记录（登陆时候的yes或no行为）；如果收到的公钥已经记录那么会比对记录是否相同，如果相同则继续登陆，如果不同就会离开登陆而返回。但是如果是服务器重新安装那么服务器的公钥就会经常变化，这样的话我们就无法正常远程登陆了</p>\n<p>A：模拟服务器重新安装后ssh登陆</p>\n<pre><code>[root@baobao ~]# rm /etc/ssh/ssh_host*\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_dsa_key.pub”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_key”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_key.pub”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key”？y\n\nrm：是否删除普通文件 “/etc/ssh/ssh_host_rsa_key.pub”？y\n\n[root@baobao ~]# /etc/init.d/sshd restart\n\n停止 sshd：[确定]\n\n生成 SSH1 RSA 主机键： [确定]\n\n生成 SSH2 RSA 主机键： [确定]\n\n正在生成 SSH2 DSA 主机键： [确定]\n\n正在启动 sshd：[确定]\n\n[root@baobao ~]# ssh 172.168.72.68\n\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n\n@WARNING: REMOTE HOSTIDENTIFICATION HAS CHANGED! @\n\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\n\nSomeone could be eavesdropping on you right now(man-in-the-middle attack)!\n\nIt is also possible that the RSA host key has just been changed.\n\nThe fingerprint for the RSA key sent by the remote host is\n\n17:7e:8e:e9:fd:df:1c:e5:c9:9d:cd:30:31:5e:a6:45.\n\nPlease contact your system administrator.\n\nAdd correct host key in /root/.ssh/known_hosts to get rid ofthis message.\n\nOffending key in /root/.ssh/known_hosts:2#有问题的数据行号\n\nRSA host key for 172.168.72.68 has changed and you haverequested strict checking.\n\nHost key verification failed.\n</code></pre><p>B：上述现象解决方法</p>\n<pre><code>[root@baobao ~]# vim /root/.ssh/known_hosts  #清空该文件\n\n[root@baobao ~]# ssh 172.168.72.68\n\nThe authenticity of host ‘172.168.72.68 (172.168.72.68)’ can’tbe established.\n\nRSA key fingerprint is17:7e:8e:e9:fd:df:1c:e5:c9:9d:cd:30:31:5e:a6:45.\n\nAre you sure you want to continue connecting (yes/no)? yes#记录公钥\n\nWarning: Permanently added ‘172.168.72.68’ (RSA) to the list ofknown hosts.\n\nroot@172.168.72.68’s password:\n\nLast login: Mon Sep 29 14:28:46 2014 from aca84448.ipt.aol.com\n</code></pre><p>3、模拟FTP的文件传输之SFTP</p>\n<p>如果想要从远程服务器下载或上传文件就不能使用ssh了，而必须使用sftp或scp，这两个指令也是使用ssh的端口22，只是模拟成ftp与复制的操作而已</p>\n<p>1)   SFTP使用的命令</p>\n<p>Sftp使用的命令与ftp是一样的</p>\n<p>A：针对远程服务器的命令</p>\n<p>跟linux服务器命令相同</p>\n<p>B：针对本机的命令</p>\n<p>在基本命令前面加“l”即代表是针对本机的操作，例如sftp&gt; lcd /tmp进入本机的该目录</p>\n<p>C：针对资料的上传或下载的命令</p>\n<p>put [本地目录或文件][远程]或put [本地目录或文件]（这样会存储到远程主机的目录下）</p>\n<p>get [远程目录或文件][本机]或get [远程目录或文件]（这样会存储到当前本机所在目录）</p>\n<p>2)   Sftp的使用范例</p>\n<p>A：sftp的登陆于退出</p>\n<pre><code>[root@baobao ~]# sftp 172.168.72.68\n\nConnecting to 172.168.72.68…\n\nroot@172.168.72.68’s password:\n\nsftp&gt;\n\n或\n\n[root@baobao ~]# sftp axing@172.168.72.68\n\nConnecting to 172.168.72.68…\n\naxing@172.168.72.68’s password:\n\nsftp&gt; exit\n</code></pre><p>B：上传与下载</p>\n<pre><code>sftp&gt; pwd#查看当前在服务器的目录\n\nRemote working directory: /home/axing\n\nsftp&gt; lls /etc/hosts #查看本机是否有该文件\n\n/etc/hosts\n\nsftp&gt; put /etc/hosts #上传该文件到远程服务器\n\nUploading /etc/hosts to /home/axing/hosts#上传到服务器的默认目录\n\n/etc/hosts 100%  1580.2KB/s   00:00\n\nsftp&gt; ls\n\nhosts\n\nsftp&gt; ls –a  #查看服务器该目录下的隐藏文件\n\n.   ..  .bash_history   .bash_logout.bash_profile   .bashrc .emacs\n\n.gnome2.mozillahosts\n\nsftp&gt; lcd /tmp#切换到本地的目录/tmp下\n\nsftp&gt; get .bashrc #从服务器下载该文件\n\nFetching /home/axing/.bashrc to .bashrc\n\n/home/axing/.bashrc   100%  124 0.1KB/s  00:00\n\nsftp&gt; lls –a #确认是否下载成功\n\n……………………………………………\n\nbaoaj  .bashrc  guoal   guobe  guobx guocq  guodj  pulse-Fhzh5o9BSGRy\n\nsftp&gt; exit\n</code></pre><p>4、文件异地直接复制SCP</p>\n<p>当已经知道服务器上的文件名时可以使用该命令，该命令的上传和下载使用格式如下：</p>\n<p>上传：scp [-pr] [-l 速率] file [账号@]主机：目录名（：后没有空格）</p>\n<p>下载：scp [-pr] [-l 速率] [账号@]主机：file 目录名（file后有空格）</p>\n<p>1)   命令参数介绍</p>\n<p>-p：     保留文件的原有权限</p>\n<p>-r：     复制整个目录</p>\n<p>-l：     传输速率</p>\n<p>2)   Scp使用范例</p>\n<p>A：上传本地文件到远程服务器</p>\n<p><code>[root@baobao ~]# scp /etc/hosts* axing@172.168.72.68:~</code> #上传到服务器的用户主目录下</p>\n<p><a href=\"mailto:axing@172.168.72.68\" target=\"_blank\" rel=\"noopener\">axing@172.168.72.68</a>’s password:</p>\n<p>hosts                100% 158     0.2KB/s   00:00</p>\n<p>hosts.allow          100% 370     0.4KB/s   00:00</p>\n<p>hosts.deny           100% 460     0.5KB/s   00:00</p>\n<p>B：从服务器下载文件到本地</p>\n<pre><code>[root@baobao ~]# scp axing@172.168.72.68:/etc/bashrc /tmp\n\naxing@172.168.72.68’s password:\n\nbashrc   100%2681 2.6KB/s   00:00\n</code></pre><p>l  windows用户ssh客户端的连接程序</p>\n<p>默认的windows并没有ssh的客户端程序，所以需要下载第三方软件才行，常见的有pietty、psftp和filezilla</p>\n<p>1、直接连接的pietty（可用作服务器管理）</p>\n<p>下载后安装即可使用，不过由于编码的问题中文会显示乱码需要设置该软件才行option—more options—features（右第二个打钩打开键盘数字）—connection—-ssh（右2only选择版本）</p>\n<p>option—font（脚本gb2312调整字符集支持中文）</p>\n<p>2、psftp</p>\n<p>下载后安装并启动，输入open172.168.72.68后连接即可</p>\n<p>3、filezilla</p>\n<p>下载后安装运行即可，是普通的中文界面ftp软件</p>\n<p>l  windows用户远程登陆管理服务器工具xshell（当前最好用的工具）</p>\n<p>1、xshell界面</p>\n<p>它是windows下当前最好用的远程管理软件，只需要你下载后安装即可使用，一般还有中文版，非常好用，以下是链接后的画面</p>\n<pre><code>Connecting to 172.168.72.68:22…\n\nConnection established.\n\nTo escape to local shell, press ‘Ctrl+Alt+]’.  #回到本地shell\n\nLast login: Tue Sep 30 08:55:23 2014 from aca80058.ipt.aol.com\n\n[root@baobao ~]# ls\n\n123baoae  cheng  last.list  lsrootaf   图片\n\nanaconda-ks.cfg  baoagguo.txt  lsrootaa regular_express.txt.1  下载\n\nbaoaa baoah  homelsrootab   xinzi.txt  音乐\n\nbaoab   baoai  homefile  lsrootac   公共的 桌面\n\n………………………………………………………\n\n[root@baobao ~]#\n</code></pre><p>2、xshell中文乱码解决法案</p>\n<p>Xshell是个非常不错的工具。但很多时候中文显示为乱码的问题，解决方法其实很简单的，即把xshell编码方式改成UTF-8即可：[文件]–&gt;[打开]–&gt;在打开的session中选择连接的那个然后右键点击[属性] -&gt; [终端]，编码选择为：Unicode(UTF-8)，然后重新连接服务器即可</p>\n<p>3、ssh远程登陆日志（重要）</p>\n<pre><code>[root@baobao ~]# cat /var/log/secure\n\nthenticationAgent, locale zh_CN.UTF-8)\n\nSep 30 08:55:23 baobao sshd[2916]: Accepted password for rootfrom 172.168.0.88 port 57853 ssh2\n\nSep 30 08:55:23 baobao sshd[2916]: pam_unix(sshd:session):session opened for user root by (uid=0)\n\nSep 30 09:21:21 baobao sshd[3331]: Accepted password for rootfrom 172.168.0.88 port 52386 ssh2\n\nSep 30 09:21:21 baobao sshd[3331]: pam_unix(sshd:session):session opened for user root by (uid=0)\n\nSep 30 09:21:55 baobao sshd[2916]: pam_unix(sshd:session):session closed for user root\n</code></pre><p>l  sshd服务器配置</p>\n<p>sshd服务器的详细配置都放在/etc/ssh/sshd_config配置文件里，只要是没有被注释的就是默认值</p>\n<pre><code>    [root@baobao ~]# vim /etc/ssh/sshd_config\n\n……………………………………………………\n\n#Port 22   #也可以设置多个端口只要添加一行然后重启即可（不建议）\n\n#ListenAddress 0.0.0.0 #默认监听所有网卡的接口，如果想指定后面直接写ip即可\n\nProtocol 2 #ssh的协议版本\n\n# HostKey for protocol version 1   #下面是不同协议版本的秘钥文件host key\n\n#HostKey /etc/ssh/ssh_host_key\n\n# HostKeys for protocol version 2\n\n#HostKey /etc/ssh/ssh_host_rsa_key\n\n#HostKey /etc/ssh/ssh_host_dsa_key\n\nSyslogFacility AUTHPRIV #ssh登陆记录，默认是/var/log/secure\n\n#LoginGraceTime 2m  #登陆超时设置\n\n#PermitRootLogin yes#是否允许root登陆，默认是允许的，建议设置为no\n\n#StrictModes yes#是否让sshd检查相关权限以免用户将某些权限设置错误\n\nPasswordAuthentication yes  #密码验证，当然需要了\n\n#PermitEmptyPasswords no#是否允许空密码登陆，当然是no了\n\n#IgnoreUserKnownHosts no#是否忽略用户主文件记录，当然是no了\n\n#IgnoreRhosts yes   #是否取消~/.ssh/.rhosts认证，当然yes了\n\nChallengeResponseAuthentication no  #该认证不安全，设置为no即可\n\nUsePAM yes#最好使用该认证模块记录与管理，所以yes\n\n#PrintLastLog yes #显示上次登陆的信息\n\n#TCPKeepAlive yes #网络不稳定时为了连接不中断可以设置为no\n\n#UsePrivilegeSeparation yes   #使用权限较低的程序来给用户操作\n\nDenyUsers #拒绝登陆的用户\n\nDenyGroups#拒绝登陆的组\n</code></pre><p>基本上ssh的默认设置已经就很安全了，不过还是建议将root的登陆权限取消，并将ssh的版本设置为2，而且通常这个文件不需要修改，如果修改了需要重启sshd</p>\n<p>l  制作不用密码接口登陆的ssh用户</p>\n<p>将客户端产生的key复制到服务器中，以后客户端再次登录的时候由于两者在ssh要连接的信号传递中已经比对过key了，所以不再需要输入密码了</p>\n<p>1、步骤一，客户端建立两把钥匙</p>\n<pre><code>[root@abao ~]# useradd abao\n\n[root@abao ~]# passwd abao\n\n更改用户 abao 的密码 。\n\n新的 密码：\n\n重新输入新的 密码：\n\npasswd： 所有的身份验证令牌已经成功更新。\n\n服务器上也做上面相同的用户配置\n\n[root@abao ~]# su – abao\n\n[abao@abao ~]$ ssh-keygen#默认以RSA建立两把钥匙\n\nGenerating public/private rsa key pair.\n\nEnter file in which to save the key (/home/abao/.ssh/id_rsa): 回车\n\nCreated directory ‘/home/abao/.ssh’. #建立主目录\n\nEnter passphrase (empty for no passphrase): 回车\n\nEnter same passphrase again: 回车\n\nYour identification has been saved in /home/abao/.ssh/id_rsa.   #私钥文件\n\nYour public key has been saved in /home/abao/.ssh/id_rsa.pub.   #公钥文件\n\nThe key fingerprint is:\n\n89:1e:87:c9:a8:68:69:df:bd:75:a4:df:54:37:70:f1 abao@abao\n\nThe key’s randomart image is:\n\n+–[ RSA 2048]—-+\n\n|   . |\n\n|o|\n\n| . .E|\n\n| o + .o  |\n\n|. * S  .   o.|\n\n| … . o  o   . o|\n\n|.+.   .  o . .  |\n\n|o . . . . o o|\n\n|   . . o.  . .   |\n\n+—————–+\n\n[abao@abao ~]$ ls -ld ~/.ssh; ls -l ~/.ssh\n\ndrwx——. 2 abao abao 4096 9月  30 11:56 /home/abao/.ssh\n\n总用量 8\n\n-rw——-. 1 abao abao1675 9月  30 11:56 id_rsa\n\n-rw-r–r–. 1 abao abao  391 9月  3011:56 id_rsa.pub\n</code></pre><p>默认情况下建立私钥后权限和文件名放置位置都是正确的。身份必须是abao，当执行ssh-keygen的时候才会在用户主目录下生成两把钥匙，需要注意的是~/.ssh/目录必有700的权限，而且私钥文件的权限必须是-rw——-且属于abao才行，否则在秘钥比对中会被误判为危险而无法成功的以公私钥成对文件的机制实现连接</p>\n<p>2、步骤二，将公钥文件数据上传到服务器</p>\n<pre><code>[root@baobao ~]# useradd abao  #先在ssh服务器端建立上传文件账户abao\n[root@baobao ~]# passwd abao\n更改用户 abao 的密码 。\n新的 密码：\n重新输入新的 密码：\npasswd： 所有的身份验证令牌已经成功更新。\n[abao@abao ~]$ scp ~/.ssh/id_rsa.pub abao@172.168.72.68:~\n\nabao@172.168.72.68’s password:\n\nid_rsa.pub100%  3910.4KB/s   00:00\n</code></pre><p>3、步骤三，蒋公钥放置到服务器端的正确目录与文件名</p>\n<p>1)   服务器上建立文件~/.ssh</p>\n<pre><code>[root@baobao ~]# su – abao\n\n[abao@baobao ~]$ ls -ld .ssh\n\nls: 无法访问.ssh: 没有那个文件或目录\n\n[abao@baobao ~]$ mkdir .ssh; chmod 700 .ssh  #注意其权限必须是700\n\n[abao@baobao ~]$ ls -ld .ssh\n\ndrwx——. 2 abao abao 4096 9月  3012:30 .ssh\n</code></pre><p>2)   将公钥文件内的数据使用cat转存到authorized_keys内</p>\n<pre><code>[abao@baobao ~]$ ls -l *pub\n\n-rw-r–r–. 1 abao abao 391 9月  3012:26 id_rsa.pub\n\n[abao@baobao ~]$ cat id_rsa.pub &gt;&gt; .ssh/authorized_keys\n\n[abao@baobao ~]$ chmod 644 .ssh/authorized_keys\n\n[abao@baobao ~]$ ls -l .ssh\n\n总用量 4\n\n-rw-r–r–. 1 abao abao 391 9月  3012:39 authorized_keys\n</code></pre><p>总结：客户端必须制作出两把钥匙，其中私钥必须放到~/.ssh内；而公钥必须上传到服务器端并且放置到用户主目录下的~/.ssh/authorized_keys，同时目录的权限必须是700,而文件权限必须是644</p>\n<p>4、步骤四，验证</p>\n<pre><code>[root@abao ~]# ssh abao@172.168.72.68\n\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n\n@WARNING: REMOTE HOSTIDENTIFICATION HAS CHANGED! @\n\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\n\nSomeone could be eavesdropping on you right now(man-in-the-middle attack)!\n\nIt is also possible that the RSA host key has just been changed.\n\nThe fingerprint for the RSA key sent by the remote host is\n\n17:7e:8e:e9:fd:df:1c:e5:c9:9d:cd:30:31:5e:a6:45.\n\nPlease contact your system administrator.\n\nAdd correct host key in /root/.ssh/known_hosts to get rid ofthis message.\n\nOffending key in /root/.ssh/known_hosts:1\n\nRSA host key for 172.168.72.68 has changed and you haverequested strict checking.\n\nHost key verification failed.\n\n[root@abao ~]##看不再需要密码了\n\n[root@abao ~]# ifconfig   #查看服务器IP地址\n\neth0  Linkencap:Ethernet  HWaddr00:0C:29:59:D9:E6\n\ninet addr:172.168.68.72  Bcast:172.168.255.255  Mask:255.255.0.0\n\ninet6 addr:fe80::20c:29ff:fe59:d9e6/64 Scope:Link\n\nUP BROADCASTRUNNING MULTICAST  MTU:1500  Metric:1\n\nRXpackets:239668 errors:0 dropped:0 overruns:0 frame:0\n\nTX packets:855errors:0 dropped:0 overruns:0 carrier:0\n\ncollisions:0txqueuelen:1000\n\nRXbytes:18091942 (17.2 MiB)  TX bytes:71093(69.4 KiB)\n</code></pre><p>l  Ssh的安全设置</p>\n<p>Sshd所谓的安全其实指的是它的数据加密功能，而对于sshd本身这个服务来说是很不安全的，所以如果不是特别需要请尽量限制在小范围内的几个ip或主机名即可</p>\n<p>1、 服务器本身的设置强化/etc/ssh/sshd——config</p>\n<pre><code>[root@baobao ~]# vim /etc/ssh/sshd_config\n</code></pre><p>1)   禁止root账号使用sshd服务</p>\n<pre><code>PermitRootLogin no                         #去掉注释并修改为no\n</code></pre><p>2)   禁止nossh这个组的用户使用sshd服务</p>\n<pre><code>DenyGroups nosh\n</code></pre><p>3)   禁止用户testssh使用sshd服务</p>\n<pre><code>DenyUsers testssh\n\n[root@abao ~]# /etc/init.d/sshd restart\n\n停止 sshd：[确定]\n\n正在启动 sshd：[确定]\n\n[root@abao ~]# cat /var/log/secure #验证上述用户不能登陆后查看其日志\n</code></pre><p>2、TCP Wrapper的使用</p>\n<pre><code>[root@baobao ~]# vim /etc/host.allow  #只允许内网和本机可以远程登陆\n\nsshd: 127.0.0.1 192.168.1.0/255.255.255.0192.168.10.0/255.255.255.0\n\n[root@baobao ~]# vim /etc/host.deny\n\nsshd: all\n</code></pre><p>3、iptables数据包过滤防火墙</p>\n<pre><code>[root@baobao ~]# iptables -A INPUT -i eth0 -s 192.168.1.0/24 -p tcp –dport 22 -j ACCEPT\n\n[root@baobao ~]# iptables -A INPUT -i eth0 -s 192.168.10.0/24 -p tcp –dport 22 -j ACCEPT\n\n[root@baobao ~]# /etc/init.d/iptables save\n\n[root@baobao ~]# /etc/init.d/iptables restart\n</code></pre><p>注意不要开放ssh的登陆权限给Internet上面的所有用户或主机，只开放给适当的部分用户或主机即可，否则会很不安全</p>"},{"title":"linux—SSH（二）Rsync备份","date":"2016-09-02T04:00:00.000Z","_content":"一、Rsync软件介绍\n\nrsync从字面上的意思就是remote sync （远程同步）的意思，是类unix系统下的远程数据镜像备份工具，可以镜像保存整个目录树和文件系统，并保持原来文件的权限、时间、软硬链接等，此外它还支持匿名传输；Rsync不仅可以远程同步数据（类似于scp）还可以本地同步数据（类似于cp），但不同于cp或scp的是rsync不像cp/scp一样会覆盖以前的数据，Rsync使用所谓的“Rsync演算法”，这个算法在第一次连通完成时，会把整份文件传输一次，下一次就只传送二个文件之间不同的部份，因此速度相当快\n<!--more-->\n二、Rsync的传输方式（或工作模式）\n\nl  在本机直接运行拷贝本地文件（不使用冒号）\n\n命令格式为：rsync[OPTION]… SRC DEST。如下\n\n    [root@abao~]# rsync -av /etc /tmp\n    \nl  通过rsh或ssh的信道在server/client之间进行传输数据（使用一个冒号）\n\n需要登录到服务器上执行任务，并且需要输入账号的密码\n\n1、 将本地机器的内容拷贝到远程机器（目标路径中使用一个冒号）\n\n命令格式为：rsync[OPTION]… SRC [USER@]HOST:DEST。如下\n\n\n    [root@abao~]# rsync -av -e ssh /tmp axing@172.168.72.68:~\n\n2、 将远程机器的内容拷贝到本地机器（源路径中使用一个冒号）\n\n命令格式为：rsync[OPTION]… [USER@]HOST:SRC DEST。如下\n\n\n    [root@abao~]# rsync -av -e ssh axing@172.168.72.68:~ /tmp\n\nl  直接通过rsync的服务来传输（此时服务器端需要启动873端口，并且使用两个冒号）\n\n这种方式在远程主机上建立一个rsync的服务器，在服务器上配置好rsync的各种应用，然后本机作为rsync的一个客户端去连接远程的rsync服务器\n\n1、 从远程rsync服务器中拷贝文件到本地机（源路径中使用一个冒号）\n\n命令格式为：rsync[OPTION]… [USER@]HOST::模块名 本地位置。如下\n\n\n    [root@abao~]# rsync -av axing@172.168.72.68:：back /databack\n\n2、从本地机器拷贝文件到远程rsync服务器中（目标路径中使用一个冒号）\n\n命令格式为：rsync[OPTION]… SRC [USER@]HOST::DEST。如下\n\n    [root@abao~]# rsync -av /databack axing@172.168.72.68:：back\n    \n以上3中传输方式的差异在于有没有冒号“：”，本地端传输不需要冒号，通过rsh或ssh传输时需要一个冒号，而通过rsync传输时需要两个冒号\n\n三、Rsync的语法\n\n    -v： 查看模式可以列出很多信息包括文件名\n    \n    -r： 递归复制，可以针对目录来复制\n    \n    -u： 仅更新，如果目标文件比较新那么则保留新文件不会覆盖\n    \n    -l： 复制链接文件的属性\n    \n    -p： 连同属性一起复制\n    \n    -g： 保存源文件的属组\n    \n    -o： 保存源文件的属主\n    \n    -D： 保存源文件的设备属性\n    \n    -t： 保存原文件的时间参数\n    \n    -z： 在传输时加上压缩\n    \n    -e： 使用的协议，例如使用ssh通道就是-e ssh\n    \n    -a： 相当于-rlptgoD，是最常用的参数\n    \n    -L： 把SRC中软连接的目标文件给拷贝到DST.\n    \n    –delete：如果在DST增加文件了，而SRC当中没有这些文件，同步时会删除新增的文件\n    \n    –exclude=filename：  指定排除不需要传输的文件，等号后面跟文件名（如*.txt）\n    \n    –progress：  可以看到同步的过程状态，比如文件数量、文件传输速度等\n\n四、在本机直接运行拷贝本地文件实例\n\n    [root@abao ~]# rsync -av /etc/tmp#首次本地备份\n    \n    …………………………………………………………………\n    \n    sent 33899909 bytes  received 35626 bytes  5220851.54 bytes/sec\n    \n    total size is 33759697  speedup is 0.99\n    \n    [root@abao ~]# ll -d /tmp/etc/etc#两文件相同\n    \n    drwxr-xr-x. 126 root root12288 10月 10 08:23 /etc\n    \n    drwxr-xr-x. 126 root root12288 10月 10 08:23 /tmp/etc\n    \n    [root@abao ~]# rsync -av /etc/tmp#再次备份时只备份差异文件\n    \n    sending incremental file list\n    \n    sent 77528 bytes  received 293 bytes  155642.00 bytes/sec\n    \n    total size is 33759697  speedup is 433.81\n\n五、通过rsh或ssh的信道在server/client之间进行传输数据实例\n\n    [root@abao ~]# /etc/init.d/sshd restart\n    \n    停止 sshd：[确定]\n    \n    正在启动 sshd：[确定]\n    \nl  将本地机器的内容拷贝到远程机器\n\n    [root@abao ~]# rsync -av -e ssh /tmp admin@172.168.72.68:~\n    \n    admin@172.168.72.68’s password:   #需要输入账户密码\n    \n    …………………………………………………………………………\n    \n    sent 238637037 bytes received 60045 bytes  3819153.31bytes/sec\n    \n    total size is 238396030 speedup is 1.00\n\nl  将远程机器的内容拷贝到本地机器\n\n    [root@abao ~]# rsync -av -e ssh axing@172.168.72.68:~ /tmp\n    \n    axing@172.168.72.68’s password:   #需要输入账户密码\n    \n    receiving incremental file list\n    \n    axing/\n    \n    axing/.ICEauthority\n    \n    …………………………………………………………………\n    \n    sent 1732 bytes  received758924 bytes  80069.05 bytes/sec\n    \n    total size is 751474 speedup is 0.99\n    \n    [root@abao ~]# ll -d /tmp/axing\n    \n    drwx——. 27 500 500 4096 10月 10 08:23 /tmp/axing\n\nl  利用crontab通过ssh进行免密码异地备份脚本（常用）\n\n我们可以针对用户admin制作一个免密码登陆的ssh秘钥，这样以后异地备份系统就可以使用crontab自动备份了，前提是先根据下面（六、直接通过rsync的服务来传输实例）安装并设置好rsync\n\n1、ssh服务器端和客户端账户建立\n\n    [root@baobao ~]# mkdir /home/back; touch /home/back/wo#创建要备份的文件\n    \n    [root@baobao ~]# chmod -R 755 /home/back/\n    \n    [root@baobao ~]# useradd admin#先在ssh服务器端ssh账号\n    \n    [root@baobao ~]# passwd admin\n    \n    更改用户 admin 的密码 。\n    \n    新的 密码：\n    \n    重新输入新的 密码：\n    \n    passwd： 所有的身份验证令牌已经成功更新。\n    \n    [root@abao ~]# useradd admin  #客户端上建立ssh账号\n    \n    [root@abao ~]# passwd admin\n    \n    更改用户 admin 的密码 。\n    \n    新的 密码：\n    \n    重新输入新的 密码：\n    \n    passwd： 所有的身份验证令牌已经成功更新。\n\n2、客户端建立两把钥匙\n\n    [root@abao ~]# su – admin\n    \n    [admin@abao ~]$ ssh-keygen\n    \n    Generating public/private rsa key pair.\n    \n    Enter file in which to save the key (/home/admin/.ssh/id_rsa):\n    \n    Created directory ‘/home/admin/.ssh’.\n    \n    Enter passphrase (empty for no passphrase):\n    \n    Enter same passphrase again:\n    \n    Your identification has been saved in /home/admin/.ssh/id_rsa.\n    \n    Your public key has been saved in /home/admin/.ssh/id_rsa.pub.\n    \n    The key fingerprint is:\n    \n    61:01:c2:9b:26:00:0a:01:c9:a0:58:7e:38:f9:85:6c admin@abao\n    \n    The key’s randomart image is:\n    \n    +–[ RSA 2048]—-+\n    \n    |@o… …|\n    \n    |B+ +.o   .   |\n    \n    |+.= Eo. o|\n    \n    |  .=+. . .   |\n    \n    |   o.   S   |\n    \n    | |\n    \n    | |\n    \n    | |\n    \n    | |\n    \n    +—————–+\n    \n    [admin@abao ~]$ ls -ld ~/.ssh; ls -l ~/.ssh\n    \n    drwx——. 2 admin admin 4096 10月 10 09:21 /home/admin/.ssh\n    \n    总用量 8\n    \n    -rw——-. 1 admin admin 1675 10月 10 09:21 id_rsa\n    \n    -rw-r–r–. 1 admin admin 392 10月 10 09:21 id_rsa.pub\n\n3、将公钥文件数据上传到服务器\n\n    [admin@abao ~]$ scp ~/.ssh/id_rsa.pub admin@172.168.72.68:~#客户端上传公钥文件\n    \n    admin@172.168.72.68’s password:\n    \n    id_rsa.pub100%  3920.4KB/s   00:00\n\n4、将公钥放置到服务器端的正确目录与文件名（服务器上操作）\n\n    [root@baobao ~]# su – admin\n    \n    [admin@baobao ~]$ ls -ld .ssh\n    \n    ls: 无法访问.ssh: 没有那个文件或目录\n    \n    [admin@baobao ~]$ mkdir .ssh; chmod 700 .ssh #服务器上建立文件~/.ssh\n    \n    [admin@baobao ~]$ ls -ld .ssh\n    \n    drwx—— 2 admin admin 4096 10月 10 09:36 .ssh\n    \n    [admin@baobao ~]$ ls -l *pub\n    \n    -rw-r–r– 1 admin admin 392 10月 10 09:27 id_rsa.pub\n    \n    [admin@baobao ~]$ cat id_rsa.pub >> .ssh/authorized_keys\n    \n    [admin@baobao ~]$ chmod 644 .ssh/authorized_keys\n    \n    [admin@baobao ~]$ ls -l .ssh\n    \n    总用量 4\n    \n    -rw-r–r– 1 admin admin 392 10月 10 09:38 authorized_keys\n\n5、在客户端建立异地备份脚本\n\n    [root@abao ~]# mkdir /backups\n    \n    [root@abao ~]# chmod -R 755 /backups/\n    \n    [root@abao ~]# su – admin\n    \n    [admin@abao ~]$ mkdir ~/bin; vim ~/bin/backup.sh\n    \n    #!/bin/bash\n    \n    localdir=/backups\n    \n    remotedir=/home/back/\n    \n    remoteip=”172.168.72.68″\n    \n    [ -d ${localdir} ] || mkdir ${localdir}   #-d是判断是否有这个目录；符号“||”是逻辑或意思，左边为假时执行右边命令；小括号一般用作执行命令，而自定义变量一般用大括号括起来\n    \n    for dir in ${remotedir}\n    \n    do\n    \n    rsync -av -essh admin@${remoteip}:${dir} ${localdir}\n    \n    done\n    \n    [admin@abao ~]$ chmod 755 ~/bin/backup.sh\n    \n    [admin@abao ~]$ ls -ld /home/admin/bin/backup.sh\n    \n    -rwxrwxr-x. 1 admin admin 224 10月 11 08:49 /home/admin/bin/backup.sh\n    \n    [admin@abao ~]$ ~/bin/backup.sh   #执行脚本\n    \n    receiving incremental filelist\n    \n    sent 11 bytes  received 43 bytes  5.68 bytes/sec\n    \n    total size is 1010  speedup is 18.70\n    \n6、制作crontab计划任务\n\n    [root@abao ~]# crontab –e #每天的凌晨02:00异地备份服务器上的/etc /root /home目录到本地的/backups/下\n    0 2 * * * /home/admin/bin/backup.sh\n\n六、直接通过rsync的服务来传输实例\n\nl  创建用户账号和rsync配置文件\n\n    [root@baobao ~]# useraddadmin   #创建链接用户\n    \n    [root@baobao ~]# passwd admin\n    \n    更改用户 admin 的密码。\n    \n    新的 密码：\n    \n    重新输入新的 密码：\n    \n    passwd： 所有的身份验证令牌已经成功更新。\n    \n    [root@baobao ~]# mkdir /home/back   #创建要进行备份的目录或文件\n    \n    [root@baobao ~]# touch/home/back/guo\n    \n    [root@baobao ~]# vim/home/back/guo\n    \n    [root@baobao ~]# chmod -R 755/home/back/#设定要备份的目录或文件权限\n    \n    [root@baobao ~]# yum -yinstall xinetd\n    \n    [root@baobao ~]# yum -yinstall rsync#安装rsync\n    \n    [root@baobao ~]# yum -yinstall rsync#客户端也安装rsync\n    \n    [root@baobao ~]# touch/etc/rsyncd.conf  #默认该文件是没有的\n    \n    [root@baobao ~]# chmod 600/etc/rsyncd.conf  #修改配置文件权限\n\nl  Rsync服务器端配置文件设置\n\n配置文件时即时生效的，不用重启服务\n\n1、/etc/rsyncd.conf配置\n\n1)  全局参数配置\n\n    [root@baobao ~]# manrsyncd.conf   #查看说明文档看下面部分参数是yes/no还是true/false\n    \n    [root@baobao ~]# vim/etc/rsyncd.conf\n    \n    uid=root  #运行RSYNC守护进程的用户\n    \n    gid=root  #运行RSYNC守护进程的组\n    \n    use chroot=false  #不使用chroot\n    \n    max connections=8 #最大连接数是4\n    \n    pid file=/var/run/rsyncd.pid  #pid文件默认存放位置\n    \n    lock file=/var/run/rsync.lock #锁文件默认存放位置（锁住rsync正在操作的文件不让其他的程序对其进行写操作）\n    \n    log file=/var/log/rsyncd.log  #日志文件默认存放位置\n    \n    strict modes=true #是否检查口令文件的权限\n    port=873  #默认端口873\n    \n2)  模块参数配置(多台客户端需要设置多个模块)\n\n    [backup]   #认证的模块名，在client端需要指定\n    \n    path=/etc  #需要做备份的目录\n    \n    comment=This is backup #这个模块的注释信息\n    \n    list=true  #当用户查询该服务器上的可用模块时，该模块是被列出（true）还是被隐藏（false）\n    \n    max connections=6  #客户端最大连接数(默认0没限制)，模块里可以不设置\n    ignore errors  #可以忽略一些无关的IO错误\n    read only=false#“yes”只读客户端不能上传；“no”客户端可以上传\n    write only=false   #“yes”客户端不能下载；“no”客户端可以下载\n    \n    uid=root   #指定该模块传输文件时守护进程应该具有的uid\n    gid=root   #指定该模块传输文件时守护进程应该具有的gid\n    hosts allow=172.168.0.0/16 #允许连接的主机（“*”充许任何主机连接），多个主机用“，”分开；多个网段用空格隔开\n    hosts deny=192.168.10.0/32 #禁止连接的主机或网段\n    \n    auth users=admin   #登陆系统使用的用户名（系统必须存在的用户），没有默认为匿名\n    secrets file= /etc/rsyncd.secrets #登陆用户的密码文件（需要自己生成）\n\n2、rsync server启动文件配置\n\n    [root@baobao ~]# vim /etc/xinetd.d/rsync#只修改disable = no即可\n    \n    # default: off\n    \n    # description: The rsyncserver is a good addition to an ftp server, as it \\\n    \n    #   allows crc checksumming etc.\n    \n    service rsync\n    \n    {\n    \n    disable = no\n    \n    flags   = IPv6\n    \n    socket_type = stream\n    \n    wait= no\n    \n    user= root\n    \n    server  = /usr/bin/rsync\n    \n    server_args = –daemon\n    \n    log_on_failure  += USERID\n    \n    }\n    \n    [root@baobao ~]# chkconfigrsync on\n    \nl  创建密码文件、欢迎信息\n\n1、生成rsync密码文件并设置该文件相应权限\n    [root@baobao ~]# touch /etc/rsyncd.secrets\n    \n    [root@baobao ~]# vim /etc/rsyncd.secrets\n    \n    admin:guobaobao!1314#格式为“账号：密码”且一行一个\n    [root@baobao ~]# chown root.root /etc/rsyncd.secrets\n    \n    [root@baobao ~]# chmod 600 /etc/rsyncd.secrets\n    \n    因为rsyncd.secrets存储了rsync服务的用户名和密码，所以要将rsyncd.secrets设置为root拥有, 且权限为600\n\n2、配置欢迎信息rsyncd.motd（可有可无）\n    [root@baobao ~]# vim /etc/rsyncd.motd   #rsyncd.motd记录了rsync服务的欢迎信息\n    \n    Welcome to use the rsyncservices!\n    [root@baobao ~]# service xinetd restart\n    \n    停止 xinetd：  [确定]\n    \n    正在启动 xinetd：  [确定]\n    \nl  Rsync的启动与开机启动\n\n1、Rsync服务端启动\n\n1)  载入配置\n\n    [root@baobao ~]# rsync –daemon–config=/etc/rsyncd.conf   #载入配置并启动\n    \n    或\n    \n    [root@baobao ~]# /etc/rc.d/init.d/xinetdreload\n    \n    重新载入配置： [确定]\n\n2)  重启rsync\n\n    [root@baobao ~]# /usr/bin/rsync –daemon\n    \n    failed to create pid file/var/run/rsyncd.pid: File exists\n    \n    或\n    \n    [root@baobao ~]# /etc/rc.d/init.d/xinetdrestart#重新启动\n    \n    停止 xinetd：  [确定]\n    \n    正在启动 xinetd：  [确定]\n\n3)  检查rsync是否启动\n\n    [root@baobao ~]# netstat -lnp | grep 873#由超级进程启动\n    \n    tcp   0  0 0.0.0.0:8730.0.0.0:*LISTEN  3133/rsync\n    \n    tcp   0  0 :::873 :::*LISTEN 3133/rsync\n    \n    或\n    \n    [root@baobao ~]# netstat -a |grep rsync\n    \n    tcp0  0*:rsync *:* LISTEN\n    \n    或\n    \n    [root@baobao ~]# lsof -i:873 #端口没有被占用\n    \n    COMMAND  PID USER  FD   TYPE DEVICE SIZE/OFF NODENAME\n    \n    rsync   3133 root   4u  IPv4  22973 0t0  TCP *:rsync (LISTEN)\n    \n    rsync   3133 root   5u  IPv6  22974 0t0  TCP *:rsync (LISTEN)\n\n4)  查看rsync日志\n\n    [root@baobao ~]# cat /var/log/rsyncd.log #查看rsync日志\n    \n    2014/10/14 15:29:13 [35681] rsyncdversion 3.0.6 starting, listening on port 873\n    \n2、将rsync加入开机启动\n\n    [root@baobao ~]# echo”/usr/bin/rsync –daemon –config=/etc/rsyncd.conf”>>/etc/rc.local\n    \n    [root@baobao ~]# cat/etc/rc.local\n    \n    #!/bin/sh\n    \n    #\n    \n    # This script will beexecuted *after* all the other init scripts.\n    \n    # You can put your owninitialization stuff in here if you don’t\n    \n    # want to do the full Sys Vstyle init stuff.\n    \n    touch /var/lock/subsys/local\n    \n    /usr/bin/rsync –daemon–config=/etc/rsyncd.conf\n\nl  Rsync服务器端配置防火墙\n\n1、防火墙设置\n\n    [root@baobao ~]# iptables -F\n    \n    [root@baobao ~]# iptables -X\n    \n    [root@baobao ~]# iptables -Z\n    \n    [root@baobao ~]# iptables -AINPUT -i eth0 -s 172.168.0.0/16 -p tcp –dport 22 -j ACCEPT\n    \n    [root@baobao ~]# iptables -L\n    \n    Chain INPUT (policy ACCEPT)\n    \n    target prot opt source   destination\n    \n    ACCEPT tcp —  ACA80000.ipt.aol.com/16  anywheretcp dpt:ssh\n    \n    Chain FORWARD (policy ACCEPT)\n    \n    target prot opt source   destination\n    \n    Chain OUTPUT (policy ACCEPT)\n    \n    target prot opt source   destination\n    \n    [root@baobao ~]#/etc/init.d/iptables save\n    \n    iptables：将防火墙规则保存到 /etc/sysconfig/iptables： [确定]\n    \n    [root@baobao ~]#/etc/init.d/iptables restart\n    \n    iptables：清除防火墙规则：[确定]\n    \n    iptables：将链设置为政策 ACCEPT：filter[确定]\n    \n    iptables：正在卸载模块：  [确定]\n    \n    iptables：应用防火墙规则：[确定]\n\n2、selinux设置\n\n\n    [root@baobao ~]# setenforce 0\n\nl  客户端测试\n\n    [root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/\n    \n    Password:\n    \n    receiving incremental filelist\n    \n    created directory /backups\n    \n    ./\n    \n    guo\n    \n    sent 79 bytes  received 1162 bytes  275.78 bytes/sec\n    \n    total size is 1010  speedup is 0.81\n\n可以看到这里还是需要输入密码，这样同样也不能写入脚本中自动执行\n\nl  常见问题处理\n\n1、错误一\n\n@ERROR: chroot failed\n\nrsync error: error startingclient-server protocol (code 5) at main.c(1522) [receiver=3.0.3]\n\n原因：服务器端的目录不存在或无权限\n\n2、错误二\n\n@ERROR: auth failed on moduletee\n\nrsync error: error startingclient-server protocol (code 5) at main.c(1522) [receiver=3.0.3]\n\n原因：服务器端该模块（tee）需要验证用户名密码，但客户端没有提供正确的用户名密码，认证失败。\n\n3、错误三\n\n@ERROR: Unknown module‘tee_nonexists’\n\nrsync error: error startingclient-server protocol (code 5) at main.c(1522) [receiver=3.0.3]\n\n原因：服务器不存在指定模块\n\n4、错误四\n\npassword file must not beother-accessible\n\ncontinuing without passwordfile\n\nPassword:\n\n原因：这是因为rsyncd.pwdrsyncd.secrets的权限不对，应该设置为600\n\n5、错误五\n\nrsync: failed to connect to218.107.243.2: No route to host (113)\n\nrsync error: error in socketIO (code 10) at clientserver.c(104) [receiver=2.6.9]\n\n原因：对方没开机、防火墙阻挡、通过的网络上有防火墙阻挡，都有可能\n\n6、错误六\n\nrsync error: error startingclient-server protocol (code 5) at main.c(1524) [Receiver=3.0.7]\n\n原因：/etc/rsyncd.conf配置文件内容有错误\n\n7、错误七\n\nrsync: chown “”failed: Invalid argument (22)\n\n原因：权限无法复制，去掉同步权限的参数即可(这种情况多见于Linux向Windows的时候)\n\n8、错误八\n\n@ERROR: daemon security issue– contact admin\nrsync error: error starting client-server protocol (code 5) at main.c(1530)[sender=3.0.6]\n\n原因：同步的目录里面有软连接文件，需要服务器端的/etc/rsyncd.conf打开use chroot = yes掠过软连接文件。\n\nl  建立不需输入密码的链接\n\n这样就可以将其写入脚本和任务计划自动运行了\n\n1、第一种方案：指定密码文件\n\n    [root@abao ~]# touch/etc/pass#客户端上建立密码文件\n    \n    [root@abao ~]# vim /etc/pass #将账户“admin”密码写入\n    \n    [root@abao ~]# cat /etc/pass\n    \n    guobaobao！1314\n    \n    [root@abao ~]# chmod 600/etc/pass\n    \n    [root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/\n    \n    Password:\n    \n    @ERROR: auth failed on modulebackup\n    \n    rsync error: error startingclient-server protocol (code 5) at main.c(1503) [receiver=3.0.6]\n    \n    [root@abao ~]#\n    \n    [root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/ –password-file=/etc/pass #注意黑体部分指定密码文件\n    \n    receiving incremental filelist\n    \n    sent 57 bytes  received 106 bytes  326.00 bytes/sec\n    \n    total size is 1010  speedup is 6.20\n    \n2、第二种方案：在rsync服务器端不指定用户\n\n    [root@baobao ~]# vim/etc/rsyncd.conf   #服务器端配置文件注释掉下面认证两行\n    \n    #auth users=admin\n    \n    #secretsfile=/etc/rsyncd.secrets\n    \n    [root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/\n    \n    receiving incremental filelist\n    \n    sent 28 bytes  received 65 bytes  37.20 bytes/sec\n    \n    total size is 1010  speedup is 10.86\n    \n    或\n    \n    [root@abao ~]# rsync -av172.168.72.68::backup /backups/#不加账户默认是root\n    \n    receiving incremental filelist\n    \n    sent 28 bytes  received 65 bytes  186.00 bytes/sec\n    \n    total size is 1010  speedup is 10.86\n","source":"_posts/linux—SSH（二）Rsync备份.md","raw":"---\ntitle: linux—SSH（二）Rsync备份\ndate: 2016-09-02\ntags: ssh\ncategories: linux\n---\n一、Rsync软件介绍\n\nrsync从字面上的意思就是remote sync （远程同步）的意思，是类unix系统下的远程数据镜像备份工具，可以镜像保存整个目录树和文件系统，并保持原来文件的权限、时间、软硬链接等，此外它还支持匿名传输；Rsync不仅可以远程同步数据（类似于scp）还可以本地同步数据（类似于cp），但不同于cp或scp的是rsync不像cp/scp一样会覆盖以前的数据，Rsync使用所谓的“Rsync演算法”，这个算法在第一次连通完成时，会把整份文件传输一次，下一次就只传送二个文件之间不同的部份，因此速度相当快\n<!--more-->\n二、Rsync的传输方式（或工作模式）\n\nl  在本机直接运行拷贝本地文件（不使用冒号）\n\n命令格式为：rsync[OPTION]… SRC DEST。如下\n\n    [root@abao~]# rsync -av /etc /tmp\n    \nl  通过rsh或ssh的信道在server/client之间进行传输数据（使用一个冒号）\n\n需要登录到服务器上执行任务，并且需要输入账号的密码\n\n1、 将本地机器的内容拷贝到远程机器（目标路径中使用一个冒号）\n\n命令格式为：rsync[OPTION]… SRC [USER@]HOST:DEST。如下\n\n\n    [root@abao~]# rsync -av -e ssh /tmp axing@172.168.72.68:~\n\n2、 将远程机器的内容拷贝到本地机器（源路径中使用一个冒号）\n\n命令格式为：rsync[OPTION]… [USER@]HOST:SRC DEST。如下\n\n\n    [root@abao~]# rsync -av -e ssh axing@172.168.72.68:~ /tmp\n\nl  直接通过rsync的服务来传输（此时服务器端需要启动873端口，并且使用两个冒号）\n\n这种方式在远程主机上建立一个rsync的服务器，在服务器上配置好rsync的各种应用，然后本机作为rsync的一个客户端去连接远程的rsync服务器\n\n1、 从远程rsync服务器中拷贝文件到本地机（源路径中使用一个冒号）\n\n命令格式为：rsync[OPTION]… [USER@]HOST::模块名 本地位置。如下\n\n\n    [root@abao~]# rsync -av axing@172.168.72.68:：back /databack\n\n2、从本地机器拷贝文件到远程rsync服务器中（目标路径中使用一个冒号）\n\n命令格式为：rsync[OPTION]… SRC [USER@]HOST::DEST。如下\n\n    [root@abao~]# rsync -av /databack axing@172.168.72.68:：back\n    \n以上3中传输方式的差异在于有没有冒号“：”，本地端传输不需要冒号，通过rsh或ssh传输时需要一个冒号，而通过rsync传输时需要两个冒号\n\n三、Rsync的语法\n\n    -v： 查看模式可以列出很多信息包括文件名\n    \n    -r： 递归复制，可以针对目录来复制\n    \n    -u： 仅更新，如果目标文件比较新那么则保留新文件不会覆盖\n    \n    -l： 复制链接文件的属性\n    \n    -p： 连同属性一起复制\n    \n    -g： 保存源文件的属组\n    \n    -o： 保存源文件的属主\n    \n    -D： 保存源文件的设备属性\n    \n    -t： 保存原文件的时间参数\n    \n    -z： 在传输时加上压缩\n    \n    -e： 使用的协议，例如使用ssh通道就是-e ssh\n    \n    -a： 相当于-rlptgoD，是最常用的参数\n    \n    -L： 把SRC中软连接的目标文件给拷贝到DST.\n    \n    –delete：如果在DST增加文件了，而SRC当中没有这些文件，同步时会删除新增的文件\n    \n    –exclude=filename：  指定排除不需要传输的文件，等号后面跟文件名（如*.txt）\n    \n    –progress：  可以看到同步的过程状态，比如文件数量、文件传输速度等\n\n四、在本机直接运行拷贝本地文件实例\n\n    [root@abao ~]# rsync -av /etc/tmp#首次本地备份\n    \n    …………………………………………………………………\n    \n    sent 33899909 bytes  received 35626 bytes  5220851.54 bytes/sec\n    \n    total size is 33759697  speedup is 0.99\n    \n    [root@abao ~]# ll -d /tmp/etc/etc#两文件相同\n    \n    drwxr-xr-x. 126 root root12288 10月 10 08:23 /etc\n    \n    drwxr-xr-x. 126 root root12288 10月 10 08:23 /tmp/etc\n    \n    [root@abao ~]# rsync -av /etc/tmp#再次备份时只备份差异文件\n    \n    sending incremental file list\n    \n    sent 77528 bytes  received 293 bytes  155642.00 bytes/sec\n    \n    total size is 33759697  speedup is 433.81\n\n五、通过rsh或ssh的信道在server/client之间进行传输数据实例\n\n    [root@abao ~]# /etc/init.d/sshd restart\n    \n    停止 sshd：[确定]\n    \n    正在启动 sshd：[确定]\n    \nl  将本地机器的内容拷贝到远程机器\n\n    [root@abao ~]# rsync -av -e ssh /tmp admin@172.168.72.68:~\n    \n    admin@172.168.72.68’s password:   #需要输入账户密码\n    \n    …………………………………………………………………………\n    \n    sent 238637037 bytes received 60045 bytes  3819153.31bytes/sec\n    \n    total size is 238396030 speedup is 1.00\n\nl  将远程机器的内容拷贝到本地机器\n\n    [root@abao ~]# rsync -av -e ssh axing@172.168.72.68:~ /tmp\n    \n    axing@172.168.72.68’s password:   #需要输入账户密码\n    \n    receiving incremental file list\n    \n    axing/\n    \n    axing/.ICEauthority\n    \n    …………………………………………………………………\n    \n    sent 1732 bytes  received758924 bytes  80069.05 bytes/sec\n    \n    total size is 751474 speedup is 0.99\n    \n    [root@abao ~]# ll -d /tmp/axing\n    \n    drwx——. 27 500 500 4096 10月 10 08:23 /tmp/axing\n\nl  利用crontab通过ssh进行免密码异地备份脚本（常用）\n\n我们可以针对用户admin制作一个免密码登陆的ssh秘钥，这样以后异地备份系统就可以使用crontab自动备份了，前提是先根据下面（六、直接通过rsync的服务来传输实例）安装并设置好rsync\n\n1、ssh服务器端和客户端账户建立\n\n    [root@baobao ~]# mkdir /home/back; touch /home/back/wo#创建要备份的文件\n    \n    [root@baobao ~]# chmod -R 755 /home/back/\n    \n    [root@baobao ~]# useradd admin#先在ssh服务器端ssh账号\n    \n    [root@baobao ~]# passwd admin\n    \n    更改用户 admin 的密码 。\n    \n    新的 密码：\n    \n    重新输入新的 密码：\n    \n    passwd： 所有的身份验证令牌已经成功更新。\n    \n    [root@abao ~]# useradd admin  #客户端上建立ssh账号\n    \n    [root@abao ~]# passwd admin\n    \n    更改用户 admin 的密码 。\n    \n    新的 密码：\n    \n    重新输入新的 密码：\n    \n    passwd： 所有的身份验证令牌已经成功更新。\n\n2、客户端建立两把钥匙\n\n    [root@abao ~]# su – admin\n    \n    [admin@abao ~]$ ssh-keygen\n    \n    Generating public/private rsa key pair.\n    \n    Enter file in which to save the key (/home/admin/.ssh/id_rsa):\n    \n    Created directory ‘/home/admin/.ssh’.\n    \n    Enter passphrase (empty for no passphrase):\n    \n    Enter same passphrase again:\n    \n    Your identification has been saved in /home/admin/.ssh/id_rsa.\n    \n    Your public key has been saved in /home/admin/.ssh/id_rsa.pub.\n    \n    The key fingerprint is:\n    \n    61:01:c2:9b:26:00:0a:01:c9:a0:58:7e:38:f9:85:6c admin@abao\n    \n    The key’s randomart image is:\n    \n    +–[ RSA 2048]—-+\n    \n    |@o… …|\n    \n    |B+ +.o   .   |\n    \n    |+.= Eo. o|\n    \n    |  .=+. . .   |\n    \n    |   o.   S   |\n    \n    | |\n    \n    | |\n    \n    | |\n    \n    | |\n    \n    +—————–+\n    \n    [admin@abao ~]$ ls -ld ~/.ssh; ls -l ~/.ssh\n    \n    drwx——. 2 admin admin 4096 10月 10 09:21 /home/admin/.ssh\n    \n    总用量 8\n    \n    -rw——-. 1 admin admin 1675 10月 10 09:21 id_rsa\n    \n    -rw-r–r–. 1 admin admin 392 10月 10 09:21 id_rsa.pub\n\n3、将公钥文件数据上传到服务器\n\n    [admin@abao ~]$ scp ~/.ssh/id_rsa.pub admin@172.168.72.68:~#客户端上传公钥文件\n    \n    admin@172.168.72.68’s password:\n    \n    id_rsa.pub100%  3920.4KB/s   00:00\n\n4、将公钥放置到服务器端的正确目录与文件名（服务器上操作）\n\n    [root@baobao ~]# su – admin\n    \n    [admin@baobao ~]$ ls -ld .ssh\n    \n    ls: 无法访问.ssh: 没有那个文件或目录\n    \n    [admin@baobao ~]$ mkdir .ssh; chmod 700 .ssh #服务器上建立文件~/.ssh\n    \n    [admin@baobao ~]$ ls -ld .ssh\n    \n    drwx—— 2 admin admin 4096 10月 10 09:36 .ssh\n    \n    [admin@baobao ~]$ ls -l *pub\n    \n    -rw-r–r– 1 admin admin 392 10月 10 09:27 id_rsa.pub\n    \n    [admin@baobao ~]$ cat id_rsa.pub >> .ssh/authorized_keys\n    \n    [admin@baobao ~]$ chmod 644 .ssh/authorized_keys\n    \n    [admin@baobao ~]$ ls -l .ssh\n    \n    总用量 4\n    \n    -rw-r–r– 1 admin admin 392 10月 10 09:38 authorized_keys\n\n5、在客户端建立异地备份脚本\n\n    [root@abao ~]# mkdir /backups\n    \n    [root@abao ~]# chmod -R 755 /backups/\n    \n    [root@abao ~]# su – admin\n    \n    [admin@abao ~]$ mkdir ~/bin; vim ~/bin/backup.sh\n    \n    #!/bin/bash\n    \n    localdir=/backups\n    \n    remotedir=/home/back/\n    \n    remoteip=”172.168.72.68″\n    \n    [ -d ${localdir} ] || mkdir ${localdir}   #-d是判断是否有这个目录；符号“||”是逻辑或意思，左边为假时执行右边命令；小括号一般用作执行命令，而自定义变量一般用大括号括起来\n    \n    for dir in ${remotedir}\n    \n    do\n    \n    rsync -av -essh admin@${remoteip}:${dir} ${localdir}\n    \n    done\n    \n    [admin@abao ~]$ chmod 755 ~/bin/backup.sh\n    \n    [admin@abao ~]$ ls -ld /home/admin/bin/backup.sh\n    \n    -rwxrwxr-x. 1 admin admin 224 10月 11 08:49 /home/admin/bin/backup.sh\n    \n    [admin@abao ~]$ ~/bin/backup.sh   #执行脚本\n    \n    receiving incremental filelist\n    \n    sent 11 bytes  received 43 bytes  5.68 bytes/sec\n    \n    total size is 1010  speedup is 18.70\n    \n6、制作crontab计划任务\n\n    [root@abao ~]# crontab –e #每天的凌晨02:00异地备份服务器上的/etc /root /home目录到本地的/backups/下\n    0 2 * * * /home/admin/bin/backup.sh\n\n六、直接通过rsync的服务来传输实例\n\nl  创建用户账号和rsync配置文件\n\n    [root@baobao ~]# useraddadmin   #创建链接用户\n    \n    [root@baobao ~]# passwd admin\n    \n    更改用户 admin 的密码。\n    \n    新的 密码：\n    \n    重新输入新的 密码：\n    \n    passwd： 所有的身份验证令牌已经成功更新。\n    \n    [root@baobao ~]# mkdir /home/back   #创建要进行备份的目录或文件\n    \n    [root@baobao ~]# touch/home/back/guo\n    \n    [root@baobao ~]# vim/home/back/guo\n    \n    [root@baobao ~]# chmod -R 755/home/back/#设定要备份的目录或文件权限\n    \n    [root@baobao ~]# yum -yinstall xinetd\n    \n    [root@baobao ~]# yum -yinstall rsync#安装rsync\n    \n    [root@baobao ~]# yum -yinstall rsync#客户端也安装rsync\n    \n    [root@baobao ~]# touch/etc/rsyncd.conf  #默认该文件是没有的\n    \n    [root@baobao ~]# chmod 600/etc/rsyncd.conf  #修改配置文件权限\n\nl  Rsync服务器端配置文件设置\n\n配置文件时即时生效的，不用重启服务\n\n1、/etc/rsyncd.conf配置\n\n1)  全局参数配置\n\n    [root@baobao ~]# manrsyncd.conf   #查看说明文档看下面部分参数是yes/no还是true/false\n    \n    [root@baobao ~]# vim/etc/rsyncd.conf\n    \n    uid=root  #运行RSYNC守护进程的用户\n    \n    gid=root  #运行RSYNC守护进程的组\n    \n    use chroot=false  #不使用chroot\n    \n    max connections=8 #最大连接数是4\n    \n    pid file=/var/run/rsyncd.pid  #pid文件默认存放位置\n    \n    lock file=/var/run/rsync.lock #锁文件默认存放位置（锁住rsync正在操作的文件不让其他的程序对其进行写操作）\n    \n    log file=/var/log/rsyncd.log  #日志文件默认存放位置\n    \n    strict modes=true #是否检查口令文件的权限\n    port=873  #默认端口873\n    \n2)  模块参数配置(多台客户端需要设置多个模块)\n\n    [backup]   #认证的模块名，在client端需要指定\n    \n    path=/etc  #需要做备份的目录\n    \n    comment=This is backup #这个模块的注释信息\n    \n    list=true  #当用户查询该服务器上的可用模块时，该模块是被列出（true）还是被隐藏（false）\n    \n    max connections=6  #客户端最大连接数(默认0没限制)，模块里可以不设置\n    ignore errors  #可以忽略一些无关的IO错误\n    read only=false#“yes”只读客户端不能上传；“no”客户端可以上传\n    write only=false   #“yes”客户端不能下载；“no”客户端可以下载\n    \n    uid=root   #指定该模块传输文件时守护进程应该具有的uid\n    gid=root   #指定该模块传输文件时守护进程应该具有的gid\n    hosts allow=172.168.0.0/16 #允许连接的主机（“*”充许任何主机连接），多个主机用“，”分开；多个网段用空格隔开\n    hosts deny=192.168.10.0/32 #禁止连接的主机或网段\n    \n    auth users=admin   #登陆系统使用的用户名（系统必须存在的用户），没有默认为匿名\n    secrets file= /etc/rsyncd.secrets #登陆用户的密码文件（需要自己生成）\n\n2、rsync server启动文件配置\n\n    [root@baobao ~]# vim /etc/xinetd.d/rsync#只修改disable = no即可\n    \n    # default: off\n    \n    # description: The rsyncserver is a good addition to an ftp server, as it \\\n    \n    #   allows crc checksumming etc.\n    \n    service rsync\n    \n    {\n    \n    disable = no\n    \n    flags   = IPv6\n    \n    socket_type = stream\n    \n    wait= no\n    \n    user= root\n    \n    server  = /usr/bin/rsync\n    \n    server_args = –daemon\n    \n    log_on_failure  += USERID\n    \n    }\n    \n    [root@baobao ~]# chkconfigrsync on\n    \nl  创建密码文件、欢迎信息\n\n1、生成rsync密码文件并设置该文件相应权限\n    [root@baobao ~]# touch /etc/rsyncd.secrets\n    \n    [root@baobao ~]# vim /etc/rsyncd.secrets\n    \n    admin:guobaobao!1314#格式为“账号：密码”且一行一个\n    [root@baobao ~]# chown root.root /etc/rsyncd.secrets\n    \n    [root@baobao ~]# chmod 600 /etc/rsyncd.secrets\n    \n    因为rsyncd.secrets存储了rsync服务的用户名和密码，所以要将rsyncd.secrets设置为root拥有, 且权限为600\n\n2、配置欢迎信息rsyncd.motd（可有可无）\n    [root@baobao ~]# vim /etc/rsyncd.motd   #rsyncd.motd记录了rsync服务的欢迎信息\n    \n    Welcome to use the rsyncservices!\n    [root@baobao ~]# service xinetd restart\n    \n    停止 xinetd：  [确定]\n    \n    正在启动 xinetd：  [确定]\n    \nl  Rsync的启动与开机启动\n\n1、Rsync服务端启动\n\n1)  载入配置\n\n    [root@baobao ~]# rsync –daemon–config=/etc/rsyncd.conf   #载入配置并启动\n    \n    或\n    \n    [root@baobao ~]# /etc/rc.d/init.d/xinetdreload\n    \n    重新载入配置： [确定]\n\n2)  重启rsync\n\n    [root@baobao ~]# /usr/bin/rsync –daemon\n    \n    failed to create pid file/var/run/rsyncd.pid: File exists\n    \n    或\n    \n    [root@baobao ~]# /etc/rc.d/init.d/xinetdrestart#重新启动\n    \n    停止 xinetd：  [确定]\n    \n    正在启动 xinetd：  [确定]\n\n3)  检查rsync是否启动\n\n    [root@baobao ~]# netstat -lnp | grep 873#由超级进程启动\n    \n    tcp   0  0 0.0.0.0:8730.0.0.0:*LISTEN  3133/rsync\n    \n    tcp   0  0 :::873 :::*LISTEN 3133/rsync\n    \n    或\n    \n    [root@baobao ~]# netstat -a |grep rsync\n    \n    tcp0  0*:rsync *:* LISTEN\n    \n    或\n    \n    [root@baobao ~]# lsof -i:873 #端口没有被占用\n    \n    COMMAND  PID USER  FD   TYPE DEVICE SIZE/OFF NODENAME\n    \n    rsync   3133 root   4u  IPv4  22973 0t0  TCP *:rsync (LISTEN)\n    \n    rsync   3133 root   5u  IPv6  22974 0t0  TCP *:rsync (LISTEN)\n\n4)  查看rsync日志\n\n    [root@baobao ~]# cat /var/log/rsyncd.log #查看rsync日志\n    \n    2014/10/14 15:29:13 [35681] rsyncdversion 3.0.6 starting, listening on port 873\n    \n2、将rsync加入开机启动\n\n    [root@baobao ~]# echo”/usr/bin/rsync –daemon –config=/etc/rsyncd.conf”>>/etc/rc.local\n    \n    [root@baobao ~]# cat/etc/rc.local\n    \n    #!/bin/sh\n    \n    #\n    \n    # This script will beexecuted *after* all the other init scripts.\n    \n    # You can put your owninitialization stuff in here if you don’t\n    \n    # want to do the full Sys Vstyle init stuff.\n    \n    touch /var/lock/subsys/local\n    \n    /usr/bin/rsync –daemon–config=/etc/rsyncd.conf\n\nl  Rsync服务器端配置防火墙\n\n1、防火墙设置\n\n    [root@baobao ~]# iptables -F\n    \n    [root@baobao ~]# iptables -X\n    \n    [root@baobao ~]# iptables -Z\n    \n    [root@baobao ~]# iptables -AINPUT -i eth0 -s 172.168.0.0/16 -p tcp –dport 22 -j ACCEPT\n    \n    [root@baobao ~]# iptables -L\n    \n    Chain INPUT (policy ACCEPT)\n    \n    target prot opt source   destination\n    \n    ACCEPT tcp —  ACA80000.ipt.aol.com/16  anywheretcp dpt:ssh\n    \n    Chain FORWARD (policy ACCEPT)\n    \n    target prot opt source   destination\n    \n    Chain OUTPUT (policy ACCEPT)\n    \n    target prot opt source   destination\n    \n    [root@baobao ~]#/etc/init.d/iptables save\n    \n    iptables：将防火墙规则保存到 /etc/sysconfig/iptables： [确定]\n    \n    [root@baobao ~]#/etc/init.d/iptables restart\n    \n    iptables：清除防火墙规则：[确定]\n    \n    iptables：将链设置为政策 ACCEPT：filter[确定]\n    \n    iptables：正在卸载模块：  [确定]\n    \n    iptables：应用防火墙规则：[确定]\n\n2、selinux设置\n\n\n    [root@baobao ~]# setenforce 0\n\nl  客户端测试\n\n    [root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/\n    \n    Password:\n    \n    receiving incremental filelist\n    \n    created directory /backups\n    \n    ./\n    \n    guo\n    \n    sent 79 bytes  received 1162 bytes  275.78 bytes/sec\n    \n    total size is 1010  speedup is 0.81\n\n可以看到这里还是需要输入密码，这样同样也不能写入脚本中自动执行\n\nl  常见问题处理\n\n1、错误一\n\n@ERROR: chroot failed\n\nrsync error: error startingclient-server protocol (code 5) at main.c(1522) [receiver=3.0.3]\n\n原因：服务器端的目录不存在或无权限\n\n2、错误二\n\n@ERROR: auth failed on moduletee\n\nrsync error: error startingclient-server protocol (code 5) at main.c(1522) [receiver=3.0.3]\n\n原因：服务器端该模块（tee）需要验证用户名密码，但客户端没有提供正确的用户名密码，认证失败。\n\n3、错误三\n\n@ERROR: Unknown module‘tee_nonexists’\n\nrsync error: error startingclient-server protocol (code 5) at main.c(1522) [receiver=3.0.3]\n\n原因：服务器不存在指定模块\n\n4、错误四\n\npassword file must not beother-accessible\n\ncontinuing without passwordfile\n\nPassword:\n\n原因：这是因为rsyncd.pwdrsyncd.secrets的权限不对，应该设置为600\n\n5、错误五\n\nrsync: failed to connect to218.107.243.2: No route to host (113)\n\nrsync error: error in socketIO (code 10) at clientserver.c(104) [receiver=2.6.9]\n\n原因：对方没开机、防火墙阻挡、通过的网络上有防火墙阻挡，都有可能\n\n6、错误六\n\nrsync error: error startingclient-server protocol (code 5) at main.c(1524) [Receiver=3.0.7]\n\n原因：/etc/rsyncd.conf配置文件内容有错误\n\n7、错误七\n\nrsync: chown “”failed: Invalid argument (22)\n\n原因：权限无法复制，去掉同步权限的参数即可(这种情况多见于Linux向Windows的时候)\n\n8、错误八\n\n@ERROR: daemon security issue– contact admin\nrsync error: error starting client-server protocol (code 5) at main.c(1530)[sender=3.0.6]\n\n原因：同步的目录里面有软连接文件，需要服务器端的/etc/rsyncd.conf打开use chroot = yes掠过软连接文件。\n\nl  建立不需输入密码的链接\n\n这样就可以将其写入脚本和任务计划自动运行了\n\n1、第一种方案：指定密码文件\n\n    [root@abao ~]# touch/etc/pass#客户端上建立密码文件\n    \n    [root@abao ~]# vim /etc/pass #将账户“admin”密码写入\n    \n    [root@abao ~]# cat /etc/pass\n    \n    guobaobao！1314\n    \n    [root@abao ~]# chmod 600/etc/pass\n    \n    [root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/\n    \n    Password:\n    \n    @ERROR: auth failed on modulebackup\n    \n    rsync error: error startingclient-server protocol (code 5) at main.c(1503) [receiver=3.0.6]\n    \n    [root@abao ~]#\n    \n    [root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/ –password-file=/etc/pass #注意黑体部分指定密码文件\n    \n    receiving incremental filelist\n    \n    sent 57 bytes  received 106 bytes  326.00 bytes/sec\n    \n    total size is 1010  speedup is 6.20\n    \n2、第二种方案：在rsync服务器端不指定用户\n\n    [root@baobao ~]# vim/etc/rsyncd.conf   #服务器端配置文件注释掉下面认证两行\n    \n    #auth users=admin\n    \n    #secretsfile=/etc/rsyncd.secrets\n    \n    [root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/\n    \n    receiving incremental filelist\n    \n    sent 28 bytes  received 65 bytes  37.20 bytes/sec\n    \n    total size is 1010  speedup is 10.86\n    \n    或\n    \n    [root@abao ~]# rsync -av172.168.72.68::backup /backups/#不加账户默认是root\n    \n    receiving incremental filelist\n    \n    sent 28 bytes  received 65 bytes  186.00 bytes/sec\n    \n    total size is 1010  speedup is 10.86\n","slug":"linux—SSH（二）Rsync备份","published":1,"updated":"2019-06-18T08:07:01.115Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9skt0018hcb7qm7ja1gp","content":"<p>一、Rsync软件介绍</p>\n<p>rsync从字面上的意思就是remote sync （远程同步）的意思，是类unix系统下的远程数据镜像备份工具，可以镜像保存整个目录树和文件系统，并保持原来文件的权限、时间、软硬链接等，此外它还支持匿名传输；Rsync不仅可以远程同步数据（类似于scp）还可以本地同步数据（类似于cp），但不同于cp或scp的是rsync不像cp/scp一样会覆盖以前的数据，Rsync使用所谓的“Rsync演算法”，这个算法在第一次连通完成时，会把整份文件传输一次，下一次就只传送二个文件之间不同的部份，因此速度相当快<br><a id=\"more\"></a><br>二、Rsync的传输方式（或工作模式）</p>\n<p>l  在本机直接运行拷贝本地文件（不使用冒号）</p>\n<p>命令格式为：rsync[OPTION]… SRC DEST。如下</p>\n<pre><code>[root@abao~]# rsync -av /etc /tmp\n</code></pre><p>l  通过rsh或ssh的信道在server/client之间进行传输数据（使用一个冒号）</p>\n<p>需要登录到服务器上执行任务，并且需要输入账号的密码</p>\n<p>1、 将本地机器的内容拷贝到远程机器（目标路径中使用一个冒号）</p>\n<p>命令格式为：rsync[OPTION]… SRC [USER@]HOST:DEST。如下</p>\n<pre><code>[root@abao~]# rsync -av -e ssh /tmp axing@172.168.72.68:~\n</code></pre><p>2、 将远程机器的内容拷贝到本地机器（源路径中使用一个冒号）</p>\n<p>命令格式为：rsync[OPTION]… [USER@]HOST:SRC DEST。如下</p>\n<pre><code>[root@abao~]# rsync -av -e ssh axing@172.168.72.68:~ /tmp\n</code></pre><p>l  直接通过rsync的服务来传输（此时服务器端需要启动873端口，并且使用两个冒号）</p>\n<p>这种方式在远程主机上建立一个rsync的服务器，在服务器上配置好rsync的各种应用，然后本机作为rsync的一个客户端去连接远程的rsync服务器</p>\n<p>1、 从远程rsync服务器中拷贝文件到本地机（源路径中使用一个冒号）</p>\n<p>命令格式为：rsync[OPTION]… [USER@]HOST::模块名 本地位置。如下</p>\n<pre><code>[root@abao~]# rsync -av axing@172.168.72.68:：back /databack\n</code></pre><p>2、从本地机器拷贝文件到远程rsync服务器中（目标路径中使用一个冒号）</p>\n<p>命令格式为：rsync[OPTION]… SRC [USER@]HOST::DEST。如下</p>\n<pre><code>[root@abao~]# rsync -av /databack axing@172.168.72.68:：back\n</code></pre><p>以上3中传输方式的差异在于有没有冒号“：”，本地端传输不需要冒号，通过rsh或ssh传输时需要一个冒号，而通过rsync传输时需要两个冒号</p>\n<p>三、Rsync的语法</p>\n<pre><code>-v： 查看模式可以列出很多信息包括文件名\n\n-r： 递归复制，可以针对目录来复制\n\n-u： 仅更新，如果目标文件比较新那么则保留新文件不会覆盖\n\n-l： 复制链接文件的属性\n\n-p： 连同属性一起复制\n\n-g： 保存源文件的属组\n\n-o： 保存源文件的属主\n\n-D： 保存源文件的设备属性\n\n-t： 保存原文件的时间参数\n\n-z： 在传输时加上压缩\n\n-e： 使用的协议，例如使用ssh通道就是-e ssh\n\n-a： 相当于-rlptgoD，是最常用的参数\n\n-L： 把SRC中软连接的目标文件给拷贝到DST.\n\n–delete：如果在DST增加文件了，而SRC当中没有这些文件，同步时会删除新增的文件\n\n–exclude=filename：  指定排除不需要传输的文件，等号后面跟文件名（如*.txt）\n\n–progress：  可以看到同步的过程状态，比如文件数量、文件传输速度等\n</code></pre><p>四、在本机直接运行拷贝本地文件实例</p>\n<pre><code>[root@abao ~]# rsync -av /etc/tmp#首次本地备份\n\n…………………………………………………………………\n\nsent 33899909 bytes  received 35626 bytes  5220851.54 bytes/sec\n\ntotal size is 33759697  speedup is 0.99\n\n[root@abao ~]# ll -d /tmp/etc/etc#两文件相同\n\ndrwxr-xr-x. 126 root root12288 10月 10 08:23 /etc\n\ndrwxr-xr-x. 126 root root12288 10月 10 08:23 /tmp/etc\n\n[root@abao ~]# rsync -av /etc/tmp#再次备份时只备份差异文件\n\nsending incremental file list\n\nsent 77528 bytes  received 293 bytes  155642.00 bytes/sec\n\ntotal size is 33759697  speedup is 433.81\n</code></pre><p>五、通过rsh或ssh的信道在server/client之间进行传输数据实例</p>\n<pre><code>[root@abao ~]# /etc/init.d/sshd restart\n\n停止 sshd：[确定]\n\n正在启动 sshd：[确定]\n</code></pre><p>l  将本地机器的内容拷贝到远程机器</p>\n<pre><code>[root@abao ~]# rsync -av -e ssh /tmp admin@172.168.72.68:~\n\nadmin@172.168.72.68’s password:   #需要输入账户密码\n\n…………………………………………………………………………\n\nsent 238637037 bytes received 60045 bytes  3819153.31bytes/sec\n\ntotal size is 238396030 speedup is 1.00\n</code></pre><p>l  将远程机器的内容拷贝到本地机器</p>\n<pre><code>[root@abao ~]# rsync -av -e ssh axing@172.168.72.68:~ /tmp\n\naxing@172.168.72.68’s password:   #需要输入账户密码\n\nreceiving incremental file list\n\naxing/\n\naxing/.ICEauthority\n\n…………………………………………………………………\n\nsent 1732 bytes  received758924 bytes  80069.05 bytes/sec\n\ntotal size is 751474 speedup is 0.99\n\n[root@abao ~]# ll -d /tmp/axing\n\ndrwx——. 27 500 500 4096 10月 10 08:23 /tmp/axing\n</code></pre><p>l  利用crontab通过ssh进行免密码异地备份脚本（常用）</p>\n<p>我们可以针对用户admin制作一个免密码登陆的ssh秘钥，这样以后异地备份系统就可以使用crontab自动备份了，前提是先根据下面（六、直接通过rsync的服务来传输实例）安装并设置好rsync</p>\n<p>1、ssh服务器端和客户端账户建立</p>\n<pre><code>[root@baobao ~]# mkdir /home/back; touch /home/back/wo#创建要备份的文件\n\n[root@baobao ~]# chmod -R 755 /home/back/\n\n[root@baobao ~]# useradd admin#先在ssh服务器端ssh账号\n\n[root@baobao ~]# passwd admin\n\n更改用户 admin 的密码 。\n\n新的 密码：\n\n重新输入新的 密码：\n\npasswd： 所有的身份验证令牌已经成功更新。\n\n[root@abao ~]# useradd admin  #客户端上建立ssh账号\n\n[root@abao ~]# passwd admin\n\n更改用户 admin 的密码 。\n\n新的 密码：\n\n重新输入新的 密码：\n\npasswd： 所有的身份验证令牌已经成功更新。\n</code></pre><p>2、客户端建立两把钥匙</p>\n<pre><code>[root@abao ~]# su – admin\n\n[admin@abao ~]$ ssh-keygen\n\nGenerating public/private rsa key pair.\n\nEnter file in which to save the key (/home/admin/.ssh/id_rsa):\n\nCreated directory ‘/home/admin/.ssh’.\n\nEnter passphrase (empty for no passphrase):\n\nEnter same passphrase again:\n\nYour identification has been saved in /home/admin/.ssh/id_rsa.\n\nYour public key has been saved in /home/admin/.ssh/id_rsa.pub.\n\nThe key fingerprint is:\n\n61:01:c2:9b:26:00:0a:01:c9:a0:58:7e:38:f9:85:6c admin@abao\n\nThe key’s randomart image is:\n\n+–[ RSA 2048]—-+\n\n|@o… …|\n\n|B+ +.o   .   |\n\n|+.= Eo. o|\n\n|  .=+. . .   |\n\n|   o.   S   |\n\n| |\n\n| |\n\n| |\n\n| |\n\n+—————–+\n\n[admin@abao ~]$ ls -ld ~/.ssh; ls -l ~/.ssh\n\ndrwx——. 2 admin admin 4096 10月 10 09:21 /home/admin/.ssh\n\n总用量 8\n\n-rw——-. 1 admin admin 1675 10月 10 09:21 id_rsa\n\n-rw-r–r–. 1 admin admin 392 10月 10 09:21 id_rsa.pub\n</code></pre><p>3、将公钥文件数据上传到服务器</p>\n<pre><code>[admin@abao ~]$ scp ~/.ssh/id_rsa.pub admin@172.168.72.68:~#客户端上传公钥文件\n\nadmin@172.168.72.68’s password:\n\nid_rsa.pub100%  3920.4KB/s   00:00\n</code></pre><p>4、将公钥放置到服务器端的正确目录与文件名（服务器上操作）</p>\n<pre><code>[root@baobao ~]# su – admin\n\n[admin@baobao ~]$ ls -ld .ssh\n\nls: 无法访问.ssh: 没有那个文件或目录\n\n[admin@baobao ~]$ mkdir .ssh; chmod 700 .ssh #服务器上建立文件~/.ssh\n\n[admin@baobao ~]$ ls -ld .ssh\n\ndrwx—— 2 admin admin 4096 10月 10 09:36 .ssh\n\n[admin@baobao ~]$ ls -l *pub\n\n-rw-r–r– 1 admin admin 392 10月 10 09:27 id_rsa.pub\n\n[admin@baobao ~]$ cat id_rsa.pub &gt;&gt; .ssh/authorized_keys\n\n[admin@baobao ~]$ chmod 644 .ssh/authorized_keys\n\n[admin@baobao ~]$ ls -l .ssh\n\n总用量 4\n\n-rw-r–r– 1 admin admin 392 10月 10 09:38 authorized_keys\n</code></pre><p>5、在客户端建立异地备份脚本</p>\n<pre><code>[root@abao ~]# mkdir /backups\n\n[root@abao ~]# chmod -R 755 /backups/\n\n[root@abao ~]# su – admin\n\n[admin@abao ~]$ mkdir ~/bin; vim ~/bin/backup.sh\n\n#!/bin/bash\n\nlocaldir=/backups\n\nremotedir=/home/back/\n\nremoteip=”172.168.72.68″\n\n[ -d ${localdir} ] || mkdir ${localdir}   #-d是判断是否有这个目录；符号“||”是逻辑或意思，左边为假时执行右边命令；小括号一般用作执行命令，而自定义变量一般用大括号括起来\n\nfor dir in ${remotedir}\n\ndo\n\nrsync -av -essh admin@${remoteip}:${dir} ${localdir}\n\ndone\n\n[admin@abao ~]$ chmod 755 ~/bin/backup.sh\n\n[admin@abao ~]$ ls -ld /home/admin/bin/backup.sh\n\n-rwxrwxr-x. 1 admin admin 224 10月 11 08:49 /home/admin/bin/backup.sh\n\n[admin@abao ~]$ ~/bin/backup.sh   #执行脚本\n\nreceiving incremental filelist\n\nsent 11 bytes  received 43 bytes  5.68 bytes/sec\n\ntotal size is 1010  speedup is 18.70\n</code></pre><p>6、制作crontab计划任务</p>\n<pre><code>[root@abao ~]# crontab –e #每天的凌晨02:00异地备份服务器上的/etc /root /home目录到本地的/backups/下\n0 2 * * * /home/admin/bin/backup.sh\n</code></pre><p>六、直接通过rsync的服务来传输实例</p>\n<p>l  创建用户账号和rsync配置文件</p>\n<pre><code>[root@baobao ~]# useraddadmin   #创建链接用户\n\n[root@baobao ~]# passwd admin\n\n更改用户 admin 的密码。\n\n新的 密码：\n\n重新输入新的 密码：\n\npasswd： 所有的身份验证令牌已经成功更新。\n\n[root@baobao ~]# mkdir /home/back   #创建要进行备份的目录或文件\n\n[root@baobao ~]# touch/home/back/guo\n\n[root@baobao ~]# vim/home/back/guo\n\n[root@baobao ~]# chmod -R 755/home/back/#设定要备份的目录或文件权限\n\n[root@baobao ~]# yum -yinstall xinetd\n\n[root@baobao ~]# yum -yinstall rsync#安装rsync\n\n[root@baobao ~]# yum -yinstall rsync#客户端也安装rsync\n\n[root@baobao ~]# touch/etc/rsyncd.conf  #默认该文件是没有的\n\n[root@baobao ~]# chmod 600/etc/rsyncd.conf  #修改配置文件权限\n</code></pre><p>l  Rsync服务器端配置文件设置</p>\n<p>配置文件时即时生效的，不用重启服务</p>\n<p>1、/etc/rsyncd.conf配置</p>\n<p>1)  全局参数配置</p>\n<pre><code>[root@baobao ~]# manrsyncd.conf   #查看说明文档看下面部分参数是yes/no还是true/false\n\n[root@baobao ~]# vim/etc/rsyncd.conf\n\nuid=root  #运行RSYNC守护进程的用户\n\ngid=root  #运行RSYNC守护进程的组\n\nuse chroot=false  #不使用chroot\n\nmax connections=8 #最大连接数是4\n\npid file=/var/run/rsyncd.pid  #pid文件默认存放位置\n\nlock file=/var/run/rsync.lock #锁文件默认存放位置（锁住rsync正在操作的文件不让其他的程序对其进行写操作）\n\nlog file=/var/log/rsyncd.log  #日志文件默认存放位置\n\nstrict modes=true #是否检查口令文件的权限\nport=873  #默认端口873\n</code></pre><p>2)  模块参数配置(多台客户端需要设置多个模块)</p>\n<pre><code>[backup]   #认证的模块名，在client端需要指定\n\npath=/etc  #需要做备份的目录\n\ncomment=This is backup #这个模块的注释信息\n\nlist=true  #当用户查询该服务器上的可用模块时，该模块是被列出（true）还是被隐藏（false）\n\nmax connections=6  #客户端最大连接数(默认0没限制)，模块里可以不设置\nignore errors  #可以忽略一些无关的IO错误\nread only=false#“yes”只读客户端不能上传；“no”客户端可以上传\nwrite only=false   #“yes”客户端不能下载；“no”客户端可以下载\n\nuid=root   #指定该模块传输文件时守护进程应该具有的uid\ngid=root   #指定该模块传输文件时守护进程应该具有的gid\nhosts allow=172.168.0.0/16 #允许连接的主机（“*”充许任何主机连接），多个主机用“，”分开；多个网段用空格隔开\nhosts deny=192.168.10.0/32 #禁止连接的主机或网段\n\nauth users=admin   #登陆系统使用的用户名（系统必须存在的用户），没有默认为匿名\nsecrets file= /etc/rsyncd.secrets #登陆用户的密码文件（需要自己生成）\n</code></pre><p>2、rsync server启动文件配置</p>\n<pre><code>[root@baobao ~]# vim /etc/xinetd.d/rsync#只修改disable = no即可\n\n# default: off\n\n# description: The rsyncserver is a good addition to an ftp server, as it \\\n\n#   allows crc checksumming etc.\n\nservice rsync\n\n{\n\ndisable = no\n\nflags   = IPv6\n\nsocket_type = stream\n\nwait= no\n\nuser= root\n\nserver  = /usr/bin/rsync\n\nserver_args = –daemon\n\nlog_on_failure  += USERID\n\n}\n\n[root@baobao ~]# chkconfigrsync on\n</code></pre><p>l  创建密码文件、欢迎信息</p>\n<p>1、生成rsync密码文件并设置该文件相应权限<br>    [root@baobao ~]# touch /etc/rsyncd.secrets</p>\n<pre><code>[root@baobao ~]# vim /etc/rsyncd.secrets\n\nadmin:guobaobao!1314#格式为“账号：密码”且一行一个\n[root@baobao ~]# chown root.root /etc/rsyncd.secrets\n\n[root@baobao ~]# chmod 600 /etc/rsyncd.secrets\n\n因为rsyncd.secrets存储了rsync服务的用户名和密码，所以要将rsyncd.secrets设置为root拥有, 且权限为600\n</code></pre><p>2、配置欢迎信息rsyncd.motd（可有可无）<br>    [root@baobao ~]# vim /etc/rsyncd.motd   #rsyncd.motd记录了rsync服务的欢迎信息</p>\n<pre><code>Welcome to use the rsyncservices!\n[root@baobao ~]# service xinetd restart\n\n停止 xinetd：  [确定]\n\n正在启动 xinetd：  [确定]\n</code></pre><p>l  Rsync的启动与开机启动</p>\n<p>1、Rsync服务端启动</p>\n<p>1)  载入配置</p>\n<pre><code>[root@baobao ~]# rsync –daemon–config=/etc/rsyncd.conf   #载入配置并启动\n\n或\n\n[root@baobao ~]# /etc/rc.d/init.d/xinetdreload\n\n重新载入配置： [确定]\n</code></pre><p>2)  重启rsync</p>\n<pre><code>[root@baobao ~]# /usr/bin/rsync –daemon\n\nfailed to create pid file/var/run/rsyncd.pid: File exists\n\n或\n\n[root@baobao ~]# /etc/rc.d/init.d/xinetdrestart#重新启动\n\n停止 xinetd：  [确定]\n\n正在启动 xinetd：  [确定]\n</code></pre><p>3)  检查rsync是否启动</p>\n<pre><code>[root@baobao ~]# netstat -lnp | grep 873#由超级进程启动\n\ntcp   0  0 0.0.0.0:8730.0.0.0:*LISTEN  3133/rsync\n\ntcp   0  0 :::873 :::*LISTEN 3133/rsync\n\n或\n\n[root@baobao ~]# netstat -a |grep rsync\n\ntcp0  0*:rsync *:* LISTEN\n\n或\n\n[root@baobao ~]# lsof -i:873 #端口没有被占用\n\nCOMMAND  PID USER  FD   TYPE DEVICE SIZE/OFF NODENAME\n\nrsync   3133 root   4u  IPv4  22973 0t0  TCP *:rsync (LISTEN)\n\nrsync   3133 root   5u  IPv6  22974 0t0  TCP *:rsync (LISTEN)\n</code></pre><p>4)  查看rsync日志</p>\n<pre><code>[root@baobao ~]# cat /var/log/rsyncd.log #查看rsync日志\n\n2014/10/14 15:29:13 [35681] rsyncdversion 3.0.6 starting, listening on port 873\n</code></pre><p>2、将rsync加入开机启动</p>\n<pre><code>[root@baobao ~]# echo”/usr/bin/rsync –daemon –config=/etc/rsyncd.conf”&gt;&gt;/etc/rc.local\n\n[root@baobao ~]# cat/etc/rc.local\n\n#!/bin/sh\n\n#\n\n# This script will beexecuted *after* all the other init scripts.\n\n# You can put your owninitialization stuff in here if you don’t\n\n# want to do the full Sys Vstyle init stuff.\n\ntouch /var/lock/subsys/local\n\n/usr/bin/rsync –daemon–config=/etc/rsyncd.conf\n</code></pre><p>l  Rsync服务器端配置防火墙</p>\n<p>1、防火墙设置</p>\n<pre><code>[root@baobao ~]# iptables -F\n\n[root@baobao ~]# iptables -X\n\n[root@baobao ~]# iptables -Z\n\n[root@baobao ~]# iptables -AINPUT -i eth0 -s 172.168.0.0/16 -p tcp –dport 22 -j ACCEPT\n\n[root@baobao ~]# iptables -L\n\nChain INPUT (policy ACCEPT)\n\ntarget prot opt source   destination\n\nACCEPT tcp —  ACA80000.ipt.aol.com/16  anywheretcp dpt:ssh\n\nChain FORWARD (policy ACCEPT)\n\ntarget prot opt source   destination\n\nChain OUTPUT (policy ACCEPT)\n\ntarget prot opt source   destination\n\n[root@baobao ~]#/etc/init.d/iptables save\n\niptables：将防火墙规则保存到 /etc/sysconfig/iptables： [确定]\n\n[root@baobao ~]#/etc/init.d/iptables restart\n\niptables：清除防火墙规则：[确定]\n\niptables：将链设置为政策 ACCEPT：filter[确定]\n\niptables：正在卸载模块：  [确定]\n\niptables：应用防火墙规则：[确定]\n</code></pre><p>2、selinux设置</p>\n<pre><code>[root@baobao ~]# setenforce 0\n</code></pre><p>l  客户端测试</p>\n<pre><code>[root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/\n\nPassword:\n\nreceiving incremental filelist\n\ncreated directory /backups\n\n./\n\nguo\n\nsent 79 bytes  received 1162 bytes  275.78 bytes/sec\n\ntotal size is 1010  speedup is 0.81\n</code></pre><p>可以看到这里还是需要输入密码，这样同样也不能写入脚本中自动执行</p>\n<p>l  常见问题处理</p>\n<p>1、错误一</p>\n<p>@ERROR: chroot failed</p>\n<p>rsync error: error startingclient-server protocol (code 5) at main.c(1522) [receiver=3.0.3]</p>\n<p>原因：服务器端的目录不存在或无权限</p>\n<p>2、错误二</p>\n<p>@ERROR: auth failed on moduletee</p>\n<p>rsync error: error startingclient-server protocol (code 5) at main.c(1522) [receiver=3.0.3]</p>\n<p>原因：服务器端该模块（tee）需要验证用户名密码，但客户端没有提供正确的用户名密码，认证失败。</p>\n<p>3、错误三</p>\n<p>@ERROR: Unknown module‘tee_nonexists’</p>\n<p>rsync error: error startingclient-server protocol (code 5) at main.c(1522) [receiver=3.0.3]</p>\n<p>原因：服务器不存在指定模块</p>\n<p>4、错误四</p>\n<p>password file must not beother-accessible</p>\n<p>continuing without passwordfile</p>\n<p>Password:</p>\n<p>原因：这是因为rsyncd.pwdrsyncd.secrets的权限不对，应该设置为600</p>\n<p>5、错误五</p>\n<p>rsync: failed to connect to218.107.243.2: No route to host (113)</p>\n<p>rsync error: error in socketIO (code 10) at clientserver.c(104) [receiver=2.6.9]</p>\n<p>原因：对方没开机、防火墙阻挡、通过的网络上有防火墙阻挡，都有可能</p>\n<p>6、错误六</p>\n<p>rsync error: error startingclient-server protocol (code 5) at main.c(1524) [Receiver=3.0.7]</p>\n<p>原因：/etc/rsyncd.conf配置文件内容有错误</p>\n<p>7、错误七</p>\n<p>rsync: chown “”failed: Invalid argument (22)</p>\n<p>原因：权限无法复制，去掉同步权限的参数即可(这种情况多见于Linux向Windows的时候)</p>\n<p>8、错误八</p>\n<p>@ERROR: daemon security issue– contact admin<br>rsync error: error starting client-server protocol (code 5) at main.c(1530)[sender=3.0.6]</p>\n<p>原因：同步的目录里面有软连接文件，需要服务器端的/etc/rsyncd.conf打开use chroot = yes掠过软连接文件。</p>\n<p>l  建立不需输入密码的链接</p>\n<p>这样就可以将其写入脚本和任务计划自动运行了</p>\n<p>1、第一种方案：指定密码文件</p>\n<pre><code>[root@abao ~]# touch/etc/pass#客户端上建立密码文件\n\n[root@abao ~]# vim /etc/pass #将账户“admin”密码写入\n\n[root@abao ~]# cat /etc/pass\n\nguobaobao！1314\n\n[root@abao ~]# chmod 600/etc/pass\n\n[root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/\n\nPassword:\n\n@ERROR: auth failed on modulebackup\n\nrsync error: error startingclient-server protocol (code 5) at main.c(1503) [receiver=3.0.6]\n\n[root@abao ~]#\n\n[root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/ –password-file=/etc/pass #注意黑体部分指定密码文件\n\nreceiving incremental filelist\n\nsent 57 bytes  received 106 bytes  326.00 bytes/sec\n\ntotal size is 1010  speedup is 6.20\n</code></pre><p>2、第二种方案：在rsync服务器端不指定用户</p>\n<pre><code>[root@baobao ~]# vim/etc/rsyncd.conf   #服务器端配置文件注释掉下面认证两行\n\n#auth users=admin\n\n#secretsfile=/etc/rsyncd.secrets\n\n[root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/\n\nreceiving incremental filelist\n\nsent 28 bytes  received 65 bytes  37.20 bytes/sec\n\ntotal size is 1010  speedup is 10.86\n\n或\n\n[root@abao ~]# rsync -av172.168.72.68::backup /backups/#不加账户默认是root\n\nreceiving incremental filelist\n\nsent 28 bytes  received 65 bytes  186.00 bytes/sec\n\ntotal size is 1010  speedup is 10.86\n</code></pre>","site":{"data":{}},"excerpt":"<p>一、Rsync软件介绍</p>\n<p>rsync从字面上的意思就是remote sync （远程同步）的意思，是类unix系统下的远程数据镜像备份工具，可以镜像保存整个目录树和文件系统，并保持原来文件的权限、时间、软硬链接等，此外它还支持匿名传输；Rsync不仅可以远程同步数据（类似于scp）还可以本地同步数据（类似于cp），但不同于cp或scp的是rsync不像cp/scp一样会覆盖以前的数据，Rsync使用所谓的“Rsync演算法”，这个算法在第一次连通完成时，会把整份文件传输一次，下一次就只传送二个文件之间不同的部份，因此速度相当快<br>","more":"<br>二、Rsync的传输方式（或工作模式）</p>\n<p>l  在本机直接运行拷贝本地文件（不使用冒号）</p>\n<p>命令格式为：rsync[OPTION]… SRC DEST。如下</p>\n<pre><code>[root@abao~]# rsync -av /etc /tmp\n</code></pre><p>l  通过rsh或ssh的信道在server/client之间进行传输数据（使用一个冒号）</p>\n<p>需要登录到服务器上执行任务，并且需要输入账号的密码</p>\n<p>1、 将本地机器的内容拷贝到远程机器（目标路径中使用一个冒号）</p>\n<p>命令格式为：rsync[OPTION]… SRC [USER@]HOST:DEST。如下</p>\n<pre><code>[root@abao~]# rsync -av -e ssh /tmp axing@172.168.72.68:~\n</code></pre><p>2、 将远程机器的内容拷贝到本地机器（源路径中使用一个冒号）</p>\n<p>命令格式为：rsync[OPTION]… [USER@]HOST:SRC DEST。如下</p>\n<pre><code>[root@abao~]# rsync -av -e ssh axing@172.168.72.68:~ /tmp\n</code></pre><p>l  直接通过rsync的服务来传输（此时服务器端需要启动873端口，并且使用两个冒号）</p>\n<p>这种方式在远程主机上建立一个rsync的服务器，在服务器上配置好rsync的各种应用，然后本机作为rsync的一个客户端去连接远程的rsync服务器</p>\n<p>1、 从远程rsync服务器中拷贝文件到本地机（源路径中使用一个冒号）</p>\n<p>命令格式为：rsync[OPTION]… [USER@]HOST::模块名 本地位置。如下</p>\n<pre><code>[root@abao~]# rsync -av axing@172.168.72.68:：back /databack\n</code></pre><p>2、从本地机器拷贝文件到远程rsync服务器中（目标路径中使用一个冒号）</p>\n<p>命令格式为：rsync[OPTION]… SRC [USER@]HOST::DEST。如下</p>\n<pre><code>[root@abao~]# rsync -av /databack axing@172.168.72.68:：back\n</code></pre><p>以上3中传输方式的差异在于有没有冒号“：”，本地端传输不需要冒号，通过rsh或ssh传输时需要一个冒号，而通过rsync传输时需要两个冒号</p>\n<p>三、Rsync的语法</p>\n<pre><code>-v： 查看模式可以列出很多信息包括文件名\n\n-r： 递归复制，可以针对目录来复制\n\n-u： 仅更新，如果目标文件比较新那么则保留新文件不会覆盖\n\n-l： 复制链接文件的属性\n\n-p： 连同属性一起复制\n\n-g： 保存源文件的属组\n\n-o： 保存源文件的属主\n\n-D： 保存源文件的设备属性\n\n-t： 保存原文件的时间参数\n\n-z： 在传输时加上压缩\n\n-e： 使用的协议，例如使用ssh通道就是-e ssh\n\n-a： 相当于-rlptgoD，是最常用的参数\n\n-L： 把SRC中软连接的目标文件给拷贝到DST.\n\n–delete：如果在DST增加文件了，而SRC当中没有这些文件，同步时会删除新增的文件\n\n–exclude=filename：  指定排除不需要传输的文件，等号后面跟文件名（如*.txt）\n\n–progress：  可以看到同步的过程状态，比如文件数量、文件传输速度等\n</code></pre><p>四、在本机直接运行拷贝本地文件实例</p>\n<pre><code>[root@abao ~]# rsync -av /etc/tmp#首次本地备份\n\n…………………………………………………………………\n\nsent 33899909 bytes  received 35626 bytes  5220851.54 bytes/sec\n\ntotal size is 33759697  speedup is 0.99\n\n[root@abao ~]# ll -d /tmp/etc/etc#两文件相同\n\ndrwxr-xr-x. 126 root root12288 10月 10 08:23 /etc\n\ndrwxr-xr-x. 126 root root12288 10月 10 08:23 /tmp/etc\n\n[root@abao ~]# rsync -av /etc/tmp#再次备份时只备份差异文件\n\nsending incremental file list\n\nsent 77528 bytes  received 293 bytes  155642.00 bytes/sec\n\ntotal size is 33759697  speedup is 433.81\n</code></pre><p>五、通过rsh或ssh的信道在server/client之间进行传输数据实例</p>\n<pre><code>[root@abao ~]# /etc/init.d/sshd restart\n\n停止 sshd：[确定]\n\n正在启动 sshd：[确定]\n</code></pre><p>l  将本地机器的内容拷贝到远程机器</p>\n<pre><code>[root@abao ~]# rsync -av -e ssh /tmp admin@172.168.72.68:~\n\nadmin@172.168.72.68’s password:   #需要输入账户密码\n\n…………………………………………………………………………\n\nsent 238637037 bytes received 60045 bytes  3819153.31bytes/sec\n\ntotal size is 238396030 speedup is 1.00\n</code></pre><p>l  将远程机器的内容拷贝到本地机器</p>\n<pre><code>[root@abao ~]# rsync -av -e ssh axing@172.168.72.68:~ /tmp\n\naxing@172.168.72.68’s password:   #需要输入账户密码\n\nreceiving incremental file list\n\naxing/\n\naxing/.ICEauthority\n\n…………………………………………………………………\n\nsent 1732 bytes  received758924 bytes  80069.05 bytes/sec\n\ntotal size is 751474 speedup is 0.99\n\n[root@abao ~]# ll -d /tmp/axing\n\ndrwx——. 27 500 500 4096 10月 10 08:23 /tmp/axing\n</code></pre><p>l  利用crontab通过ssh进行免密码异地备份脚本（常用）</p>\n<p>我们可以针对用户admin制作一个免密码登陆的ssh秘钥，这样以后异地备份系统就可以使用crontab自动备份了，前提是先根据下面（六、直接通过rsync的服务来传输实例）安装并设置好rsync</p>\n<p>1、ssh服务器端和客户端账户建立</p>\n<pre><code>[root@baobao ~]# mkdir /home/back; touch /home/back/wo#创建要备份的文件\n\n[root@baobao ~]# chmod -R 755 /home/back/\n\n[root@baobao ~]# useradd admin#先在ssh服务器端ssh账号\n\n[root@baobao ~]# passwd admin\n\n更改用户 admin 的密码 。\n\n新的 密码：\n\n重新输入新的 密码：\n\npasswd： 所有的身份验证令牌已经成功更新。\n\n[root@abao ~]# useradd admin  #客户端上建立ssh账号\n\n[root@abao ~]# passwd admin\n\n更改用户 admin 的密码 。\n\n新的 密码：\n\n重新输入新的 密码：\n\npasswd： 所有的身份验证令牌已经成功更新。\n</code></pre><p>2、客户端建立两把钥匙</p>\n<pre><code>[root@abao ~]# su – admin\n\n[admin@abao ~]$ ssh-keygen\n\nGenerating public/private rsa key pair.\n\nEnter file in which to save the key (/home/admin/.ssh/id_rsa):\n\nCreated directory ‘/home/admin/.ssh’.\n\nEnter passphrase (empty for no passphrase):\n\nEnter same passphrase again:\n\nYour identification has been saved in /home/admin/.ssh/id_rsa.\n\nYour public key has been saved in /home/admin/.ssh/id_rsa.pub.\n\nThe key fingerprint is:\n\n61:01:c2:9b:26:00:0a:01:c9:a0:58:7e:38:f9:85:6c admin@abao\n\nThe key’s randomart image is:\n\n+–[ RSA 2048]—-+\n\n|@o… …|\n\n|B+ +.o   .   |\n\n|+.= Eo. o|\n\n|  .=+. . .   |\n\n|   o.   S   |\n\n| |\n\n| |\n\n| |\n\n| |\n\n+—————–+\n\n[admin@abao ~]$ ls -ld ~/.ssh; ls -l ~/.ssh\n\ndrwx——. 2 admin admin 4096 10月 10 09:21 /home/admin/.ssh\n\n总用量 8\n\n-rw——-. 1 admin admin 1675 10月 10 09:21 id_rsa\n\n-rw-r–r–. 1 admin admin 392 10月 10 09:21 id_rsa.pub\n</code></pre><p>3、将公钥文件数据上传到服务器</p>\n<pre><code>[admin@abao ~]$ scp ~/.ssh/id_rsa.pub admin@172.168.72.68:~#客户端上传公钥文件\n\nadmin@172.168.72.68’s password:\n\nid_rsa.pub100%  3920.4KB/s   00:00\n</code></pre><p>4、将公钥放置到服务器端的正确目录与文件名（服务器上操作）</p>\n<pre><code>[root@baobao ~]# su – admin\n\n[admin@baobao ~]$ ls -ld .ssh\n\nls: 无法访问.ssh: 没有那个文件或目录\n\n[admin@baobao ~]$ mkdir .ssh; chmod 700 .ssh #服务器上建立文件~/.ssh\n\n[admin@baobao ~]$ ls -ld .ssh\n\ndrwx—— 2 admin admin 4096 10月 10 09:36 .ssh\n\n[admin@baobao ~]$ ls -l *pub\n\n-rw-r–r– 1 admin admin 392 10月 10 09:27 id_rsa.pub\n\n[admin@baobao ~]$ cat id_rsa.pub &gt;&gt; .ssh/authorized_keys\n\n[admin@baobao ~]$ chmod 644 .ssh/authorized_keys\n\n[admin@baobao ~]$ ls -l .ssh\n\n总用量 4\n\n-rw-r–r– 1 admin admin 392 10月 10 09:38 authorized_keys\n</code></pre><p>5、在客户端建立异地备份脚本</p>\n<pre><code>[root@abao ~]# mkdir /backups\n\n[root@abao ~]# chmod -R 755 /backups/\n\n[root@abao ~]# su – admin\n\n[admin@abao ~]$ mkdir ~/bin; vim ~/bin/backup.sh\n\n#!/bin/bash\n\nlocaldir=/backups\n\nremotedir=/home/back/\n\nremoteip=”172.168.72.68″\n\n[ -d ${localdir} ] || mkdir ${localdir}   #-d是判断是否有这个目录；符号“||”是逻辑或意思，左边为假时执行右边命令；小括号一般用作执行命令，而自定义变量一般用大括号括起来\n\nfor dir in ${remotedir}\n\ndo\n\nrsync -av -essh admin@${remoteip}:${dir} ${localdir}\n\ndone\n\n[admin@abao ~]$ chmod 755 ~/bin/backup.sh\n\n[admin@abao ~]$ ls -ld /home/admin/bin/backup.sh\n\n-rwxrwxr-x. 1 admin admin 224 10月 11 08:49 /home/admin/bin/backup.sh\n\n[admin@abao ~]$ ~/bin/backup.sh   #执行脚本\n\nreceiving incremental filelist\n\nsent 11 bytes  received 43 bytes  5.68 bytes/sec\n\ntotal size is 1010  speedup is 18.70\n</code></pre><p>6、制作crontab计划任务</p>\n<pre><code>[root@abao ~]# crontab –e #每天的凌晨02:00异地备份服务器上的/etc /root /home目录到本地的/backups/下\n0 2 * * * /home/admin/bin/backup.sh\n</code></pre><p>六、直接通过rsync的服务来传输实例</p>\n<p>l  创建用户账号和rsync配置文件</p>\n<pre><code>[root@baobao ~]# useraddadmin   #创建链接用户\n\n[root@baobao ~]# passwd admin\n\n更改用户 admin 的密码。\n\n新的 密码：\n\n重新输入新的 密码：\n\npasswd： 所有的身份验证令牌已经成功更新。\n\n[root@baobao ~]# mkdir /home/back   #创建要进行备份的目录或文件\n\n[root@baobao ~]# touch/home/back/guo\n\n[root@baobao ~]# vim/home/back/guo\n\n[root@baobao ~]# chmod -R 755/home/back/#设定要备份的目录或文件权限\n\n[root@baobao ~]# yum -yinstall xinetd\n\n[root@baobao ~]# yum -yinstall rsync#安装rsync\n\n[root@baobao ~]# yum -yinstall rsync#客户端也安装rsync\n\n[root@baobao ~]# touch/etc/rsyncd.conf  #默认该文件是没有的\n\n[root@baobao ~]# chmod 600/etc/rsyncd.conf  #修改配置文件权限\n</code></pre><p>l  Rsync服务器端配置文件设置</p>\n<p>配置文件时即时生效的，不用重启服务</p>\n<p>1、/etc/rsyncd.conf配置</p>\n<p>1)  全局参数配置</p>\n<pre><code>[root@baobao ~]# manrsyncd.conf   #查看说明文档看下面部分参数是yes/no还是true/false\n\n[root@baobao ~]# vim/etc/rsyncd.conf\n\nuid=root  #运行RSYNC守护进程的用户\n\ngid=root  #运行RSYNC守护进程的组\n\nuse chroot=false  #不使用chroot\n\nmax connections=8 #最大连接数是4\n\npid file=/var/run/rsyncd.pid  #pid文件默认存放位置\n\nlock file=/var/run/rsync.lock #锁文件默认存放位置（锁住rsync正在操作的文件不让其他的程序对其进行写操作）\n\nlog file=/var/log/rsyncd.log  #日志文件默认存放位置\n\nstrict modes=true #是否检查口令文件的权限\nport=873  #默认端口873\n</code></pre><p>2)  模块参数配置(多台客户端需要设置多个模块)</p>\n<pre><code>[backup]   #认证的模块名，在client端需要指定\n\npath=/etc  #需要做备份的目录\n\ncomment=This is backup #这个模块的注释信息\n\nlist=true  #当用户查询该服务器上的可用模块时，该模块是被列出（true）还是被隐藏（false）\n\nmax connections=6  #客户端最大连接数(默认0没限制)，模块里可以不设置\nignore errors  #可以忽略一些无关的IO错误\nread only=false#“yes”只读客户端不能上传；“no”客户端可以上传\nwrite only=false   #“yes”客户端不能下载；“no”客户端可以下载\n\nuid=root   #指定该模块传输文件时守护进程应该具有的uid\ngid=root   #指定该模块传输文件时守护进程应该具有的gid\nhosts allow=172.168.0.0/16 #允许连接的主机（“*”充许任何主机连接），多个主机用“，”分开；多个网段用空格隔开\nhosts deny=192.168.10.0/32 #禁止连接的主机或网段\n\nauth users=admin   #登陆系统使用的用户名（系统必须存在的用户），没有默认为匿名\nsecrets file= /etc/rsyncd.secrets #登陆用户的密码文件（需要自己生成）\n</code></pre><p>2、rsync server启动文件配置</p>\n<pre><code>[root@baobao ~]# vim /etc/xinetd.d/rsync#只修改disable = no即可\n\n# default: off\n\n# description: The rsyncserver is a good addition to an ftp server, as it \\\n\n#   allows crc checksumming etc.\n\nservice rsync\n\n{\n\ndisable = no\n\nflags   = IPv6\n\nsocket_type = stream\n\nwait= no\n\nuser= root\n\nserver  = /usr/bin/rsync\n\nserver_args = –daemon\n\nlog_on_failure  += USERID\n\n}\n\n[root@baobao ~]# chkconfigrsync on\n</code></pre><p>l  创建密码文件、欢迎信息</p>\n<p>1、生成rsync密码文件并设置该文件相应权限<br>    [root@baobao ~]# touch /etc/rsyncd.secrets</p>\n<pre><code>[root@baobao ~]# vim /etc/rsyncd.secrets\n\nadmin:guobaobao!1314#格式为“账号：密码”且一行一个\n[root@baobao ~]# chown root.root /etc/rsyncd.secrets\n\n[root@baobao ~]# chmod 600 /etc/rsyncd.secrets\n\n因为rsyncd.secrets存储了rsync服务的用户名和密码，所以要将rsyncd.secrets设置为root拥有, 且权限为600\n</code></pre><p>2、配置欢迎信息rsyncd.motd（可有可无）<br>    [root@baobao ~]# vim /etc/rsyncd.motd   #rsyncd.motd记录了rsync服务的欢迎信息</p>\n<pre><code>Welcome to use the rsyncservices!\n[root@baobao ~]# service xinetd restart\n\n停止 xinetd：  [确定]\n\n正在启动 xinetd：  [确定]\n</code></pre><p>l  Rsync的启动与开机启动</p>\n<p>1、Rsync服务端启动</p>\n<p>1)  载入配置</p>\n<pre><code>[root@baobao ~]# rsync –daemon–config=/etc/rsyncd.conf   #载入配置并启动\n\n或\n\n[root@baobao ~]# /etc/rc.d/init.d/xinetdreload\n\n重新载入配置： [确定]\n</code></pre><p>2)  重启rsync</p>\n<pre><code>[root@baobao ~]# /usr/bin/rsync –daemon\n\nfailed to create pid file/var/run/rsyncd.pid: File exists\n\n或\n\n[root@baobao ~]# /etc/rc.d/init.d/xinetdrestart#重新启动\n\n停止 xinetd：  [确定]\n\n正在启动 xinetd：  [确定]\n</code></pre><p>3)  检查rsync是否启动</p>\n<pre><code>[root@baobao ~]# netstat -lnp | grep 873#由超级进程启动\n\ntcp   0  0 0.0.0.0:8730.0.0.0:*LISTEN  3133/rsync\n\ntcp   0  0 :::873 :::*LISTEN 3133/rsync\n\n或\n\n[root@baobao ~]# netstat -a |grep rsync\n\ntcp0  0*:rsync *:* LISTEN\n\n或\n\n[root@baobao ~]# lsof -i:873 #端口没有被占用\n\nCOMMAND  PID USER  FD   TYPE DEVICE SIZE/OFF NODENAME\n\nrsync   3133 root   4u  IPv4  22973 0t0  TCP *:rsync (LISTEN)\n\nrsync   3133 root   5u  IPv6  22974 0t0  TCP *:rsync (LISTEN)\n</code></pre><p>4)  查看rsync日志</p>\n<pre><code>[root@baobao ~]# cat /var/log/rsyncd.log #查看rsync日志\n\n2014/10/14 15:29:13 [35681] rsyncdversion 3.0.6 starting, listening on port 873\n</code></pre><p>2、将rsync加入开机启动</p>\n<pre><code>[root@baobao ~]# echo”/usr/bin/rsync –daemon –config=/etc/rsyncd.conf”&gt;&gt;/etc/rc.local\n\n[root@baobao ~]# cat/etc/rc.local\n\n#!/bin/sh\n\n#\n\n# This script will beexecuted *after* all the other init scripts.\n\n# You can put your owninitialization stuff in here if you don’t\n\n# want to do the full Sys Vstyle init stuff.\n\ntouch /var/lock/subsys/local\n\n/usr/bin/rsync –daemon–config=/etc/rsyncd.conf\n</code></pre><p>l  Rsync服务器端配置防火墙</p>\n<p>1、防火墙设置</p>\n<pre><code>[root@baobao ~]# iptables -F\n\n[root@baobao ~]# iptables -X\n\n[root@baobao ~]# iptables -Z\n\n[root@baobao ~]# iptables -AINPUT -i eth0 -s 172.168.0.0/16 -p tcp –dport 22 -j ACCEPT\n\n[root@baobao ~]# iptables -L\n\nChain INPUT (policy ACCEPT)\n\ntarget prot opt source   destination\n\nACCEPT tcp —  ACA80000.ipt.aol.com/16  anywheretcp dpt:ssh\n\nChain FORWARD (policy ACCEPT)\n\ntarget prot opt source   destination\n\nChain OUTPUT (policy ACCEPT)\n\ntarget prot opt source   destination\n\n[root@baobao ~]#/etc/init.d/iptables save\n\niptables：将防火墙规则保存到 /etc/sysconfig/iptables： [确定]\n\n[root@baobao ~]#/etc/init.d/iptables restart\n\niptables：清除防火墙规则：[确定]\n\niptables：将链设置为政策 ACCEPT：filter[确定]\n\niptables：正在卸载模块：  [确定]\n\niptables：应用防火墙规则：[确定]\n</code></pre><p>2、selinux设置</p>\n<pre><code>[root@baobao ~]# setenforce 0\n</code></pre><p>l  客户端测试</p>\n<pre><code>[root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/\n\nPassword:\n\nreceiving incremental filelist\n\ncreated directory /backups\n\n./\n\nguo\n\nsent 79 bytes  received 1162 bytes  275.78 bytes/sec\n\ntotal size is 1010  speedup is 0.81\n</code></pre><p>可以看到这里还是需要输入密码，这样同样也不能写入脚本中自动执行</p>\n<p>l  常见问题处理</p>\n<p>1、错误一</p>\n<p>@ERROR: chroot failed</p>\n<p>rsync error: error startingclient-server protocol (code 5) at main.c(1522) [receiver=3.0.3]</p>\n<p>原因：服务器端的目录不存在或无权限</p>\n<p>2、错误二</p>\n<p>@ERROR: auth failed on moduletee</p>\n<p>rsync error: error startingclient-server protocol (code 5) at main.c(1522) [receiver=3.0.3]</p>\n<p>原因：服务器端该模块（tee）需要验证用户名密码，但客户端没有提供正确的用户名密码，认证失败。</p>\n<p>3、错误三</p>\n<p>@ERROR: Unknown module‘tee_nonexists’</p>\n<p>rsync error: error startingclient-server protocol (code 5) at main.c(1522) [receiver=3.0.3]</p>\n<p>原因：服务器不存在指定模块</p>\n<p>4、错误四</p>\n<p>password file must not beother-accessible</p>\n<p>continuing without passwordfile</p>\n<p>Password:</p>\n<p>原因：这是因为rsyncd.pwdrsyncd.secrets的权限不对，应该设置为600</p>\n<p>5、错误五</p>\n<p>rsync: failed to connect to218.107.243.2: No route to host (113)</p>\n<p>rsync error: error in socketIO (code 10) at clientserver.c(104) [receiver=2.6.9]</p>\n<p>原因：对方没开机、防火墙阻挡、通过的网络上有防火墙阻挡，都有可能</p>\n<p>6、错误六</p>\n<p>rsync error: error startingclient-server protocol (code 5) at main.c(1524) [Receiver=3.0.7]</p>\n<p>原因：/etc/rsyncd.conf配置文件内容有错误</p>\n<p>7、错误七</p>\n<p>rsync: chown “”failed: Invalid argument (22)</p>\n<p>原因：权限无法复制，去掉同步权限的参数即可(这种情况多见于Linux向Windows的时候)</p>\n<p>8、错误八</p>\n<p>@ERROR: daemon security issue– contact admin<br>rsync error: error starting client-server protocol (code 5) at main.c(1530)[sender=3.0.6]</p>\n<p>原因：同步的目录里面有软连接文件，需要服务器端的/etc/rsyncd.conf打开use chroot = yes掠过软连接文件。</p>\n<p>l  建立不需输入密码的链接</p>\n<p>这样就可以将其写入脚本和任务计划自动运行了</p>\n<p>1、第一种方案：指定密码文件</p>\n<pre><code>[root@abao ~]# touch/etc/pass#客户端上建立密码文件\n\n[root@abao ~]# vim /etc/pass #将账户“admin”密码写入\n\n[root@abao ~]# cat /etc/pass\n\nguobaobao！1314\n\n[root@abao ~]# chmod 600/etc/pass\n\n[root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/\n\nPassword:\n\n@ERROR: auth failed on modulebackup\n\nrsync error: error startingclient-server protocol (code 5) at main.c(1503) [receiver=3.0.6]\n\n[root@abao ~]#\n\n[root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/ –password-file=/etc/pass #注意黑体部分指定密码文件\n\nreceiving incremental filelist\n\nsent 57 bytes  received 106 bytes  326.00 bytes/sec\n\ntotal size is 1010  speedup is 6.20\n</code></pre><p>2、第二种方案：在rsync服务器端不指定用户</p>\n<pre><code>[root@baobao ~]# vim/etc/rsyncd.conf   #服务器端配置文件注释掉下面认证两行\n\n#auth users=admin\n\n#secretsfile=/etc/rsyncd.secrets\n\n[root@abao ~]# rsync -avadmin@172.168.72.68::backup /backups/\n\nreceiving incremental filelist\n\nsent 28 bytes  received 65 bytes  37.20 bytes/sec\n\ntotal size is 1010  speedup is 10.86\n\n或\n\n[root@abao ~]# rsync -av172.168.72.68::backup /backups/#不加账户默认是root\n\nreceiving incremental filelist\n\nsent 28 bytes  received 65 bytes  186.00 bytes/sec\n\ntotal size is 1010  speedup is 10.86\n</code></pre>"},{"title":"linux开机启动顺序","date":"2017-06-28T04:00:00.000Z","_content":"\n\n![](http://blog.chinaunix.net/attachment/201209/23/26495963_1348382510SRUx.png)  \n## 启动第一步－－加载BIOS ##  \n当你打开计算机电源，计算机会首先加载BIOS信息，BIOS信息是如此的重要，以至于计算机必须在最开始就找到它。这是因为BIOS中包含了CPU的相关信息、设备启动顺序信息、硬盘信息、内存信息、时钟信息、PnP特性等等。在此之后，计算机心里就有谱了，知道应该去读取哪个硬件设备了。  \n\n<!--more-->\n## 启动第二步－－读取MBR    ##\n众所周知，硬盘上第0磁道第一个扇区被称为MBR，也就是Master Boot Record，即主引导记录，它的大小是512字节，别看地方不大，可里面却存放了预启动信息、分区表信息。  \n系统找到BIOS所指定的硬盘的MBR后，就会将其复制到0×7c00地址所在的物理内存中。其实被复制到物理内存的内容就是Boot Loader，而具体到你的电脑，那就是lilo或者grub了。    \n\n## 启动第三步－－Boot Loader ##\nBoot Loader 就是在操作系统内核运行之前运行的一段小程序。通过这段小程序，我们可以初始化硬件设备、建立内存空间的映射图，从而将系统的软硬件环境带到一个合适的状态，以便为最终调用操作系统内核做好一切准备。  \nBoot Loader有若干种，其中Grub、Lilo和spfdisk是常见的Loader。  \n我们以Grub为例来讲解吧，毕竟用lilo和spfdisk的人并不多。  \n系统读取内存中的grub配置信息（一般为menu.lst或grub.lst），并依照此配置信息来启动不同的操作系统。  \n\n## 启动第四步－－加载内核 ##  \n根据grub设定的内核映像所在路径，系统读取内存映像，并进行解压缩操作。此时，屏幕一般会输出“Uncompressing Linux”的提示。当解压缩内核完成后，屏幕输出“OK, booting the kernel”。  \n系统将解压后的内核放置在内存之中，并调用start_kernel()函数来启动一系列的初始化函数并初始化各种设备，完成Linux核心环境的建立。至此，Linux内核已经建立起来了，基于Linux的程序应该可以正常运行了。  \n\n## 启动第五步－－用户层init依据inittab文件来设定运行等级 ##  \n内核被加载后，第一个运行的程序便是/sbin/init，该文件会读取/etc/inittab文件，并依据此文件来进行初始化工作。  \n其实/etc/inittab文件最主要的作用就是设定Linux的运行等级，其设定形式是“：id:5:initdefault:”，这就表明Linux需要运行在等级5上。Linux的运行等级设定如下：  \n0：关机  \n1：单用户模式  \n2：无网络支持的多用户模式  \n3：有网络支持的多用户模式  \n4：保留，未使用  \n5：有网络支持有X-Window支持的多用户模式  \n6：重新引导系统，即重启  \n关于/etc/inittab文件的学问，其实还有很多  \n\n## 启动第六步－－init进程执行rc.sysinit ##\n在设定了运行等级后，Linux系统执行的第一个用户层文件就是/etc/rc.d/rc.sysinit脚本程序，它做的工作非常多，包括设定PATH、设定网络配置（/etc/sysconfig/network）、启动swap分区、设定/proc等等。如果你有兴趣，可以到/etc/rc.d中查看一下rc.sysinit文件，里面的脚本够你看几天的  \n\n## 启动第七步－－启动内核模块 ##\n具体是依据/etc/modules.conf文件或/etc/modules.d目录下的文件来装载内核模块。  \n\n## 启动第八步－－执行不同运行级别的脚本程序  ##  \n根据运行级别的不同，系统会运行rc0.d到rc6.d中的相应的脚本程序，来完成相应的初始化工作和启动相应的服务。  \n\n## 启动第九步－－执行/etc/rc.d/rc.local ##  \n你如果打开了此文件，里面有一句话，读过之后，你就会对此命令的作用一目了然：  \n # This script will be executed *after* all the other init scripts.  \n # You can put your own initialization stuff in here if you don’t  \n # want to do the full Sys V style init stuff.  \nrc.local就是在一切初始化工作后，Linux留给用户进行个性化的地方。你可以把你想设置和启动的东西放到这里。  \n\n## 启动第十步－－执行/bin/login程序，进入登录状态 ##\n此时，系统已经进入到了等待用户输入username和password的时候了，你已经可以用自己的帐号登入系统了。\n","source":"_posts/linux开机启动顺序.md","raw":"---\ntitle: linux开机启动顺序\ndate: 2017-06-28\ntags: linux\ncategories: linux\n---\n\n\n![](http://blog.chinaunix.net/attachment/201209/23/26495963_1348382510SRUx.png)  \n## 启动第一步－－加载BIOS ##  \n当你打开计算机电源，计算机会首先加载BIOS信息，BIOS信息是如此的重要，以至于计算机必须在最开始就找到它。这是因为BIOS中包含了CPU的相关信息、设备启动顺序信息、硬盘信息、内存信息、时钟信息、PnP特性等等。在此之后，计算机心里就有谱了，知道应该去读取哪个硬件设备了。  \n\n<!--more-->\n## 启动第二步－－读取MBR    ##\n众所周知，硬盘上第0磁道第一个扇区被称为MBR，也就是Master Boot Record，即主引导记录，它的大小是512字节，别看地方不大，可里面却存放了预启动信息、分区表信息。  \n系统找到BIOS所指定的硬盘的MBR后，就会将其复制到0×7c00地址所在的物理内存中。其实被复制到物理内存的内容就是Boot Loader，而具体到你的电脑，那就是lilo或者grub了。    \n\n## 启动第三步－－Boot Loader ##\nBoot Loader 就是在操作系统内核运行之前运行的一段小程序。通过这段小程序，我们可以初始化硬件设备、建立内存空间的映射图，从而将系统的软硬件环境带到一个合适的状态，以便为最终调用操作系统内核做好一切准备。  \nBoot Loader有若干种，其中Grub、Lilo和spfdisk是常见的Loader。  \n我们以Grub为例来讲解吧，毕竟用lilo和spfdisk的人并不多。  \n系统读取内存中的grub配置信息（一般为menu.lst或grub.lst），并依照此配置信息来启动不同的操作系统。  \n\n## 启动第四步－－加载内核 ##  \n根据grub设定的内核映像所在路径，系统读取内存映像，并进行解压缩操作。此时，屏幕一般会输出“Uncompressing Linux”的提示。当解压缩内核完成后，屏幕输出“OK, booting the kernel”。  \n系统将解压后的内核放置在内存之中，并调用start_kernel()函数来启动一系列的初始化函数并初始化各种设备，完成Linux核心环境的建立。至此，Linux内核已经建立起来了，基于Linux的程序应该可以正常运行了。  \n\n## 启动第五步－－用户层init依据inittab文件来设定运行等级 ##  \n内核被加载后，第一个运行的程序便是/sbin/init，该文件会读取/etc/inittab文件，并依据此文件来进行初始化工作。  \n其实/etc/inittab文件最主要的作用就是设定Linux的运行等级，其设定形式是“：id:5:initdefault:”，这就表明Linux需要运行在等级5上。Linux的运行等级设定如下：  \n0：关机  \n1：单用户模式  \n2：无网络支持的多用户模式  \n3：有网络支持的多用户模式  \n4：保留，未使用  \n5：有网络支持有X-Window支持的多用户模式  \n6：重新引导系统，即重启  \n关于/etc/inittab文件的学问，其实还有很多  \n\n## 启动第六步－－init进程执行rc.sysinit ##\n在设定了运行等级后，Linux系统执行的第一个用户层文件就是/etc/rc.d/rc.sysinit脚本程序，它做的工作非常多，包括设定PATH、设定网络配置（/etc/sysconfig/network）、启动swap分区、设定/proc等等。如果你有兴趣，可以到/etc/rc.d中查看一下rc.sysinit文件，里面的脚本够你看几天的  \n\n## 启动第七步－－启动内核模块 ##\n具体是依据/etc/modules.conf文件或/etc/modules.d目录下的文件来装载内核模块。  \n\n## 启动第八步－－执行不同运行级别的脚本程序  ##  \n根据运行级别的不同，系统会运行rc0.d到rc6.d中的相应的脚本程序，来完成相应的初始化工作和启动相应的服务。  \n\n## 启动第九步－－执行/etc/rc.d/rc.local ##  \n你如果打开了此文件，里面有一句话，读过之后，你就会对此命令的作用一目了然：  \n # This script will be executed *after* all the other init scripts.  \n # You can put your own initialization stuff in here if you don’t  \n # want to do the full Sys V style init stuff.  \nrc.local就是在一切初始化工作后，Linux留给用户进行个性化的地方。你可以把你想设置和启动的东西放到这里。  \n\n## 启动第十步－－执行/bin/login程序，进入登录状态 ##\n此时，系统已经进入到了等待用户输入username和password的时候了，你已经可以用自己的帐号登入系统了。\n","slug":"linux开机启动顺序","published":1,"updated":"2019-06-18T08:07:01.115Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sl1001dhcb70kfb7860","content":"<p><img src=\"http://blog.chinaunix.net/attachment/201209/23/26495963_1348382510SRUx.png\" alt=\"\">  </p>\n<h2 id=\"启动第一步－－加载BIOS\"><a href=\"#启动第一步－－加载BIOS\" class=\"headerlink\" title=\"启动第一步－－加载BIOS\"></a>启动第一步－－加载BIOS</h2><p>当你打开计算机电源，计算机会首先加载BIOS信息，BIOS信息是如此的重要，以至于计算机必须在最开始就找到它。这是因为BIOS中包含了CPU的相关信息、设备启动顺序信息、硬盘信息、内存信息、时钟信息、PnP特性等等。在此之后，计算机心里就有谱了，知道应该去读取哪个硬件设备了。  </p>\n<a id=\"more\"></a>\n<h2 id=\"启动第二步－－读取MBR\"><a href=\"#启动第二步－－读取MBR\" class=\"headerlink\" title=\"启动第二步－－读取MBR\"></a>启动第二步－－读取MBR</h2><p>众所周知，硬盘上第0磁道第一个扇区被称为MBR，也就是Master Boot Record，即主引导记录，它的大小是512字节，别看地方不大，可里面却存放了预启动信息、分区表信息。<br>系统找到BIOS所指定的硬盘的MBR后，就会将其复制到0×7c00地址所在的物理内存中。其实被复制到物理内存的内容就是Boot Loader，而具体到你的电脑，那就是lilo或者grub了。    </p>\n<h2 id=\"启动第三步－－Boot-Loader\"><a href=\"#启动第三步－－Boot-Loader\" class=\"headerlink\" title=\"启动第三步－－Boot Loader\"></a>启动第三步－－Boot Loader</h2><p>Boot Loader 就是在操作系统内核运行之前运行的一段小程序。通过这段小程序，我们可以初始化硬件设备、建立内存空间的映射图，从而将系统的软硬件环境带到一个合适的状态，以便为最终调用操作系统内核做好一切准备。<br>Boot Loader有若干种，其中Grub、Lilo和spfdisk是常见的Loader。<br>我们以Grub为例来讲解吧，毕竟用lilo和spfdisk的人并不多。<br>系统读取内存中的grub配置信息（一般为menu.lst或grub.lst），并依照此配置信息来启动不同的操作系统。  </p>\n<h2 id=\"启动第四步－－加载内核\"><a href=\"#启动第四步－－加载内核\" class=\"headerlink\" title=\"启动第四步－－加载内核\"></a>启动第四步－－加载内核</h2><p>根据grub设定的内核映像所在路径，系统读取内存映像，并进行解压缩操作。此时，屏幕一般会输出“Uncompressing Linux”的提示。当解压缩内核完成后，屏幕输出“OK, booting the kernel”。<br>系统将解压后的内核放置在内存之中，并调用start_kernel()函数来启动一系列的初始化函数并初始化各种设备，完成Linux核心环境的建立。至此，Linux内核已经建立起来了，基于Linux的程序应该可以正常运行了。  </p>\n<h2 id=\"启动第五步－－用户层init依据inittab文件来设定运行等级\"><a href=\"#启动第五步－－用户层init依据inittab文件来设定运行等级\" class=\"headerlink\" title=\"启动第五步－－用户层init依据inittab文件来设定运行等级\"></a>启动第五步－－用户层init依据inittab文件来设定运行等级</h2><p>内核被加载后，第一个运行的程序便是/sbin/init，该文件会读取/etc/inittab文件，并依据此文件来进行初始化工作。<br>其实/etc/inittab文件最主要的作用就是设定Linux的运行等级，其设定形式是“：id:5:initdefault:”，这就表明Linux需要运行在等级5上。Linux的运行等级设定如下：<br>0：关机<br>1：单用户模式<br>2：无网络支持的多用户模式<br>3：有网络支持的多用户模式<br>4：保留，未使用<br>5：有网络支持有X-Window支持的多用户模式<br>6：重新引导系统，即重启<br>关于/etc/inittab文件的学问，其实还有很多  </p>\n<h2 id=\"启动第六步－－init进程执行rc-sysinit\"><a href=\"#启动第六步－－init进程执行rc-sysinit\" class=\"headerlink\" title=\"启动第六步－－init进程执行rc.sysinit\"></a>启动第六步－－init进程执行rc.sysinit</h2><p>在设定了运行等级后，Linux系统执行的第一个用户层文件就是/etc/rc.d/rc.sysinit脚本程序，它做的工作非常多，包括设定PATH、设定网络配置（/etc/sysconfig/network）、启动swap分区、设定/proc等等。如果你有兴趣，可以到/etc/rc.d中查看一下rc.sysinit文件，里面的脚本够你看几天的  </p>\n<h2 id=\"启动第七步－－启动内核模块\"><a href=\"#启动第七步－－启动内核模块\" class=\"headerlink\" title=\"启动第七步－－启动内核模块\"></a>启动第七步－－启动内核模块</h2><p>具体是依据/etc/modules.conf文件或/etc/modules.d目录下的文件来装载内核模块。  </p>\n<h2 id=\"启动第八步－－执行不同运行级别的脚本程序\"><a href=\"#启动第八步－－执行不同运行级别的脚本程序\" class=\"headerlink\" title=\"启动第八步－－执行不同运行级别的脚本程序\"></a>启动第八步－－执行不同运行级别的脚本程序</h2><p>根据运行级别的不同，系统会运行rc0.d到rc6.d中的相应的脚本程序，来完成相应的初始化工作和启动相应的服务。  </p>\n<h2 id=\"启动第九步－－执行-etc-rc-d-rc-local\"><a href=\"#启动第九步－－执行-etc-rc-d-rc-local\" class=\"headerlink\" title=\"启动第九步－－执行/etc/rc.d/rc.local\"></a>启动第九步－－执行/etc/rc.d/rc.local</h2><p>你如果打开了此文件，里面有一句话，读过之后，你就会对此命令的作用一目了然：  </p>\n<h1 id=\"This-script-will-be-executed-after-all-the-other-init-scripts\"><a href=\"#This-script-will-be-executed-after-all-the-other-init-scripts\" class=\"headerlink\" title=\"This script will be executed after all the other init scripts.\"></a>This script will be executed <em>after</em> all the other init scripts.</h1><h1 id=\"You-can-put-your-own-initialization-stuff-in-here-if-you-don’t\"><a href=\"#You-can-put-your-own-initialization-stuff-in-here-if-you-don’t\" class=\"headerlink\" title=\"You can put your own initialization stuff in here if you don’t\"></a>You can put your own initialization stuff in here if you don’t</h1><h1 id=\"want-to-do-the-full-Sys-V-style-init-stuff\"><a href=\"#want-to-do-the-full-Sys-V-style-init-stuff\" class=\"headerlink\" title=\"want to do the full Sys V style init stuff.\"></a>want to do the full Sys V style init stuff.</h1><p>rc.local就是在一切初始化工作后，Linux留给用户进行个性化的地方。你可以把你想设置和启动的东西放到这里。  </p>\n<h2 id=\"启动第十步－－执行-bin-login程序，进入登录状态\"><a href=\"#启动第十步－－执行-bin-login程序，进入登录状态\" class=\"headerlink\" title=\"启动第十步－－执行/bin/login程序，进入登录状态\"></a>启动第十步－－执行/bin/login程序，进入登录状态</h2><p>此时，系统已经进入到了等待用户输入username和password的时候了，你已经可以用自己的帐号登入系统了。</p>\n","site":{"data":{}},"excerpt":"<p><img src=\"http://blog.chinaunix.net/attachment/201209/23/26495963_1348382510SRUx.png\" alt=\"\">  </p>\n<h2 id=\"启动第一步－－加载BIOS\"><a href=\"#启动第一步－－加载BIOS\" class=\"headerlink\" title=\"启动第一步－－加载BIOS\"></a>启动第一步－－加载BIOS</h2><p>当你打开计算机电源，计算机会首先加载BIOS信息，BIOS信息是如此的重要，以至于计算机必须在最开始就找到它。这是因为BIOS中包含了CPU的相关信息、设备启动顺序信息、硬盘信息、内存信息、时钟信息、PnP特性等等。在此之后，计算机心里就有谱了，知道应该去读取哪个硬件设备了。  </p>","more":"<h2 id=\"启动第二步－－读取MBR\"><a href=\"#启动第二步－－读取MBR\" class=\"headerlink\" title=\"启动第二步－－读取MBR\"></a>启动第二步－－读取MBR</h2><p>众所周知，硬盘上第0磁道第一个扇区被称为MBR，也就是Master Boot Record，即主引导记录，它的大小是512字节，别看地方不大，可里面却存放了预启动信息、分区表信息。<br>系统找到BIOS所指定的硬盘的MBR后，就会将其复制到0×7c00地址所在的物理内存中。其实被复制到物理内存的内容就是Boot Loader，而具体到你的电脑，那就是lilo或者grub了。    </p>\n<h2 id=\"启动第三步－－Boot-Loader\"><a href=\"#启动第三步－－Boot-Loader\" class=\"headerlink\" title=\"启动第三步－－Boot Loader\"></a>启动第三步－－Boot Loader</h2><p>Boot Loader 就是在操作系统内核运行之前运行的一段小程序。通过这段小程序，我们可以初始化硬件设备、建立内存空间的映射图，从而将系统的软硬件环境带到一个合适的状态，以便为最终调用操作系统内核做好一切准备。<br>Boot Loader有若干种，其中Grub、Lilo和spfdisk是常见的Loader。<br>我们以Grub为例来讲解吧，毕竟用lilo和spfdisk的人并不多。<br>系统读取内存中的grub配置信息（一般为menu.lst或grub.lst），并依照此配置信息来启动不同的操作系统。  </p>\n<h2 id=\"启动第四步－－加载内核\"><a href=\"#启动第四步－－加载内核\" class=\"headerlink\" title=\"启动第四步－－加载内核\"></a>启动第四步－－加载内核</h2><p>根据grub设定的内核映像所在路径，系统读取内存映像，并进行解压缩操作。此时，屏幕一般会输出“Uncompressing Linux”的提示。当解压缩内核完成后，屏幕输出“OK, booting the kernel”。<br>系统将解压后的内核放置在内存之中，并调用start_kernel()函数来启动一系列的初始化函数并初始化各种设备，完成Linux核心环境的建立。至此，Linux内核已经建立起来了，基于Linux的程序应该可以正常运行了。  </p>\n<h2 id=\"启动第五步－－用户层init依据inittab文件来设定运行等级\"><a href=\"#启动第五步－－用户层init依据inittab文件来设定运行等级\" class=\"headerlink\" title=\"启动第五步－－用户层init依据inittab文件来设定运行等级\"></a>启动第五步－－用户层init依据inittab文件来设定运行等级</h2><p>内核被加载后，第一个运行的程序便是/sbin/init，该文件会读取/etc/inittab文件，并依据此文件来进行初始化工作。<br>其实/etc/inittab文件最主要的作用就是设定Linux的运行等级，其设定形式是“：id:5:initdefault:”，这就表明Linux需要运行在等级5上。Linux的运行等级设定如下：<br>0：关机<br>1：单用户模式<br>2：无网络支持的多用户模式<br>3：有网络支持的多用户模式<br>4：保留，未使用<br>5：有网络支持有X-Window支持的多用户模式<br>6：重新引导系统，即重启<br>关于/etc/inittab文件的学问，其实还有很多  </p>\n<h2 id=\"启动第六步－－init进程执行rc-sysinit\"><a href=\"#启动第六步－－init进程执行rc-sysinit\" class=\"headerlink\" title=\"启动第六步－－init进程执行rc.sysinit\"></a>启动第六步－－init进程执行rc.sysinit</h2><p>在设定了运行等级后，Linux系统执行的第一个用户层文件就是/etc/rc.d/rc.sysinit脚本程序，它做的工作非常多，包括设定PATH、设定网络配置（/etc/sysconfig/network）、启动swap分区、设定/proc等等。如果你有兴趣，可以到/etc/rc.d中查看一下rc.sysinit文件，里面的脚本够你看几天的  </p>\n<h2 id=\"启动第七步－－启动内核模块\"><a href=\"#启动第七步－－启动内核模块\" class=\"headerlink\" title=\"启动第七步－－启动内核模块\"></a>启动第七步－－启动内核模块</h2><p>具体是依据/etc/modules.conf文件或/etc/modules.d目录下的文件来装载内核模块。  </p>\n<h2 id=\"启动第八步－－执行不同运行级别的脚本程序\"><a href=\"#启动第八步－－执行不同运行级别的脚本程序\" class=\"headerlink\" title=\"启动第八步－－执行不同运行级别的脚本程序\"></a>启动第八步－－执行不同运行级别的脚本程序</h2><p>根据运行级别的不同，系统会运行rc0.d到rc6.d中的相应的脚本程序，来完成相应的初始化工作和启动相应的服务。  </p>\n<h2 id=\"启动第九步－－执行-etc-rc-d-rc-local\"><a href=\"#启动第九步－－执行-etc-rc-d-rc-local\" class=\"headerlink\" title=\"启动第九步－－执行/etc/rc.d/rc.local\"></a>启动第九步－－执行/etc/rc.d/rc.local</h2><p>你如果打开了此文件，里面有一句话，读过之后，你就会对此命令的作用一目了然：  </p>\n<h1 id=\"This-script-will-be-executed-after-all-the-other-init-scripts\"><a href=\"#This-script-will-be-executed-after-all-the-other-init-scripts\" class=\"headerlink\" title=\"This script will be executed after all the other init scripts.\"></a>This script will be executed <em>after</em> all the other init scripts.</h1><h1 id=\"You-can-put-your-own-initialization-stuff-in-here-if-you-don’t\"><a href=\"#You-can-put-your-own-initialization-stuff-in-here-if-you-don’t\" class=\"headerlink\" title=\"You can put your own initialization stuff in here if you don’t\"></a>You can put your own initialization stuff in here if you don’t</h1><h1 id=\"want-to-do-the-full-Sys-V-style-init-stuff\"><a href=\"#want-to-do-the-full-Sys-V-style-init-stuff\" class=\"headerlink\" title=\"want to do the full Sys V style init stuff.\"></a>want to do the full Sys V style init stuff.</h1><p>rc.local就是在一切初始化工作后，Linux留给用户进行个性化的地方。你可以把你想设置和启动的东西放到这里。  </p>\n<h2 id=\"启动第十步－－执行-bin-login程序，进入登录状态\"><a href=\"#启动第十步－－执行-bin-login程序，进入登录状态\" class=\"headerlink\" title=\"启动第十步－－执行/bin/login程序，进入登录状态\"></a>启动第十步－－执行/bin/login程序，进入登录状态</h2><p>此时，系统已经进入到了等待用户输入username和password的时候了，你已经可以用自己的帐号登入系统了。</p>"},{"title":"centos 7 部署 lsyncd 实时同步","date":"2017-09-13T04:00:00.000Z","_content":"## 几大实时同步工具比较\n<!--more-->\n\n### inotify + rsync\n最近一直在寻求生产服务服务器上的同步替代方案，原先使用的是inotify + rsync，但随着文件数量的增大到100W+，目录下的文件列表就达20M，在网络状况不佳或者限速的情况下，变更的文件可能10来个才几M，却因此要发送的文件列表就达20M，严重减低的带宽的使用效率以及同步效率；更为要紧的是，加入inotifywait在5s内监控到10个小文件发生变化，便会触发10个rsync同步操作，结果就是真正需要传输的才2-3M的文件，比对的文件列表就达200M。使用这两个组合的好处在于，它们都是最基本的软件，可以通过不同选项做到很精确的控制，比如排除同步的目录，同步多个模块或同步到多个主机。  \n\n搭建过程参考[linux 下同步工具inotify + rsync 使用详解](http://www.datura.me/2017/09/13/linux_下同步工具inotify_+_rsync_使用详解/)\n\n### sersync\n\n后来听同事说 sersync 这么个工具可以提高同步的性能，也解决了同步大文件时出现异常的问题，所以就尝试了一下。sersync是国内的一个开发者开源出来的，使用c++编写，采用多线程的方式进行同步，失败后还有重传机制，对临时文件过滤，自带crontab定时同步功能。网上看到有人说性能还不错，说一下我的观点：\n>国产开源，文档不是很全，在2011年之后就没更新了（googlecode都要快关闭了，其实可以转交其他人维护），网上关于它的使用和讨论都止于10年了  \n>采用xml配置文件的方式，可读性比较好，但是有些原生的有些功能没有实现就没法使用了  \n>无法实现多目录同步，只能通过多个配置文件启动多个进程  \n>文件排除功能太弱。这个要看需求，不是每个人都需要排除子目录。而对于我的环境中，这个功能很重要，而且排除的规则较多  \n>虽然提供插件的功能，但很鸡肋，因为软件本身没有持续更新，也没有看到贡献有其它插件出现（可能是我知识面不够，还用不到里面的refreshCDN plugin）。\n\n### lsyncd\n\n废话说这么多，本文就是介绍它了。有些博客说lsyncd是谷歌开源的，实际不是了，只是托管在了googlecode上而已，幸运的是已经迁移到github了：  [[https://github.com/826167518/lsyncd]](https://github.com/826167518/lsyncd)\n\nLysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。\n\n实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。\n\n## 使用 lsyncd 本地目录实时备份\n\n这一节实现的功能是，本地目录source实时同步到另一个目录target，而在source下有大量的文件，并且有部分目录和临时文件不需要同步。\n\n### 安装lsyncd\n\n安装lsyncd极为简单，已经收录在ubuntu的官方镜像源里，直接通过apt-get install lsyncd就可以。  \n在Redhat系（我的环境是CentOS 6.2 x86_64 ），可以手动去下载 lsyncd-2.1.5-6.fc21.x86_64.rpm，但首先你得安装两个依赖yum install lua lua-devel。也可以通过在线安装，需要epel-release扩展包：\n\n\t# rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n\t# yum install lsyncd\n\n源码编译安装\n\n从源码编译安装可以使用最新版的lsyncd程序，但必须要相应的依赖库文件和编译工具：  \n\n\tyum install lua lua-devel asciidoc cmake。\n\n\n从 googlecode lsyncd 上下载的lsyncd-2.1.5.tar.gz，直接./configure、make && make install就可以了。\n\n从github上下载[lsyncd-master.zip](https://github.com/axkibe/lsyncd/archive/master.zip) 的2.1.5版本使用的是 cmake 编译工具，无法./configure：\n>uzip lsyncd-master.zip  \n>cd lsyncd-master  \n>cmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncd-2.1.5  \n>make && make install  \n\n我这个版本编译时有个小bug，如果按照INSTALL在build目录中make，会提示：\n\n>[100%] Generating doc/lsyncd.1  \n>Updating the manpage  \n>a2x: failed: source file not found: doc/lsyncd.1.txt  \n>make[2]: *** [doc/lsyncd.1] Error 1  \n>make[1]: *** [CMakeFiles/manpage.dir/all] Error 2  \n>make: *** [all] Error 2  \n\n解决办法是要么直接在解压目录下cmake，不要mkdir build，要么在CMakeList.txt中搜索doc字符串，在前面加上${PROJECT_SOURCE_DIR}。\n\n### lsyncd.conf\n\n下面都是在编译安装的情况下操作。\n\n#### lsyncd同步配置\n\n\tcd /usr/local/lsyncd-2.1.5\n\tmkdir etc var\n\tvim etc/lsyncd.conf\n\n\tsettings {  \n        logfile      =\"/usr/local/lsyncd-2.1.5/var/  lsyncd.log\",  \n        statusFile   =\"/usr/local/lsyncd-2.1.5/var/  lsyncd.status\",  \n        inotifyMode  = \"CloseWrite\",  \n        maxProcesses = 7,  \n        -- nodaemon =true,  \n        }  \n\n\tsync {  \n\t   default.rsync,  \n\t   source    = \"/tmp/src\", \n\t   target    = \"/tmp/dest\",  \n\t   -- excludeFrom = \"/etc/rsyncd.d/rsync_exclude.lst\",  \n\t   rsync     = {  \n\t        binary    = \"/usr/bin/rsync\",  \n\t        archive   = true,  \n\t        compress  = true,  \n\t        verbose   = true  \n\t        }  \n\t    }  \n\n到这启动 lsycnd 就可以完成实时同步了，默认的许多参数可以满足绝大部分需求，非常简单。\n\n#### lsyncd.conf配置选项说明\n\nsettings\n\n里面是全局设置，--开头表示注释，下面是几个常用选项说明：\n>logfile 定义日志文件  \n>stausFile 定义状态文件  \n>nodaemon=true 表示不启用守护模式，默认  \n>statusInterval 将lsyncd的状态写入上面的statusFile的间隔，默认10秒  \n>inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify  \n>maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而>maxProcesses = 8，则最大能看到有8个rysnc进程  \n>maxDelays 累计到多少所监控的事件激活一次同步，即使后面的delay延迟时间还未到  \n\nsync\n\n里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式：\n\n>>default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程；  \n>>default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份；  \n>>default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证  \n\n>source 同步的源目录，使用绝对路径。  \n>>target 定义目的地址.对应不同的模式有几种写法：   \n>>/tmp/dest ：本地目录同步，可用于direct和rsync模式  \n>>172.29.88.223:/tmp/dest ：同步到远程服务器目录，可用于rsync和rsyncssh模式，拼接的命令类似于/usr/bin/rsync -ltsd --delete --include-from=- --exclude=* SOURCE TARGET，剩下的就是rsync的内容了，比如指定username，免密码同步  \n>>172.29.88.223::module ：同步到远程服务器目录，用于rsync模式\n>  \n>三种模式的示例会在后面给出。\n>init 这是一个优化选项，当init = false，只同步进程启动以后发生改动事件的文件，原有的目录即使有差异也不会同步。默认是true  \n>delay 累计事件，等待rsync同步延时时间，默认15秒（最大累计到1000个不可合并的事件）。也就是15s内监控目录下发生的改动，会累积到一次rsync同步，避免过于频繁的同步。（可合并的意思是，15s内两次修改了同一文件，最后只同步最新的文件）  \n>excludeFrom 排除选项，后面指定排除的列表文件，如excludeFrom = \"/etc/lsyncd.exclude\"，如果是简单的排除，可以使用exclude = LIST。  \n>>这里的排除规则写法与原生rsync有点不同，更为简单：  \n>>监控路径里的任何部分匹配到一个文本，都会被排除，例如/bin/foo/bar可以匹配规则foo\n>>如果规则以斜线/开头，则从头开始要匹配全部\n>>如果规则以/结尾，则要匹配监控路径的末尾\n>>?匹配任何字符，但不包括/\n>>*匹配0或多个字符，但不包括/\n>>**匹配0或多个字符，可以是/  \n>delete 为了保持target与souce完全同步，Lsyncd默认会delete = true来允许同步删除。它除了false，还有startup、running值。\n\nrsync  \n（提示一下，delete和exclude本来都是rsync的选项，上面是配置在sync中的，我想这样做的原因是为了减少rsync的开销）\n\n>bwlimit 限速，单位kb/s，与rsync相同（这么重要的选项在文档里竟然没有标出）  \n>compress 压缩传输默认为true。在带宽与cpu负载之间权衡，本地目录同步可以考虑把它设为false  \n>perms 默认保留文件权限。  \n>其它rsync的选项  \n\n其它还有rsyncssh模式独有的配置项，如host、targetdir、rsync_path、password_file，见后文示例。rsyncOps={\"-avz\",\"--delete\"}这样的写法在2.1.*版本已经不支持。\n\nlsyncd.conf可以有多个sync，各自的source，各自的target，各自的模式，互不影响。\n\n### 启动lsyncd\n\n使用命令加载配置文件，启动守护进程，自动同步目录操作。\n\n\tlsyncd -log Exec /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\n\n### lsyncd.conf其它模式示例\n\n\n以下配置本人都已经过验证可行，必须根据实际需要裁剪配置：\n\n\tsettings {\n    logfile =\"/usr/local/lsyncd-2.1.5/var/lsyncd.log\",\n    statusFile =\"/usr/local/lsyncd-2.1.5/var/lsyncd.status\",\n    inotifyMode = \"CloseWrite\",\n    maxProcesses = 8,\n    }\n\n\n\t-- I. 本地目录同步，direct：cp/rm/mv。 适用：500+万文件，变动不大\n\tsync {\n \t   default.direct,\n \t   source    = \"/tmp/src\",\n \t   target    = \"/tmp/dest\",\n  \t  delay = 1\n  \t  maxProcesses = 1\n \t   }\n\n\t-- II. 本地目录同步，rsync模式：rsync\n\tsync {\n \t   default.rsync,\n \t   source    = \"/tmp/src\",\n  \t  target    = \"/tmp/dest1\",\n  \t  excludeFrom = \"/etc/rsyncd.d/rsync_exclude.lst\",\n  \t  rsync     = {\n  \t      binary = \"/usr/bin/rsync\",\n  \t      archive = true,\n  \t      compress = true,\n  \t      bwlimit   = 2000\n  \t      } \n  \t  }\n\n\t-- III. 远程目录同步，rsync模式 + rsyncd daemon\n\tsync {\n  \t  default.rsync,\n  \t  source    = \"/tmp/src\",\n  \t  target    = \"syncuser@172.29.88.223::module1\",\n  \t  delete=\"running\",\n  \t  exclude = { \".*\", \".tmp\" },\n  \t  delay = 30,\n      init = false,\n  \t  rsync     = {\n   \t     binary = \"/usr/bin/rsync\",\n   \t     archive = true,\n  \t     compress = true,\n  \t     verbose   = true,\n   \t     password_file = \"/etc/rsyncd.d/rsync.pwd\",\n    \t _extra    = {\"--bwlimit=200\"}\n   \t\t     }\n  \t\t }\n\n\t-- IV. 远程目录同步，rsync模式 + ssh shell\n\tsync {\n \t  default.rsync,\n  \t  source    = \"/tmp/src\",\n  \t  target    = \"172.29.88.223:/tmp/dest\",\n   \t  -- target    = \"root@172.29.88.223:/remote/dest\",\n      -- 上面target，注意如果是普通用户，必须拥有写权限\n      maxDelays = 5,\n      delay = 30,\n      -- init = true,\n      rsync     = {\n        binary = \"/usr/bin/rsync\",\n        archive = true,\n        compress = true,\n        bwlimit   = 2000\n        -- rsh = \"/usr/bin/ssh -p 22 -o StrictHostKeyChecking=no\"\n        -- 如果要指定其它端口，请用上面的rsh\n        }\n      } \n\n\t-- V. 远程目录同步，rsync模式 + rsyncssh，效果与上面相同\n\tsync {\n\t    default.rsyncssh,\n\t    source    = \"/tmp/src2\",\n\t    host      = \"172.29.88.223\",\n\t    targetdir = \"/remote/dir\",\n\t    excludeFrom = \"/etc/rsyncd.d/rsync_exclude.lst\",\n\t    -- maxDelays = 5,\n\t    delay = 0,\n\t    -- init = false,\n\t    rsync    = {\n  \t      binary = \"/usr/bin/rsync\",\n  \t      archive = true,\n  \t      compress = true,\n   \t      verbose   = true,\n          _extra = {\"--bwlimit=2000\"},\n  \t      },\n  \t  ssh      = {\n   \t     port  =  1234\n  \t      }\n  \t  }\n\n上面的内容几乎涵盖了所有同步的模式，其中第III个要求像rsync一样配置rsyncd服务端，见本文开头。第IV、V配置ssh方式同步，达到的效果相同，但实际同步时你会发现每次同步都会提示输入ssh的密码，可以通过以下方法解决：\n\n在远端被同步的服务器上开启ssh无密码登录，请注意用户身份：\n\n\tuser$ ssh-keygen -t rsa\n\t一路回车...\n\tuser$ cd ~/.ssh\n\tuser$ cat id_rsa.pub >> authorized_keys\n\n把id_rsa私钥拷贝到执行lsyncd的机器上\n\n\tuser$ chmod 600 ~/.ssh/id_rsa\n\t测试能否无密码登录\n\tuser$ ssh user@172.29.88.223\n\n## lsyncd的其它功能\n\nlsyncd的功能不仅仅是同步，官方手册 [Lsyncd 2.1.x ‖ Layer 2 Config ‖ Advanced onAction](https://axkibe.github.io/lsyncd/) 高级功能提到，还可以监控某个目录下的文件，根据触发的事件自己定义要执行的命令，example是监控某个某个目录，只要是有jpg、gif、png格式的文件参数，就把它们转成pdf，然后同步到另一个目录。正好在我运维的一个项目中有这个需求，现在都是在java代码里转换，还容易出现异常，通过lsyncd可以代替这样的功能。但，门槛在于要会一点点lua语言（根据官方example还是可以写出来）。\n\n另外偶然想到个问题，同时设置了maxDelays和delay，当监控目录一直没有文件变化了，也会发生同步操作，虽然没有可rsync的文件。\n\nTO-DO：\n\n其它同步工具：csync2，clsync，btsync，drdb 。\n\nlsyncd双向同步：[GlusterFS](https://axkibe.github.io/lsyncd/)\n","source":"_posts/lsyncd实时同步.md","raw":"---\ntitle: centos 7 部署 lsyncd 实时同步\ndate: 2017-09-13\ntags: lsync\ncategories: lsync\n---\n## 几大实时同步工具比较\n<!--more-->\n\n### inotify + rsync\n最近一直在寻求生产服务服务器上的同步替代方案，原先使用的是inotify + rsync，但随着文件数量的增大到100W+，目录下的文件列表就达20M，在网络状况不佳或者限速的情况下，变更的文件可能10来个才几M，却因此要发送的文件列表就达20M，严重减低的带宽的使用效率以及同步效率；更为要紧的是，加入inotifywait在5s内监控到10个小文件发生变化，便会触发10个rsync同步操作，结果就是真正需要传输的才2-3M的文件，比对的文件列表就达200M。使用这两个组合的好处在于，它们都是最基本的软件，可以通过不同选项做到很精确的控制，比如排除同步的目录，同步多个模块或同步到多个主机。  \n\n搭建过程参考[linux 下同步工具inotify + rsync 使用详解](http://www.datura.me/2017/09/13/linux_下同步工具inotify_+_rsync_使用详解/)\n\n### sersync\n\n后来听同事说 sersync 这么个工具可以提高同步的性能，也解决了同步大文件时出现异常的问题，所以就尝试了一下。sersync是国内的一个开发者开源出来的，使用c++编写，采用多线程的方式进行同步，失败后还有重传机制，对临时文件过滤，自带crontab定时同步功能。网上看到有人说性能还不错，说一下我的观点：\n>国产开源，文档不是很全，在2011年之后就没更新了（googlecode都要快关闭了，其实可以转交其他人维护），网上关于它的使用和讨论都止于10年了  \n>采用xml配置文件的方式，可读性比较好，但是有些原生的有些功能没有实现就没法使用了  \n>无法实现多目录同步，只能通过多个配置文件启动多个进程  \n>文件排除功能太弱。这个要看需求，不是每个人都需要排除子目录。而对于我的环境中，这个功能很重要，而且排除的规则较多  \n>虽然提供插件的功能，但很鸡肋，因为软件本身没有持续更新，也没有看到贡献有其它插件出现（可能是我知识面不够，还用不到里面的refreshCDN plugin）。\n\n### lsyncd\n\n废话说这么多，本文就是介绍它了。有些博客说lsyncd是谷歌开源的，实际不是了，只是托管在了googlecode上而已，幸运的是已经迁移到github了：  [[https://github.com/826167518/lsyncd]](https://github.com/826167518/lsyncd)\n\nLysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。\n\n实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。\n\n## 使用 lsyncd 本地目录实时备份\n\n这一节实现的功能是，本地目录source实时同步到另一个目录target，而在source下有大量的文件，并且有部分目录和临时文件不需要同步。\n\n### 安装lsyncd\n\n安装lsyncd极为简单，已经收录在ubuntu的官方镜像源里，直接通过apt-get install lsyncd就可以。  \n在Redhat系（我的环境是CentOS 6.2 x86_64 ），可以手动去下载 lsyncd-2.1.5-6.fc21.x86_64.rpm，但首先你得安装两个依赖yum install lua lua-devel。也可以通过在线安装，需要epel-release扩展包：\n\n\t# rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n\t# yum install lsyncd\n\n源码编译安装\n\n从源码编译安装可以使用最新版的lsyncd程序，但必须要相应的依赖库文件和编译工具：  \n\n\tyum install lua lua-devel asciidoc cmake。\n\n\n从 googlecode lsyncd 上下载的lsyncd-2.1.5.tar.gz，直接./configure、make && make install就可以了。\n\n从github上下载[lsyncd-master.zip](https://github.com/axkibe/lsyncd/archive/master.zip) 的2.1.5版本使用的是 cmake 编译工具，无法./configure：\n>uzip lsyncd-master.zip  \n>cd lsyncd-master  \n>cmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncd-2.1.5  \n>make && make install  \n\n我这个版本编译时有个小bug，如果按照INSTALL在build目录中make，会提示：\n\n>[100%] Generating doc/lsyncd.1  \n>Updating the manpage  \n>a2x: failed: source file not found: doc/lsyncd.1.txt  \n>make[2]: *** [doc/lsyncd.1] Error 1  \n>make[1]: *** [CMakeFiles/manpage.dir/all] Error 2  \n>make: *** [all] Error 2  \n\n解决办法是要么直接在解压目录下cmake，不要mkdir build，要么在CMakeList.txt中搜索doc字符串，在前面加上${PROJECT_SOURCE_DIR}。\n\n### lsyncd.conf\n\n下面都是在编译安装的情况下操作。\n\n#### lsyncd同步配置\n\n\tcd /usr/local/lsyncd-2.1.5\n\tmkdir etc var\n\tvim etc/lsyncd.conf\n\n\tsettings {  \n        logfile      =\"/usr/local/lsyncd-2.1.5/var/  lsyncd.log\",  \n        statusFile   =\"/usr/local/lsyncd-2.1.5/var/  lsyncd.status\",  \n        inotifyMode  = \"CloseWrite\",  \n        maxProcesses = 7,  \n        -- nodaemon =true,  \n        }  \n\n\tsync {  \n\t   default.rsync,  \n\t   source    = \"/tmp/src\", \n\t   target    = \"/tmp/dest\",  \n\t   -- excludeFrom = \"/etc/rsyncd.d/rsync_exclude.lst\",  \n\t   rsync     = {  \n\t        binary    = \"/usr/bin/rsync\",  \n\t        archive   = true,  \n\t        compress  = true,  \n\t        verbose   = true  \n\t        }  \n\t    }  \n\n到这启动 lsycnd 就可以完成实时同步了，默认的许多参数可以满足绝大部分需求，非常简单。\n\n#### lsyncd.conf配置选项说明\n\nsettings\n\n里面是全局设置，--开头表示注释，下面是几个常用选项说明：\n>logfile 定义日志文件  \n>stausFile 定义状态文件  \n>nodaemon=true 表示不启用守护模式，默认  \n>statusInterval 将lsyncd的状态写入上面的statusFile的间隔，默认10秒  \n>inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify  \n>maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而>maxProcesses = 8，则最大能看到有8个rysnc进程  \n>maxDelays 累计到多少所监控的事件激活一次同步，即使后面的delay延迟时间还未到  \n\nsync\n\n里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式：\n\n>>default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程；  \n>>default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份；  \n>>default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证  \n\n>source 同步的源目录，使用绝对路径。  \n>>target 定义目的地址.对应不同的模式有几种写法：   \n>>/tmp/dest ：本地目录同步，可用于direct和rsync模式  \n>>172.29.88.223:/tmp/dest ：同步到远程服务器目录，可用于rsync和rsyncssh模式，拼接的命令类似于/usr/bin/rsync -ltsd --delete --include-from=- --exclude=* SOURCE TARGET，剩下的就是rsync的内容了，比如指定username，免密码同步  \n>>172.29.88.223::module ：同步到远程服务器目录，用于rsync模式\n>  \n>三种模式的示例会在后面给出。\n>init 这是一个优化选项，当init = false，只同步进程启动以后发生改动事件的文件，原有的目录即使有差异也不会同步。默认是true  \n>delay 累计事件，等待rsync同步延时时间，默认15秒（最大累计到1000个不可合并的事件）。也就是15s内监控目录下发生的改动，会累积到一次rsync同步，避免过于频繁的同步。（可合并的意思是，15s内两次修改了同一文件，最后只同步最新的文件）  \n>excludeFrom 排除选项，后面指定排除的列表文件，如excludeFrom = \"/etc/lsyncd.exclude\"，如果是简单的排除，可以使用exclude = LIST。  \n>>这里的排除规则写法与原生rsync有点不同，更为简单：  \n>>监控路径里的任何部分匹配到一个文本，都会被排除，例如/bin/foo/bar可以匹配规则foo\n>>如果规则以斜线/开头，则从头开始要匹配全部\n>>如果规则以/结尾，则要匹配监控路径的末尾\n>>?匹配任何字符，但不包括/\n>>*匹配0或多个字符，但不包括/\n>>**匹配0或多个字符，可以是/  \n>delete 为了保持target与souce完全同步，Lsyncd默认会delete = true来允许同步删除。它除了false，还有startup、running值。\n\nrsync  \n（提示一下，delete和exclude本来都是rsync的选项，上面是配置在sync中的，我想这样做的原因是为了减少rsync的开销）\n\n>bwlimit 限速，单位kb/s，与rsync相同（这么重要的选项在文档里竟然没有标出）  \n>compress 压缩传输默认为true。在带宽与cpu负载之间权衡，本地目录同步可以考虑把它设为false  \n>perms 默认保留文件权限。  \n>其它rsync的选项  \n\n其它还有rsyncssh模式独有的配置项，如host、targetdir、rsync_path、password_file，见后文示例。rsyncOps={\"-avz\",\"--delete\"}这样的写法在2.1.*版本已经不支持。\n\nlsyncd.conf可以有多个sync，各自的source，各自的target，各自的模式，互不影响。\n\n### 启动lsyncd\n\n使用命令加载配置文件，启动守护进程，自动同步目录操作。\n\n\tlsyncd -log Exec /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\n\n### lsyncd.conf其它模式示例\n\n\n以下配置本人都已经过验证可行，必须根据实际需要裁剪配置：\n\n\tsettings {\n    logfile =\"/usr/local/lsyncd-2.1.5/var/lsyncd.log\",\n    statusFile =\"/usr/local/lsyncd-2.1.5/var/lsyncd.status\",\n    inotifyMode = \"CloseWrite\",\n    maxProcesses = 8,\n    }\n\n\n\t-- I. 本地目录同步，direct：cp/rm/mv。 适用：500+万文件，变动不大\n\tsync {\n \t   default.direct,\n \t   source    = \"/tmp/src\",\n \t   target    = \"/tmp/dest\",\n  \t  delay = 1\n  \t  maxProcesses = 1\n \t   }\n\n\t-- II. 本地目录同步，rsync模式：rsync\n\tsync {\n \t   default.rsync,\n \t   source    = \"/tmp/src\",\n  \t  target    = \"/tmp/dest1\",\n  \t  excludeFrom = \"/etc/rsyncd.d/rsync_exclude.lst\",\n  \t  rsync     = {\n  \t      binary = \"/usr/bin/rsync\",\n  \t      archive = true,\n  \t      compress = true,\n  \t      bwlimit   = 2000\n  \t      } \n  \t  }\n\n\t-- III. 远程目录同步，rsync模式 + rsyncd daemon\n\tsync {\n  \t  default.rsync,\n  \t  source    = \"/tmp/src\",\n  \t  target    = \"syncuser@172.29.88.223::module1\",\n  \t  delete=\"running\",\n  \t  exclude = { \".*\", \".tmp\" },\n  \t  delay = 30,\n      init = false,\n  \t  rsync     = {\n   \t     binary = \"/usr/bin/rsync\",\n   \t     archive = true,\n  \t     compress = true,\n  \t     verbose   = true,\n   \t     password_file = \"/etc/rsyncd.d/rsync.pwd\",\n    \t _extra    = {\"--bwlimit=200\"}\n   \t\t     }\n  \t\t }\n\n\t-- IV. 远程目录同步，rsync模式 + ssh shell\n\tsync {\n \t  default.rsync,\n  \t  source    = \"/tmp/src\",\n  \t  target    = \"172.29.88.223:/tmp/dest\",\n   \t  -- target    = \"root@172.29.88.223:/remote/dest\",\n      -- 上面target，注意如果是普通用户，必须拥有写权限\n      maxDelays = 5,\n      delay = 30,\n      -- init = true,\n      rsync     = {\n        binary = \"/usr/bin/rsync\",\n        archive = true,\n        compress = true,\n        bwlimit   = 2000\n        -- rsh = \"/usr/bin/ssh -p 22 -o StrictHostKeyChecking=no\"\n        -- 如果要指定其它端口，请用上面的rsh\n        }\n      } \n\n\t-- V. 远程目录同步，rsync模式 + rsyncssh，效果与上面相同\n\tsync {\n\t    default.rsyncssh,\n\t    source    = \"/tmp/src2\",\n\t    host      = \"172.29.88.223\",\n\t    targetdir = \"/remote/dir\",\n\t    excludeFrom = \"/etc/rsyncd.d/rsync_exclude.lst\",\n\t    -- maxDelays = 5,\n\t    delay = 0,\n\t    -- init = false,\n\t    rsync    = {\n  \t      binary = \"/usr/bin/rsync\",\n  \t      archive = true,\n  \t      compress = true,\n   \t      verbose   = true,\n          _extra = {\"--bwlimit=2000\"},\n  \t      },\n  \t  ssh      = {\n   \t     port  =  1234\n  \t      }\n  \t  }\n\n上面的内容几乎涵盖了所有同步的模式，其中第III个要求像rsync一样配置rsyncd服务端，见本文开头。第IV、V配置ssh方式同步，达到的效果相同，但实际同步时你会发现每次同步都会提示输入ssh的密码，可以通过以下方法解决：\n\n在远端被同步的服务器上开启ssh无密码登录，请注意用户身份：\n\n\tuser$ ssh-keygen -t rsa\n\t一路回车...\n\tuser$ cd ~/.ssh\n\tuser$ cat id_rsa.pub >> authorized_keys\n\n把id_rsa私钥拷贝到执行lsyncd的机器上\n\n\tuser$ chmod 600 ~/.ssh/id_rsa\n\t测试能否无密码登录\n\tuser$ ssh user@172.29.88.223\n\n## lsyncd的其它功能\n\nlsyncd的功能不仅仅是同步，官方手册 [Lsyncd 2.1.x ‖ Layer 2 Config ‖ Advanced onAction](https://axkibe.github.io/lsyncd/) 高级功能提到，还可以监控某个目录下的文件，根据触发的事件自己定义要执行的命令，example是监控某个某个目录，只要是有jpg、gif、png格式的文件参数，就把它们转成pdf，然后同步到另一个目录。正好在我运维的一个项目中有这个需求，现在都是在java代码里转换，还容易出现异常，通过lsyncd可以代替这样的功能。但，门槛在于要会一点点lua语言（根据官方example还是可以写出来）。\n\n另外偶然想到个问题，同时设置了maxDelays和delay，当监控目录一直没有文件变化了，也会发生同步操作，虽然没有可rsync的文件。\n\nTO-DO：\n\n其它同步工具：csync2，clsync，btsync，drdb 。\n\nlsyncd双向同步：[GlusterFS](https://axkibe.github.io/lsyncd/)\n","slug":"lsyncd实时同步","published":1,"updated":"2019-06-18T08:07:01.116Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sla001ehcb7efldu6mz","content":"<h2 id=\"几大实时同步工具比较\"><a href=\"#几大实时同步工具比较\" class=\"headerlink\" title=\"几大实时同步工具比较\"></a>几大实时同步工具比较</h2><a id=\"more\"></a>\n<h3 id=\"inotify-rsync\"><a href=\"#inotify-rsync\" class=\"headerlink\" title=\"inotify + rsync\"></a>inotify + rsync</h3><p>最近一直在寻求生产服务服务器上的同步替代方案，原先使用的是inotify + rsync，但随着文件数量的增大到100W+，目录下的文件列表就达20M，在网络状况不佳或者限速的情况下，变更的文件可能10来个才几M，却因此要发送的文件列表就达20M，严重减低的带宽的使用效率以及同步效率；更为要紧的是，加入inotifywait在5s内监控到10个小文件发生变化，便会触发10个rsync同步操作，结果就是真正需要传输的才2-3M的文件，比对的文件列表就达200M。使用这两个组合的好处在于，它们都是最基本的软件，可以通过不同选项做到很精确的控制，比如排除同步的目录，同步多个模块或同步到多个主机。  </p>\n<p>搭建过程参考<a href=\"http://www.datura.me/2017/09/13/linux_下同步工具inotify_+_rsync_使用详解/\" target=\"_blank\" rel=\"noopener\">linux 下同步工具inotify + rsync 使用详解</a></p>\n<h3 id=\"sersync\"><a href=\"#sersync\" class=\"headerlink\" title=\"sersync\"></a>sersync</h3><p>后来听同事说 sersync 这么个工具可以提高同步的性能，也解决了同步大文件时出现异常的问题，所以就尝试了一下。sersync是国内的一个开发者开源出来的，使用c++编写，采用多线程的方式进行同步，失败后还有重传机制，对临时文件过滤，自带crontab定时同步功能。网上看到有人说性能还不错，说一下我的观点：</p>\n<blockquote>\n<p>国产开源，文档不是很全，在2011年之后就没更新了（googlecode都要快关闭了，其实可以转交其他人维护），网上关于它的使用和讨论都止于10年了<br>采用xml配置文件的方式，可读性比较好，但是有些原生的有些功能没有实现就没法使用了<br>无法实现多目录同步，只能通过多个配置文件启动多个进程<br>文件排除功能太弱。这个要看需求，不是每个人都需要排除子目录。而对于我的环境中，这个功能很重要，而且排除的规则较多<br>虽然提供插件的功能，但很鸡肋，因为软件本身没有持续更新，也没有看到贡献有其它插件出现（可能是我知识面不够，还用不到里面的refreshCDN plugin）。</p>\n</blockquote>\n<h3 id=\"lsyncd\"><a href=\"#lsyncd\" class=\"headerlink\" title=\"lsyncd\"></a>lsyncd</h3><p>废话说这么多，本文就是介绍它了。有些博客说lsyncd是谷歌开源的，实际不是了，只是托管在了googlecode上而已，幸运的是已经迁移到github了：  <a href=\"https://github.com/826167518/lsyncd\" target=\"_blank\" rel=\"noopener\">[https://github.com/826167518/lsyncd]</a></p>\n<p>Lysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。</p>\n<p>实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。</p>\n<h2 id=\"使用-lsyncd-本地目录实时备份\"><a href=\"#使用-lsyncd-本地目录实时备份\" class=\"headerlink\" title=\"使用 lsyncd 本地目录实时备份\"></a>使用 lsyncd 本地目录实时备份</h2><p>这一节实现的功能是，本地目录source实时同步到另一个目录target，而在source下有大量的文件，并且有部分目录和临时文件不需要同步。</p>\n<h3 id=\"安装lsyncd\"><a href=\"#安装lsyncd\" class=\"headerlink\" title=\"安装lsyncd\"></a>安装lsyncd</h3><p>安装lsyncd极为简单，已经收录在ubuntu的官方镜像源里，直接通过apt-get install lsyncd就可以。<br>在Redhat系（我的环境是CentOS 6.2 x86_64 ），可以手动去下载 lsyncd-2.1.5-6.fc21.x86_64.rpm，但首先你得安装两个依赖yum install lua lua-devel。也可以通过在线安装，需要epel-release扩展包：</p>\n<pre><code># rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n# yum install lsyncd\n</code></pre><p>源码编译安装</p>\n<p>从源码编译安装可以使用最新版的lsyncd程序，但必须要相应的依赖库文件和编译工具：  </p>\n<pre><code>yum install lua lua-devel asciidoc cmake。\n</code></pre><p>从 googlecode lsyncd 上下载的lsyncd-2.1.5.tar.gz，直接./configure、make &amp;&amp; make install就可以了。</p>\n<p>从github上下载<a href=\"https://github.com/axkibe/lsyncd/archive/master.zip\" target=\"_blank\" rel=\"noopener\">lsyncd-master.zip</a> 的2.1.5版本使用的是 cmake 编译工具，无法./configure：</p>\n<blockquote>\n<p>uzip lsyncd-master.zip<br>cd lsyncd-master<br>cmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncd-2.1.5<br>make &amp;&amp; make install  </p>\n</blockquote>\n<p>我这个版本编译时有个小bug，如果按照INSTALL在build目录中make，会提示：</p>\n<blockquote>\n<p>[100%] Generating doc/lsyncd.1<br>Updating the manpage<br>a2x: failed: source file not found: doc/lsyncd.1.txt<br>make[2]: <strong><em> [doc/lsyncd.1] Error 1<br>make[1]: </em></strong> [CMakeFiles/manpage.dir/all] Error 2<br>make: *** [all] Error 2  </p>\n</blockquote>\n<p>解决办法是要么直接在解压目录下cmake，不要mkdir build，要么在CMakeList.txt中搜索doc字符串，在前面加上${PROJECT_SOURCE_DIR}。</p>\n<h3 id=\"lsyncd-conf\"><a href=\"#lsyncd-conf\" class=\"headerlink\" title=\"lsyncd.conf\"></a>lsyncd.conf</h3><p>下面都是在编译安装的情况下操作。</p>\n<h4 id=\"lsyncd同步配置\"><a href=\"#lsyncd同步配置\" class=\"headerlink\" title=\"lsyncd同步配置\"></a>lsyncd同步配置</h4><pre><code>cd /usr/local/lsyncd-2.1.5\nmkdir etc var\nvim etc/lsyncd.conf\n\nsettings {  \n    logfile      =&quot;/usr/local/lsyncd-2.1.5/var/  lsyncd.log&quot;,  \n    statusFile   =&quot;/usr/local/lsyncd-2.1.5/var/  lsyncd.status&quot;,  \n    inotifyMode  = &quot;CloseWrite&quot;,  \n    maxProcesses = 7,  \n    -- nodaemon =true,  \n    }  \n\nsync {  \n   default.rsync,  \n   source    = &quot;/tmp/src&quot;, \n   target    = &quot;/tmp/dest&quot;,  \n   -- excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;,  \n   rsync     = {  \n        binary    = &quot;/usr/bin/rsync&quot;,  \n        archive   = true,  \n        compress  = true,  \n        verbose   = true  \n        }  \n    }  \n</code></pre><p>到这启动 lsycnd 就可以完成实时同步了，默认的许多参数可以满足绝大部分需求，非常简单。</p>\n<h4 id=\"lsyncd-conf配置选项说明\"><a href=\"#lsyncd-conf配置选项说明\" class=\"headerlink\" title=\"lsyncd.conf配置选项说明\"></a>lsyncd.conf配置选项说明</h4><p>settings</p>\n<p>里面是全局设置，–开头表示注释，下面是几个常用选项说明：</p>\n<blockquote>\n<p>logfile 定义日志文件<br>stausFile 定义状态文件<br>nodaemon=true 表示不启用守护模式，默认<br>statusInterval 将lsyncd的状态写入上面的statusFile的间隔，默认10秒<br>inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify<br>maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而&gt;maxProcesses = 8，则最大能看到有8个rysnc进程<br>maxDelays 累计到多少所监控的事件激活一次同步，即使后面的delay延迟时间还未到  </p>\n</blockquote>\n<p>sync</p>\n<p>里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式：</p>\n<blockquote>\n<blockquote>\n<p>default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程；<br>default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份；<br>default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证  </p>\n</blockquote>\n</blockquote>\n<blockquote>\n<p>source 同步的源目录，使用绝对路径。  </p>\n<blockquote>\n<p>target 定义目的地址.对应不同的模式有几种写法：<br>/tmp/dest ：本地目录同步，可用于direct和rsync模式<br>172.29.88.223:/tmp/dest ：同步到远程服务器目录，可用于rsync和rsyncssh模式，拼接的命令类似于/usr/bin/rsync -ltsd –delete –include-from=- –exclude=* SOURCE TARGET，剩下的就是rsync的内容了，比如指定username，免密码同步<br>172.29.88.223::module ：同步到远程服务器目录，用于rsync模式</p>\n</blockquote>\n<p>三种模式的示例会在后面给出。<br>init 这是一个优化选项，当init = false，只同步进程启动以后发生改动事件的文件，原有的目录即使有差异也不会同步。默认是true<br>delay 累计事件，等待rsync同步延时时间，默认15秒（最大累计到1000个不可合并的事件）。也就是15s内监控目录下发生的改动，会累积到一次rsync同步，避免过于频繁的同步。（可合并的意思是，15s内两次修改了同一文件，最后只同步最新的文件）<br>excludeFrom 排除选项，后面指定排除的列表文件，如excludeFrom = “/etc/lsyncd.exclude”，如果是简单的排除，可以使用exclude = LIST。  </p>\n<blockquote>\n<p>这里的排除规则写法与原生rsync有点不同，更为简单：<br>监控路径里的任何部分匹配到一个文本，都会被排除，例如/bin/foo/bar可以匹配规则foo<br>如果规则以斜线/开头，则从头开始要匹配全部<br>如果规则以/结尾，则要匹配监控路径的末尾<br>?匹配任何字符，但不包括/<br>*匹配0或多个字符，但不包括/<br>**匹配0或多个字符，可以是/<br>delete 为了保持target与souce完全同步，Lsyncd默认会delete = true来允许同步删除。它除了false，还有startup、running值。</p>\n</blockquote>\n</blockquote>\n<p>rsync<br>（提示一下，delete和exclude本来都是rsync的选项，上面是配置在sync中的，我想这样做的原因是为了减少rsync的开销）</p>\n<blockquote>\n<p>bwlimit 限速，单位kb/s，与rsync相同（这么重要的选项在文档里竟然没有标出）<br>compress 压缩传输默认为true。在带宽与cpu负载之间权衡，本地目录同步可以考虑把它设为false<br>perms 默认保留文件权限。<br>其它rsync的选项  </p>\n</blockquote>\n<p>其它还有rsyncssh模式独有的配置项，如host、targetdir、rsync_path、password_file，见后文示例。rsyncOps={“-avz”,”–delete”}这样的写法在2.1.*版本已经不支持。</p>\n<p>lsyncd.conf可以有多个sync，各自的source，各自的target，各自的模式，互不影响。</p>\n<h3 id=\"启动lsyncd\"><a href=\"#启动lsyncd\" class=\"headerlink\" title=\"启动lsyncd\"></a>启动lsyncd</h3><p>使用命令加载配置文件，启动守护进程，自动同步目录操作。</p>\n<pre><code>lsyncd -log Exec /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\n</code></pre><h3 id=\"lsyncd-conf其它模式示例\"><a href=\"#lsyncd-conf其它模式示例\" class=\"headerlink\" title=\"lsyncd.conf其它模式示例\"></a>lsyncd.conf其它模式示例</h3><p>以下配置本人都已经过验证可行，必须根据实际需要裁剪配置：</p>\n<pre><code>settings {\nlogfile =&quot;/usr/local/lsyncd-2.1.5/var/lsyncd.log&quot;,\nstatusFile =&quot;/usr/local/lsyncd-2.1.5/var/lsyncd.status&quot;,\ninotifyMode = &quot;CloseWrite&quot;,\nmaxProcesses = 8,\n}\n\n\n-- I. 本地目录同步，direct：cp/rm/mv。 适用：500+万文件，变动不大\nsync {\n    default.direct,\n    source    = &quot;/tmp/src&quot;,\n    target    = &quot;/tmp/dest&quot;,\n    delay = 1\n    maxProcesses = 1\n    }\n\n-- II. 本地目录同步，rsync模式：rsync\nsync {\n    default.rsync,\n    source    = &quot;/tmp/src&quot;,\n    target    = &quot;/tmp/dest1&quot;,\n    excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;,\n    rsync     = {\n        binary = &quot;/usr/bin/rsync&quot;,\n        archive = true,\n        compress = true,\n        bwlimit   = 2000\n        } \n    }\n\n-- III. 远程目录同步，rsync模式 + rsyncd daemon\nsync {\n    default.rsync,\n    source    = &quot;/tmp/src&quot;,\n    target    = &quot;syncuser@172.29.88.223::module1&quot;,\n    delete=&quot;running&quot;,\n    exclude = { &quot;.*&quot;, &quot;.tmp&quot; },\n    delay = 30,\n  init = false,\n    rsync     = {\n        binary = &quot;/usr/bin/rsync&quot;,\n        archive = true,\n       compress = true,\n       verbose   = true,\n        password_file = &quot;/etc/rsyncd.d/rsync.pwd&quot;,\n     _extra    = {&quot;--bwlimit=200&quot;}\n            }\n       }\n\n-- IV. 远程目录同步，rsync模式 + ssh shell\nsync {\n   default.rsync,\n    source    = &quot;/tmp/src&quot;,\n    target    = &quot;172.29.88.223:/tmp/dest&quot;,\n     -- target    = &quot;root@172.29.88.223:/remote/dest&quot;,\n  -- 上面target，注意如果是普通用户，必须拥有写权限\n  maxDelays = 5,\n  delay = 30,\n  -- init = true,\n  rsync     = {\n    binary = &quot;/usr/bin/rsync&quot;,\n    archive = true,\n    compress = true,\n    bwlimit   = 2000\n    -- rsh = &quot;/usr/bin/ssh -p 22 -o StrictHostKeyChecking=no&quot;\n    -- 如果要指定其它端口，请用上面的rsh\n    }\n  } \n\n-- V. 远程目录同步，rsync模式 + rsyncssh，效果与上面相同\nsync {\n    default.rsyncssh,\n    source    = &quot;/tmp/src2&quot;,\n    host      = &quot;172.29.88.223&quot;,\n    targetdir = &quot;/remote/dir&quot;,\n    excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;,\n    -- maxDelays = 5,\n    delay = 0,\n    -- init = false,\n    rsync    = {\n        binary = &quot;/usr/bin/rsync&quot;,\n        archive = true,\n        compress = true,\n         verbose   = true,\n      _extra = {&quot;--bwlimit=2000&quot;},\n        },\n    ssh      = {\n        port  =  1234\n        }\n    }\n</code></pre><p>上面的内容几乎涵盖了所有同步的模式，其中第III个要求像rsync一样配置rsyncd服务端，见本文开头。第IV、V配置ssh方式同步，达到的效果相同，但实际同步时你会发现每次同步都会提示输入ssh的密码，可以通过以下方法解决：</p>\n<p>在远端被同步的服务器上开启ssh无密码登录，请注意用户身份：</p>\n<pre><code>user$ ssh-keygen -t rsa\n一路回车...\nuser$ cd ~/.ssh\nuser$ cat id_rsa.pub &gt;&gt; authorized_keys\n</code></pre><p>把id_rsa私钥拷贝到执行lsyncd的机器上</p>\n<pre><code>user$ chmod 600 ~/.ssh/id_rsa\n测试能否无密码登录\nuser$ ssh user@172.29.88.223\n</code></pre><h2 id=\"lsyncd的其它功能\"><a href=\"#lsyncd的其它功能\" class=\"headerlink\" title=\"lsyncd的其它功能\"></a>lsyncd的其它功能</h2><p>lsyncd的功能不仅仅是同步，官方手册 <a href=\"https://axkibe.github.io/lsyncd/\" target=\"_blank\" rel=\"noopener\">Lsyncd 2.1.x ‖ Layer 2 Config ‖ Advanced onAction</a> 高级功能提到，还可以监控某个目录下的文件，根据触发的事件自己定义要执行的命令，example是监控某个某个目录，只要是有jpg、gif、png格式的文件参数，就把它们转成pdf，然后同步到另一个目录。正好在我运维的一个项目中有这个需求，现在都是在java代码里转换，还容易出现异常，通过lsyncd可以代替这样的功能。但，门槛在于要会一点点lua语言（根据官方example还是可以写出来）。</p>\n<p>另外偶然想到个问题，同时设置了maxDelays和delay，当监控目录一直没有文件变化了，也会发生同步操作，虽然没有可rsync的文件。</p>\n<p>TO-DO：</p>\n<p>其它同步工具：csync2，clsync，btsync，drdb 。</p>\n<p>lsyncd双向同步：<a href=\"https://axkibe.github.io/lsyncd/\" target=\"_blank\" rel=\"noopener\">GlusterFS</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"几大实时同步工具比较\"><a href=\"#几大实时同步工具比较\" class=\"headerlink\" title=\"几大实时同步工具比较\"></a>几大实时同步工具比较</h2>","more":"<h3 id=\"inotify-rsync\"><a href=\"#inotify-rsync\" class=\"headerlink\" title=\"inotify + rsync\"></a>inotify + rsync</h3><p>最近一直在寻求生产服务服务器上的同步替代方案，原先使用的是inotify + rsync，但随着文件数量的增大到100W+，目录下的文件列表就达20M，在网络状况不佳或者限速的情况下，变更的文件可能10来个才几M，却因此要发送的文件列表就达20M，严重减低的带宽的使用效率以及同步效率；更为要紧的是，加入inotifywait在5s内监控到10个小文件发生变化，便会触发10个rsync同步操作，结果就是真正需要传输的才2-3M的文件，比对的文件列表就达200M。使用这两个组合的好处在于，它们都是最基本的软件，可以通过不同选项做到很精确的控制，比如排除同步的目录，同步多个模块或同步到多个主机。  </p>\n<p>搭建过程参考<a href=\"http://www.datura.me/2017/09/13/linux_下同步工具inotify_+_rsync_使用详解/\" target=\"_blank\" rel=\"noopener\">linux 下同步工具inotify + rsync 使用详解</a></p>\n<h3 id=\"sersync\"><a href=\"#sersync\" class=\"headerlink\" title=\"sersync\"></a>sersync</h3><p>后来听同事说 sersync 这么个工具可以提高同步的性能，也解决了同步大文件时出现异常的问题，所以就尝试了一下。sersync是国内的一个开发者开源出来的，使用c++编写，采用多线程的方式进行同步，失败后还有重传机制，对临时文件过滤，自带crontab定时同步功能。网上看到有人说性能还不错，说一下我的观点：</p>\n<blockquote>\n<p>国产开源，文档不是很全，在2011年之后就没更新了（googlecode都要快关闭了，其实可以转交其他人维护），网上关于它的使用和讨论都止于10年了<br>采用xml配置文件的方式，可读性比较好，但是有些原生的有些功能没有实现就没法使用了<br>无法实现多目录同步，只能通过多个配置文件启动多个进程<br>文件排除功能太弱。这个要看需求，不是每个人都需要排除子目录。而对于我的环境中，这个功能很重要，而且排除的规则较多<br>虽然提供插件的功能，但很鸡肋，因为软件本身没有持续更新，也没有看到贡献有其它插件出现（可能是我知识面不够，还用不到里面的refreshCDN plugin）。</p>\n</blockquote>\n<h3 id=\"lsyncd\"><a href=\"#lsyncd\" class=\"headerlink\" title=\"lsyncd\"></a>lsyncd</h3><p>废话说这么多，本文就是介绍它了。有些博客说lsyncd是谷歌开源的，实际不是了，只是托管在了googlecode上而已，幸运的是已经迁移到github了：  <a href=\"https://github.com/826167518/lsyncd\" target=\"_blank\" rel=\"noopener\">[https://github.com/826167518/lsyncd]</a></p>\n<p>Lysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。</p>\n<p>实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。</p>\n<h2 id=\"使用-lsyncd-本地目录实时备份\"><a href=\"#使用-lsyncd-本地目录实时备份\" class=\"headerlink\" title=\"使用 lsyncd 本地目录实时备份\"></a>使用 lsyncd 本地目录实时备份</h2><p>这一节实现的功能是，本地目录source实时同步到另一个目录target，而在source下有大量的文件，并且有部分目录和临时文件不需要同步。</p>\n<h3 id=\"安装lsyncd\"><a href=\"#安装lsyncd\" class=\"headerlink\" title=\"安装lsyncd\"></a>安装lsyncd</h3><p>安装lsyncd极为简单，已经收录在ubuntu的官方镜像源里，直接通过apt-get install lsyncd就可以。<br>在Redhat系（我的环境是CentOS 6.2 x86_64 ），可以手动去下载 lsyncd-2.1.5-6.fc21.x86_64.rpm，但首先你得安装两个依赖yum install lua lua-devel。也可以通过在线安装，需要epel-release扩展包：</p>\n<pre><code># rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n# yum install lsyncd\n</code></pre><p>源码编译安装</p>\n<p>从源码编译安装可以使用最新版的lsyncd程序，但必须要相应的依赖库文件和编译工具：  </p>\n<pre><code>yum install lua lua-devel asciidoc cmake。\n</code></pre><p>从 googlecode lsyncd 上下载的lsyncd-2.1.5.tar.gz，直接./configure、make &amp;&amp; make install就可以了。</p>\n<p>从github上下载<a href=\"https://github.com/axkibe/lsyncd/archive/master.zip\" target=\"_blank\" rel=\"noopener\">lsyncd-master.zip</a> 的2.1.5版本使用的是 cmake 编译工具，无法./configure：</p>\n<blockquote>\n<p>uzip lsyncd-master.zip<br>cd lsyncd-master<br>cmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncd-2.1.5<br>make &amp;&amp; make install  </p>\n</blockquote>\n<p>我这个版本编译时有个小bug，如果按照INSTALL在build目录中make，会提示：</p>\n<blockquote>\n<p>[100%] Generating doc/lsyncd.1<br>Updating the manpage<br>a2x: failed: source file not found: doc/lsyncd.1.txt<br>make[2]: <strong><em> [doc/lsyncd.1] Error 1<br>make[1]: </em></strong> [CMakeFiles/manpage.dir/all] Error 2<br>make: *** [all] Error 2  </p>\n</blockquote>\n<p>解决办法是要么直接在解压目录下cmake，不要mkdir build，要么在CMakeList.txt中搜索doc字符串，在前面加上${PROJECT_SOURCE_DIR}。</p>\n<h3 id=\"lsyncd-conf\"><a href=\"#lsyncd-conf\" class=\"headerlink\" title=\"lsyncd.conf\"></a>lsyncd.conf</h3><p>下面都是在编译安装的情况下操作。</p>\n<h4 id=\"lsyncd同步配置\"><a href=\"#lsyncd同步配置\" class=\"headerlink\" title=\"lsyncd同步配置\"></a>lsyncd同步配置</h4><pre><code>cd /usr/local/lsyncd-2.1.5\nmkdir etc var\nvim etc/lsyncd.conf\n\nsettings {  \n    logfile      =&quot;/usr/local/lsyncd-2.1.5/var/  lsyncd.log&quot;,  \n    statusFile   =&quot;/usr/local/lsyncd-2.1.5/var/  lsyncd.status&quot;,  \n    inotifyMode  = &quot;CloseWrite&quot;,  \n    maxProcesses = 7,  \n    -- nodaemon =true,  \n    }  \n\nsync {  \n   default.rsync,  \n   source    = &quot;/tmp/src&quot;, \n   target    = &quot;/tmp/dest&quot;,  \n   -- excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;,  \n   rsync     = {  \n        binary    = &quot;/usr/bin/rsync&quot;,  \n        archive   = true,  \n        compress  = true,  \n        verbose   = true  \n        }  \n    }  \n</code></pre><p>到这启动 lsycnd 就可以完成实时同步了，默认的许多参数可以满足绝大部分需求，非常简单。</p>\n<h4 id=\"lsyncd-conf配置选项说明\"><a href=\"#lsyncd-conf配置选项说明\" class=\"headerlink\" title=\"lsyncd.conf配置选项说明\"></a>lsyncd.conf配置选项说明</h4><p>settings</p>\n<p>里面是全局设置，–开头表示注释，下面是几个常用选项说明：</p>\n<blockquote>\n<p>logfile 定义日志文件<br>stausFile 定义状态文件<br>nodaemon=true 表示不启用守护模式，默认<br>statusInterval 将lsyncd的状态写入上面的statusFile的间隔，默认10秒<br>inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify<br>maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而&gt;maxProcesses = 8，则最大能看到有8个rysnc进程<br>maxDelays 累计到多少所监控的事件激活一次同步，即使后面的delay延迟时间还未到  </p>\n</blockquote>\n<p>sync</p>\n<p>里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式：</p>\n<blockquote>\n<blockquote>\n<p>default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程；<br>default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份；<br>default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证  </p>\n</blockquote>\n</blockquote>\n<blockquote>\n<p>source 同步的源目录，使用绝对路径。  </p>\n<blockquote>\n<p>target 定义目的地址.对应不同的模式有几种写法：<br>/tmp/dest ：本地目录同步，可用于direct和rsync模式<br>172.29.88.223:/tmp/dest ：同步到远程服务器目录，可用于rsync和rsyncssh模式，拼接的命令类似于/usr/bin/rsync -ltsd –delete –include-from=- –exclude=* SOURCE TARGET，剩下的就是rsync的内容了，比如指定username，免密码同步<br>172.29.88.223::module ：同步到远程服务器目录，用于rsync模式</p>\n</blockquote>\n<p>三种模式的示例会在后面给出。<br>init 这是一个优化选项，当init = false，只同步进程启动以后发生改动事件的文件，原有的目录即使有差异也不会同步。默认是true<br>delay 累计事件，等待rsync同步延时时间，默认15秒（最大累计到1000个不可合并的事件）。也就是15s内监控目录下发生的改动，会累积到一次rsync同步，避免过于频繁的同步。（可合并的意思是，15s内两次修改了同一文件，最后只同步最新的文件）<br>excludeFrom 排除选项，后面指定排除的列表文件，如excludeFrom = “/etc/lsyncd.exclude”，如果是简单的排除，可以使用exclude = LIST。  </p>\n<blockquote>\n<p>这里的排除规则写法与原生rsync有点不同，更为简单：<br>监控路径里的任何部分匹配到一个文本，都会被排除，例如/bin/foo/bar可以匹配规则foo<br>如果规则以斜线/开头，则从头开始要匹配全部<br>如果规则以/结尾，则要匹配监控路径的末尾<br>?匹配任何字符，但不包括/<br>*匹配0或多个字符，但不包括/<br>**匹配0或多个字符，可以是/<br>delete 为了保持target与souce完全同步，Lsyncd默认会delete = true来允许同步删除。它除了false，还有startup、running值。</p>\n</blockquote>\n</blockquote>\n<p>rsync<br>（提示一下，delete和exclude本来都是rsync的选项，上面是配置在sync中的，我想这样做的原因是为了减少rsync的开销）</p>\n<blockquote>\n<p>bwlimit 限速，单位kb/s，与rsync相同（这么重要的选项在文档里竟然没有标出）<br>compress 压缩传输默认为true。在带宽与cpu负载之间权衡，本地目录同步可以考虑把它设为false<br>perms 默认保留文件权限。<br>其它rsync的选项  </p>\n</blockquote>\n<p>其它还有rsyncssh模式独有的配置项，如host、targetdir、rsync_path、password_file，见后文示例。rsyncOps={“-avz”,”–delete”}这样的写法在2.1.*版本已经不支持。</p>\n<p>lsyncd.conf可以有多个sync，各自的source，各自的target，各自的模式，互不影响。</p>\n<h3 id=\"启动lsyncd\"><a href=\"#启动lsyncd\" class=\"headerlink\" title=\"启动lsyncd\"></a>启动lsyncd</h3><p>使用命令加载配置文件，启动守护进程，自动同步目录操作。</p>\n<pre><code>lsyncd -log Exec /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\n</code></pre><h3 id=\"lsyncd-conf其它模式示例\"><a href=\"#lsyncd-conf其它模式示例\" class=\"headerlink\" title=\"lsyncd.conf其它模式示例\"></a>lsyncd.conf其它模式示例</h3><p>以下配置本人都已经过验证可行，必须根据实际需要裁剪配置：</p>\n<pre><code>settings {\nlogfile =&quot;/usr/local/lsyncd-2.1.5/var/lsyncd.log&quot;,\nstatusFile =&quot;/usr/local/lsyncd-2.1.5/var/lsyncd.status&quot;,\ninotifyMode = &quot;CloseWrite&quot;,\nmaxProcesses = 8,\n}\n\n\n-- I. 本地目录同步，direct：cp/rm/mv。 适用：500+万文件，变动不大\nsync {\n    default.direct,\n    source    = &quot;/tmp/src&quot;,\n    target    = &quot;/tmp/dest&quot;,\n    delay = 1\n    maxProcesses = 1\n    }\n\n-- II. 本地目录同步，rsync模式：rsync\nsync {\n    default.rsync,\n    source    = &quot;/tmp/src&quot;,\n    target    = &quot;/tmp/dest1&quot;,\n    excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;,\n    rsync     = {\n        binary = &quot;/usr/bin/rsync&quot;,\n        archive = true,\n        compress = true,\n        bwlimit   = 2000\n        } \n    }\n\n-- III. 远程目录同步，rsync模式 + rsyncd daemon\nsync {\n    default.rsync,\n    source    = &quot;/tmp/src&quot;,\n    target    = &quot;syncuser@172.29.88.223::module1&quot;,\n    delete=&quot;running&quot;,\n    exclude = { &quot;.*&quot;, &quot;.tmp&quot; },\n    delay = 30,\n  init = false,\n    rsync     = {\n        binary = &quot;/usr/bin/rsync&quot;,\n        archive = true,\n       compress = true,\n       verbose   = true,\n        password_file = &quot;/etc/rsyncd.d/rsync.pwd&quot;,\n     _extra    = {&quot;--bwlimit=200&quot;}\n            }\n       }\n\n-- IV. 远程目录同步，rsync模式 + ssh shell\nsync {\n   default.rsync,\n    source    = &quot;/tmp/src&quot;,\n    target    = &quot;172.29.88.223:/tmp/dest&quot;,\n     -- target    = &quot;root@172.29.88.223:/remote/dest&quot;,\n  -- 上面target，注意如果是普通用户，必须拥有写权限\n  maxDelays = 5,\n  delay = 30,\n  -- init = true,\n  rsync     = {\n    binary = &quot;/usr/bin/rsync&quot;,\n    archive = true,\n    compress = true,\n    bwlimit   = 2000\n    -- rsh = &quot;/usr/bin/ssh -p 22 -o StrictHostKeyChecking=no&quot;\n    -- 如果要指定其它端口，请用上面的rsh\n    }\n  } \n\n-- V. 远程目录同步，rsync模式 + rsyncssh，效果与上面相同\nsync {\n    default.rsyncssh,\n    source    = &quot;/tmp/src2&quot;,\n    host      = &quot;172.29.88.223&quot;,\n    targetdir = &quot;/remote/dir&quot;,\n    excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;,\n    -- maxDelays = 5,\n    delay = 0,\n    -- init = false,\n    rsync    = {\n        binary = &quot;/usr/bin/rsync&quot;,\n        archive = true,\n        compress = true,\n         verbose   = true,\n      _extra = {&quot;--bwlimit=2000&quot;},\n        },\n    ssh      = {\n        port  =  1234\n        }\n    }\n</code></pre><p>上面的内容几乎涵盖了所有同步的模式，其中第III个要求像rsync一样配置rsyncd服务端，见本文开头。第IV、V配置ssh方式同步，达到的效果相同，但实际同步时你会发现每次同步都会提示输入ssh的密码，可以通过以下方法解决：</p>\n<p>在远端被同步的服务器上开启ssh无密码登录，请注意用户身份：</p>\n<pre><code>user$ ssh-keygen -t rsa\n一路回车...\nuser$ cd ~/.ssh\nuser$ cat id_rsa.pub &gt;&gt; authorized_keys\n</code></pre><p>把id_rsa私钥拷贝到执行lsyncd的机器上</p>\n<pre><code>user$ chmod 600 ~/.ssh/id_rsa\n测试能否无密码登录\nuser$ ssh user@172.29.88.223\n</code></pre><h2 id=\"lsyncd的其它功能\"><a href=\"#lsyncd的其它功能\" class=\"headerlink\" title=\"lsyncd的其它功能\"></a>lsyncd的其它功能</h2><p>lsyncd的功能不仅仅是同步，官方手册 <a href=\"https://axkibe.github.io/lsyncd/\" target=\"_blank\" rel=\"noopener\">Lsyncd 2.1.x ‖ Layer 2 Config ‖ Advanced onAction</a> 高级功能提到，还可以监控某个目录下的文件，根据触发的事件自己定义要执行的命令，example是监控某个某个目录，只要是有jpg、gif、png格式的文件参数，就把它们转成pdf，然后同步到另一个目录。正好在我运维的一个项目中有这个需求，现在都是在java代码里转换，还容易出现异常，通过lsyncd可以代替这样的功能。但，门槛在于要会一点点lua语言（根据官方example还是可以写出来）。</p>\n<p>另外偶然想到个问题，同时设置了maxDelays和delay，当监控目录一直没有文件变化了，也会发生同步操作，虽然没有可rsync的文件。</p>\n<p>TO-DO：</p>\n<p>其它同步工具：csync2，clsync，btsync，drdb 。</p>\n<p>lsyncd双向同步：<a href=\"https://axkibe.github.io/lsyncd/\" target=\"_blank\" rel=\"noopener\">GlusterFS</a></p>"},{"title":"centos 7 lsyncd实时同步","date":"2017-09-22T04:00:00.000Z","_content":"## lsyncd实时同步\n### lsyncd简介\n<!--more-->\nLysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。\n实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。\n\n\n\n### 首先客户端和服务端都需要安装rsync\n\tyum -y install rsync\n\n### lsyncd的安装\n\n\trpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n\tyum install lsyncd\n\n### 创建lsyncd的工作目录\n\tmkdir -p /usr/local/lsyncd-2.1.5/etc/\n\tmkdir -p /usr/local/lsyncd-2.1.5/var/\n\n### 创建lsyncd的配置文件\n\tvim /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\n\tsettings {\n\t\tlogfile      = \"/usr/local/lsyncd-2.1.5/var/lsyncd.log\",\n\t\tstatusFile   = \"/usr/local/lsyncd-2.1.5/var/lsyncd.status\",\n\t\tinotifyMode  = \"CloseWrite\",\n\t\tmaxProcesses = 7,\n    }\n\n\n\tsync {\n\t\tdefault.rsync,  \n\t\tsource    = \"/var/opt/gitlab/backups\",  \n\t\ttarget    = \"root@10.1.10.101:/var/opt/gitlab/  backups-BF\",  \n\t\tmaxDelays = 5,  \n\t\tdelay = 30,  \n\t\trsync     = {  \n\t\t\tbinary = \"/bin/rsync\",  \n            archive = true,\n     \t    compress = true,\n     \t    bwlimit   = 2000\n\t\t}\n\t}\n\n### lsyncd.conf配置文件说明\n\n#### settings\n\n里面是全局配置，-开头表示注释\n\n\t>logfile 定义日志文件\n\t>stausFile 定义状态文件\n\t>inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify\n\t>maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而>maxProcesses = 7，则最大能看到有7个rysnc进程\n\n#### sync\n\n里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式：\n\n\t>default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程；\n\t>default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份；\n\t>default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证\n\n\tsource 同步的源目录，使用绝对路径。\n\target 定义目的地址\n\t\n\n#### rsync\n\tbinary 定义rsync位置，位置有可能不一样\n\n### 做公私钥认证 \n将服务的的公钥写到客户端的`root/.ssh/authorized_keys`文件中\n\n使用ssh验证ssh访问是否正常\n\n\n### 在服务端启动lsyncd服务\n\n\tlsyncd -log Exec /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\n\n\n### 观察客户端同步目录是否正确\n\n\n### 在服务端写入定时任务备份文件\n\tcrontab -e\n\t0 0 * * *  /bin/gitlab-rake gitlab:backup:create\n\t0 1 */2 * * find /var/opt/gitlab/backups -mtime +7 -name \"*_gitlab_backup.tar\"|xargs rm -rf\n\t\n我这里写的是每周二会清理`/var/opt/gitlab/backups`文件中gitlab的备份文件，该时间可以由自己需求进行更改\n\n\n","source":"_posts/lsyncd实现文件目录同步简要说明.md","raw":"---\ntitle: centos 7 lsyncd实时同步\ndate: 2017-09-22\ntags: lsync\ncategories: lsync\n---\n## lsyncd实时同步\n### lsyncd简介\n<!--more-->\nLysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。\n实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。\n\n\n\n### 首先客户端和服务端都需要安装rsync\n\tyum -y install rsync\n\n### lsyncd的安装\n\n\trpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n\tyum install lsyncd\n\n### 创建lsyncd的工作目录\n\tmkdir -p /usr/local/lsyncd-2.1.5/etc/\n\tmkdir -p /usr/local/lsyncd-2.1.5/var/\n\n### 创建lsyncd的配置文件\n\tvim /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\n\tsettings {\n\t\tlogfile      = \"/usr/local/lsyncd-2.1.5/var/lsyncd.log\",\n\t\tstatusFile   = \"/usr/local/lsyncd-2.1.5/var/lsyncd.status\",\n\t\tinotifyMode  = \"CloseWrite\",\n\t\tmaxProcesses = 7,\n    }\n\n\n\tsync {\n\t\tdefault.rsync,  \n\t\tsource    = \"/var/opt/gitlab/backups\",  \n\t\ttarget    = \"root@10.1.10.101:/var/opt/gitlab/  backups-BF\",  \n\t\tmaxDelays = 5,  \n\t\tdelay = 30,  \n\t\trsync     = {  \n\t\t\tbinary = \"/bin/rsync\",  \n            archive = true,\n     \t    compress = true,\n     \t    bwlimit   = 2000\n\t\t}\n\t}\n\n### lsyncd.conf配置文件说明\n\n#### settings\n\n里面是全局配置，-开头表示注释\n\n\t>logfile 定义日志文件\n\t>stausFile 定义状态文件\n\t>inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify\n\t>maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而>maxProcesses = 7，则最大能看到有7个rysnc进程\n\n#### sync\n\n里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式：\n\n\t>default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程；\n\t>default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份；\n\t>default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证\n\n\tsource 同步的源目录，使用绝对路径。\n\target 定义目的地址\n\t\n\n#### rsync\n\tbinary 定义rsync位置，位置有可能不一样\n\n### 做公私钥认证 \n将服务的的公钥写到客户端的`root/.ssh/authorized_keys`文件中\n\n使用ssh验证ssh访问是否正常\n\n\n### 在服务端启动lsyncd服务\n\n\tlsyncd -log Exec /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\n\n\n### 观察客户端同步目录是否正确\n\n\n### 在服务端写入定时任务备份文件\n\tcrontab -e\n\t0 0 * * *  /bin/gitlab-rake gitlab:backup:create\n\t0 1 */2 * * find /var/opt/gitlab/backups -mtime +7 -name \"*_gitlab_backup.tar\"|xargs rm -rf\n\t\n我这里写的是每周二会清理`/var/opt/gitlab/backups`文件中gitlab的备份文件，该时间可以由自己需求进行更改\n\n\n","slug":"lsyncd实现文件目录同步简要说明","published":1,"updated":"2019-06-18T08:07:01.116Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sll001jhcb70h0b1dhj","content":"<h2 id=\"lsyncd实时同步\"><a href=\"#lsyncd实时同步\" class=\"headerlink\" title=\"lsyncd实时同步\"></a>lsyncd实时同步</h2><h3 id=\"lsyncd简介\"><a href=\"#lsyncd简介\" class=\"headerlink\" title=\"lsyncd简介\"></a>lsyncd简介</h3><a id=\"more\"></a>\n<p>Lysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。<br>实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。</p>\n<h3 id=\"首先客户端和服务端都需要安装rsync\"><a href=\"#首先客户端和服务端都需要安装rsync\" class=\"headerlink\" title=\"首先客户端和服务端都需要安装rsync\"></a>首先客户端和服务端都需要安装rsync</h3><pre><code>yum -y install rsync\n</code></pre><h3 id=\"lsyncd的安装\"><a href=\"#lsyncd的安装\" class=\"headerlink\" title=\"lsyncd的安装\"></a>lsyncd的安装</h3><pre><code>rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\nyum install lsyncd\n</code></pre><h3 id=\"创建lsyncd的工作目录\"><a href=\"#创建lsyncd的工作目录\" class=\"headerlink\" title=\"创建lsyncd的工作目录\"></a>创建lsyncd的工作目录</h3><pre><code>mkdir -p /usr/local/lsyncd-2.1.5/etc/\nmkdir -p /usr/local/lsyncd-2.1.5/var/\n</code></pre><h3 id=\"创建lsyncd的配置文件\"><a href=\"#创建lsyncd的配置文件\" class=\"headerlink\" title=\"创建lsyncd的配置文件\"></a>创建lsyncd的配置文件</h3><pre><code>vim /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\nsettings {\n    logfile      = &quot;/usr/local/lsyncd-2.1.5/var/lsyncd.log&quot;,\n    statusFile   = &quot;/usr/local/lsyncd-2.1.5/var/lsyncd.status&quot;,\n    inotifyMode  = &quot;CloseWrite&quot;,\n    maxProcesses = 7,\n}\n\n\nsync {\n    default.rsync,  \n    source    = &quot;/var/opt/gitlab/backups&quot;,  \n    target    = &quot;root@10.1.10.101:/var/opt/gitlab/  backups-BF&quot;,  \n    maxDelays = 5,  \n    delay = 30,  \n    rsync     = {  \n        binary = &quot;/bin/rsync&quot;,  \n        archive = true,\n         compress = true,\n         bwlimit   = 2000\n    }\n}\n</code></pre><h3 id=\"lsyncd-conf配置文件说明\"><a href=\"#lsyncd-conf配置文件说明\" class=\"headerlink\" title=\"lsyncd.conf配置文件说明\"></a>lsyncd.conf配置文件说明</h3><h4 id=\"settings\"><a href=\"#settings\" class=\"headerlink\" title=\"settings\"></a>settings</h4><p>里面是全局配置，-开头表示注释</p>\n<pre><code>&gt;logfile 定义日志文件\n&gt;stausFile 定义状态文件\n&gt;inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify\n&gt;maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而&gt;maxProcesses = 7，则最大能看到有7个rysnc进程\n</code></pre><h4 id=\"sync\"><a href=\"#sync\" class=\"headerlink\" title=\"sync\"></a>sync</h4><p>里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式：</p>\n<pre><code>&gt;default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程；\n&gt;default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份；\n&gt;default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证\n\nsource 同步的源目录，使用绝对路径。\narget 定义目的地址\n</code></pre><h4 id=\"rsync\"><a href=\"#rsync\" class=\"headerlink\" title=\"rsync\"></a>rsync</h4><pre><code>binary 定义rsync位置，位置有可能不一样\n</code></pre><h3 id=\"做公私钥认证\"><a href=\"#做公私钥认证\" class=\"headerlink\" title=\"做公私钥认证\"></a>做公私钥认证</h3><p>将服务的的公钥写到客户端的<code>root/.ssh/authorized_keys</code>文件中</p>\n<p>使用ssh验证ssh访问是否正常</p>\n<h3 id=\"在服务端启动lsyncd服务\"><a href=\"#在服务端启动lsyncd服务\" class=\"headerlink\" title=\"在服务端启动lsyncd服务\"></a>在服务端启动lsyncd服务</h3><pre><code>lsyncd -log Exec /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\n</code></pre><h3 id=\"观察客户端同步目录是否正确\"><a href=\"#观察客户端同步目录是否正确\" class=\"headerlink\" title=\"观察客户端同步目录是否正确\"></a>观察客户端同步目录是否正确</h3><h3 id=\"在服务端写入定时任务备份文件\"><a href=\"#在服务端写入定时任务备份文件\" class=\"headerlink\" title=\"在服务端写入定时任务备份文件\"></a>在服务端写入定时任务备份文件</h3><pre><code>crontab -e\n0 0 * * *  /bin/gitlab-rake gitlab:backup:create\n0 1 */2 * * find /var/opt/gitlab/backups -mtime +7 -name &quot;*_gitlab_backup.tar&quot;|xargs rm -rf\n</code></pre><p>我这里写的是每周二会清理<code>/var/opt/gitlab/backups</code>文件中gitlab的备份文件，该时间可以由自己需求进行更改</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"lsyncd实时同步\"><a href=\"#lsyncd实时同步\" class=\"headerlink\" title=\"lsyncd实时同步\"></a>lsyncd实时同步</h2><h3 id=\"lsyncd简介\"><a href=\"#lsyncd简介\" class=\"headerlink\" title=\"lsyncd简介\"></a>lsyncd简介</h3>","more":"<p>Lysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。<br>实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。</p>\n<h3 id=\"首先客户端和服务端都需要安装rsync\"><a href=\"#首先客户端和服务端都需要安装rsync\" class=\"headerlink\" title=\"首先客户端和服务端都需要安装rsync\"></a>首先客户端和服务端都需要安装rsync</h3><pre><code>yum -y install rsync\n</code></pre><h3 id=\"lsyncd的安装\"><a href=\"#lsyncd的安装\" class=\"headerlink\" title=\"lsyncd的安装\"></a>lsyncd的安装</h3><pre><code>rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\nyum install lsyncd\n</code></pre><h3 id=\"创建lsyncd的工作目录\"><a href=\"#创建lsyncd的工作目录\" class=\"headerlink\" title=\"创建lsyncd的工作目录\"></a>创建lsyncd的工作目录</h3><pre><code>mkdir -p /usr/local/lsyncd-2.1.5/etc/\nmkdir -p /usr/local/lsyncd-2.1.5/var/\n</code></pre><h3 id=\"创建lsyncd的配置文件\"><a href=\"#创建lsyncd的配置文件\" class=\"headerlink\" title=\"创建lsyncd的配置文件\"></a>创建lsyncd的配置文件</h3><pre><code>vim /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\nsettings {\n    logfile      = &quot;/usr/local/lsyncd-2.1.5/var/lsyncd.log&quot;,\n    statusFile   = &quot;/usr/local/lsyncd-2.1.5/var/lsyncd.status&quot;,\n    inotifyMode  = &quot;CloseWrite&quot;,\n    maxProcesses = 7,\n}\n\n\nsync {\n    default.rsync,  \n    source    = &quot;/var/opt/gitlab/backups&quot;,  \n    target    = &quot;root@10.1.10.101:/var/opt/gitlab/  backups-BF&quot;,  \n    maxDelays = 5,  \n    delay = 30,  \n    rsync     = {  \n        binary = &quot;/bin/rsync&quot;,  \n        archive = true,\n         compress = true,\n         bwlimit   = 2000\n    }\n}\n</code></pre><h3 id=\"lsyncd-conf配置文件说明\"><a href=\"#lsyncd-conf配置文件说明\" class=\"headerlink\" title=\"lsyncd.conf配置文件说明\"></a>lsyncd.conf配置文件说明</h3><h4 id=\"settings\"><a href=\"#settings\" class=\"headerlink\" title=\"settings\"></a>settings</h4><p>里面是全局配置，-开头表示注释</p>\n<pre><code>&gt;logfile 定义日志文件\n&gt;stausFile 定义状态文件\n&gt;inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify\n&gt;maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而&gt;maxProcesses = 7，则最大能看到有7个rysnc进程\n</code></pre><h4 id=\"sync\"><a href=\"#sync\" class=\"headerlink\" title=\"sync\"></a>sync</h4><p>里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式：</p>\n<pre><code>&gt;default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程；\n&gt;default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份；\n&gt;default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证\n\nsource 同步的源目录，使用绝对路径。\narget 定义目的地址\n</code></pre><h4 id=\"rsync\"><a href=\"#rsync\" class=\"headerlink\" title=\"rsync\"></a>rsync</h4><pre><code>binary 定义rsync位置，位置有可能不一样\n</code></pre><h3 id=\"做公私钥认证\"><a href=\"#做公私钥认证\" class=\"headerlink\" title=\"做公私钥认证\"></a>做公私钥认证</h3><p>将服务的的公钥写到客户端的<code>root/.ssh/authorized_keys</code>文件中</p>\n<p>使用ssh验证ssh访问是否正常</p>\n<h3 id=\"在服务端启动lsyncd服务\"><a href=\"#在服务端启动lsyncd服务\" class=\"headerlink\" title=\"在服务端启动lsyncd服务\"></a>在服务端启动lsyncd服务</h3><pre><code>lsyncd -log Exec /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\n</code></pre><h3 id=\"观察客户端同步目录是否正确\"><a href=\"#观察客户端同步目录是否正确\" class=\"headerlink\" title=\"观察客户端同步目录是否正确\"></a>观察客户端同步目录是否正确</h3><h3 id=\"在服务端写入定时任务备份文件\"><a href=\"#在服务端写入定时任务备份文件\" class=\"headerlink\" title=\"在服务端写入定时任务备份文件\"></a>在服务端写入定时任务备份文件</h3><pre><code>crontab -e\n0 0 * * *  /bin/gitlab-rake gitlab:backup:create\n0 1 */2 * * find /var/opt/gitlab/backups -mtime +7 -name &quot;*_gitlab_backup.tar&quot;|xargs rm -rf\n</code></pre><p>我这里写的是每周二会清理<code>/var/opt/gitlab/backups</code>文件中gitlab的备份文件，该时间可以由自己需求进行更改</p>"},{"title":"mtr命令详解","date":"2016-11-03T04:00:00.000Z","_content":"一般在windows 来判断网络连通性用ping 和tracert,ping的话可以来判断丢包率，tracert可以用来跟踪路由，在Linux中有一个更好的网络连通性判断工具，它可以结合ping nslookup tracert 来判断网络的相关特性,这个命令就是mtr\n<!--more-->\n    [root@10.10.90.97 ~]# mtr -h\n    usage: mtr [-hvrctglspni46] [--help] [--version] [--report]\n    [--report-cycles=COUNT] [--curses] [--gtk]\n    [--raw] [--split] [--no-dns] [--address interface]\n    [--psize=bytes/-s bytes]\n        [--interval=SECONDS] HOSTNAME [PACKETSIZE]\n    \n    \n    mtr -h 提供帮助命令\n    mtr -v 显示mtr的版本信息\n    mtr -r 已报告模式显示\n\n    [root@10.10.90.97 ~]# mtr -r 202.108.33.94\n    FOCUS9097 Snt: 10 Loss% Last Avg Best Wrst StDev\n    220.181.61.252 0.0% 6.8 3.3 1.8 7.4 2.2\n    220.181.17.217 0.0% 0.4 0.5 0.4 0.7 0.1\n    220.181.16.17 0.0% 0.6 0.5 0.5 0.6 0.0\n    202.97.53.14 10.0% 0.7 0.7 0.7 0.8 0.0\n    219.158.35.1 0.0% 0.8 0.8 0.8 0.9 0.0\n    219.158.5.81 0.0% 1.2 1.3 1.2 1.6 0.1\n    123.126.0.138 0.0% 1.2 1.1 1.1 1.3 0.1\n    61.148.153.126 0.0% 1.9 10.5 1.5 89.9 27.9\n    61.148.143.22 0.0% 1.5 1.6 1.5 1.7 0.0\n    210.74.178.198 0.0% 1.6 1.6 1.5 1.9 0.1\n    202.108.33.94 0.0% 1.5 1.5 1.4 1.5 0.0\n\n\n报告说明：\n第一列:显示的是IP地址和本机域名，这点和tracert很像\n第二列:snt:10 设置每秒发送数据包的数量，默认值是10 可以通过参数 -c来指定。\n\n    [root@10.10.90.97 ~]# mtr -r -c 15 202.108.33.94\n    FOCUS9097 Snt: 15 Loss% Last Avg Best Wrst StDev\n    220.181.61.252 0.0% 1.9 3.4 1.8 12.9 3.1\n    220.181.17.217 0.0% 0.5 0.5 0.4 0.8 0.1\n    220.181.16.17 0.0% 0.5 0.6 0.5 2.3 0.5\n    202.97.53.14 0.0% 0.7 0.7 0.7 0.7 0.0\n    219.158.35.1 0.0% 0.9 0.8 0.8 0.9 0.0\n    219.158.5.81 0.0% 1.3 2.8 1.2 22.8 5.5\n    123.126.0.138 0.0% 1.1 1.1 1.1 1.2 0.0\n    61.148.153.126 0.0% 13.8 7.4 1.6 60.4 15.5\n    61.148.143.22 0.0% 1.7 1.6 1.5 1.8 0.1\n    210.74.178.198 0.0% 1.6 1.6 1.4 1.7 0.1\n    202.108.33.94 0.0% 1.5 1.5 1.4 1.7 0.1\n    \n\n其中-c的说明是：–report-cycles COUNT\n\n第三列:是显示的每个对应IP的丢包率\n第四列:显示的最近一次的返回时延\n第五列:是平均值 这个应该是发送ping包的平均时延\n第六列:是最好或者说时延最短的\n第七列:是最差或者说时延最常的\n第八列:是标准偏差\n接下来接着说相关参数：\n\n    mtr -s 用来指定ping数据包的大小\n    mtr -n no-dns不对IP地址做域名解析\n    mtr -a 来设置发送数据包的IP地址 这个对一个主机由多个IP地址是有用的\n    mtr -i 使用这个参数来设置ICMP返回之间的要求默认是1秒\n    mtr -4 IPv4\n    mtr -6 IPv6\n","source":"_posts/mtr命令详解.md","raw":"---\ntitle: mtr命令详解\ndate: 2016-11-03\ntags: mtr\ncategories: mtr\n---\n一般在windows 来判断网络连通性用ping 和tracert,ping的话可以来判断丢包率，tracert可以用来跟踪路由，在Linux中有一个更好的网络连通性判断工具，它可以结合ping nslookup tracert 来判断网络的相关特性,这个命令就是mtr\n<!--more-->\n    [root@10.10.90.97 ~]# mtr -h\n    usage: mtr [-hvrctglspni46] [--help] [--version] [--report]\n    [--report-cycles=COUNT] [--curses] [--gtk]\n    [--raw] [--split] [--no-dns] [--address interface]\n    [--psize=bytes/-s bytes]\n        [--interval=SECONDS] HOSTNAME [PACKETSIZE]\n    \n    \n    mtr -h 提供帮助命令\n    mtr -v 显示mtr的版本信息\n    mtr -r 已报告模式显示\n\n    [root@10.10.90.97 ~]# mtr -r 202.108.33.94\n    FOCUS9097 Snt: 10 Loss% Last Avg Best Wrst StDev\n    220.181.61.252 0.0% 6.8 3.3 1.8 7.4 2.2\n    220.181.17.217 0.0% 0.4 0.5 0.4 0.7 0.1\n    220.181.16.17 0.0% 0.6 0.5 0.5 0.6 0.0\n    202.97.53.14 10.0% 0.7 0.7 0.7 0.8 0.0\n    219.158.35.1 0.0% 0.8 0.8 0.8 0.9 0.0\n    219.158.5.81 0.0% 1.2 1.3 1.2 1.6 0.1\n    123.126.0.138 0.0% 1.2 1.1 1.1 1.3 0.1\n    61.148.153.126 0.0% 1.9 10.5 1.5 89.9 27.9\n    61.148.143.22 0.0% 1.5 1.6 1.5 1.7 0.0\n    210.74.178.198 0.0% 1.6 1.6 1.5 1.9 0.1\n    202.108.33.94 0.0% 1.5 1.5 1.4 1.5 0.0\n\n\n报告说明：\n第一列:显示的是IP地址和本机域名，这点和tracert很像\n第二列:snt:10 设置每秒发送数据包的数量，默认值是10 可以通过参数 -c来指定。\n\n    [root@10.10.90.97 ~]# mtr -r -c 15 202.108.33.94\n    FOCUS9097 Snt: 15 Loss% Last Avg Best Wrst StDev\n    220.181.61.252 0.0% 1.9 3.4 1.8 12.9 3.1\n    220.181.17.217 0.0% 0.5 0.5 0.4 0.8 0.1\n    220.181.16.17 0.0% 0.5 0.6 0.5 2.3 0.5\n    202.97.53.14 0.0% 0.7 0.7 0.7 0.7 0.0\n    219.158.35.1 0.0% 0.9 0.8 0.8 0.9 0.0\n    219.158.5.81 0.0% 1.3 2.8 1.2 22.8 5.5\n    123.126.0.138 0.0% 1.1 1.1 1.1 1.2 0.0\n    61.148.153.126 0.0% 13.8 7.4 1.6 60.4 15.5\n    61.148.143.22 0.0% 1.7 1.6 1.5 1.8 0.1\n    210.74.178.198 0.0% 1.6 1.6 1.4 1.7 0.1\n    202.108.33.94 0.0% 1.5 1.5 1.4 1.7 0.1\n    \n\n其中-c的说明是：–report-cycles COUNT\n\n第三列:是显示的每个对应IP的丢包率\n第四列:显示的最近一次的返回时延\n第五列:是平均值 这个应该是发送ping包的平均时延\n第六列:是最好或者说时延最短的\n第七列:是最差或者说时延最常的\n第八列:是标准偏差\n接下来接着说相关参数：\n\n    mtr -s 用来指定ping数据包的大小\n    mtr -n no-dns不对IP地址做域名解析\n    mtr -a 来设置发送数据包的IP地址 这个对一个主机由多个IP地址是有用的\n    mtr -i 使用这个参数来设置ICMP返回之间的要求默认是1秒\n    mtr -4 IPv4\n    mtr -6 IPv6\n","slug":"mtr命令详解","published":1,"updated":"2019-06-18T08:07:01.116Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9slo001lhcb7wys86y75","content":"<p>一般在windows 来判断网络连通性用ping 和tracert,ping的话可以来判断丢包率，tracert可以用来跟踪路由，在Linux中有一个更好的网络连通性判断工具，它可以结合ping nslookup tracert 来判断网络的相关特性,这个命令就是mtr<br><a id=\"more\"></a><br>    [<a href=\"mailto:root@10.10.90.97\" target=\"_blank\" rel=\"noopener\">root@10.10.90.97</a> ~]# mtr -h<br>    usage: mtr [-hvrctglspni46] [–help] [–version] [–report]<br>    [–report-cycles=COUNT] [–curses] [–gtk]<br>    [–raw] [–split] [–no-dns] [–address interface]<br>    [–psize=bytes/-s bytes]<br>        [–interval=SECONDS] HOSTNAME [PACKETSIZE]</p>\n<pre><code>mtr -h 提供帮助命令\nmtr -v 显示mtr的版本信息\nmtr -r 已报告模式显示\n\n[root@10.10.90.97 ~]# mtr -r 202.108.33.94\nFOCUS9097 Snt: 10 Loss% Last Avg Best Wrst StDev\n220.181.61.252 0.0% 6.8 3.3 1.8 7.4 2.2\n220.181.17.217 0.0% 0.4 0.5 0.4 0.7 0.1\n220.181.16.17 0.0% 0.6 0.5 0.5 0.6 0.0\n202.97.53.14 10.0% 0.7 0.7 0.7 0.8 0.0\n219.158.35.1 0.0% 0.8 0.8 0.8 0.9 0.0\n219.158.5.81 0.0% 1.2 1.3 1.2 1.6 0.1\n123.126.0.138 0.0% 1.2 1.1 1.1 1.3 0.1\n61.148.153.126 0.0% 1.9 10.5 1.5 89.9 27.9\n61.148.143.22 0.0% 1.5 1.6 1.5 1.7 0.0\n210.74.178.198 0.0% 1.6 1.6 1.5 1.9 0.1\n202.108.33.94 0.0% 1.5 1.5 1.4 1.5 0.0\n</code></pre><p>报告说明：<br>第一列:显示的是IP地址和本机域名，这点和tracert很像<br>第二列:snt:10 设置每秒发送数据包的数量，默认值是10 可以通过参数 -c来指定。</p>\n<pre><code>[root@10.10.90.97 ~]# mtr -r -c 15 202.108.33.94\nFOCUS9097 Snt: 15 Loss% Last Avg Best Wrst StDev\n220.181.61.252 0.0% 1.9 3.4 1.8 12.9 3.1\n220.181.17.217 0.0% 0.5 0.5 0.4 0.8 0.1\n220.181.16.17 0.0% 0.5 0.6 0.5 2.3 0.5\n202.97.53.14 0.0% 0.7 0.7 0.7 0.7 0.0\n219.158.35.1 0.0% 0.9 0.8 0.8 0.9 0.0\n219.158.5.81 0.0% 1.3 2.8 1.2 22.8 5.5\n123.126.0.138 0.0% 1.1 1.1 1.1 1.2 0.0\n61.148.153.126 0.0% 13.8 7.4 1.6 60.4 15.5\n61.148.143.22 0.0% 1.7 1.6 1.5 1.8 0.1\n210.74.178.198 0.0% 1.6 1.6 1.4 1.7 0.1\n202.108.33.94 0.0% 1.5 1.5 1.4 1.7 0.1\n</code></pre><p>其中-c的说明是：–report-cycles COUNT</p>\n<p>第三列:是显示的每个对应IP的丢包率<br>第四列:显示的最近一次的返回时延<br>第五列:是平均值 这个应该是发送ping包的平均时延<br>第六列:是最好或者说时延最短的<br>第七列:是最差或者说时延最常的<br>第八列:是标准偏差<br>接下来接着说相关参数：</p>\n<pre><code>mtr -s 用来指定ping数据包的大小\nmtr -n no-dns不对IP地址做域名解析\nmtr -a 来设置发送数据包的IP地址 这个对一个主机由多个IP地址是有用的\nmtr -i 使用这个参数来设置ICMP返回之间的要求默认是1秒\nmtr -4 IPv4\nmtr -6 IPv6\n</code></pre>","site":{"data":{}},"excerpt":"<p>一般在windows 来判断网络连通性用ping 和tracert,ping的话可以来判断丢包率，tracert可以用来跟踪路由，在Linux中有一个更好的网络连通性判断工具，它可以结合ping nslookup tracert 来判断网络的相关特性,这个命令就是mtr<br>","more":"<br>    [<a href=\"mailto:root@10.10.90.97\" target=\"_blank\" rel=\"noopener\">root@10.10.90.97</a> ~]# mtr -h<br>    usage: mtr [-hvrctglspni46] [–help] [–version] [–report]<br>    [–report-cycles=COUNT] [–curses] [–gtk]<br>    [–raw] [–split] [–no-dns] [–address interface]<br>    [–psize=bytes/-s bytes]<br>        [–interval=SECONDS] HOSTNAME [PACKETSIZE]</p>\n<pre><code>mtr -h 提供帮助命令\nmtr -v 显示mtr的版本信息\nmtr -r 已报告模式显示\n\n[root@10.10.90.97 ~]# mtr -r 202.108.33.94\nFOCUS9097 Snt: 10 Loss% Last Avg Best Wrst StDev\n220.181.61.252 0.0% 6.8 3.3 1.8 7.4 2.2\n220.181.17.217 0.0% 0.4 0.5 0.4 0.7 0.1\n220.181.16.17 0.0% 0.6 0.5 0.5 0.6 0.0\n202.97.53.14 10.0% 0.7 0.7 0.7 0.8 0.0\n219.158.35.1 0.0% 0.8 0.8 0.8 0.9 0.0\n219.158.5.81 0.0% 1.2 1.3 1.2 1.6 0.1\n123.126.0.138 0.0% 1.2 1.1 1.1 1.3 0.1\n61.148.153.126 0.0% 1.9 10.5 1.5 89.9 27.9\n61.148.143.22 0.0% 1.5 1.6 1.5 1.7 0.0\n210.74.178.198 0.0% 1.6 1.6 1.5 1.9 0.1\n202.108.33.94 0.0% 1.5 1.5 1.4 1.5 0.0\n</code></pre><p>报告说明：<br>第一列:显示的是IP地址和本机域名，这点和tracert很像<br>第二列:snt:10 设置每秒发送数据包的数量，默认值是10 可以通过参数 -c来指定。</p>\n<pre><code>[root@10.10.90.97 ~]# mtr -r -c 15 202.108.33.94\nFOCUS9097 Snt: 15 Loss% Last Avg Best Wrst StDev\n220.181.61.252 0.0% 1.9 3.4 1.8 12.9 3.1\n220.181.17.217 0.0% 0.5 0.5 0.4 0.8 0.1\n220.181.16.17 0.0% 0.5 0.6 0.5 2.3 0.5\n202.97.53.14 0.0% 0.7 0.7 0.7 0.7 0.0\n219.158.35.1 0.0% 0.9 0.8 0.8 0.9 0.0\n219.158.5.81 0.0% 1.3 2.8 1.2 22.8 5.5\n123.126.0.138 0.0% 1.1 1.1 1.1 1.2 0.0\n61.148.153.126 0.0% 13.8 7.4 1.6 60.4 15.5\n61.148.143.22 0.0% 1.7 1.6 1.5 1.8 0.1\n210.74.178.198 0.0% 1.6 1.6 1.4 1.7 0.1\n202.108.33.94 0.0% 1.5 1.5 1.4 1.7 0.1\n</code></pre><p>其中-c的说明是：–report-cycles COUNT</p>\n<p>第三列:是显示的每个对应IP的丢包率<br>第四列:显示的最近一次的返回时延<br>第五列:是平均值 这个应该是发送ping包的平均时延<br>第六列:是最好或者说时延最短的<br>第七列:是最差或者说时延最常的<br>第八列:是标准偏差<br>接下来接着说相关参数：</p>\n<pre><code>mtr -s 用来指定ping数据包的大小\nmtr -n no-dns不对IP地址做域名解析\nmtr -a 来设置发送数据包的IP地址 这个对一个主机由多个IP地址是有用的\nmtr -i 使用这个参数来设置ICMP返回之间的要求默认是1秒\nmtr -4 IPv4\nmtr -6 IPv6\n</code></pre>"},{"title":"mysql主从配置文件内容","date":"2016-09-05T04:00:00.000Z","_content":"\nmysql简要配置文件---master\n<!--more-->\n    [client]  \n    port = 3306  \n    default-character-set=utf8  \n    [mysqld]  \n    server-id=10  \n    log-bin=mysql-master-bin  \n    binlog_format = mixed  \n    expire_logs_days=15  \n    max_connections=10000  \n    innodb_flush_log_at_trx_commit=1  \n    sync_binlog=1  \n    binlog-ignore-db=mysql,test,information_schema  \n    skip-name-resolve  \n    port = 3306  \n    key_buffer_size = 16M  \n    max_allowed_packet = 16M  \n    join_buffer_size = 512M  \n    sort_buffer_size = 256M  \n    read_rnd_buffer_size = 128M  \n    innodb_buffer_pool_size = 4096M  \n    sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES  \n    [mysqld_safe]  \n    default-character-set=utf8mb4  \n    \n\n\nmysql简要配置文件---slave\n    [client]   \n    port = 3306  \n    default-character-set=utf8  \n    [mysqld]  \n    server-id=100  \n    #log-bin=mysql-slave-bin  \n    relay-log=mysqld-relay-bin  \n    max_binlog_size = 1000M  \n    binlog_format = mixed  \n    expire_logs_days=7  \n    innodb_flush_log_at_trx_commit=1  \n    sync_binlog=1  \n    read_only=1  \n    binlog-ignore-db=mysql,test,information_schema  \n    skip-name-resolve  \n    max_connections=10000  \n    max_user_connections=490  \n    max_connect_errors=2  \n    key_buffer_size = 16M  \n    max_allowed_packet = 16M  \n    join_buffer_size = 512M  \n    sort_buffer_size = 256M  \n    read_rnd_buffer_size = 128M  \n    innodb_buffer_pool_size = 4096M  \n    sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES  \n    [mysqld_safe]  \n    default-character-set=utf8mb4  \n","source":"_posts/mysql主从配置文件内容.md","raw":"---\ntitle: mysql主从配置文件内容\ndate: 2016-09-05\ntags: mysql\ncategories: mysql\n---\n\nmysql简要配置文件---master\n<!--more-->\n    [client]  \n    port = 3306  \n    default-character-set=utf8  \n    [mysqld]  \n    server-id=10  \n    log-bin=mysql-master-bin  \n    binlog_format = mixed  \n    expire_logs_days=15  \n    max_connections=10000  \n    innodb_flush_log_at_trx_commit=1  \n    sync_binlog=1  \n    binlog-ignore-db=mysql,test,information_schema  \n    skip-name-resolve  \n    port = 3306  \n    key_buffer_size = 16M  \n    max_allowed_packet = 16M  \n    join_buffer_size = 512M  \n    sort_buffer_size = 256M  \n    read_rnd_buffer_size = 128M  \n    innodb_buffer_pool_size = 4096M  \n    sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES  \n    [mysqld_safe]  \n    default-character-set=utf8mb4  \n    \n\n\nmysql简要配置文件---slave\n    [client]   \n    port = 3306  \n    default-character-set=utf8  \n    [mysqld]  \n    server-id=100  \n    #log-bin=mysql-slave-bin  \n    relay-log=mysqld-relay-bin  \n    max_binlog_size = 1000M  \n    binlog_format = mixed  \n    expire_logs_days=7  \n    innodb_flush_log_at_trx_commit=1  \n    sync_binlog=1  \n    read_only=1  \n    binlog-ignore-db=mysql,test,information_schema  \n    skip-name-resolve  \n    max_connections=10000  \n    max_user_connections=490  \n    max_connect_errors=2  \n    key_buffer_size = 16M  \n    max_allowed_packet = 16M  \n    join_buffer_size = 512M  \n    sort_buffer_size = 256M  \n    read_rnd_buffer_size = 128M  \n    innodb_buffer_pool_size = 4096M  \n    sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES  \n    [mysqld_safe]  \n    default-character-set=utf8mb4  \n","slug":"mysql主从配置文件内容","published":1,"updated":"2019-06-18T08:07:01.116Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9slv001phcb72y8almt0","content":"<p>mysql简要配置文件—master<br><a id=\"more\"></a><br>    [client]<br>    port = 3306<br>    default-character-set=utf8<br>    [mysqld]<br>    server-id=10<br>    log-bin=mysql-master-bin<br>    binlog_format = mixed<br>    expire_logs_days=15<br>    max_connections=10000<br>    innodb_flush_log_at_trx_commit=1<br>    sync_binlog=1<br>    binlog-ignore-db=mysql,test,information_schema<br>    skip-name-resolve<br>    port = 3306<br>    key_buffer_size = 16M<br>    max_allowed_packet = 16M<br>    join_buffer_size = 512M<br>    sort_buffer_size = 256M<br>    read_rnd_buffer_size = 128M<br>    innodb_buffer_pool_size = 4096M<br>    sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES<br>    [mysqld_safe]<br>    default-character-set=utf8mb4  </p>\n<p>mysql简要配置文件—slave<br>    [client]<br>    port = 3306<br>    default-character-set=utf8<br>    [mysqld]<br>    server-id=100  </p>\n<pre><code>#log-bin=mysql-slave-bin  \nrelay-log=mysqld-relay-bin  \nmax_binlog_size = 1000M  \nbinlog_format = mixed  \nexpire_logs_days=7  \ninnodb_flush_log_at_trx_commit=1  \nsync_binlog=1  \nread_only=1  \nbinlog-ignore-db=mysql,test,information_schema  \nskip-name-resolve  \nmax_connections=10000  \nmax_user_connections=490  \nmax_connect_errors=2  \nkey_buffer_size = 16M  \nmax_allowed_packet = 16M  \njoin_buffer_size = 512M  \nsort_buffer_size = 256M  \nread_rnd_buffer_size = 128M  \ninnodb_buffer_pool_size = 4096M  \nsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES  \n[mysqld_safe]  \ndefault-character-set=utf8mb4  \n</code></pre>","site":{"data":{}},"excerpt":"<p>mysql简要配置文件—master<br>","more":"<br>    [client]<br>    port = 3306<br>    default-character-set=utf8<br>    [mysqld]<br>    server-id=10<br>    log-bin=mysql-master-bin<br>    binlog_format = mixed<br>    expire_logs_days=15<br>    max_connections=10000<br>    innodb_flush_log_at_trx_commit=1<br>    sync_binlog=1<br>    binlog-ignore-db=mysql,test,information_schema<br>    skip-name-resolve<br>    port = 3306<br>    key_buffer_size = 16M<br>    max_allowed_packet = 16M<br>    join_buffer_size = 512M<br>    sort_buffer_size = 256M<br>    read_rnd_buffer_size = 128M<br>    innodb_buffer_pool_size = 4096M<br>    sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES<br>    [mysqld_safe]<br>    default-character-set=utf8mb4  </p>\n<p>mysql简要配置文件—slave<br>    [client]<br>    port = 3306<br>    default-character-set=utf8<br>    [mysqld]<br>    server-id=100  </p>\n<pre><code>#log-bin=mysql-slave-bin  \nrelay-log=mysqld-relay-bin  \nmax_binlog_size = 1000M  \nbinlog_format = mixed  \nexpire_logs_days=7  \ninnodb_flush_log_at_trx_commit=1  \nsync_binlog=1  \nread_only=1  \nbinlog-ignore-db=mysql,test,information_schema  \nskip-name-resolve  \nmax_connections=10000  \nmax_user_connections=490  \nmax_connect_errors=2  \nkey_buffer_size = 16M  \nmax_allowed_packet = 16M  \njoin_buffer_size = 512M  \nsort_buffer_size = 256M  \nread_rnd_buffer_size = 128M  \ninnodb_buffer_pool_size = 4096M  \nsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES  \n[mysqld_safe]  \ndefault-character-set=utf8mb4  \n</code></pre>"},{"title":"mysql使用binlog日志恢复","date":"2018-11-07T05:00:00.000Z","_content":"众所周知，binlog日志对于mysql数据库来说是十分重要的。在数据丢失的紧急情况下，我们往往会想到用binlog日志功能进行数据恢复（定时全备份+binlog日志恢复增量数据部分），化险为夷！\n<!--more-->\n废话不多说，下面是梳理的binlog日志操作解说：\n\n## 一、初步了解binlog\n\nMySQL的二进制日志binlog可以说是MySQL最重要的日志，它记录了所有的DDL和DML语句（除了数据查询语句select），以事件形式记录，还包含语句所执行的消耗的时间，MySQL的二进制日志是事务安全型的。\n\n----------------------------------------------------------------------------------------------------------------------------------------------\nDDL\n\n----Data Definition Language 数据库定义语言 \n\n主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表（TABLE）的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用。\n\nDML\n\n----Data Manipulation Language 数据操纵语言\n\n主要的命令是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言\n\n----------------------------------------------------------------------------------------------------------------------------------------------\n\nmysqlbinlog常见的选项有以下几个：\n--start-datetime：从二进制日志中读取指定等于时间戳或者晚于本地计算机的时间\n--stop-datetime：从二进制日志中读取指定小于时间戳或者等于本地计算机的时间 取值和上述一样\n--start-position：从二进制日志中读取指定position 事件位置作为开始。\n--stop-position：从二进制日志中读取指定position 事件位置作为事件截至\n\n*********************************************************************\n\n一般来说开启binlog日志大概会有1%的性能损耗。\n### binlog日志有两个最重要的使用场景: \n 1）MySQL主从复制：MySQL Replication在Master端开启binlog，Master把它的二进制日志传递给slaves来达到\nmaster-slave数据一致的目的。 \n 2）自然就是数据恢复了，通过使用mysqlbinlog工具来使恢复数据。\n### binlog日志包括两类文件：\n 1）二进制日志索引文件（文件名后缀为.index）用于记录所有的二进制文件\n 2）二进制日志文件（文件名后缀为.00000*）记录数据库所有的DDL和DML(除了数据查询语句select)语句事件。\n\n## 二、开启binlog日志：\n 1）编辑打开mysql配置文件/etc/mys.cnf\n\n```\n[root@vm-002 ~]# vim /etc/my.cnf\n\n在[mysqld] 区块添加 \nlog-bin=mysql-bin 确认是打开状态(mysql-bin 是日志的基本名或前缀名)；\n```\n 2）重启mysqld服务使配置生效\n\n```\n[root@vm-002 ~]# /etc/init.d/mysqld stop\n[root@vm-002 ~]# /etc/init.d/mysqld restart\nStopping mysqld: [ OK ]\nStarting mysqld: [ OK ]\n```\n\n 3）查看binlog日志是否开启\n```\nmysql> show variables like 'log_%'; \n+---------------------------------+---------------------+\n| Variable_name | Value |\n+---------------------------------+---------------------+\n| log_bin | ON |\n| log_bin_trust_function_creators | OFF |\n| log_bin_trust_routine_creators | OFF |\n| log_error | /var/log/mysqld.log |\n| log_output | FILE |\n| log_queries_not_using_indexes | OFF |\n| log_slave_updates | OFF |\n| log_slow_queries | OFF |\n| log_warnings | 1 |\n+---------------------------------+---------------------+\n9 rows in set (0.00 sec)\n```\n\n## 三、常用的binlog日志操作命令\n\n 1）查看所有binlog日志列表\n```\nmysql> show master logs;\n+------------------+-----------+\n| Log_name | File_size |\n+------------------+-----------+\n| mysql-bin.000001 | 149 |\n| mysql-bin.000002 | 4102 |\n+------------------+-----------+\n2 rows in set (0.00 sec)\n```\n\n 2）查看master状态，即最后(最新)一个binlog日志的编号名称，及其最后一个操作事件pos结束点(Position)值\n```\nmysql> show master status;\n+------------------+----------+--------------+------------------+\n| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |\n+------------------+----------+--------------+------------------+\n| mysql-bin.000002 | 4102 | | |\n+------------------+----------+--------------+------------------+\n1 row in set (0.00 sec)\n```\n\n 3）flush刷新log日志，自此刻开始产生一个新编号的binlog日志文件\n```\nmysql> flush logs; \nQuery OK, 0 rows affected (0.13 sec)\n\nmysql> show master logs; \n+------------------+-----------+\n| Log_name | File_size |\n+------------------+-----------+\n| mysql-bin.000001 | 149 |\n| mysql-bin.000002 | 4145 |\n| mysql-bin.000003 | 106 |\n+------------------+-----------+\n3 rows in set (0.00 sec)\n```\n\n注意：\n每当mysqld服务重启时，会自动执行此命令，刷新binlog日志；在mysqldump备份数据时加 -F 选项也会刷新binlog日志；\n\n 4）重置(清空)所有binlog日志\n```\nmysql> reset master;\nQuery OK, 0 rows affected (0.12 sec)\n\nmysql> show master logs; \n+------------------+-----------+\n| Log_name | File_size |\n+------------------+-----------+\n| mysql-bin.000001 | 106 |\n+------------------+-----------+\n1 row in set (0.00 sec)\n```\n\n## 四、查看binlog日志内容，常用有两种方式：\n 1）使用mysqlbinlog自带查看命令法：\n注意：\n-->binlog是二进制文件，普通文件查看器cat、more、vim等都无法打开，必须使用自带的mysqlbinlog命令查看\n-->binlog日志与数据库文件在同目录中\n-->在MySQL5.5以下版本使用mysqlbinlog命令时如果报错，就加上 “--no-defaults”选项\n\n查看mysql的数据存放目录，从下面结果可知是/var/lib//mysql\n```\n[root@vm-002 ~]# ps -ef|grep mysql\nroot 9791 1 0 21:18 pts/0 00:00:00 /bin/sh /usr/bin/mysqld_safe --datadir=/var/lib/mysql --socket=/var/lib/mysql/mysql.sock --pid-file=/var/run/mysqld/mysqld.pid --basedir=/usr --user=mysql\nmysql 9896 9791 0 21:18 pts/0 00:00:00 /usr/libexec/mysqld --basedir=/usr --datadir=/var/lib/mysql --user=mysql --log-error=/var/log/mysqld.log --pid-file=/var/run/mysqld/mysqld.pid --socket=/var/lib/mysql/mysql.sock\nroot 9916 9699 0 21:18 pts/0 00:00:00 mysql -px xxxx\nroot 9919 9715 0 21:23 pts/1 00:00:00 grep --color mysql\n\n[root@vm-002 ~]# cd /var/lib/mysql/\n[root@vm-002 mysql]# ls\nibdata1 ib_logfile0 ib_logfile1 mysql mysql-bin.000001 mysql-bin.000002 mysql-bin.index mysql.sock ops test\n\n使用mysqlbinlog命令查看binlog日志内容，下面截取其中的一个片段分析：\n[root@vm-002 mysql]# mysqlbinlog mysql-bin.000002\n..............\n# at 624\n#160925 21:29:53 server id 1 end_log_pos 796 Query\tthread_id=3\texec_time=0\terror_code=0\nSET TIMESTAMP=1474810193/*!*/;\ninsert into member(`name`,`sex`,`age`,`classid`) values('wangshibo','m',27,'cls1'),('guohuihui','w',27,'cls2')        #执行的sql语句\n/*!*/;\n#at 796\n#160925 21:29:53 server id 1 end_log_pos 823 Xid = 17                  #执行的时间\n.............\n```\n解释：\nserver id 1 ： 数据库主机的服务号；\nend_log_pos 796： sql结束时的pos节点\nthread_id=11： 线程号\n\n 2）上面这种办法读取出binlog日志的全文内容比较多，不容易分辨查看到pos点信息\n下面介绍一种更为方便的查询命令：\n命令格式：\n```\nmysql> show binlog events [IN 'log_name'] [FROM pos] [LIMIT [offset,] row_count];\n```\n参数解释：\nIN 'log_name' ：指定要查询的binlog文件名(不指定就是第一个binlog文件)\nFROM pos ：指定从哪个pos起始点开始查起(不指定就是从整个文件首个pos点开始算)\nLIMIT [offset,] ：偏移量(不指定就是0)\nrow_count ：查询总条数(不指定就是所有行)\n```\nmysql> show master logs;\n+------------------+-----------+\n| Log_name | File_size |\n+------------------+-----------+\n| mysql-bin.000001 | 125 |\n| mysql-bin.000002 | 823 |\n+------------------+-----------+\n2 rows in set (0.00 sec)\n\nmysql> show binlog events in 'mysql-bin.000002'\\G;\n*************************** 1. row ***************************\nLog_name: mysql-bin.000002\nPos: 4\nEvent_type: Format_desc\nServer_id: 1\nEnd_log_pos: 106\nInfo: Server ver: 5.1.73-log, Binlog ver: 4\n*************************** 2. row ***************************\nLog_name: mysql-bin.000002\nPos: 106\nEvent_type: Query\nServer_id: 1\nEnd_log_pos: 188\nInfo: use `ops`; drop table customers\n*************************** 3. row ***************************\nLog_name: mysql-bin.000002\nPos: 188\nEvent_type: Query\nServer_id: 1\nEnd_log_pos: 529\nInfo: use `ops`; CREATE TABLE IF NOT EXISTS `member` (\n`id` int(10) unsigned NOT NULL AUTO_INCREMENT,\n`name` varchar(16) NOT NULL,\n`sex` enum('m','w') NOT NULL DEFAULT 'm',\n`age` tinyint(3) unsigned NOT NULL,\n`classid` char(6) DEFAULT NULL,\nPRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n*************************** 4. row ***************************\nLog_name: mysql-bin.000002\nPos: 529\nEvent_type: Query\nServer_id: 1\nEnd_log_pos: 596\nInfo: BEGIN\n*************************** 5. row ***************************\nLog_name: mysql-bin.000002\nPos: 596\nEvent_type: Intvar\nServer_id: 1\nEnd_log_pos: 624\nInfo: INSERT_ID=1\n*************************** 6. row ***************************\nLog_name: mysql-bin.000002\nPos: 624\nEvent_type: Query\nServer_id: 1\nEnd_log_pos: 796\nInfo: use `ops`; insert into member(`name`,`sex`,`age`,`classid`) values('wangshibo','m',27,'cls1'),('guohuihui','w',27,'cls2')\n*************************** 7. row ***************************\nLog_name: mysql-bin.000002\nPos: 796\nEvent_type: Xid\nServer_id: 1\nEnd_log_pos: 823\nInfo: COMMIT /* xid=17 */\n7 rows in set (0.00 sec)\n\nERROR: \nNo query specified\n\nmysql>\n```\n上面这条语句可以将指定的binlog日志文件，分成有效事件行的方式返回，并可使用limit指定pos点的起始偏移，查询条数！\n如下操作示例：\n a）查询第一个(最早)的binlog日志：\n```\nmysql> show binlog events\\G;\n```\n\n b）指定查询 mysql-bin.000002这个文件：\n```\nmysql> show binlog events in 'mysql-bin.000002'\\G;\n```\n\nc）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起：\n```\nmysql> show binlog events in 'mysql-bin.000002' from 624\\G;\n```\n\nd）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起，查询10条（即10条语句）\n```\nmysql> show binlog events in 'mysql-bin.000002' from 624 limit 10\\G;\n```\n\ne）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起，偏移2行（即中间跳过2个），查询10条\n```\nmysql> show binlog events in 'mysql-bin.000002' from 624 limit 2,10\\G;\n```\n\n## 五、利用binlog日志恢复mysql数据\n\n以下对ops库的member表进行操作\n```\nmysql> use ops；\nmysql> CREATE TABLE IF NOT EXISTS `member` (\n-> `id` int(10) unsigned NOT NULL AUTO_INCREMENT,\n-> `name` varchar(16) NOT NULL,\n-> `sex` enum('m','w') NOT NULL DEFAULT 'm',\n-> `age` tinyint(3) unsigned NOT NULL,\n-> `classid` char(6) DEFAULT NULL,\n-> PRIMARY KEY (`id`)\n-> ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\nQuery OK, 0 rows affected (0.10 sec)\n\nmysql> show tables;\n+---------------+\n| Tables_in_ops |\n+---------------+\n| member |\n+---------------+\n1 row in set (0.00 sec)\n\nmysql> desc member;\n+---------+---------------------+------+-----+---------+----------------+\n| Field | Type | Null | Key | Default | Extra |\n+---------+---------------------+------+-----+---------+----------------+\n| id | int(10) unsigned | NO | PRI | NULL | auto_increment |\n| name | varchar(16) | NO | | NULL | |\n| sex | enum('m','w') | NO | | m | |\n| age | tinyint(3) unsigned | NO | | NULL | |\n| classid | char(6) | YES | | NULL | |\n+---------+---------------------+------+-----+---------+----------------+\n5 rows in set (0.00 sec)\n```\n事先插入两条数据\n```\nmysql> insert into member(`name`,`sex`,`age`,`classid`) values('wangshibo','m',27,'cls1'),('guohuihui','w',27,'cls2');\nQuery OK, 2 rows affected (0.08 sec)\nRecords: 2 Duplicates: 0 Warnings: 0\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n+----+-----------+-----+-----+---------+\n2 rows in set (0.00 sec)\n```\n下面开始进行场景模拟：\n1）\nops库会在每天凌晨4点进行一次完全备份的定时计划任务，如下：\n```\n[root@vm-002 ~]# crontab -l\n0 4 * * * /usr/bin/mysqldump -uroot -p -B -F -R -x --master-data=2 ops|gzip >/opt/backup/ops_$(date +%F).sql.gz\n```\n这里手动执行下，将ops数据库备份到/opt/backup/ops_$(date +%F).sql.gz文件中：\n```\n[root@vm-002 ~]# mysqldump -uroot -p -B -F -R -x --master-data=2 ops|gzip >/opt/backup/ops_$(date +%F).sql.gz\nEnter password: \n[root@vm-002 ~]# ls /opt/backup/\nops_2016-09-25.sql.gz\n```\n-----------------\n参数说明：\n-B：指定数据库\n-F：刷新日志\n-R：备份存储过程等\n-x：锁表\n--master-data：在备份语句里添加CHANGE MASTER语句以及binlog文件及位置点信息\n\n-----------------\n待到数据库备份完成，就不用担心数据丢失了，因为有完全备份数据在！！\n\n由于上面在全备份的时候使用了-F选项，那么当数据备份操作刚开始的时候系统就会自动刷新log，这样就会自动产生\n一个新的binlog日志，这个新的binlog日志就会用来记录备份之后的数据库“增删改”操作\n查看一下：\n```\nmysql> show master status;\n+------------------+----------+--------------+------------------+\n| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |\n+------------------+----------+--------------+------------------+\n| mysql-bin.000003 | 106 | | |\n+------------------+----------+--------------+------------------+\n1 row in set (0.00 sec)\n```\n也就是说， mysql-bin.000003 是用来记录4:00之后对数据库的所有“增删改”操作。\n\n2）\n早上9点上班了，由于业务的需求会对数据库进行各种“增删改”操作。\n比如：在ops库下member表内插入、修改了数据等等：\n\n先是早上进行插入数据：\n```\nmysql> insert into ops.member(`name`,`sex`,`age`,`classid`) values('yiyi','w',20,'cls1'),('xiaoer','m',22,'cls3'),('zhangsan','w',21,'cls5'),('lisi','m',20,'cls4'),('wangwu','w',26,'cls6');\nQuery OK, 5 rows affected (0.08 sec)\nRecords: 5 Duplicates: 0 Warnings: 0\n\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | xiaoer | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n```\n3）\n中午又执行了修改数据操作：\n```\nmysql> update ops.member set name='李四' where id=4;\nQuery OK, 1 row affected (0.07 sec)\nRows matched: 1 Changed: 1 Warnings: 0\n\nmysql> update ops.member set name='小二' where id=2;\nQuery OK, 1 row affected (0.06 sec)\nRows matched: 1 Changed: 1 Warnings: 0\n\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | 小二 | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | 李四 | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n```\n\n4）\n在下午18:00的时候，悲剧莫名其妙的出现了！\n手贱执行了drop语句，直接删除了ops库！吓尿！\n```\nmysql> drop database ops;\nQuery OK, 1 row affected (0.02 sec)\n```\n5）\n这种时候，一定不要慌张！！！\n先仔细查看最后一个binlog日志，并记录下关键的pos点，到底是哪个pos点的操作导致了数据库的破坏(通常在最后几步)；\n\n先备份一下最后一个binlog日志文件：\n```\n[root@vm-002 ~]# cd /var/lib/mysql/\n[root@vm-002 mysql]# cp -v mysql-bin.000003 /opt/backup/\n`mysql-bin.000003' -> `/opt/backup/mysql-bin.000003'\n[root@vm-002 mysql]# ls /opt/backup/\nmysql-bin.000003 ops_2016-09-25.sql.gz\n```\n\n接着执行一次刷新日志索引操作，重新开始新的binlog日志记录文件。按理说mysql-bin.000003\n这个文件不会再有后续写入了，因为便于我们分析原因及查找ops节点，以后所有数据库操作都会写入到下一个日志文件。\n```\nmysql> flush logs;\nQuery OK, 0 rows affected (0.13 sec)\n\nmysql> show master status;\n+------------------+----------+--------------+------------------+\n| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |\n+------------------+----------+--------------+------------------+\n| mysql-bin.000004 | 106 | | |\n+------------------+----------+--------------+------------------+\n1 row in set (0.00 sec)\n```\n\n6）\n读取binlog日志，分析问题。\n读取binlog日志的方法上面已经说到。\n方法一：使用mysqlbinlog读取binlog日志：\n```\n[root@vm-002 ~]# cd /var/lib/mysql/\n[root@vm-002 mysql]# mysqlbinlog mysql-bin.000003\n```\n\n方法二：登录服务器，并查看(推荐此种方法)\n```\nmysql> show binlog events in 'mysql-bin.000003';\n\n+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+\n| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |\n+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+\n| mysql-bin.000003 | 4 | Format_desc | 1 | 106 | Server ver: 5.1.73-log, Binlog ver: 4 |\n| mysql-bin.000003 | 106 | Query | 1 | 173 | BEGIN |\n| mysql-bin.000003 | 173 | Intvar | 1 | 201 | INSERT_ID=3 |\n| mysql-bin.000003 | 201 | Query | 1 | 444 | use `ops`; insert into ops.member(`name`,`sex`,`age`,`gsan','w',21,'cls5'),('lisi','m',20,'cls4'),('wangwu','w',26,'cls6') |\n| mysql-bin.000003 | 444 | Xid | 1 | 471 | COMMIT /* xid=66 */ |\n| mysql-bin.000003 | 471 | Query | 1 | 538 | BEGIN |\n| mysql-bin.000003 | 538 | Query | 1 | 646 | use `ops`; update ops.member set name='李四' where id= |\n| mysql-bin.000003 | 646 | Xid | 1 | 673 | COMMIT /* xid=68 */ |\n| mysql-bin.000003 | 673 | Query | 1 | 740 | BEGIN |\n| mysql-bin.000003 | 740 | Query | 1 | 848 | use `ops`; update ops.member set name='小二' where id= |\n| mysql-bin.000003 | 848 | Xid | 1 | 875 | COMMIT /* xid=69 */ |\n| mysql-bin.000003 | 875 | Query | 1 | 954 | drop database ops |\n| mysql-bin.000003 | 954 | Rotate | 1 | 997 | mysql-bin.000004;pos=4 |\n+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+\n13 rows in set (0.00 sec)\n\n或者：\n\nmysql> show binlog events in 'mysql-bin.000003'\\G;\n.........\n.........\n*************************** 12. row ***************************\nLog_name: mysql-bin.000003\nPos: 875\nEvent_type: Query\nServer_id: 1\nEnd_log_pos: 954\nInfo: drop database ops\n*************************** 13. row ***************************\nLog_name: mysql-bin.000003\nPos: 954\nEvent_type: Rotate\nServer_id: 1\nEnd_log_pos: 997\nInfo: mysql-bin.000004;pos=4\n13 rows in set (0.00 sec)\n```\n通过分析，造成数据库破坏的pos点区间是介于 875--954 之间（这是按照日志区间的pos节点算的），只要恢复到875前就可。\n\n7）\n先把凌晨4点全备份的数据恢复：\n```\n[root@vm-002 ~]# cd /opt/backup/\n[root@vm-002 backup]# ls\nmysql-bin.000003 ops_2016-09-25.sql.gz\n[root@vm-002 backup]# gzip -d ops_2016-09-25.sql.gz \n[root@vm-002 backup]# mysql -uroot -p -v < ops_2016-09-25.sql \nEnter password: \n--------------\n/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */\n--------------\n\n--------------\n/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */\n--------------\n\n.............\n.............\n\n--------------\n/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */\n--------------\n\n这样就恢复了截至当日凌晨(4:00)前的备份数据都恢复了。\n\nmysql> show databases;                        #发现ops库已经恢复回来了\nmysql> use ops;\nReading table information for completion of table and column names\nYou can turn off this feature to get a quicker startup with -A\n\nDatabase changed\nmysql> show tables;\n+---------------+\n| Tables_in_ops |\n+---------------+\n| member |\n+---------------+\n1 row in set (0.00 sec)\n\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n+----+-----------+-----+-----+---------+\n2 rows in set (0.00 sec)\n\nmysql>\n```\n但是这仅仅只是恢复了当天凌晨4点之前的数据，在4:00--18:00之间的数据还没有恢复回来！！\n怎么办呢？\n莫慌！这可以根据前面提到的mysql-bin.000003的新binlog日志进行恢复。\n\n8）\n从binlog日志恢复数据\n恢复命令的语法格式：\n```\nmysqlbinlog mysql-bin.0000xx | mysql -u用户名 -p密码 数据库名\n```\n--------------------------------------------------------\n常用参数选项解释：\n--start-position=875 起始pos点\n--stop-position=954 结束pos点\n--start-datetime=\"2016-9-25 22:01:08\" 起始时间点\n--stop-datetime=\"2019-9-25 22:09:46\" 结束时间点\n--database=zyyshop 指定只恢复zyyshop数据库(一台主机上往往有多个数据库，只限本地log日志)\n\n-------------------------------------------------------- \n\n不常用选项： \n-u --user=name 连接到远程主机的用户名\n-p --password[=name] 连接到远程主机的密码\n-h --host=name 从远程主机上获取binlog日志\n--read-from-remote-server 从某个MySQL服务器上读取binlog日志\n\n--------------------------------------------------------\n\n小结：实际是将读出的binlog日志内容，通过管道符传递给mysql命令。这些命令、文件尽量写成绝对路径；\n\na）完全恢复(需要手动vim编辑mysql-bin.000003，将那条drop语句剔除掉)\n```\n[root@vm-002 backup]# /usr/bin/mysqlbinlog /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n```\nb）指定pos结束点恢复(部分恢复)：\n--stop-position=471 pos结束节点（按照事务区间算，是471）\n\n注意：\n此pos结束节点介于“member表原始数据”与更新“name='李四'”之前的数据，这样就可以恢复到更改“name='李四'”之前的数据了。\n操作如下：\n```\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --stop-position=471 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | xiaoer | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n\n恢复截止到更改“name='李四'”之间的数据（按照事务区间算，是673）\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --stop-position=673 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | 李四 | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n```\n\nc）指定pso点区间恢复(部分恢复)：\n更新 name='李四' 这条数据，日志区间是Pos[538] --> End_log_pos[646]，按事务区间是：Pos[471] --> End_log_pos[673]\n\n更新 name='小二' 这条数据，日志区间是Pos[740] --> End_log_pos[848]，按事务区间是：Pos[673] --> End_log_pos[875]\n\nc1）\n单独恢复 name='李四' 这步操作，可这样：\n按照binlog日志区间单独恢复：\n```\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=538 --stop-position=646 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n\n按照事务区间单独恢复\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=471 --stop-position=673 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n```\nc2）\n单独恢复 name='小二' 这步操作，可这样：\n按照binlog日志区间单独恢复：\n```\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=740 --stop-position=848 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n\n按照事务区间单独恢复\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=673 --stop-position=875 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n```\nc3）\n将 name='李四'、name='小二' 多步操作一起恢复，需要按事务区间，可这样：\n```\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=471 --stop-position=875 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n\n查看数据库：\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | 小二 | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | 李四 | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n```\n这样，就恢复了删除前的数据状态了！！\n\n-----------------\n另外：\n也可指定时间节点区间恢复(部分恢复)：\n除了用pos节点的办法进行恢复，也可以通过指定时间节点区间进行恢复，按时间恢复需要用mysqlbinlog命令读取binlog日志内容，找时间节点。\n\n如上，误删除ops库后：\n先进行全备份恢复\n```\n[root@vm-002 backup]# mysql -uroot -p -v < ops_2016-09-25.sql\n```\n查看ops数据库\n```\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n+----+-----------+-----+-----+---------+\n2 rows in set (0.00 sec)\n\nmysql>\n\n查看mysq-bin00003日志，找出时间节点\n[root@vm-002 ~]# cd /var/lib/mysql\n[root@vm-002 mysql]# mysqlbinlog mysql-bin.000003 \n.............\n.............\nBEGIN\n/*!*/;\n# at 173\n#160925 21:57:19 server id 1 end_log_pos 201 Intvar\nSET INSERT_ID=3/*!*/;\n# at 201\n#160925 21:57:19 server id 1 end_log_pos 444 Query thread_id=3 exec_time=0 error_code=0\nuse `ops`/*!*/;\nSET TIMESTAMP=1474811839/*!*/;\ninsert into ops.member(`name`,`sex`,`age`,`classid`) values('yiyi','w',20,'cls1'),('xiaoer','m',22,'cls3'),('zhangsan','w',21,'cls5'),('lisi','m',20,'cls4'),('wangwu','w',26,'cls6')                               #执行的sql语句\n/*!*/;\n# at 444\n#160925 21:57:19 server id 1 end_log_pos 471 Xid = 66    #开始执行的时间\nCOMMIT/*!*/;\n# at 471\n#160925 21:58:41 server id 1 end_log_pos 538 Query thread_id=3 exec_time=0 error_code=0    #结束时间\nSET TIMESTAMP=1474811921/*!*/;\nBEGIN\n/*!*/;\n# at 538\n#160925 21:58:41 server id 1 end_log_pos 646 Query thread_id=3 exec_time=0 error_code=0\nSET TIMESTAMP=1474811921/*!*/;\nupdate ops.member set name='李四' where id=4     #执行的sql语句\n/*!*/;\n# at 646\n#160925 21:58:41 server id 1 end_log_pos 673 Xid = 68    #开始执行的时间\nCOMMIT/*!*/;\n# at 673\n#160925 21:58:56 server id 1 end_log_pos 740 Query thread_id=3 exec_time=0 error_code=0   #结束时间\nSET TIMESTAMP=1474811936/*!*/;\nBEGIN\n/*!*/;\n# at 740\n#160925 21:58:56 server id 1 end_log_pos 848 Query thread_id=3 exec_time=0 error_code=0\nSET TIMESTAMP=1474811936/*!*/;\nupdate ops.member set name='小二' where id=2      #执行的sql语句\n/*!*/;\n# at 848\n#160925 21:58:56 server id 1 end_log_pos 875 Xid = 69   #开始执行的时间\nCOMMIT/*!*/;\n# at 875\n#160925 22:01:08 server id 1 end_log_pos 954 Query thread_id=3 exec_time=0 error_code=0    #结束时间\nSET TIMESTAMP=1474812068/*!*/;\ndrop database ops\n/*!*/;\n# at 954\n#160925 22:09:46 server id 1 end_log_pos 997 Rotate to mysql-bin.000004 pos: 4\nDELIMITER ;\n# End of log file\nROLLBACK /* added by mysqlbinlog */;\n/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;\n\n恢复到更改“name='李四'”之前的数据\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=\"2016-09-25 21:57:19\" --stop-datetime=\"2016-09-25 21:58:41\" --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | xiaoer | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=\"2016-09-25 21:58:41\" --stop-datetime=\"2016-09-25 21:58:56\" --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | 李四 | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=\"2016-09-25 21:58:56\" --stop-datetime=\"2016-09-25 22:01:08\" --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | 小二 | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | 李四 | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n```\n这样，就恢复了删除前的状态了！\n\n总结：\n所谓恢复，就是让mysql将保存在binlog日志中指定段落区间的sql语句逐个重新执行一次而已。\n","source":"_posts/mysql使用binlog日志恢复.md","raw":"---\ntitle: mysql使用binlog日志恢复\ndate: 2018-11-7\ntags: mysql\ncategories: mysql\n---\n众所周知，binlog日志对于mysql数据库来说是十分重要的。在数据丢失的紧急情况下，我们往往会想到用binlog日志功能进行数据恢复（定时全备份+binlog日志恢复增量数据部分），化险为夷！\n<!--more-->\n废话不多说，下面是梳理的binlog日志操作解说：\n\n## 一、初步了解binlog\n\nMySQL的二进制日志binlog可以说是MySQL最重要的日志，它记录了所有的DDL和DML语句（除了数据查询语句select），以事件形式记录，还包含语句所执行的消耗的时间，MySQL的二进制日志是事务安全型的。\n\n----------------------------------------------------------------------------------------------------------------------------------------------\nDDL\n\n----Data Definition Language 数据库定义语言 \n\n主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表（TABLE）的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用。\n\nDML\n\n----Data Manipulation Language 数据操纵语言\n\n主要的命令是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言\n\n----------------------------------------------------------------------------------------------------------------------------------------------\n\nmysqlbinlog常见的选项有以下几个：\n--start-datetime：从二进制日志中读取指定等于时间戳或者晚于本地计算机的时间\n--stop-datetime：从二进制日志中读取指定小于时间戳或者等于本地计算机的时间 取值和上述一样\n--start-position：从二进制日志中读取指定position 事件位置作为开始。\n--stop-position：从二进制日志中读取指定position 事件位置作为事件截至\n\n*********************************************************************\n\n一般来说开启binlog日志大概会有1%的性能损耗。\n### binlog日志有两个最重要的使用场景: \n 1）MySQL主从复制：MySQL Replication在Master端开启binlog，Master把它的二进制日志传递给slaves来达到\nmaster-slave数据一致的目的。 \n 2）自然就是数据恢复了，通过使用mysqlbinlog工具来使恢复数据。\n### binlog日志包括两类文件：\n 1）二进制日志索引文件（文件名后缀为.index）用于记录所有的二进制文件\n 2）二进制日志文件（文件名后缀为.00000*）记录数据库所有的DDL和DML(除了数据查询语句select)语句事件。\n\n## 二、开启binlog日志：\n 1）编辑打开mysql配置文件/etc/mys.cnf\n\n```\n[root@vm-002 ~]# vim /etc/my.cnf\n\n在[mysqld] 区块添加 \nlog-bin=mysql-bin 确认是打开状态(mysql-bin 是日志的基本名或前缀名)；\n```\n 2）重启mysqld服务使配置生效\n\n```\n[root@vm-002 ~]# /etc/init.d/mysqld stop\n[root@vm-002 ~]# /etc/init.d/mysqld restart\nStopping mysqld: [ OK ]\nStarting mysqld: [ OK ]\n```\n\n 3）查看binlog日志是否开启\n```\nmysql> show variables like 'log_%'; \n+---------------------------------+---------------------+\n| Variable_name | Value |\n+---------------------------------+---------------------+\n| log_bin | ON |\n| log_bin_trust_function_creators | OFF |\n| log_bin_trust_routine_creators | OFF |\n| log_error | /var/log/mysqld.log |\n| log_output | FILE |\n| log_queries_not_using_indexes | OFF |\n| log_slave_updates | OFF |\n| log_slow_queries | OFF |\n| log_warnings | 1 |\n+---------------------------------+---------------------+\n9 rows in set (0.00 sec)\n```\n\n## 三、常用的binlog日志操作命令\n\n 1）查看所有binlog日志列表\n```\nmysql> show master logs;\n+------------------+-----------+\n| Log_name | File_size |\n+------------------+-----------+\n| mysql-bin.000001 | 149 |\n| mysql-bin.000002 | 4102 |\n+------------------+-----------+\n2 rows in set (0.00 sec)\n```\n\n 2）查看master状态，即最后(最新)一个binlog日志的编号名称，及其最后一个操作事件pos结束点(Position)值\n```\nmysql> show master status;\n+------------------+----------+--------------+------------------+\n| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |\n+------------------+----------+--------------+------------------+\n| mysql-bin.000002 | 4102 | | |\n+------------------+----------+--------------+------------------+\n1 row in set (0.00 sec)\n```\n\n 3）flush刷新log日志，自此刻开始产生一个新编号的binlog日志文件\n```\nmysql> flush logs; \nQuery OK, 0 rows affected (0.13 sec)\n\nmysql> show master logs; \n+------------------+-----------+\n| Log_name | File_size |\n+------------------+-----------+\n| mysql-bin.000001 | 149 |\n| mysql-bin.000002 | 4145 |\n| mysql-bin.000003 | 106 |\n+------------------+-----------+\n3 rows in set (0.00 sec)\n```\n\n注意：\n每当mysqld服务重启时，会自动执行此命令，刷新binlog日志；在mysqldump备份数据时加 -F 选项也会刷新binlog日志；\n\n 4）重置(清空)所有binlog日志\n```\nmysql> reset master;\nQuery OK, 0 rows affected (0.12 sec)\n\nmysql> show master logs; \n+------------------+-----------+\n| Log_name | File_size |\n+------------------+-----------+\n| mysql-bin.000001 | 106 |\n+------------------+-----------+\n1 row in set (0.00 sec)\n```\n\n## 四、查看binlog日志内容，常用有两种方式：\n 1）使用mysqlbinlog自带查看命令法：\n注意：\n-->binlog是二进制文件，普通文件查看器cat、more、vim等都无法打开，必须使用自带的mysqlbinlog命令查看\n-->binlog日志与数据库文件在同目录中\n-->在MySQL5.5以下版本使用mysqlbinlog命令时如果报错，就加上 “--no-defaults”选项\n\n查看mysql的数据存放目录，从下面结果可知是/var/lib//mysql\n```\n[root@vm-002 ~]# ps -ef|grep mysql\nroot 9791 1 0 21:18 pts/0 00:00:00 /bin/sh /usr/bin/mysqld_safe --datadir=/var/lib/mysql --socket=/var/lib/mysql/mysql.sock --pid-file=/var/run/mysqld/mysqld.pid --basedir=/usr --user=mysql\nmysql 9896 9791 0 21:18 pts/0 00:00:00 /usr/libexec/mysqld --basedir=/usr --datadir=/var/lib/mysql --user=mysql --log-error=/var/log/mysqld.log --pid-file=/var/run/mysqld/mysqld.pid --socket=/var/lib/mysql/mysql.sock\nroot 9916 9699 0 21:18 pts/0 00:00:00 mysql -px xxxx\nroot 9919 9715 0 21:23 pts/1 00:00:00 grep --color mysql\n\n[root@vm-002 ~]# cd /var/lib/mysql/\n[root@vm-002 mysql]# ls\nibdata1 ib_logfile0 ib_logfile1 mysql mysql-bin.000001 mysql-bin.000002 mysql-bin.index mysql.sock ops test\n\n使用mysqlbinlog命令查看binlog日志内容，下面截取其中的一个片段分析：\n[root@vm-002 mysql]# mysqlbinlog mysql-bin.000002\n..............\n# at 624\n#160925 21:29:53 server id 1 end_log_pos 796 Query\tthread_id=3\texec_time=0\terror_code=0\nSET TIMESTAMP=1474810193/*!*/;\ninsert into member(`name`,`sex`,`age`,`classid`) values('wangshibo','m',27,'cls1'),('guohuihui','w',27,'cls2')        #执行的sql语句\n/*!*/;\n#at 796\n#160925 21:29:53 server id 1 end_log_pos 823 Xid = 17                  #执行的时间\n.............\n```\n解释：\nserver id 1 ： 数据库主机的服务号；\nend_log_pos 796： sql结束时的pos节点\nthread_id=11： 线程号\n\n 2）上面这种办法读取出binlog日志的全文内容比较多，不容易分辨查看到pos点信息\n下面介绍一种更为方便的查询命令：\n命令格式：\n```\nmysql> show binlog events [IN 'log_name'] [FROM pos] [LIMIT [offset,] row_count];\n```\n参数解释：\nIN 'log_name' ：指定要查询的binlog文件名(不指定就是第一个binlog文件)\nFROM pos ：指定从哪个pos起始点开始查起(不指定就是从整个文件首个pos点开始算)\nLIMIT [offset,] ：偏移量(不指定就是0)\nrow_count ：查询总条数(不指定就是所有行)\n```\nmysql> show master logs;\n+------------------+-----------+\n| Log_name | File_size |\n+------------------+-----------+\n| mysql-bin.000001 | 125 |\n| mysql-bin.000002 | 823 |\n+------------------+-----------+\n2 rows in set (0.00 sec)\n\nmysql> show binlog events in 'mysql-bin.000002'\\G;\n*************************** 1. row ***************************\nLog_name: mysql-bin.000002\nPos: 4\nEvent_type: Format_desc\nServer_id: 1\nEnd_log_pos: 106\nInfo: Server ver: 5.1.73-log, Binlog ver: 4\n*************************** 2. row ***************************\nLog_name: mysql-bin.000002\nPos: 106\nEvent_type: Query\nServer_id: 1\nEnd_log_pos: 188\nInfo: use `ops`; drop table customers\n*************************** 3. row ***************************\nLog_name: mysql-bin.000002\nPos: 188\nEvent_type: Query\nServer_id: 1\nEnd_log_pos: 529\nInfo: use `ops`; CREATE TABLE IF NOT EXISTS `member` (\n`id` int(10) unsigned NOT NULL AUTO_INCREMENT,\n`name` varchar(16) NOT NULL,\n`sex` enum('m','w') NOT NULL DEFAULT 'm',\n`age` tinyint(3) unsigned NOT NULL,\n`classid` char(6) DEFAULT NULL,\nPRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n*************************** 4. row ***************************\nLog_name: mysql-bin.000002\nPos: 529\nEvent_type: Query\nServer_id: 1\nEnd_log_pos: 596\nInfo: BEGIN\n*************************** 5. row ***************************\nLog_name: mysql-bin.000002\nPos: 596\nEvent_type: Intvar\nServer_id: 1\nEnd_log_pos: 624\nInfo: INSERT_ID=1\n*************************** 6. row ***************************\nLog_name: mysql-bin.000002\nPos: 624\nEvent_type: Query\nServer_id: 1\nEnd_log_pos: 796\nInfo: use `ops`; insert into member(`name`,`sex`,`age`,`classid`) values('wangshibo','m',27,'cls1'),('guohuihui','w',27,'cls2')\n*************************** 7. row ***************************\nLog_name: mysql-bin.000002\nPos: 796\nEvent_type: Xid\nServer_id: 1\nEnd_log_pos: 823\nInfo: COMMIT /* xid=17 */\n7 rows in set (0.00 sec)\n\nERROR: \nNo query specified\n\nmysql>\n```\n上面这条语句可以将指定的binlog日志文件，分成有效事件行的方式返回，并可使用limit指定pos点的起始偏移，查询条数！\n如下操作示例：\n a）查询第一个(最早)的binlog日志：\n```\nmysql> show binlog events\\G;\n```\n\n b）指定查询 mysql-bin.000002这个文件：\n```\nmysql> show binlog events in 'mysql-bin.000002'\\G;\n```\n\nc）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起：\n```\nmysql> show binlog events in 'mysql-bin.000002' from 624\\G;\n```\n\nd）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起，查询10条（即10条语句）\n```\nmysql> show binlog events in 'mysql-bin.000002' from 624 limit 10\\G;\n```\n\ne）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起，偏移2行（即中间跳过2个），查询10条\n```\nmysql> show binlog events in 'mysql-bin.000002' from 624 limit 2,10\\G;\n```\n\n## 五、利用binlog日志恢复mysql数据\n\n以下对ops库的member表进行操作\n```\nmysql> use ops；\nmysql> CREATE TABLE IF NOT EXISTS `member` (\n-> `id` int(10) unsigned NOT NULL AUTO_INCREMENT,\n-> `name` varchar(16) NOT NULL,\n-> `sex` enum('m','w') NOT NULL DEFAULT 'm',\n-> `age` tinyint(3) unsigned NOT NULL,\n-> `classid` char(6) DEFAULT NULL,\n-> PRIMARY KEY (`id`)\n-> ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\nQuery OK, 0 rows affected (0.10 sec)\n\nmysql> show tables;\n+---------------+\n| Tables_in_ops |\n+---------------+\n| member |\n+---------------+\n1 row in set (0.00 sec)\n\nmysql> desc member;\n+---------+---------------------+------+-----+---------+----------------+\n| Field | Type | Null | Key | Default | Extra |\n+---------+---------------------+------+-----+---------+----------------+\n| id | int(10) unsigned | NO | PRI | NULL | auto_increment |\n| name | varchar(16) | NO | | NULL | |\n| sex | enum('m','w') | NO | | m | |\n| age | tinyint(3) unsigned | NO | | NULL | |\n| classid | char(6) | YES | | NULL | |\n+---------+---------------------+------+-----+---------+----------------+\n5 rows in set (0.00 sec)\n```\n事先插入两条数据\n```\nmysql> insert into member(`name`,`sex`,`age`,`classid`) values('wangshibo','m',27,'cls1'),('guohuihui','w',27,'cls2');\nQuery OK, 2 rows affected (0.08 sec)\nRecords: 2 Duplicates: 0 Warnings: 0\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n+----+-----------+-----+-----+---------+\n2 rows in set (0.00 sec)\n```\n下面开始进行场景模拟：\n1）\nops库会在每天凌晨4点进行一次完全备份的定时计划任务，如下：\n```\n[root@vm-002 ~]# crontab -l\n0 4 * * * /usr/bin/mysqldump -uroot -p -B -F -R -x --master-data=2 ops|gzip >/opt/backup/ops_$(date +%F).sql.gz\n```\n这里手动执行下，将ops数据库备份到/opt/backup/ops_$(date +%F).sql.gz文件中：\n```\n[root@vm-002 ~]# mysqldump -uroot -p -B -F -R -x --master-data=2 ops|gzip >/opt/backup/ops_$(date +%F).sql.gz\nEnter password: \n[root@vm-002 ~]# ls /opt/backup/\nops_2016-09-25.sql.gz\n```\n-----------------\n参数说明：\n-B：指定数据库\n-F：刷新日志\n-R：备份存储过程等\n-x：锁表\n--master-data：在备份语句里添加CHANGE MASTER语句以及binlog文件及位置点信息\n\n-----------------\n待到数据库备份完成，就不用担心数据丢失了，因为有完全备份数据在！！\n\n由于上面在全备份的时候使用了-F选项，那么当数据备份操作刚开始的时候系统就会自动刷新log，这样就会自动产生\n一个新的binlog日志，这个新的binlog日志就会用来记录备份之后的数据库“增删改”操作\n查看一下：\n```\nmysql> show master status;\n+------------------+----------+--------------+------------------+\n| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |\n+------------------+----------+--------------+------------------+\n| mysql-bin.000003 | 106 | | |\n+------------------+----------+--------------+------------------+\n1 row in set (0.00 sec)\n```\n也就是说， mysql-bin.000003 是用来记录4:00之后对数据库的所有“增删改”操作。\n\n2）\n早上9点上班了，由于业务的需求会对数据库进行各种“增删改”操作。\n比如：在ops库下member表内插入、修改了数据等等：\n\n先是早上进行插入数据：\n```\nmysql> insert into ops.member(`name`,`sex`,`age`,`classid`) values('yiyi','w',20,'cls1'),('xiaoer','m',22,'cls3'),('zhangsan','w',21,'cls5'),('lisi','m',20,'cls4'),('wangwu','w',26,'cls6');\nQuery OK, 5 rows affected (0.08 sec)\nRecords: 5 Duplicates: 0 Warnings: 0\n\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | xiaoer | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n```\n3）\n中午又执行了修改数据操作：\n```\nmysql> update ops.member set name='李四' where id=4;\nQuery OK, 1 row affected (0.07 sec)\nRows matched: 1 Changed: 1 Warnings: 0\n\nmysql> update ops.member set name='小二' where id=2;\nQuery OK, 1 row affected (0.06 sec)\nRows matched: 1 Changed: 1 Warnings: 0\n\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | 小二 | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | 李四 | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n```\n\n4）\n在下午18:00的时候，悲剧莫名其妙的出现了！\n手贱执行了drop语句，直接删除了ops库！吓尿！\n```\nmysql> drop database ops;\nQuery OK, 1 row affected (0.02 sec)\n```\n5）\n这种时候，一定不要慌张！！！\n先仔细查看最后一个binlog日志，并记录下关键的pos点，到底是哪个pos点的操作导致了数据库的破坏(通常在最后几步)；\n\n先备份一下最后一个binlog日志文件：\n```\n[root@vm-002 ~]# cd /var/lib/mysql/\n[root@vm-002 mysql]# cp -v mysql-bin.000003 /opt/backup/\n`mysql-bin.000003' -> `/opt/backup/mysql-bin.000003'\n[root@vm-002 mysql]# ls /opt/backup/\nmysql-bin.000003 ops_2016-09-25.sql.gz\n```\n\n接着执行一次刷新日志索引操作，重新开始新的binlog日志记录文件。按理说mysql-bin.000003\n这个文件不会再有后续写入了，因为便于我们分析原因及查找ops节点，以后所有数据库操作都会写入到下一个日志文件。\n```\nmysql> flush logs;\nQuery OK, 0 rows affected (0.13 sec)\n\nmysql> show master status;\n+------------------+----------+--------------+------------------+\n| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |\n+------------------+----------+--------------+------------------+\n| mysql-bin.000004 | 106 | | |\n+------------------+----------+--------------+------------------+\n1 row in set (0.00 sec)\n```\n\n6）\n读取binlog日志，分析问题。\n读取binlog日志的方法上面已经说到。\n方法一：使用mysqlbinlog读取binlog日志：\n```\n[root@vm-002 ~]# cd /var/lib/mysql/\n[root@vm-002 mysql]# mysqlbinlog mysql-bin.000003\n```\n\n方法二：登录服务器，并查看(推荐此种方法)\n```\nmysql> show binlog events in 'mysql-bin.000003';\n\n+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+\n| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |\n+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+\n| mysql-bin.000003 | 4 | Format_desc | 1 | 106 | Server ver: 5.1.73-log, Binlog ver: 4 |\n| mysql-bin.000003 | 106 | Query | 1 | 173 | BEGIN |\n| mysql-bin.000003 | 173 | Intvar | 1 | 201 | INSERT_ID=3 |\n| mysql-bin.000003 | 201 | Query | 1 | 444 | use `ops`; insert into ops.member(`name`,`sex`,`age`,`gsan','w',21,'cls5'),('lisi','m',20,'cls4'),('wangwu','w',26,'cls6') |\n| mysql-bin.000003 | 444 | Xid | 1 | 471 | COMMIT /* xid=66 */ |\n| mysql-bin.000003 | 471 | Query | 1 | 538 | BEGIN |\n| mysql-bin.000003 | 538 | Query | 1 | 646 | use `ops`; update ops.member set name='李四' where id= |\n| mysql-bin.000003 | 646 | Xid | 1 | 673 | COMMIT /* xid=68 */ |\n| mysql-bin.000003 | 673 | Query | 1 | 740 | BEGIN |\n| mysql-bin.000003 | 740 | Query | 1 | 848 | use `ops`; update ops.member set name='小二' where id= |\n| mysql-bin.000003 | 848 | Xid | 1 | 875 | COMMIT /* xid=69 */ |\n| mysql-bin.000003 | 875 | Query | 1 | 954 | drop database ops |\n| mysql-bin.000003 | 954 | Rotate | 1 | 997 | mysql-bin.000004;pos=4 |\n+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+\n13 rows in set (0.00 sec)\n\n或者：\n\nmysql> show binlog events in 'mysql-bin.000003'\\G;\n.........\n.........\n*************************** 12. row ***************************\nLog_name: mysql-bin.000003\nPos: 875\nEvent_type: Query\nServer_id: 1\nEnd_log_pos: 954\nInfo: drop database ops\n*************************** 13. row ***************************\nLog_name: mysql-bin.000003\nPos: 954\nEvent_type: Rotate\nServer_id: 1\nEnd_log_pos: 997\nInfo: mysql-bin.000004;pos=4\n13 rows in set (0.00 sec)\n```\n通过分析，造成数据库破坏的pos点区间是介于 875--954 之间（这是按照日志区间的pos节点算的），只要恢复到875前就可。\n\n7）\n先把凌晨4点全备份的数据恢复：\n```\n[root@vm-002 ~]# cd /opt/backup/\n[root@vm-002 backup]# ls\nmysql-bin.000003 ops_2016-09-25.sql.gz\n[root@vm-002 backup]# gzip -d ops_2016-09-25.sql.gz \n[root@vm-002 backup]# mysql -uroot -p -v < ops_2016-09-25.sql \nEnter password: \n--------------\n/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */\n--------------\n\n--------------\n/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */\n--------------\n\n.............\n.............\n\n--------------\n/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */\n--------------\n\n这样就恢复了截至当日凌晨(4:00)前的备份数据都恢复了。\n\nmysql> show databases;                        #发现ops库已经恢复回来了\nmysql> use ops;\nReading table information for completion of table and column names\nYou can turn off this feature to get a quicker startup with -A\n\nDatabase changed\nmysql> show tables;\n+---------------+\n| Tables_in_ops |\n+---------------+\n| member |\n+---------------+\n1 row in set (0.00 sec)\n\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n+----+-----------+-----+-----+---------+\n2 rows in set (0.00 sec)\n\nmysql>\n```\n但是这仅仅只是恢复了当天凌晨4点之前的数据，在4:00--18:00之间的数据还没有恢复回来！！\n怎么办呢？\n莫慌！这可以根据前面提到的mysql-bin.000003的新binlog日志进行恢复。\n\n8）\n从binlog日志恢复数据\n恢复命令的语法格式：\n```\nmysqlbinlog mysql-bin.0000xx | mysql -u用户名 -p密码 数据库名\n```\n--------------------------------------------------------\n常用参数选项解释：\n--start-position=875 起始pos点\n--stop-position=954 结束pos点\n--start-datetime=\"2016-9-25 22:01:08\" 起始时间点\n--stop-datetime=\"2019-9-25 22:09:46\" 结束时间点\n--database=zyyshop 指定只恢复zyyshop数据库(一台主机上往往有多个数据库，只限本地log日志)\n\n-------------------------------------------------------- \n\n不常用选项： \n-u --user=name 连接到远程主机的用户名\n-p --password[=name] 连接到远程主机的密码\n-h --host=name 从远程主机上获取binlog日志\n--read-from-remote-server 从某个MySQL服务器上读取binlog日志\n\n--------------------------------------------------------\n\n小结：实际是将读出的binlog日志内容，通过管道符传递给mysql命令。这些命令、文件尽量写成绝对路径；\n\na）完全恢复(需要手动vim编辑mysql-bin.000003，将那条drop语句剔除掉)\n```\n[root@vm-002 backup]# /usr/bin/mysqlbinlog /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n```\nb）指定pos结束点恢复(部分恢复)：\n--stop-position=471 pos结束节点（按照事务区间算，是471）\n\n注意：\n此pos结束节点介于“member表原始数据”与更新“name='李四'”之前的数据，这样就可以恢复到更改“name='李四'”之前的数据了。\n操作如下：\n```\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --stop-position=471 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | xiaoer | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n\n恢复截止到更改“name='李四'”之间的数据（按照事务区间算，是673）\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --stop-position=673 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | 李四 | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n```\n\nc）指定pso点区间恢复(部分恢复)：\n更新 name='李四' 这条数据，日志区间是Pos[538] --> End_log_pos[646]，按事务区间是：Pos[471] --> End_log_pos[673]\n\n更新 name='小二' 这条数据，日志区间是Pos[740] --> End_log_pos[848]，按事务区间是：Pos[673] --> End_log_pos[875]\n\nc1）\n单独恢复 name='李四' 这步操作，可这样：\n按照binlog日志区间单独恢复：\n```\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=538 --stop-position=646 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n\n按照事务区间单独恢复\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=471 --stop-position=673 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n```\nc2）\n单独恢复 name='小二' 这步操作，可这样：\n按照binlog日志区间单独恢复：\n```\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=740 --stop-position=848 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n\n按照事务区间单独恢复\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=673 --stop-position=875 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n```\nc3）\n将 name='李四'、name='小二' 多步操作一起恢复，需要按事务区间，可这样：\n```\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=471 --stop-position=875 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n\n查看数据库：\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | 小二 | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | 李四 | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n```\n这样，就恢复了删除前的数据状态了！！\n\n-----------------\n另外：\n也可指定时间节点区间恢复(部分恢复)：\n除了用pos节点的办法进行恢复，也可以通过指定时间节点区间进行恢复，按时间恢复需要用mysqlbinlog命令读取binlog日志内容，找时间节点。\n\n如上，误删除ops库后：\n先进行全备份恢复\n```\n[root@vm-002 backup]# mysql -uroot -p -v < ops_2016-09-25.sql\n```\n查看ops数据库\n```\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n+----+-----------+-----+-----+---------+\n2 rows in set (0.00 sec)\n\nmysql>\n\n查看mysq-bin00003日志，找出时间节点\n[root@vm-002 ~]# cd /var/lib/mysql\n[root@vm-002 mysql]# mysqlbinlog mysql-bin.000003 \n.............\n.............\nBEGIN\n/*!*/;\n# at 173\n#160925 21:57:19 server id 1 end_log_pos 201 Intvar\nSET INSERT_ID=3/*!*/;\n# at 201\n#160925 21:57:19 server id 1 end_log_pos 444 Query thread_id=3 exec_time=0 error_code=0\nuse `ops`/*!*/;\nSET TIMESTAMP=1474811839/*!*/;\ninsert into ops.member(`name`,`sex`,`age`,`classid`) values('yiyi','w',20,'cls1'),('xiaoer','m',22,'cls3'),('zhangsan','w',21,'cls5'),('lisi','m',20,'cls4'),('wangwu','w',26,'cls6')                               #执行的sql语句\n/*!*/;\n# at 444\n#160925 21:57:19 server id 1 end_log_pos 471 Xid = 66    #开始执行的时间\nCOMMIT/*!*/;\n# at 471\n#160925 21:58:41 server id 1 end_log_pos 538 Query thread_id=3 exec_time=0 error_code=0    #结束时间\nSET TIMESTAMP=1474811921/*!*/;\nBEGIN\n/*!*/;\n# at 538\n#160925 21:58:41 server id 1 end_log_pos 646 Query thread_id=3 exec_time=0 error_code=0\nSET TIMESTAMP=1474811921/*!*/;\nupdate ops.member set name='李四' where id=4     #执行的sql语句\n/*!*/;\n# at 646\n#160925 21:58:41 server id 1 end_log_pos 673 Xid = 68    #开始执行的时间\nCOMMIT/*!*/;\n# at 673\n#160925 21:58:56 server id 1 end_log_pos 740 Query thread_id=3 exec_time=0 error_code=0   #结束时间\nSET TIMESTAMP=1474811936/*!*/;\nBEGIN\n/*!*/;\n# at 740\n#160925 21:58:56 server id 1 end_log_pos 848 Query thread_id=3 exec_time=0 error_code=0\nSET TIMESTAMP=1474811936/*!*/;\nupdate ops.member set name='小二' where id=2      #执行的sql语句\n/*!*/;\n# at 848\n#160925 21:58:56 server id 1 end_log_pos 875 Xid = 69   #开始执行的时间\nCOMMIT/*!*/;\n# at 875\n#160925 22:01:08 server id 1 end_log_pos 954 Query thread_id=3 exec_time=0 error_code=0    #结束时间\nSET TIMESTAMP=1474812068/*!*/;\ndrop database ops\n/*!*/;\n# at 954\n#160925 22:09:46 server id 1 end_log_pos 997 Rotate to mysql-bin.000004 pos: 4\nDELIMITER ;\n# End of log file\nROLLBACK /* added by mysqlbinlog */;\n/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;\n\n恢复到更改“name='李四'”之前的数据\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=\"2016-09-25 21:57:19\" --stop-datetime=\"2016-09-25 21:58:41\" --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\n\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | xiaoer | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=\"2016-09-25 21:58:41\" --stop-datetime=\"2016-09-25 21:58:56\" --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | guohuihui | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | 李四 | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n\n[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=\"2016-09-25 21:58:56\" --stop-datetime=\"2016-09-25 22:01:08\" --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops\nmysql> select * from member;\n+----+-----------+-----+-----+---------+\n| id | name | sex | age | classid |\n+----+-----------+-----+-----+---------+\n| 1 | wangshibo | m | 27 | cls1 |\n| 2 | 小二 | w | 27 | cls2 |\n| 3 | yiyi | w | 20 | cls1 |\n| 4 | 李四 | m | 22 | cls3 |\n| 5 | zhangsan | w | 21 | cls5 |\n| 6 | lisi | m | 20 | cls4 |\n| 7 | wangwu | w | 26 | cls6 |\n+----+-----------+-----+-----+---------+\n7 rows in set (0.00 sec)\n```\n这样，就恢复了删除前的状态了！\n\n总结：\n所谓恢复，就是让mysql将保存在binlog日志中指定段落区间的sql语句逐个重新执行一次而已。\n","slug":"mysql使用binlog日志恢复","published":1,"updated":"2019-06-18T08:07:01.116Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sm1001shcb794swp09t","content":"<p>众所周知，binlog日志对于mysql数据库来说是十分重要的。在数据丢失的紧急情况下，我们往往会想到用binlog日志功能进行数据恢复（定时全备份+binlog日志恢复增量数据部分），化险为夷！<br><a id=\"more\"></a><br>废话不多说，下面是梳理的binlog日志操作解说：</p>\n<h2 id=\"一、初步了解binlog\"><a href=\"#一、初步了解binlog\" class=\"headerlink\" title=\"一、初步了解binlog\"></a>一、初步了解binlog</h2><p>MySQL的二进制日志binlog可以说是MySQL最重要的日志，它记录了所有的DDL和DML语句（除了数据查询语句select），以事件形式记录，还包含语句所执行的消耗的时间，MySQL的二进制日志是事务安全型的。</p>\n<hr>\n<p>DDL</p>\n<p>—-Data Definition Language 数据库定义语言 </p>\n<p>主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表（TABLE）的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用。</p>\n<p>DML</p>\n<p>—-Data Manipulation Language 数据操纵语言</p>\n<p>主要的命令是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言</p>\n<hr>\n<p>mysqlbinlog常见的选项有以下几个：<br>–start-datetime：从二进制日志中读取指定等于时间戳或者晚于本地计算机的时间<br>–stop-datetime：从二进制日志中读取指定小于时间戳或者等于本地计算机的时间 取值和上述一样<br>–start-position：从二进制日志中读取指定position 事件位置作为开始。<br>–stop-position：从二进制日志中读取指定position 事件位置作为事件截至</p>\n<hr>\n<p>一般来说开启binlog日志大概会有1%的性能损耗。</p>\n<h3 id=\"binlog日志有两个最重要的使用场景\"><a href=\"#binlog日志有两个最重要的使用场景\" class=\"headerlink\" title=\"binlog日志有两个最重要的使用场景:\"></a>binlog日志有两个最重要的使用场景:</h3><p> 1）MySQL主从复制：MySQL Replication在Master端开启binlog，Master把它的二进制日志传递给slaves来达到<br>master-slave数据一致的目的。<br> 2）自然就是数据恢复了，通过使用mysqlbinlog工具来使恢复数据。</p>\n<h3 id=\"binlog日志包括两类文件：\"><a href=\"#binlog日志包括两类文件：\" class=\"headerlink\" title=\"binlog日志包括两类文件：\"></a>binlog日志包括两类文件：</h3><p> 1）二进制日志索引文件（文件名后缀为.index）用于记录所有的二进制文件<br> 2）二进制日志文件（文件名后缀为.00000*）记录数据库所有的DDL和DML(除了数据查询语句select)语句事件。</p>\n<h2 id=\"二、开启binlog日志：\"><a href=\"#二、开启binlog日志：\" class=\"headerlink\" title=\"二、开启binlog日志：\"></a>二、开启binlog日志：</h2><p> 1）编辑打开mysql配置文件/etc/mys.cnf</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# vim /etc/my.cnf</span><br><span class=\"line\"></span><br><span class=\"line\">在[mysqld] 区块添加 </span><br><span class=\"line\">log-bin=mysql-bin 确认是打开状态(mysql-bin 是日志的基本名或前缀名)；</span><br></pre></td></tr></table></figure>\n<p> 2）重启mysqld服务使配置生效</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# /etc/init.d/mysqld stop</span><br><span class=\"line\">[root@vm-002 ~]# /etc/init.d/mysqld restart</span><br><span class=\"line\">Stopping mysqld: [ OK ]</span><br><span class=\"line\">Starting mysqld: [ OK ]</span><br></pre></td></tr></table></figure>\n<p> 3）查看binlog日志是否开启<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show variables like &apos;log_%&apos;; </span><br><span class=\"line\">+---------------------------------+---------------------+</span><br><span class=\"line\">| Variable_name | Value |</span><br><span class=\"line\">+---------------------------------+---------------------+</span><br><span class=\"line\">| log_bin | ON |</span><br><span class=\"line\">| log_bin_trust_function_creators | OFF |</span><br><span class=\"line\">| log_bin_trust_routine_creators | OFF |</span><br><span class=\"line\">| log_error | /var/log/mysqld.log |</span><br><span class=\"line\">| log_output | FILE |</span><br><span class=\"line\">| log_queries_not_using_indexes | OFF |</span><br><span class=\"line\">| log_slave_updates | OFF |</span><br><span class=\"line\">| log_slow_queries | OFF |</span><br><span class=\"line\">| log_warnings | 1 |</span><br><span class=\"line\">+---------------------------------+---------------------+</span><br><span class=\"line\">9 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"三、常用的binlog日志操作命令\"><a href=\"#三、常用的binlog日志操作命令\" class=\"headerlink\" title=\"三、常用的binlog日志操作命令\"></a>三、常用的binlog日志操作命令</h2><p> 1）查看所有binlog日志列表<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show master logs;</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| Log_name | File_size |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| mysql-bin.000001 | 149 |</span><br><span class=\"line\">| mysql-bin.000002 | 4102 |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">2 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p> 2）查看master状态，即最后(最新)一个binlog日志的编号名称，及其最后一个操作事件pos结束点(Position)值<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show master status;</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">| mysql-bin.000002 | 4102 | | |</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p> 3）flush刷新log日志，自此刻开始产生一个新编号的binlog日志文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; flush logs; </span><br><span class=\"line\">Query OK, 0 rows affected (0.13 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show master logs; </span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| Log_name | File_size |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| mysql-bin.000001 | 149 |</span><br><span class=\"line\">| mysql-bin.000002 | 4145 |</span><br><span class=\"line\">| mysql-bin.000003 | 106 |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">3 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>注意：<br>每当mysqld服务重启时，会自动执行此命令，刷新binlog日志；在mysqldump备份数据时加 -F 选项也会刷新binlog日志；</p>\n<p> 4）重置(清空)所有binlog日志<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; reset master;</span><br><span class=\"line\">Query OK, 0 rows affected (0.12 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show master logs; </span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| Log_name | File_size |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| mysql-bin.000001 | 106 |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"四、查看binlog日志内容，常用有两种方式：\"><a href=\"#四、查看binlog日志内容，常用有两种方式：\" class=\"headerlink\" title=\"四、查看binlog日志内容，常用有两种方式：\"></a>四、查看binlog日志内容，常用有两种方式：</h2><p> 1）使用mysqlbinlog自带查看命令法：<br>注意：<br>–&gt;binlog是二进制文件，普通文件查看器cat、more、vim等都无法打开，必须使用自带的mysqlbinlog命令查看<br>–&gt;binlog日志与数据库文件在同目录中<br>–&gt;在MySQL5.5以下版本使用mysqlbinlog命令时如果报错，就加上 “–no-defaults”选项</p>\n<p>查看mysql的数据存放目录，从下面结果可知是/var/lib//mysql<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# ps -ef|grep mysql</span><br><span class=\"line\">root 9791 1 0 21:18 pts/0 00:00:00 /bin/sh /usr/bin/mysqld_safe --datadir=/var/lib/mysql --socket=/var/lib/mysql/mysql.sock --pid-file=/var/run/mysqld/mysqld.pid --basedir=/usr --user=mysql</span><br><span class=\"line\">mysql 9896 9791 0 21:18 pts/0 00:00:00 /usr/libexec/mysqld --basedir=/usr --datadir=/var/lib/mysql --user=mysql --log-error=/var/log/mysqld.log --pid-file=/var/run/mysqld/mysqld.pid --socket=/var/lib/mysql/mysql.sock</span><br><span class=\"line\">root 9916 9699 0 21:18 pts/0 00:00:00 mysql -px xxxx</span><br><span class=\"line\">root 9919 9715 0 21:23 pts/1 00:00:00 grep --color mysql</span><br><span class=\"line\"></span><br><span class=\"line\">[root@vm-002 ~]# cd /var/lib/mysql/</span><br><span class=\"line\">[root@vm-002 mysql]# ls</span><br><span class=\"line\">ibdata1 ib_logfile0 ib_logfile1 mysql mysql-bin.000001 mysql-bin.000002 mysql-bin.index mysql.sock ops test</span><br><span class=\"line\"></span><br><span class=\"line\">使用mysqlbinlog命令查看binlog日志内容，下面截取其中的一个片段分析：</span><br><span class=\"line\">[root@vm-002 mysql]# mysqlbinlog mysql-bin.000002</span><br><span class=\"line\">..............</span><br><span class=\"line\"># at 624</span><br><span class=\"line\">#160925 21:29:53 server id 1 end_log_pos 796 Query\tthread_id=3\texec_time=0\terror_code=0</span><br><span class=\"line\">SET TIMESTAMP=1474810193/*!*/;</span><br><span class=\"line\">insert into member(`name`,`sex`,`age`,`classid`) values(&apos;wangshibo&apos;,&apos;m&apos;,27,&apos;cls1&apos;),(&apos;guohuihui&apos;,&apos;w&apos;,27,&apos;cls2&apos;)        #执行的sql语句</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\">#at 796</span><br><span class=\"line\">#160925 21:29:53 server id 1 end_log_pos 823 Xid = 17                  #执行的时间</span><br><span class=\"line\">.............</span><br></pre></td></tr></table></figure></p>\n<p>解释：<br>server id 1 ： 数据库主机的服务号；<br>end_log_pos 796： sql结束时的pos节点<br>thread_id=11： 线程号</p>\n<p> 2）上面这种办法读取出binlog日志的全文内容比较多，不容易分辨查看到pos点信息<br>下面介绍一种更为方便的查询命令：<br>命令格式：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events [IN &apos;log_name&apos;] [FROM pos] [LIMIT [offset,] row_count];</span><br></pre></td></tr></table></figure></p>\n<p>参数解释：<br>IN ‘log_name’ ：指定要查询的binlog文件名(不指定就是第一个binlog文件)<br>FROM pos ：指定从哪个pos起始点开始查起(不指定就是从整个文件首个pos点开始算)<br>LIMIT [offset,] ：偏移量(不指定就是0)<br>row_count ：查询总条数(不指定就是所有行)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show master logs;</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| Log_name | File_size |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| mysql-bin.000001 | 125 |</span><br><span class=\"line\">| mysql-bin.000002 | 823 |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">2 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos;\\G;</span><br><span class=\"line\">*************************** 1. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 4</span><br><span class=\"line\">Event_type: Format_desc</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 106</span><br><span class=\"line\">Info: Server ver: 5.1.73-log, Binlog ver: 4</span><br><span class=\"line\">*************************** 2. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 106</span><br><span class=\"line\">Event_type: Query</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 188</span><br><span class=\"line\">Info: use `ops`; drop table customers</span><br><span class=\"line\">*************************** 3. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 188</span><br><span class=\"line\">Event_type: Query</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 529</span><br><span class=\"line\">Info: use `ops`; CREATE TABLE IF NOT EXISTS `member` (</span><br><span class=\"line\">`id` int(10) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class=\"line\">`name` varchar(16) NOT NULL,</span><br><span class=\"line\">`sex` enum(&apos;m&apos;,&apos;w&apos;) NOT NULL DEFAULT &apos;m&apos;,</span><br><span class=\"line\">`age` tinyint(3) unsigned NOT NULL,</span><br><span class=\"line\">`classid` char(6) DEFAULT NULL,</span><br><span class=\"line\">PRIMARY KEY (`id`)</span><br><span class=\"line\">) ENGINE=InnoDB DEFAULT CHARSET=utf8</span><br><span class=\"line\">*************************** 4. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 529</span><br><span class=\"line\">Event_type: Query</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 596</span><br><span class=\"line\">Info: BEGIN</span><br><span class=\"line\">*************************** 5. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 596</span><br><span class=\"line\">Event_type: Intvar</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 624</span><br><span class=\"line\">Info: INSERT_ID=1</span><br><span class=\"line\">*************************** 6. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 624</span><br><span class=\"line\">Event_type: Query</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 796</span><br><span class=\"line\">Info: use `ops`; insert into member(`name`,`sex`,`age`,`classid`) values(&apos;wangshibo&apos;,&apos;m&apos;,27,&apos;cls1&apos;),(&apos;guohuihui&apos;,&apos;w&apos;,27,&apos;cls2&apos;)</span><br><span class=\"line\">*************************** 7. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 796</span><br><span class=\"line\">Event_type: Xid</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 823</span><br><span class=\"line\">Info: COMMIT /* xid=17 */</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">ERROR: </span><br><span class=\"line\">No query specified</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt;</span><br></pre></td></tr></table></figure></p>\n<p>上面这条语句可以将指定的binlog日志文件，分成有效事件行的方式返回，并可使用limit指定pos点的起始偏移，查询条数！<br>如下操作示例：<br> a）查询第一个(最早)的binlog日志：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events\\G;</span><br></pre></td></tr></table></figure></p>\n<p> b）指定查询 mysql-bin.000002这个文件：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos;\\G;</span><br></pre></td></tr></table></figure></p>\n<p>c）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos; from 624\\G;</span><br></pre></td></tr></table></figure></p>\n<p>d）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起，查询10条（即10条语句）<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos; from 624 limit 10\\G;</span><br></pre></td></tr></table></figure></p>\n<p>e）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起，偏移2行（即中间跳过2个），查询10条<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos; from 624 limit 2,10\\G;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"五、利用binlog日志恢复mysql数据\"><a href=\"#五、利用binlog日志恢复mysql数据\" class=\"headerlink\" title=\"五、利用binlog日志恢复mysql数据\"></a>五、利用binlog日志恢复mysql数据</h2><p>以下对ops库的member表进行操作<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; use ops；</span><br><span class=\"line\">mysql&gt; CREATE TABLE IF NOT EXISTS `member` (</span><br><span class=\"line\">-&gt; `id` int(10) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class=\"line\">-&gt; `name` varchar(16) NOT NULL,</span><br><span class=\"line\">-&gt; `sex` enum(&apos;m&apos;,&apos;w&apos;) NOT NULL DEFAULT &apos;m&apos;,</span><br><span class=\"line\">-&gt; `age` tinyint(3) unsigned NOT NULL,</span><br><span class=\"line\">-&gt; `classid` char(6) DEFAULT NULL,</span><br><span class=\"line\">-&gt; PRIMARY KEY (`id`)</span><br><span class=\"line\">-&gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8;</span><br><span class=\"line\">Query OK, 0 rows affected (0.10 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show tables;</span><br><span class=\"line\">+---------------+</span><br><span class=\"line\">| Tables_in_ops |</span><br><span class=\"line\">+---------------+</span><br><span class=\"line\">| member |</span><br><span class=\"line\">+---------------+</span><br><span class=\"line\">1 row in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; desc member;</span><br><span class=\"line\">+---------+---------------------+------+-----+---------+----------------+</span><br><span class=\"line\">| Field | Type | Null | Key | Default | Extra |</span><br><span class=\"line\">+---------+---------------------+------+-----+---------+----------------+</span><br><span class=\"line\">| id | int(10) unsigned | NO | PRI | NULL | auto_increment |</span><br><span class=\"line\">| name | varchar(16) | NO | | NULL | |</span><br><span class=\"line\">| sex | enum(&apos;m&apos;,&apos;w&apos;) | NO | | m | |</span><br><span class=\"line\">| age | tinyint(3) unsigned | NO | | NULL | |</span><br><span class=\"line\">| classid | char(6) | YES | | NULL | |</span><br><span class=\"line\">+---------+---------------------+------+-----+---------+----------------+</span><br><span class=\"line\">5 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>事先插入两条数据<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; insert into member(`name`,`sex`,`age`,`classid`) values(&apos;wangshibo&apos;,&apos;m&apos;,27,&apos;cls1&apos;),(&apos;guohuihui&apos;,&apos;w&apos;,27,&apos;cls2&apos;);</span><br><span class=\"line\">Query OK, 2 rows affected (0.08 sec)</span><br><span class=\"line\">Records: 2 Duplicates: 0 Warnings: 0</span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">2 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>下面开始进行场景模拟：<br>1）<br>ops库会在每天凌晨4点进行一次完全备份的定时计划任务，如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# crontab -l</span><br><span class=\"line\">0 4 * * * /usr/bin/mysqldump -uroot -p -B -F -R -x --master-data=2 ops|gzip &gt;/opt/backup/ops_$(date +%F).sql.gz</span><br></pre></td></tr></table></figure></p>\n<p>这里手动执行下，将ops数据库备份到/opt/backup/ops_$(date +%F).sql.gz文件中：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# mysqldump -uroot -p -B -F -R -x --master-data=2 ops|gzip &gt;/opt/backup/ops_$(date +%F).sql.gz</span><br><span class=\"line\">Enter password: </span><br><span class=\"line\">[root@vm-002 ~]# ls /opt/backup/</span><br><span class=\"line\">ops_2016-09-25.sql.gz</span><br></pre></td></tr></table></figure></p>\n<hr>\n<p>参数说明：<br>-B：指定数据库<br>-F：刷新日志<br>-R：备份存储过程等<br>-x：锁表<br>–master-data：在备份语句里添加CHANGE MASTER语句以及binlog文件及位置点信息</p>\n<hr>\n<p>待到数据库备份完成，就不用担心数据丢失了，因为有完全备份数据在！！</p>\n<p>由于上面在全备份的时候使用了-F选项，那么当数据备份操作刚开始的时候系统就会自动刷新log，这样就会自动产生<br>一个新的binlog日志，这个新的binlog日志就会用来记录备份之后的数据库“增删改”操作<br>查看一下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show master status;</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">| mysql-bin.000003 | 106 | | |</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>也就是说， mysql-bin.000003 是用来记录4:00之后对数据库的所有“增删改”操作。</p>\n<p>2）<br>早上9点上班了，由于业务的需求会对数据库进行各种“增删改”操作。<br>比如：在ops库下member表内插入、修改了数据等等：</p>\n<p>先是早上进行插入数据：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; insert into ops.member(`name`,`sex`,`age`,`classid`) values(&apos;yiyi&apos;,&apos;w&apos;,20,&apos;cls1&apos;),(&apos;xiaoer&apos;,&apos;m&apos;,22,&apos;cls3&apos;),(&apos;zhangsan&apos;,&apos;w&apos;,21,&apos;cls5&apos;),(&apos;lisi&apos;,&apos;m&apos;,20,&apos;cls4&apos;),(&apos;wangwu&apos;,&apos;w&apos;,26,&apos;cls6&apos;);</span><br><span class=\"line\">Query OK, 5 rows affected (0.08 sec)</span><br><span class=\"line\">Records: 5 Duplicates: 0 Warnings: 0</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | xiaoer | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>3）<br>中午又执行了修改数据操作：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; update ops.member set name=&apos;李四&apos; where id=4;</span><br><span class=\"line\">Query OK, 1 row affected (0.07 sec)</span><br><span class=\"line\">Rows matched: 1 Changed: 1 Warnings: 0</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; update ops.member set name=&apos;小二&apos; where id=2;</span><br><span class=\"line\">Query OK, 1 row affected (0.06 sec)</span><br><span class=\"line\">Rows matched: 1 Changed: 1 Warnings: 0</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | 小二 | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | 李四 | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>4）<br>在下午18:00的时候，悲剧莫名其妙的出现了！<br>手贱执行了drop语句，直接删除了ops库！吓尿！<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; drop database ops;</span><br><span class=\"line\">Query OK, 1 row affected (0.02 sec)</span><br></pre></td></tr></table></figure></p>\n<p>5）<br>这种时候，一定不要慌张！！！<br>先仔细查看最后一个binlog日志，并记录下关键的pos点，到底是哪个pos点的操作导致了数据库的破坏(通常在最后几步)；</p>\n<p>先备份一下最后一个binlog日志文件：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# cd /var/lib/mysql/</span><br><span class=\"line\">[root@vm-002 mysql]# cp -v mysql-bin.000003 /opt/backup/</span><br><span class=\"line\">`mysql-bin.000003&apos; -&gt; `/opt/backup/mysql-bin.000003&apos;</span><br><span class=\"line\">[root@vm-002 mysql]# ls /opt/backup/</span><br><span class=\"line\">mysql-bin.000003 ops_2016-09-25.sql.gz</span><br></pre></td></tr></table></figure></p>\n<p>接着执行一次刷新日志索引操作，重新开始新的binlog日志记录文件。按理说mysql-bin.000003<br>这个文件不会再有后续写入了，因为便于我们分析原因及查找ops节点，以后所有数据库操作都会写入到下一个日志文件。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; flush logs;</span><br><span class=\"line\">Query OK, 0 rows affected (0.13 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show master status;</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">| mysql-bin.000004 | 106 | | |</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>6）<br>读取binlog日志，分析问题。<br>读取binlog日志的方法上面已经说到。<br>方法一：使用mysqlbinlog读取binlog日志：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# cd /var/lib/mysql/</span><br><span class=\"line\">[root@vm-002 mysql]# mysqlbinlog mysql-bin.000003</span><br></pre></td></tr></table></figure></p>\n<p>方法二：登录服务器，并查看(推荐此种方法)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000003&apos;;</span><br><span class=\"line\"></span><br><span class=\"line\">+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+</span><br><span class=\"line\">| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |</span><br><span class=\"line\">+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+</span><br><span class=\"line\">| mysql-bin.000003 | 4 | Format_desc | 1 | 106 | Server ver: 5.1.73-log, Binlog ver: 4 |</span><br><span class=\"line\">| mysql-bin.000003 | 106 | Query | 1 | 173 | BEGIN |</span><br><span class=\"line\">| mysql-bin.000003 | 173 | Intvar | 1 | 201 | INSERT_ID=3 |</span><br><span class=\"line\">| mysql-bin.000003 | 201 | Query | 1 | 444 | use `ops`; insert into ops.member(`name`,`sex`,`age`,`gsan&apos;,&apos;w&apos;,21,&apos;cls5&apos;),(&apos;lisi&apos;,&apos;m&apos;,20,&apos;cls4&apos;),(&apos;wangwu&apos;,&apos;w&apos;,26,&apos;cls6&apos;) |</span><br><span class=\"line\">| mysql-bin.000003 | 444 | Xid | 1 | 471 | COMMIT /* xid=66 */ |</span><br><span class=\"line\">| mysql-bin.000003 | 471 | Query | 1 | 538 | BEGIN |</span><br><span class=\"line\">| mysql-bin.000003 | 538 | Query | 1 | 646 | use `ops`; update ops.member set name=&apos;李四&apos; where id= |</span><br><span class=\"line\">| mysql-bin.000003 | 646 | Xid | 1 | 673 | COMMIT /* xid=68 */ |</span><br><span class=\"line\">| mysql-bin.000003 | 673 | Query | 1 | 740 | BEGIN |</span><br><span class=\"line\">| mysql-bin.000003 | 740 | Query | 1 | 848 | use `ops`; update ops.member set name=&apos;小二&apos; where id= |</span><br><span class=\"line\">| mysql-bin.000003 | 848 | Xid | 1 | 875 | COMMIT /* xid=69 */ |</span><br><span class=\"line\">| mysql-bin.000003 | 875 | Query | 1 | 954 | drop database ops |</span><br><span class=\"line\">| mysql-bin.000003 | 954 | Rotate | 1 | 997 | mysql-bin.000004;pos=4 |</span><br><span class=\"line\">+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+</span><br><span class=\"line\">13 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">或者：</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000003&apos;\\G;</span><br><span class=\"line\">.........</span><br><span class=\"line\">.........</span><br><span class=\"line\">*************************** 12. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000003</span><br><span class=\"line\">Pos: 875</span><br><span class=\"line\">Event_type: Query</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 954</span><br><span class=\"line\">Info: drop database ops</span><br><span class=\"line\">*************************** 13. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000003</span><br><span class=\"line\">Pos: 954</span><br><span class=\"line\">Event_type: Rotate</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 997</span><br><span class=\"line\">Info: mysql-bin.000004;pos=4</span><br><span class=\"line\">13 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>通过分析，造成数据库破坏的pos点区间是介于 875–954 之间（这是按照日志区间的pos节点算的），只要恢复到875前就可。</p>\n<p>7）<br>先把凌晨4点全备份的数据恢复：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# cd /opt/backup/</span><br><span class=\"line\">[root@vm-002 backup]# ls</span><br><span class=\"line\">mysql-bin.000003 ops_2016-09-25.sql.gz</span><br><span class=\"line\">[root@vm-002 backup]# gzip -d ops_2016-09-25.sql.gz </span><br><span class=\"line\">[root@vm-002 backup]# mysql -uroot -p -v &lt; ops_2016-09-25.sql </span><br><span class=\"line\">Enter password: </span><br><span class=\"line\">--------------</span><br><span class=\"line\">/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */</span><br><span class=\"line\">--------------</span><br><span class=\"line\"></span><br><span class=\"line\">--------------</span><br><span class=\"line\">/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */</span><br><span class=\"line\">--------------</span><br><span class=\"line\"></span><br><span class=\"line\">.............</span><br><span class=\"line\">.............</span><br><span class=\"line\"></span><br><span class=\"line\">--------------</span><br><span class=\"line\">/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */</span><br><span class=\"line\">--------------</span><br><span class=\"line\"></span><br><span class=\"line\">这样就恢复了截至当日凌晨(4:00)前的备份数据都恢复了。</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show databases;                        #发现ops库已经恢复回来了</span><br><span class=\"line\">mysql&gt; use ops;</span><br><span class=\"line\">Reading table information for completion of table and column names</span><br><span class=\"line\">You can turn off this feature to get a quicker startup with -A</span><br><span class=\"line\"></span><br><span class=\"line\">Database changed</span><br><span class=\"line\">mysql&gt; show tables;</span><br><span class=\"line\">+---------------+</span><br><span class=\"line\">| Tables_in_ops |</span><br><span class=\"line\">+---------------+</span><br><span class=\"line\">| member |</span><br><span class=\"line\">+---------------+</span><br><span class=\"line\">1 row in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">2 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt;</span><br></pre></td></tr></table></figure></p>\n<p>但是这仅仅只是恢复了当天凌晨4点之前的数据，在4:00–18:00之间的数据还没有恢复回来！！<br>怎么办呢？<br>莫慌！这可以根据前面提到的mysql-bin.000003的新binlog日志进行恢复。</p>\n<p>8）<br>从binlog日志恢复数据<br>恢复命令的语法格式：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysqlbinlog mysql-bin.0000xx | mysql -u用户名 -p密码 数据库名</span><br></pre></td></tr></table></figure></p>\n<hr>\n<p>常用参数选项解释：<br>–start-position=875 起始pos点<br>–stop-position=954 结束pos点<br>–start-datetime=”2016-9-25 22:01:08” 起始时间点<br>–stop-datetime=”2019-9-25 22:09:46” 结束时间点<br>–database=zyyshop 指定只恢复zyyshop数据库(一台主机上往往有多个数据库，只限本地log日志)</p>\n<hr>\n<p>不常用选项：<br>-u –user=name 连接到远程主机的用户名<br>-p –password[=name] 连接到远程主机的密码<br>-h –host=name 从远程主机上获取binlog日志<br>–read-from-remote-server 从某个MySQL服务器上读取binlog日志</p>\n<hr>\n<p>小结：实际是将读出的binlog日志内容，通过管道符传递给mysql命令。这些命令、文件尽量写成绝对路径；</p>\n<p>a）完全恢复(需要手动vim编辑mysql-bin.000003，将那条drop语句剔除掉)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 backup]# /usr/bin/mysqlbinlog /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br></pre></td></tr></table></figure></p>\n<p>b）指定pos结束点恢复(部分恢复)：<br>–stop-position=471 pos结束节点（按照事务区间算，是471）</p>\n<p>注意：<br>此pos结束节点介于“member表原始数据”与更新“name=’李四’”之前的数据，这样就可以恢复到更改“name=’李四’”之前的数据了。<br>操作如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --stop-position=471 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | xiaoer | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">恢复截止到更改“name=&apos;李四&apos;”之间的数据（按照事务区间算，是673）</span><br><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --stop-position=673 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | 李四 | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>c）指定pso点区间恢复(部分恢复)：<br>更新 name=’李四’ 这条数据，日志区间是Pos[538] –&gt; End_log_pos[646]，按事务区间是：Pos[471] –&gt; End_log_pos[673]</p>\n<p>更新 name=’小二’ 这条数据，日志区间是Pos[740] –&gt; End_log_pos[848]，按事务区间是：Pos[673] –&gt; End_log_pos[875]</p>\n<p>c1）<br>单独恢复 name=’李四’ 这步操作，可这样：<br>按照binlog日志区间单独恢复：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=538 --stop-position=646 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\"></span><br><span class=\"line\">按照事务区间单独恢复</span><br><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=471 --stop-position=673 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br></pre></td></tr></table></figure></p>\n<p>c2）<br>单独恢复 name=’小二’ 这步操作，可这样：<br>按照binlog日志区间单独恢复：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=740 --stop-position=848 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\"></span><br><span class=\"line\">按照事务区间单独恢复</span><br><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=673 --stop-position=875 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br></pre></td></tr></table></figure></p>\n<p>c3）<br>将 name=’李四’、name=’小二’ 多步操作一起恢复，需要按事务区间，可这样：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=471 --stop-position=875 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\"></span><br><span class=\"line\">查看数据库：</span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | 小二 | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | 李四 | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>这样，就恢复了删除前的数据状态了！！</p>\n<hr>\n<p>另外：<br>也可指定时间节点区间恢复(部分恢复)：<br>除了用pos节点的办法进行恢复，也可以通过指定时间节点区间进行恢复，按时间恢复需要用mysqlbinlog命令读取binlog日志内容，找时间节点。</p>\n<p>如上，误删除ops库后：<br>先进行全备份恢复<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 backup]# mysql -uroot -p -v &lt; ops_2016-09-25.sql</span><br></pre></td></tr></table></figure></p>\n<p>查看ops数据库<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">2 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">查看mysq-bin00003日志，找出时间节点</span><br><span class=\"line\">[root@vm-002 ~]# cd /var/lib/mysql</span><br><span class=\"line\">[root@vm-002 mysql]# mysqlbinlog mysql-bin.000003 </span><br><span class=\"line\">.............</span><br><span class=\"line\">.............</span><br><span class=\"line\">BEGIN</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 173</span><br><span class=\"line\">#160925 21:57:19 server id 1 end_log_pos 201 Intvar</span><br><span class=\"line\">SET INSERT_ID=3/*!*/;</span><br><span class=\"line\"># at 201</span><br><span class=\"line\">#160925 21:57:19 server id 1 end_log_pos 444 Query thread_id=3 exec_time=0 error_code=0</span><br><span class=\"line\">use `ops`/*!*/;</span><br><span class=\"line\">SET TIMESTAMP=1474811839/*!*/;</span><br><span class=\"line\">insert into ops.member(`name`,`sex`,`age`,`classid`) values(&apos;yiyi&apos;,&apos;w&apos;,20,&apos;cls1&apos;),(&apos;xiaoer&apos;,&apos;m&apos;,22,&apos;cls3&apos;),(&apos;zhangsan&apos;,&apos;w&apos;,21,&apos;cls5&apos;),(&apos;lisi&apos;,&apos;m&apos;,20,&apos;cls4&apos;),(&apos;wangwu&apos;,&apos;w&apos;,26,&apos;cls6&apos;)                               #执行的sql语句</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 444</span><br><span class=\"line\">#160925 21:57:19 server id 1 end_log_pos 471 Xid = 66    #开始执行的时间</span><br><span class=\"line\">COMMIT/*!*/;</span><br><span class=\"line\"># at 471</span><br><span class=\"line\">#160925 21:58:41 server id 1 end_log_pos 538 Query thread_id=3 exec_time=0 error_code=0    #结束时间</span><br><span class=\"line\">SET TIMESTAMP=1474811921/*!*/;</span><br><span class=\"line\">BEGIN</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 538</span><br><span class=\"line\">#160925 21:58:41 server id 1 end_log_pos 646 Query thread_id=3 exec_time=0 error_code=0</span><br><span class=\"line\">SET TIMESTAMP=1474811921/*!*/;</span><br><span class=\"line\">update ops.member set name=&apos;李四&apos; where id=4     #执行的sql语句</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 646</span><br><span class=\"line\">#160925 21:58:41 server id 1 end_log_pos 673 Xid = 68    #开始执行的时间</span><br><span class=\"line\">COMMIT/*!*/;</span><br><span class=\"line\"># at 673</span><br><span class=\"line\">#160925 21:58:56 server id 1 end_log_pos 740 Query thread_id=3 exec_time=0 error_code=0   #结束时间</span><br><span class=\"line\">SET TIMESTAMP=1474811936/*!*/;</span><br><span class=\"line\">BEGIN</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 740</span><br><span class=\"line\">#160925 21:58:56 server id 1 end_log_pos 848 Query thread_id=3 exec_time=0 error_code=0</span><br><span class=\"line\">SET TIMESTAMP=1474811936/*!*/;</span><br><span class=\"line\">update ops.member set name=&apos;小二&apos; where id=2      #执行的sql语句</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 848</span><br><span class=\"line\">#160925 21:58:56 server id 1 end_log_pos 875 Xid = 69   #开始执行的时间</span><br><span class=\"line\">COMMIT/*!*/;</span><br><span class=\"line\"># at 875</span><br><span class=\"line\">#160925 22:01:08 server id 1 end_log_pos 954 Query thread_id=3 exec_time=0 error_code=0    #结束时间</span><br><span class=\"line\">SET TIMESTAMP=1474812068/*!*/;</span><br><span class=\"line\">drop database ops</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 954</span><br><span class=\"line\">#160925 22:09:46 server id 1 end_log_pos 997 Rotate to mysql-bin.000004 pos: 4</span><br><span class=\"line\">DELIMITER ;</span><br><span class=\"line\"># End of log file</span><br><span class=\"line\">ROLLBACK /* added by mysqlbinlog */;</span><br><span class=\"line\">/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;</span><br><span class=\"line\"></span><br><span class=\"line\">恢复到更改“name=&apos;李四&apos;”之前的数据</span><br><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=&quot;2016-09-25 21:57:19&quot; --stop-datetime=&quot;2016-09-25 21:58:41&quot; --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | xiaoer | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=&quot;2016-09-25 21:58:41&quot; --stop-datetime=&quot;2016-09-25 21:58:56&quot; --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | 李四 | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=&quot;2016-09-25 21:58:56&quot; --stop-datetime=&quot;2016-09-25 22:01:08&quot; --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | 小二 | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | 李四 | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>这样，就恢复了删除前的状态了！</p>\n<p>总结：<br>所谓恢复，就是让mysql将保存在binlog日志中指定段落区间的sql语句逐个重新执行一次而已。</p>\n","site":{"data":{}},"excerpt":"<p>众所周知，binlog日志对于mysql数据库来说是十分重要的。在数据丢失的紧急情况下，我们往往会想到用binlog日志功能进行数据恢复（定时全备份+binlog日志恢复增量数据部分），化险为夷！<br>","more":"<br>废话不多说，下面是梳理的binlog日志操作解说：</p>\n<h2 id=\"一、初步了解binlog\"><a href=\"#一、初步了解binlog\" class=\"headerlink\" title=\"一、初步了解binlog\"></a>一、初步了解binlog</h2><p>MySQL的二进制日志binlog可以说是MySQL最重要的日志，它记录了所有的DDL和DML语句（除了数据查询语句select），以事件形式记录，还包含语句所执行的消耗的时间，MySQL的二进制日志是事务安全型的。</p>\n<hr>\n<p>DDL</p>\n<p>—-Data Definition Language 数据库定义语言 </p>\n<p>主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表（TABLE）的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用。</p>\n<p>DML</p>\n<p>—-Data Manipulation Language 数据操纵语言</p>\n<p>主要的命令是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言</p>\n<hr>\n<p>mysqlbinlog常见的选项有以下几个：<br>–start-datetime：从二进制日志中读取指定等于时间戳或者晚于本地计算机的时间<br>–stop-datetime：从二进制日志中读取指定小于时间戳或者等于本地计算机的时间 取值和上述一样<br>–start-position：从二进制日志中读取指定position 事件位置作为开始。<br>–stop-position：从二进制日志中读取指定position 事件位置作为事件截至</p>\n<hr>\n<p>一般来说开启binlog日志大概会有1%的性能损耗。</p>\n<h3 id=\"binlog日志有两个最重要的使用场景\"><a href=\"#binlog日志有两个最重要的使用场景\" class=\"headerlink\" title=\"binlog日志有两个最重要的使用场景:\"></a>binlog日志有两个最重要的使用场景:</h3><p> 1）MySQL主从复制：MySQL Replication在Master端开启binlog，Master把它的二进制日志传递给slaves来达到<br>master-slave数据一致的目的。<br> 2）自然就是数据恢复了，通过使用mysqlbinlog工具来使恢复数据。</p>\n<h3 id=\"binlog日志包括两类文件：\"><a href=\"#binlog日志包括两类文件：\" class=\"headerlink\" title=\"binlog日志包括两类文件：\"></a>binlog日志包括两类文件：</h3><p> 1）二进制日志索引文件（文件名后缀为.index）用于记录所有的二进制文件<br> 2）二进制日志文件（文件名后缀为.00000*）记录数据库所有的DDL和DML(除了数据查询语句select)语句事件。</p>\n<h2 id=\"二、开启binlog日志：\"><a href=\"#二、开启binlog日志：\" class=\"headerlink\" title=\"二、开启binlog日志：\"></a>二、开启binlog日志：</h2><p> 1）编辑打开mysql配置文件/etc/mys.cnf</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# vim /etc/my.cnf</span><br><span class=\"line\"></span><br><span class=\"line\">在[mysqld] 区块添加 </span><br><span class=\"line\">log-bin=mysql-bin 确认是打开状态(mysql-bin 是日志的基本名或前缀名)；</span><br></pre></td></tr></table></figure>\n<p> 2）重启mysqld服务使配置生效</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# /etc/init.d/mysqld stop</span><br><span class=\"line\">[root@vm-002 ~]# /etc/init.d/mysqld restart</span><br><span class=\"line\">Stopping mysqld: [ OK ]</span><br><span class=\"line\">Starting mysqld: [ OK ]</span><br></pre></td></tr></table></figure>\n<p> 3）查看binlog日志是否开启<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show variables like &apos;log_%&apos;; </span><br><span class=\"line\">+---------------------------------+---------------------+</span><br><span class=\"line\">| Variable_name | Value |</span><br><span class=\"line\">+---------------------------------+---------------------+</span><br><span class=\"line\">| log_bin | ON |</span><br><span class=\"line\">| log_bin_trust_function_creators | OFF |</span><br><span class=\"line\">| log_bin_trust_routine_creators | OFF |</span><br><span class=\"line\">| log_error | /var/log/mysqld.log |</span><br><span class=\"line\">| log_output | FILE |</span><br><span class=\"line\">| log_queries_not_using_indexes | OFF |</span><br><span class=\"line\">| log_slave_updates | OFF |</span><br><span class=\"line\">| log_slow_queries | OFF |</span><br><span class=\"line\">| log_warnings | 1 |</span><br><span class=\"line\">+---------------------------------+---------------------+</span><br><span class=\"line\">9 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"三、常用的binlog日志操作命令\"><a href=\"#三、常用的binlog日志操作命令\" class=\"headerlink\" title=\"三、常用的binlog日志操作命令\"></a>三、常用的binlog日志操作命令</h2><p> 1）查看所有binlog日志列表<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show master logs;</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| Log_name | File_size |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| mysql-bin.000001 | 149 |</span><br><span class=\"line\">| mysql-bin.000002 | 4102 |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">2 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p> 2）查看master状态，即最后(最新)一个binlog日志的编号名称，及其最后一个操作事件pos结束点(Position)值<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show master status;</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">| mysql-bin.000002 | 4102 | | |</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p> 3）flush刷新log日志，自此刻开始产生一个新编号的binlog日志文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; flush logs; </span><br><span class=\"line\">Query OK, 0 rows affected (0.13 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show master logs; </span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| Log_name | File_size |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| mysql-bin.000001 | 149 |</span><br><span class=\"line\">| mysql-bin.000002 | 4145 |</span><br><span class=\"line\">| mysql-bin.000003 | 106 |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">3 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>注意：<br>每当mysqld服务重启时，会自动执行此命令，刷新binlog日志；在mysqldump备份数据时加 -F 选项也会刷新binlog日志；</p>\n<p> 4）重置(清空)所有binlog日志<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; reset master;</span><br><span class=\"line\">Query OK, 0 rows affected (0.12 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show master logs; </span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| Log_name | File_size |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| mysql-bin.000001 | 106 |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"四、查看binlog日志内容，常用有两种方式：\"><a href=\"#四、查看binlog日志内容，常用有两种方式：\" class=\"headerlink\" title=\"四、查看binlog日志内容，常用有两种方式：\"></a>四、查看binlog日志内容，常用有两种方式：</h2><p> 1）使用mysqlbinlog自带查看命令法：<br>注意：<br>–&gt;binlog是二进制文件，普通文件查看器cat、more、vim等都无法打开，必须使用自带的mysqlbinlog命令查看<br>–&gt;binlog日志与数据库文件在同目录中<br>–&gt;在MySQL5.5以下版本使用mysqlbinlog命令时如果报错，就加上 “–no-defaults”选项</p>\n<p>查看mysql的数据存放目录，从下面结果可知是/var/lib//mysql<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# ps -ef|grep mysql</span><br><span class=\"line\">root 9791 1 0 21:18 pts/0 00:00:00 /bin/sh /usr/bin/mysqld_safe --datadir=/var/lib/mysql --socket=/var/lib/mysql/mysql.sock --pid-file=/var/run/mysqld/mysqld.pid --basedir=/usr --user=mysql</span><br><span class=\"line\">mysql 9896 9791 0 21:18 pts/0 00:00:00 /usr/libexec/mysqld --basedir=/usr --datadir=/var/lib/mysql --user=mysql --log-error=/var/log/mysqld.log --pid-file=/var/run/mysqld/mysqld.pid --socket=/var/lib/mysql/mysql.sock</span><br><span class=\"line\">root 9916 9699 0 21:18 pts/0 00:00:00 mysql -px xxxx</span><br><span class=\"line\">root 9919 9715 0 21:23 pts/1 00:00:00 grep --color mysql</span><br><span class=\"line\"></span><br><span class=\"line\">[root@vm-002 ~]# cd /var/lib/mysql/</span><br><span class=\"line\">[root@vm-002 mysql]# ls</span><br><span class=\"line\">ibdata1 ib_logfile0 ib_logfile1 mysql mysql-bin.000001 mysql-bin.000002 mysql-bin.index mysql.sock ops test</span><br><span class=\"line\"></span><br><span class=\"line\">使用mysqlbinlog命令查看binlog日志内容，下面截取其中的一个片段分析：</span><br><span class=\"line\">[root@vm-002 mysql]# mysqlbinlog mysql-bin.000002</span><br><span class=\"line\">..............</span><br><span class=\"line\"># at 624</span><br><span class=\"line\">#160925 21:29:53 server id 1 end_log_pos 796 Query\tthread_id=3\texec_time=0\terror_code=0</span><br><span class=\"line\">SET TIMESTAMP=1474810193/*!*/;</span><br><span class=\"line\">insert into member(`name`,`sex`,`age`,`classid`) values(&apos;wangshibo&apos;,&apos;m&apos;,27,&apos;cls1&apos;),(&apos;guohuihui&apos;,&apos;w&apos;,27,&apos;cls2&apos;)        #执行的sql语句</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\">#at 796</span><br><span class=\"line\">#160925 21:29:53 server id 1 end_log_pos 823 Xid = 17                  #执行的时间</span><br><span class=\"line\">.............</span><br></pre></td></tr></table></figure></p>\n<p>解释：<br>server id 1 ： 数据库主机的服务号；<br>end_log_pos 796： sql结束时的pos节点<br>thread_id=11： 线程号</p>\n<p> 2）上面这种办法读取出binlog日志的全文内容比较多，不容易分辨查看到pos点信息<br>下面介绍一种更为方便的查询命令：<br>命令格式：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events [IN &apos;log_name&apos;] [FROM pos] [LIMIT [offset,] row_count];</span><br></pre></td></tr></table></figure></p>\n<p>参数解释：<br>IN ‘log_name’ ：指定要查询的binlog文件名(不指定就是第一个binlog文件)<br>FROM pos ：指定从哪个pos起始点开始查起(不指定就是从整个文件首个pos点开始算)<br>LIMIT [offset,] ：偏移量(不指定就是0)<br>row_count ：查询总条数(不指定就是所有行)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show master logs;</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| Log_name | File_size |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">| mysql-bin.000001 | 125 |</span><br><span class=\"line\">| mysql-bin.000002 | 823 |</span><br><span class=\"line\">+------------------+-----------+</span><br><span class=\"line\">2 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos;\\G;</span><br><span class=\"line\">*************************** 1. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 4</span><br><span class=\"line\">Event_type: Format_desc</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 106</span><br><span class=\"line\">Info: Server ver: 5.1.73-log, Binlog ver: 4</span><br><span class=\"line\">*************************** 2. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 106</span><br><span class=\"line\">Event_type: Query</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 188</span><br><span class=\"line\">Info: use `ops`; drop table customers</span><br><span class=\"line\">*************************** 3. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 188</span><br><span class=\"line\">Event_type: Query</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 529</span><br><span class=\"line\">Info: use `ops`; CREATE TABLE IF NOT EXISTS `member` (</span><br><span class=\"line\">`id` int(10) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class=\"line\">`name` varchar(16) NOT NULL,</span><br><span class=\"line\">`sex` enum(&apos;m&apos;,&apos;w&apos;) NOT NULL DEFAULT &apos;m&apos;,</span><br><span class=\"line\">`age` tinyint(3) unsigned NOT NULL,</span><br><span class=\"line\">`classid` char(6) DEFAULT NULL,</span><br><span class=\"line\">PRIMARY KEY (`id`)</span><br><span class=\"line\">) ENGINE=InnoDB DEFAULT CHARSET=utf8</span><br><span class=\"line\">*************************** 4. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 529</span><br><span class=\"line\">Event_type: Query</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 596</span><br><span class=\"line\">Info: BEGIN</span><br><span class=\"line\">*************************** 5. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 596</span><br><span class=\"line\">Event_type: Intvar</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 624</span><br><span class=\"line\">Info: INSERT_ID=1</span><br><span class=\"line\">*************************** 6. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 624</span><br><span class=\"line\">Event_type: Query</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 796</span><br><span class=\"line\">Info: use `ops`; insert into member(`name`,`sex`,`age`,`classid`) values(&apos;wangshibo&apos;,&apos;m&apos;,27,&apos;cls1&apos;),(&apos;guohuihui&apos;,&apos;w&apos;,27,&apos;cls2&apos;)</span><br><span class=\"line\">*************************** 7. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000002</span><br><span class=\"line\">Pos: 796</span><br><span class=\"line\">Event_type: Xid</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 823</span><br><span class=\"line\">Info: COMMIT /* xid=17 */</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">ERROR: </span><br><span class=\"line\">No query specified</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt;</span><br></pre></td></tr></table></figure></p>\n<p>上面这条语句可以将指定的binlog日志文件，分成有效事件行的方式返回，并可使用limit指定pos点的起始偏移，查询条数！<br>如下操作示例：<br> a）查询第一个(最早)的binlog日志：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events\\G;</span><br></pre></td></tr></table></figure></p>\n<p> b）指定查询 mysql-bin.000002这个文件：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos;\\G;</span><br></pre></td></tr></table></figure></p>\n<p>c）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos; from 624\\G;</span><br></pre></td></tr></table></figure></p>\n<p>d）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起，查询10条（即10条语句）<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos; from 624 limit 10\\G;</span><br></pre></td></tr></table></figure></p>\n<p>e）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起，偏移2行（即中间跳过2个），查询10条<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos; from 624 limit 2,10\\G;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"五、利用binlog日志恢复mysql数据\"><a href=\"#五、利用binlog日志恢复mysql数据\" class=\"headerlink\" title=\"五、利用binlog日志恢复mysql数据\"></a>五、利用binlog日志恢复mysql数据</h2><p>以下对ops库的member表进行操作<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; use ops；</span><br><span class=\"line\">mysql&gt; CREATE TABLE IF NOT EXISTS `member` (</span><br><span class=\"line\">-&gt; `id` int(10) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class=\"line\">-&gt; `name` varchar(16) NOT NULL,</span><br><span class=\"line\">-&gt; `sex` enum(&apos;m&apos;,&apos;w&apos;) NOT NULL DEFAULT &apos;m&apos;,</span><br><span class=\"line\">-&gt; `age` tinyint(3) unsigned NOT NULL,</span><br><span class=\"line\">-&gt; `classid` char(6) DEFAULT NULL,</span><br><span class=\"line\">-&gt; PRIMARY KEY (`id`)</span><br><span class=\"line\">-&gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8;</span><br><span class=\"line\">Query OK, 0 rows affected (0.10 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show tables;</span><br><span class=\"line\">+---------------+</span><br><span class=\"line\">| Tables_in_ops |</span><br><span class=\"line\">+---------------+</span><br><span class=\"line\">| member |</span><br><span class=\"line\">+---------------+</span><br><span class=\"line\">1 row in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; desc member;</span><br><span class=\"line\">+---------+---------------------+------+-----+---------+----------------+</span><br><span class=\"line\">| Field | Type | Null | Key | Default | Extra |</span><br><span class=\"line\">+---------+---------------------+------+-----+---------+----------------+</span><br><span class=\"line\">| id | int(10) unsigned | NO | PRI | NULL | auto_increment |</span><br><span class=\"line\">| name | varchar(16) | NO | | NULL | |</span><br><span class=\"line\">| sex | enum(&apos;m&apos;,&apos;w&apos;) | NO | | m | |</span><br><span class=\"line\">| age | tinyint(3) unsigned | NO | | NULL | |</span><br><span class=\"line\">| classid | char(6) | YES | | NULL | |</span><br><span class=\"line\">+---------+---------------------+------+-----+---------+----------------+</span><br><span class=\"line\">5 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>事先插入两条数据<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; insert into member(`name`,`sex`,`age`,`classid`) values(&apos;wangshibo&apos;,&apos;m&apos;,27,&apos;cls1&apos;),(&apos;guohuihui&apos;,&apos;w&apos;,27,&apos;cls2&apos;);</span><br><span class=\"line\">Query OK, 2 rows affected (0.08 sec)</span><br><span class=\"line\">Records: 2 Duplicates: 0 Warnings: 0</span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">2 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>下面开始进行场景模拟：<br>1）<br>ops库会在每天凌晨4点进行一次完全备份的定时计划任务，如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# crontab -l</span><br><span class=\"line\">0 4 * * * /usr/bin/mysqldump -uroot -p -B -F -R -x --master-data=2 ops|gzip &gt;/opt/backup/ops_$(date +%F).sql.gz</span><br></pre></td></tr></table></figure></p>\n<p>这里手动执行下，将ops数据库备份到/opt/backup/ops_$(date +%F).sql.gz文件中：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# mysqldump -uroot -p -B -F -R -x --master-data=2 ops|gzip &gt;/opt/backup/ops_$(date +%F).sql.gz</span><br><span class=\"line\">Enter password: </span><br><span class=\"line\">[root@vm-002 ~]# ls /opt/backup/</span><br><span class=\"line\">ops_2016-09-25.sql.gz</span><br></pre></td></tr></table></figure></p>\n<hr>\n<p>参数说明：<br>-B：指定数据库<br>-F：刷新日志<br>-R：备份存储过程等<br>-x：锁表<br>–master-data：在备份语句里添加CHANGE MASTER语句以及binlog文件及位置点信息</p>\n<hr>\n<p>待到数据库备份完成，就不用担心数据丢失了，因为有完全备份数据在！！</p>\n<p>由于上面在全备份的时候使用了-F选项，那么当数据备份操作刚开始的时候系统就会自动刷新log，这样就会自动产生<br>一个新的binlog日志，这个新的binlog日志就会用来记录备份之后的数据库“增删改”操作<br>查看一下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show master status;</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">| mysql-bin.000003 | 106 | | |</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>也就是说， mysql-bin.000003 是用来记录4:00之后对数据库的所有“增删改”操作。</p>\n<p>2）<br>早上9点上班了，由于业务的需求会对数据库进行各种“增删改”操作。<br>比如：在ops库下member表内插入、修改了数据等等：</p>\n<p>先是早上进行插入数据：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; insert into ops.member(`name`,`sex`,`age`,`classid`) values(&apos;yiyi&apos;,&apos;w&apos;,20,&apos;cls1&apos;),(&apos;xiaoer&apos;,&apos;m&apos;,22,&apos;cls3&apos;),(&apos;zhangsan&apos;,&apos;w&apos;,21,&apos;cls5&apos;),(&apos;lisi&apos;,&apos;m&apos;,20,&apos;cls4&apos;),(&apos;wangwu&apos;,&apos;w&apos;,26,&apos;cls6&apos;);</span><br><span class=\"line\">Query OK, 5 rows affected (0.08 sec)</span><br><span class=\"line\">Records: 5 Duplicates: 0 Warnings: 0</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | xiaoer | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>3）<br>中午又执行了修改数据操作：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; update ops.member set name=&apos;李四&apos; where id=4;</span><br><span class=\"line\">Query OK, 1 row affected (0.07 sec)</span><br><span class=\"line\">Rows matched: 1 Changed: 1 Warnings: 0</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; update ops.member set name=&apos;小二&apos; where id=2;</span><br><span class=\"line\">Query OK, 1 row affected (0.06 sec)</span><br><span class=\"line\">Rows matched: 1 Changed: 1 Warnings: 0</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | 小二 | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | 李四 | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>4）<br>在下午18:00的时候，悲剧莫名其妙的出现了！<br>手贱执行了drop语句，直接删除了ops库！吓尿！<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; drop database ops;</span><br><span class=\"line\">Query OK, 1 row affected (0.02 sec)</span><br></pre></td></tr></table></figure></p>\n<p>5）<br>这种时候，一定不要慌张！！！<br>先仔细查看最后一个binlog日志，并记录下关键的pos点，到底是哪个pos点的操作导致了数据库的破坏(通常在最后几步)；</p>\n<p>先备份一下最后一个binlog日志文件：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# cd /var/lib/mysql/</span><br><span class=\"line\">[root@vm-002 mysql]# cp -v mysql-bin.000003 /opt/backup/</span><br><span class=\"line\">`mysql-bin.000003&apos; -&gt; `/opt/backup/mysql-bin.000003&apos;</span><br><span class=\"line\">[root@vm-002 mysql]# ls /opt/backup/</span><br><span class=\"line\">mysql-bin.000003 ops_2016-09-25.sql.gz</span><br></pre></td></tr></table></figure></p>\n<p>接着执行一次刷新日志索引操作，重新开始新的binlog日志记录文件。按理说mysql-bin.000003<br>这个文件不会再有后续写入了，因为便于我们分析原因及查找ops节点，以后所有数据库操作都会写入到下一个日志文件。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; flush logs;</span><br><span class=\"line\">Query OK, 0 rows affected (0.13 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show master status;</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">| mysql-bin.000004 | 106 | | |</span><br><span class=\"line\">+------------------+----------+--------------+------------------+</span><br><span class=\"line\">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>6）<br>读取binlog日志，分析问题。<br>读取binlog日志的方法上面已经说到。<br>方法一：使用mysqlbinlog读取binlog日志：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# cd /var/lib/mysql/</span><br><span class=\"line\">[root@vm-002 mysql]# mysqlbinlog mysql-bin.000003</span><br></pre></td></tr></table></figure></p>\n<p>方法二：登录服务器，并查看(推荐此种方法)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000003&apos;;</span><br><span class=\"line\"></span><br><span class=\"line\">+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+</span><br><span class=\"line\">| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |</span><br><span class=\"line\">+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+</span><br><span class=\"line\">| mysql-bin.000003 | 4 | Format_desc | 1 | 106 | Server ver: 5.1.73-log, Binlog ver: 4 |</span><br><span class=\"line\">| mysql-bin.000003 | 106 | Query | 1 | 173 | BEGIN |</span><br><span class=\"line\">| mysql-bin.000003 | 173 | Intvar | 1 | 201 | INSERT_ID=3 |</span><br><span class=\"line\">| mysql-bin.000003 | 201 | Query | 1 | 444 | use `ops`; insert into ops.member(`name`,`sex`,`age`,`gsan&apos;,&apos;w&apos;,21,&apos;cls5&apos;),(&apos;lisi&apos;,&apos;m&apos;,20,&apos;cls4&apos;),(&apos;wangwu&apos;,&apos;w&apos;,26,&apos;cls6&apos;) |</span><br><span class=\"line\">| mysql-bin.000003 | 444 | Xid | 1 | 471 | COMMIT /* xid=66 */ |</span><br><span class=\"line\">| mysql-bin.000003 | 471 | Query | 1 | 538 | BEGIN |</span><br><span class=\"line\">| mysql-bin.000003 | 538 | Query | 1 | 646 | use `ops`; update ops.member set name=&apos;李四&apos; where id= |</span><br><span class=\"line\">| mysql-bin.000003 | 646 | Xid | 1 | 673 | COMMIT /* xid=68 */ |</span><br><span class=\"line\">| mysql-bin.000003 | 673 | Query | 1 | 740 | BEGIN |</span><br><span class=\"line\">| mysql-bin.000003 | 740 | Query | 1 | 848 | use `ops`; update ops.member set name=&apos;小二&apos; where id= |</span><br><span class=\"line\">| mysql-bin.000003 | 848 | Xid | 1 | 875 | COMMIT /* xid=69 */ |</span><br><span class=\"line\">| mysql-bin.000003 | 875 | Query | 1 | 954 | drop database ops |</span><br><span class=\"line\">| mysql-bin.000003 | 954 | Rotate | 1 | 997 | mysql-bin.000004;pos=4 |</span><br><span class=\"line\">+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+</span><br><span class=\"line\">13 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">或者：</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show binlog events in &apos;mysql-bin.000003&apos;\\G;</span><br><span class=\"line\">.........</span><br><span class=\"line\">.........</span><br><span class=\"line\">*************************** 12. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000003</span><br><span class=\"line\">Pos: 875</span><br><span class=\"line\">Event_type: Query</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 954</span><br><span class=\"line\">Info: drop database ops</span><br><span class=\"line\">*************************** 13. row ***************************</span><br><span class=\"line\">Log_name: mysql-bin.000003</span><br><span class=\"line\">Pos: 954</span><br><span class=\"line\">Event_type: Rotate</span><br><span class=\"line\">Server_id: 1</span><br><span class=\"line\">End_log_pos: 997</span><br><span class=\"line\">Info: mysql-bin.000004;pos=4</span><br><span class=\"line\">13 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>通过分析，造成数据库破坏的pos点区间是介于 875–954 之间（这是按照日志区间的pos节点算的），只要恢复到875前就可。</p>\n<p>7）<br>先把凌晨4点全备份的数据恢复：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# cd /opt/backup/</span><br><span class=\"line\">[root@vm-002 backup]# ls</span><br><span class=\"line\">mysql-bin.000003 ops_2016-09-25.sql.gz</span><br><span class=\"line\">[root@vm-002 backup]# gzip -d ops_2016-09-25.sql.gz </span><br><span class=\"line\">[root@vm-002 backup]# mysql -uroot -p -v &lt; ops_2016-09-25.sql </span><br><span class=\"line\">Enter password: </span><br><span class=\"line\">--------------</span><br><span class=\"line\">/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */</span><br><span class=\"line\">--------------</span><br><span class=\"line\"></span><br><span class=\"line\">--------------</span><br><span class=\"line\">/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */</span><br><span class=\"line\">--------------</span><br><span class=\"line\"></span><br><span class=\"line\">.............</span><br><span class=\"line\">.............</span><br><span class=\"line\"></span><br><span class=\"line\">--------------</span><br><span class=\"line\">/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */</span><br><span class=\"line\">--------------</span><br><span class=\"line\"></span><br><span class=\"line\">这样就恢复了截至当日凌晨(4:00)前的备份数据都恢复了。</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show databases;                        #发现ops库已经恢复回来了</span><br><span class=\"line\">mysql&gt; use ops;</span><br><span class=\"line\">Reading table information for completion of table and column names</span><br><span class=\"line\">You can turn off this feature to get a quicker startup with -A</span><br><span class=\"line\"></span><br><span class=\"line\">Database changed</span><br><span class=\"line\">mysql&gt; show tables;</span><br><span class=\"line\">+---------------+</span><br><span class=\"line\">| Tables_in_ops |</span><br><span class=\"line\">+---------------+</span><br><span class=\"line\">| member |</span><br><span class=\"line\">+---------------+</span><br><span class=\"line\">1 row in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">2 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt;</span><br></pre></td></tr></table></figure></p>\n<p>但是这仅仅只是恢复了当天凌晨4点之前的数据，在4:00–18:00之间的数据还没有恢复回来！！<br>怎么办呢？<br>莫慌！这可以根据前面提到的mysql-bin.000003的新binlog日志进行恢复。</p>\n<p>8）<br>从binlog日志恢复数据<br>恢复命令的语法格式：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysqlbinlog mysql-bin.0000xx | mysql -u用户名 -p密码 数据库名</span><br></pre></td></tr></table></figure></p>\n<hr>\n<p>常用参数选项解释：<br>–start-position=875 起始pos点<br>–stop-position=954 结束pos点<br>–start-datetime=”2016-9-25 22:01:08” 起始时间点<br>–stop-datetime=”2019-9-25 22:09:46” 结束时间点<br>–database=zyyshop 指定只恢复zyyshop数据库(一台主机上往往有多个数据库，只限本地log日志)</p>\n<hr>\n<p>不常用选项：<br>-u –user=name 连接到远程主机的用户名<br>-p –password[=name] 连接到远程主机的密码<br>-h –host=name 从远程主机上获取binlog日志<br>–read-from-remote-server 从某个MySQL服务器上读取binlog日志</p>\n<hr>\n<p>小结：实际是将读出的binlog日志内容，通过管道符传递给mysql命令。这些命令、文件尽量写成绝对路径；</p>\n<p>a）完全恢复(需要手动vim编辑mysql-bin.000003，将那条drop语句剔除掉)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 backup]# /usr/bin/mysqlbinlog /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br></pre></td></tr></table></figure></p>\n<p>b）指定pos结束点恢复(部分恢复)：<br>–stop-position=471 pos结束节点（按照事务区间算，是471）</p>\n<p>注意：<br>此pos结束节点介于“member表原始数据”与更新“name=’李四’”之前的数据，这样就可以恢复到更改“name=’李四’”之前的数据了。<br>操作如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --stop-position=471 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | xiaoer | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">恢复截止到更改“name=&apos;李四&apos;”之间的数据（按照事务区间算，是673）</span><br><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --stop-position=673 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | 李四 | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>c）指定pso点区间恢复(部分恢复)：<br>更新 name=’李四’ 这条数据，日志区间是Pos[538] –&gt; End_log_pos[646]，按事务区间是：Pos[471] –&gt; End_log_pos[673]</p>\n<p>更新 name=’小二’ 这条数据，日志区间是Pos[740] –&gt; End_log_pos[848]，按事务区间是：Pos[673] –&gt; End_log_pos[875]</p>\n<p>c1）<br>单独恢复 name=’李四’ 这步操作，可这样：<br>按照binlog日志区间单独恢复：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=538 --stop-position=646 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\"></span><br><span class=\"line\">按照事务区间单独恢复</span><br><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=471 --stop-position=673 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br></pre></td></tr></table></figure></p>\n<p>c2）<br>单独恢复 name=’小二’ 这步操作，可这样：<br>按照binlog日志区间单独恢复：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=740 --stop-position=848 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\"></span><br><span class=\"line\">按照事务区间单独恢复</span><br><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=673 --stop-position=875 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br></pre></td></tr></table></figure></p>\n<p>c3）<br>将 name=’李四’、name=’小二’ 多步操作一起恢复，需要按事务区间，可这样：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=471 --stop-position=875 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\"></span><br><span class=\"line\">查看数据库：</span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | 小二 | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | 李四 | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>这样，就恢复了删除前的数据状态了！！</p>\n<hr>\n<p>另外：<br>也可指定时间节点区间恢复(部分恢复)：<br>除了用pos节点的办法进行恢复，也可以通过指定时间节点区间进行恢复，按时间恢复需要用mysqlbinlog命令读取binlog日志内容，找时间节点。</p>\n<p>如上，误删除ops库后：<br>先进行全备份恢复<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@vm-002 backup]# mysql -uroot -p -v &lt; ops_2016-09-25.sql</span><br></pre></td></tr></table></figure></p>\n<p>查看ops数据库<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">2 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">查看mysq-bin00003日志，找出时间节点</span><br><span class=\"line\">[root@vm-002 ~]# cd /var/lib/mysql</span><br><span class=\"line\">[root@vm-002 mysql]# mysqlbinlog mysql-bin.000003 </span><br><span class=\"line\">.............</span><br><span class=\"line\">.............</span><br><span class=\"line\">BEGIN</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 173</span><br><span class=\"line\">#160925 21:57:19 server id 1 end_log_pos 201 Intvar</span><br><span class=\"line\">SET INSERT_ID=3/*!*/;</span><br><span class=\"line\"># at 201</span><br><span class=\"line\">#160925 21:57:19 server id 1 end_log_pos 444 Query thread_id=3 exec_time=0 error_code=0</span><br><span class=\"line\">use `ops`/*!*/;</span><br><span class=\"line\">SET TIMESTAMP=1474811839/*!*/;</span><br><span class=\"line\">insert into ops.member(`name`,`sex`,`age`,`classid`) values(&apos;yiyi&apos;,&apos;w&apos;,20,&apos;cls1&apos;),(&apos;xiaoer&apos;,&apos;m&apos;,22,&apos;cls3&apos;),(&apos;zhangsan&apos;,&apos;w&apos;,21,&apos;cls5&apos;),(&apos;lisi&apos;,&apos;m&apos;,20,&apos;cls4&apos;),(&apos;wangwu&apos;,&apos;w&apos;,26,&apos;cls6&apos;)                               #执行的sql语句</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 444</span><br><span class=\"line\">#160925 21:57:19 server id 1 end_log_pos 471 Xid = 66    #开始执行的时间</span><br><span class=\"line\">COMMIT/*!*/;</span><br><span class=\"line\"># at 471</span><br><span class=\"line\">#160925 21:58:41 server id 1 end_log_pos 538 Query thread_id=3 exec_time=0 error_code=0    #结束时间</span><br><span class=\"line\">SET TIMESTAMP=1474811921/*!*/;</span><br><span class=\"line\">BEGIN</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 538</span><br><span class=\"line\">#160925 21:58:41 server id 1 end_log_pos 646 Query thread_id=3 exec_time=0 error_code=0</span><br><span class=\"line\">SET TIMESTAMP=1474811921/*!*/;</span><br><span class=\"line\">update ops.member set name=&apos;李四&apos; where id=4     #执行的sql语句</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 646</span><br><span class=\"line\">#160925 21:58:41 server id 1 end_log_pos 673 Xid = 68    #开始执行的时间</span><br><span class=\"line\">COMMIT/*!*/;</span><br><span class=\"line\"># at 673</span><br><span class=\"line\">#160925 21:58:56 server id 1 end_log_pos 740 Query thread_id=3 exec_time=0 error_code=0   #结束时间</span><br><span class=\"line\">SET TIMESTAMP=1474811936/*!*/;</span><br><span class=\"line\">BEGIN</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 740</span><br><span class=\"line\">#160925 21:58:56 server id 1 end_log_pos 848 Query thread_id=3 exec_time=0 error_code=0</span><br><span class=\"line\">SET TIMESTAMP=1474811936/*!*/;</span><br><span class=\"line\">update ops.member set name=&apos;小二&apos; where id=2      #执行的sql语句</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 848</span><br><span class=\"line\">#160925 21:58:56 server id 1 end_log_pos 875 Xid = 69   #开始执行的时间</span><br><span class=\"line\">COMMIT/*!*/;</span><br><span class=\"line\"># at 875</span><br><span class=\"line\">#160925 22:01:08 server id 1 end_log_pos 954 Query thread_id=3 exec_time=0 error_code=0    #结束时间</span><br><span class=\"line\">SET TIMESTAMP=1474812068/*!*/;</span><br><span class=\"line\">drop database ops</span><br><span class=\"line\">/*!*/;</span><br><span class=\"line\"># at 954</span><br><span class=\"line\">#160925 22:09:46 server id 1 end_log_pos 997 Rotate to mysql-bin.000004 pos: 4</span><br><span class=\"line\">DELIMITER ;</span><br><span class=\"line\"># End of log file</span><br><span class=\"line\">ROLLBACK /* added by mysqlbinlog */;</span><br><span class=\"line\">/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;</span><br><span class=\"line\"></span><br><span class=\"line\">恢复到更改“name=&apos;李四&apos;”之前的数据</span><br><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=&quot;2016-09-25 21:57:19&quot; --stop-datetime=&quot;2016-09-25 21:58:41&quot; --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | xiaoer | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=&quot;2016-09-25 21:58:41&quot; --stop-datetime=&quot;2016-09-25 21:58:56&quot; --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | 李四 | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=&quot;2016-09-25 21:58:56&quot; --stop-datetime=&quot;2016-09-25 22:01:08&quot; --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class=\"line\">mysql&gt; select * from member;</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| id | name | sex | age | classid |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class=\"line\">| 2 | 小二 | w | 27 | cls2 |</span><br><span class=\"line\">| 3 | yiyi | w | 20 | cls1 |</span><br><span class=\"line\">| 4 | 李四 | m | 22 | cls3 |</span><br><span class=\"line\">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class=\"line\">| 6 | lisi | m | 20 | cls4 |</span><br><span class=\"line\">| 7 | wangwu | w | 26 | cls6 |</span><br><span class=\"line\">+----+-----------+-----+-----+---------+</span><br><span class=\"line\">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>这样，就恢复了删除前的状态了！</p>\n<p>总结：<br>所谓恢复，就是让mysql将保存在binlog日志中指定段落区间的sql语句逐个重新执行一次而已。</p>"},{"title":"centos 7 部署 open-falcon 0.2.1","date":"2017-08-31T04:00:00.000Z","_content":"## 环境准备\n\n### 更换阿里yum\n<!--more-->\n 步骤：  \n1）下载wget  \n\n    yum install -y wget\n  \n2）备份默认的yum  \n\n    mv /etc/yum.repos.d /etc/yum.repos.d.backup\n  \n3）设置新的yum目录  \n\n    mkdir /etc/yum.repos.d  \n\n4）下载阿里yum配置到该目录中   \n\n    wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\n\n5）重建缓存  \n\n    yum clean all  \n    yum makecache  \n\n6）升级所有包（改变软件设置和系统设置，系统版本内核都升级，故需要几分钟耐心等待）  \n\n    yum update -y  \n\n###  安装vim  \n\n    yum install -y vim  \n\n###  安装git  \n\n    yum install -y git  \n\n安装结束后安全起见，确认是否满足官方要求的Git >= 1.7.5  \n\n    git version\n\n###  安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）\n\n    yum install -y epel-release\n    yum install golang -y\n\n安装结束后安全起见，确认是否满足官方要求的Go >= 1.6  \n\n    go version\n\n###  安装redis\n\n由于部署go时已经安装了epel，故直接执行下面的安装命令（如果没有装epel，会提示No package redis available，也就是没有安装包可用，因为官方yum和阿里yum都没有redis，故只能通过fedora的epel仓库来安装）  \n\n    yum install redis -y\n\n启动redis  \n\n    systemctl start redis  \n\n设置redis开机启动   \n\n    systemctl enable redis\n\n可以用下面的语句查看redis是否开启  \n\n    systemctl status redis  \n\n###  安装mysql\n\n 步骤：  \n\n1）下载repo源\n\n    wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm  \n\n2）安装该rpm包（安装这个包后，会获得两个mysql的yum repo源：/etc/yum.repos.d/mysql-community.repo，/etc/yum.repos.d/mysql-community-source.repo）  \n\n    rpm -ivh mysql-community-release-el7-5.noarch.rpm  \n\n3）安装mysql  \n\n    yum install mysql-server -y  \n\n4）启动mysql  \n\n    systemctl start mysql  \n\n可以用下面的语句查看mysql是否开启  \n\n    systemctl status mysql  \n\n###  设置环境变量GOROOT和GOPATH  \n\n    export GOROOT=/usr/lib/golang\n    export GOPATH=/home  \n\n###  将open-falcon的源码从github上get下来  \n\n步骤：\n\n1）创建GOPATH下的一个本地的路径  \n\n    mkdir -p $GOPATH/src/github.com/open-falcon  \n\n2）进入该路径  \n\n    cd $GOPATH/src/github.com/open-falcon  \n\n3）将源码get到本地  \n\n    git clone https://github.com/open-falcon/falcon-plus.git\n\n###  初始化数据库\n\n    cd $GOPATH/src/github.com/open-falcon/falcon-plus/scripts/mysql/db_schema/\n    mysql -h 127.0.0.1 -u root -p < 1_uic-db-schema.sql\n    mysql -h 127.0.0.1 -u root -p < 2_portal-db-schema.sql\n    mysql -h 127.0.0.1 -u root -p < 3_dashboard-db-schema.sql\n    mysql -h 127.0.0.1 -u root -p < 4_graph-db-schema.sql\n    mysql -h 127.0.0.1 -u root -p < 5_alarms-db-schema.sql\n\n再运行“mysql -h..................”时会提示“Enter password”，如果mysql的root没有设置密码，回车即可。\n\n\n###  编译源码并打包  \n \n步骤：  \n\n1）进入本地源码路径下  \n\n    cd $GOPATH/src/github.com/open-falcon/falcon-plus/\n\n2）使用go get获取rrdtool工具包（make过程卡壳的一个点）  \n \n    go get github.com/open-falcon/rrdlite\n    \n这一步是官方教程没有提到的内容，如果不获取该工具包make的时候会报错  \n\n\n3）编译所有模块  \n\n    make all\n\n 4）打包\n  \n    make pack  \n\n在$GOPATH/src/github.com/open-falcon/falcon-plus/目录下就多了刚才的压缩包“open-falcon-v0.2.0.tar.gz”。\n\n###  官方提供的安装包  \n\nhttps://book.open-falcon.org/zh_0_2/quick_install/prepare.html中官方有提供编译包，如果编译过程不顺利可以直接下载编译包。\n\n## 部署后端\n\n###  创建工作目录\n\n    export WORKSPACE=/home/work\n    mkdir -p $WORKSPACE\n\n###  解压二进制包（包名根据实际进行修改） \n\n由于我是根据本教程编译源码获得的压缩包，故需要切换到“$GOPATH/src/github.com/open-falcon/falcon-plus/”路径下。\n\n包名由于make pack的时候就是open-falcon-v0.2.0.tar.gz，具体根据实际情况。\n\n    cd $GOPATH/src/github.com/open-falcon/falcon-plus/\n    tar -xzvf open-falcon-v0.2.0.tar.gz -C $WORKSPACE\n\n###  修改配置文件cfg.json\n\n猜测部分模块依赖连接数据库，因为如果不修改配置文件，aggregator模块会出现无法启动，graph、hbs、nodata、api、alarm模块会出现开启不报错但是状态为开启失败的情况。（个人认为这块的设计值得作为open-falcon优化的一个点，连接本机mysql如果失败是可以收到错误提示的，第一时间有报错提示总比什么都不显示或显示开启但实际开启失败强，如果别人服务都不知道怎么开起来，系统功能再强大有多少人硬着头皮部署下去而不是选择换个系统试试呢）    \n\n如果需要每个模块都能正常启动，需要将上面模块的cfg.json的数据库信息进行修改。根据本教程的配置，需要修改配置文件所在的目录：   \n\n模块\t配置文件所在路径  \n\naggregator    \t/home/work/aggregator/config/cfg.json  \ngraph         \t/home/work/graph/config/cfg.json  \nhbs\t            /home/work/hbs/config/cfg.json  \nnodata      \t/home/work/nodata/config/cfg.json  \napi\t            /home/work/api/config/cfg.json  \nalarm       \t/home/work/alarm/config/cfg.json  \n\n1）修改aggregator的配置文件  \n\n    vim /home/work/aggregator/config/cfg.json\n\n\nmysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。   \n\n2）修改graph的配置文件  \n\n    vim /home/work/graph/config/cfg.json    \n\n\nmysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  \n\n3）修改hbs的配置文件\n\n    vim /home/work/hbs/config/cfg.json  \n\n\nmysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  \n\n4）修改nodata的配置文件  \n\n    vim /home/work/nodata/config/cfg.json  \n\n\nmysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  \n\n5）修改api的配置文件  \n\n    vim /home/work/api/config/cfg.json  \n\n\nmysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。\n\n6）修改alarm的配置文件  \n\n    vim /home/work/alarm/config/cfg.json  \n \n\nmysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。   \n\n###  启动后端模块\n  \n    cd $WORKSPACE\n    ./open-falcon start  \n\n可以用下面的命令检查各个模块的启动情况  \n\n    ./open-falcon check  \n\n更多命令的用法（命令的例子是启动agent模块）\n\n    ./open-falcon [start|stop|restart|check|monitor|reload] module\n    ./open-falcon start agent\n    ./open-falcon check\n\n\n        falcon-graph         UP           53007\n          falcon-hbs         UP           53014\n        falcon-judge         UP           53020\n     falcon-transfer         UP           53026\n       falcon-nodata         UP           53032\n    falcon-aggregator         UP           53038\n        falcon-agent         UP           53044\n      falcon-gateway         UP           53050\n          falcon-api         UP           53056\n        falcon-alarm         UP           53063\n\n    For debugging , You can check $WorkDir/$moduleName/log/logs/xxx.log  \n\n## 部署前端\n\n### 创建工作目录   \n\n    export FRONTSPACE=/home/front/open-falcon\n    mkdir -p $FRONTSPACE\n\n###  获取前端代码\n\n    cd $FRONTSPACE\n    git clone https://github.com/open-falcon/dashboard.git\n\n###  安装依赖包\n\n    yum install -y python-virtualenv\n    yum install -y python-devel\n    yum install -y openldap-devel\n    yum install -y mysql-devel\n    yum groupinstall \"Development tools\" -y\n\n    cd $FRONTSPACE/dashboard/\n    virtualenv ./env\n\n    ./env/bin/pip install -r pip_requirements.txt\n\n###  修改配置\n\n根据本次记录的配置，dashboard的配置文件在/home/front/open-falcon/dashboard/rrd/config.py，需要根据实际情况对内部配置进行修改。  \n\n由于前端后台搭在一台虚拟机里，且暂时不接入LDAP，且数据库root的密码为空，故先不修改配置文件。\n\n###  开启8081端口  \n\n1）防火墙添加8081端口永久开放\n\n    firewall-cmd --add-port=8081/tcp --permanent    \n\n2）重新载入防火墙配置 \n  \n    firewall-cmd --reload\n\n###  在生产环境启动\n\n    bash control start\n\n由于虚拟机ip配置为192.168.3.1，故在浏览器中输入192.168.3.1:8081后跳转。\n\n###  以开发者模式启动 \n\n    ./env/bin/python wsgi.py\n\n## 安装agent端\n\n###  创建agent安装目录\n\n    mkdir -p $GOPATH/src/github.com/open-falcon\n    cd $GOPATH/src/github.com/open-falcon\n\n###  从git上下载agent分支\n\n    git clone https://github.com/open-falcon/agent.git\n\n###  源码编译安装启动\n\n    cd agent\n    go get ./...\n    ./control build\n    ./control start\n    ./control pack\n\n最后一步会pack出一个tar.gz的安装包，拿着这个包去部署服务即可。需要注意的是在源码编译时：\n\n1、需要主机配置GOPATH环境变量（一般可以配置为用户家家目录）；\n\n2、需要主机可以连接外网，通过go get下载相关源码包。\n\n3、编译pack 出的包，在其他agent主机上部署时，无需连接外网 ，pack出的包，可以类似的理解为由c源代码编译后得出的二进制文件。\n\n### 配置说明\n\n配置文件必须叫cfg.json，可以基于cfg.example.json修改，默认该文件并不存在，通过./control start时自动会从cfg.example.json复制一份为cfg.json 。\n\n> {  \n    \"debug\": true,  \n    \"hostname\": \"\",  \n    \"ip\": \"\",  \n    \"plugin\": {  \n        \"enabled\": false, # 默认不开启插件机制  \n        \"dir\": \"./plugin\",  \n        \"git\": \"https://coding.net/ulricqin/plugin.git\",  \n        \"logs\": \"./logs\"  \n    },  \n    \"heartbeat\": {  \n        \"enabled\": true, # 此处enabled要设置为true  \n        \"addr\": \"127.0.0.1:6030\", # hbs的地址，端口是hbs的rpc端口  \n        \"interval\": 60,  \n        \"timeout\": 1000  \n    },  \n    \"transfer\": {  \n        \"enabled\": true, # 此处enabled要设置为true  \n        \"addr\": \"127.0.0.1:8433\", # transfer的地址，端口是transfer的rpc端口  \n        \"interval\": 60,  \n        \"timeout\": 1000  \n    },  \n    \"http\": {  \n        \"enabled\": true,  \n        \"listen\": \":1988\"  \n    },  \n    \"collector\": {  \n        \"ifacePrefix\": [\"eth\", \"em\"] # 默认配置只会采集网卡名称前缀是eth、em的网卡流量，配置为空就会采集所有的，lo的也会采集。可以从/proc/net/dev看到各个网卡的流量信息  \n    },  \n    \"ignore\": { # 默认采集了200多个metric，可以通过ignore设置为不采集  \n        \"cpu.busy\": true,  \n        \"mem.swapfree\": true  \n    }  \n}  \n\n###  进程管理\n\n    ./control start 启动进程\n    ./control stop 停止进程\n    ./control restart 重启进程\n    ./control status 查看进程状态\n    ./control tail 用tail -f的方式查看var/app.log\n\n验证 \n\n看var目录下的log是否正常，或者浏览器访问其1988端口。另外agent提供了一个--check参数，可以检查agent是否可以正常跑在当前机器上。  \n\n    ./falcon-agent --check\n\n打url  http://IP:1988可以查看相关监控信息。  \n","source":"_posts/open-falcon安装.md","raw":"---\ntitle: centos 7 部署 open-falcon 0.2.1\ndate: 2017-08-31\ntags: open-falcon\ncategories: open-falcon\n---\n## 环境准备\n\n### 更换阿里yum\n<!--more-->\n 步骤：  \n1）下载wget  \n\n    yum install -y wget\n  \n2）备份默认的yum  \n\n    mv /etc/yum.repos.d /etc/yum.repos.d.backup\n  \n3）设置新的yum目录  \n\n    mkdir /etc/yum.repos.d  \n\n4）下载阿里yum配置到该目录中   \n\n    wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\n\n5）重建缓存  \n\n    yum clean all  \n    yum makecache  \n\n6）升级所有包（改变软件设置和系统设置，系统版本内核都升级，故需要几分钟耐心等待）  \n\n    yum update -y  \n\n###  安装vim  \n\n    yum install -y vim  \n\n###  安装git  \n\n    yum install -y git  \n\n安装结束后安全起见，确认是否满足官方要求的Git >= 1.7.5  \n\n    git version\n\n###  安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）\n\n    yum install -y epel-release\n    yum install golang -y\n\n安装结束后安全起见，确认是否满足官方要求的Go >= 1.6  \n\n    go version\n\n###  安装redis\n\n由于部署go时已经安装了epel，故直接执行下面的安装命令（如果没有装epel，会提示No package redis available，也就是没有安装包可用，因为官方yum和阿里yum都没有redis，故只能通过fedora的epel仓库来安装）  \n\n    yum install redis -y\n\n启动redis  \n\n    systemctl start redis  \n\n设置redis开机启动   \n\n    systemctl enable redis\n\n可以用下面的语句查看redis是否开启  \n\n    systemctl status redis  \n\n###  安装mysql\n\n 步骤：  \n\n1）下载repo源\n\n    wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm  \n\n2）安装该rpm包（安装这个包后，会获得两个mysql的yum repo源：/etc/yum.repos.d/mysql-community.repo，/etc/yum.repos.d/mysql-community-source.repo）  \n\n    rpm -ivh mysql-community-release-el7-5.noarch.rpm  \n\n3）安装mysql  \n\n    yum install mysql-server -y  \n\n4）启动mysql  \n\n    systemctl start mysql  \n\n可以用下面的语句查看mysql是否开启  \n\n    systemctl status mysql  \n\n###  设置环境变量GOROOT和GOPATH  \n\n    export GOROOT=/usr/lib/golang\n    export GOPATH=/home  \n\n###  将open-falcon的源码从github上get下来  \n\n步骤：\n\n1）创建GOPATH下的一个本地的路径  \n\n    mkdir -p $GOPATH/src/github.com/open-falcon  \n\n2）进入该路径  \n\n    cd $GOPATH/src/github.com/open-falcon  \n\n3）将源码get到本地  \n\n    git clone https://github.com/open-falcon/falcon-plus.git\n\n###  初始化数据库\n\n    cd $GOPATH/src/github.com/open-falcon/falcon-plus/scripts/mysql/db_schema/\n    mysql -h 127.0.0.1 -u root -p < 1_uic-db-schema.sql\n    mysql -h 127.0.0.1 -u root -p < 2_portal-db-schema.sql\n    mysql -h 127.0.0.1 -u root -p < 3_dashboard-db-schema.sql\n    mysql -h 127.0.0.1 -u root -p < 4_graph-db-schema.sql\n    mysql -h 127.0.0.1 -u root -p < 5_alarms-db-schema.sql\n\n再运行“mysql -h..................”时会提示“Enter password”，如果mysql的root没有设置密码，回车即可。\n\n\n###  编译源码并打包  \n \n步骤：  \n\n1）进入本地源码路径下  \n\n    cd $GOPATH/src/github.com/open-falcon/falcon-plus/\n\n2）使用go get获取rrdtool工具包（make过程卡壳的一个点）  \n \n    go get github.com/open-falcon/rrdlite\n    \n这一步是官方教程没有提到的内容，如果不获取该工具包make的时候会报错  \n\n\n3）编译所有模块  \n\n    make all\n\n 4）打包\n  \n    make pack  \n\n在$GOPATH/src/github.com/open-falcon/falcon-plus/目录下就多了刚才的压缩包“open-falcon-v0.2.0.tar.gz”。\n\n###  官方提供的安装包  \n\nhttps://book.open-falcon.org/zh_0_2/quick_install/prepare.html中官方有提供编译包，如果编译过程不顺利可以直接下载编译包。\n\n## 部署后端\n\n###  创建工作目录\n\n    export WORKSPACE=/home/work\n    mkdir -p $WORKSPACE\n\n###  解压二进制包（包名根据实际进行修改） \n\n由于我是根据本教程编译源码获得的压缩包，故需要切换到“$GOPATH/src/github.com/open-falcon/falcon-plus/”路径下。\n\n包名由于make pack的时候就是open-falcon-v0.2.0.tar.gz，具体根据实际情况。\n\n    cd $GOPATH/src/github.com/open-falcon/falcon-plus/\n    tar -xzvf open-falcon-v0.2.0.tar.gz -C $WORKSPACE\n\n###  修改配置文件cfg.json\n\n猜测部分模块依赖连接数据库，因为如果不修改配置文件，aggregator模块会出现无法启动，graph、hbs、nodata、api、alarm模块会出现开启不报错但是状态为开启失败的情况。（个人认为这块的设计值得作为open-falcon优化的一个点，连接本机mysql如果失败是可以收到错误提示的，第一时间有报错提示总比什么都不显示或显示开启但实际开启失败强，如果别人服务都不知道怎么开起来，系统功能再强大有多少人硬着头皮部署下去而不是选择换个系统试试呢）    \n\n如果需要每个模块都能正常启动，需要将上面模块的cfg.json的数据库信息进行修改。根据本教程的配置，需要修改配置文件所在的目录：   \n\n模块\t配置文件所在路径  \n\naggregator    \t/home/work/aggregator/config/cfg.json  \ngraph         \t/home/work/graph/config/cfg.json  \nhbs\t            /home/work/hbs/config/cfg.json  \nnodata      \t/home/work/nodata/config/cfg.json  \napi\t            /home/work/api/config/cfg.json  \nalarm       \t/home/work/alarm/config/cfg.json  \n\n1）修改aggregator的配置文件  \n\n    vim /home/work/aggregator/config/cfg.json\n\n\nmysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。   \n\n2）修改graph的配置文件  \n\n    vim /home/work/graph/config/cfg.json    \n\n\nmysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  \n\n3）修改hbs的配置文件\n\n    vim /home/work/hbs/config/cfg.json  \n\n\nmysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  \n\n4）修改nodata的配置文件  \n\n    vim /home/work/nodata/config/cfg.json  \n\n\nmysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  \n\n5）修改api的配置文件  \n\n    vim /home/work/api/config/cfg.json  \n\n\nmysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。\n\n6）修改alarm的配置文件  \n\n    vim /home/work/alarm/config/cfg.json  \n \n\nmysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。   \n\n###  启动后端模块\n  \n    cd $WORKSPACE\n    ./open-falcon start  \n\n可以用下面的命令检查各个模块的启动情况  \n\n    ./open-falcon check  \n\n更多命令的用法（命令的例子是启动agent模块）\n\n    ./open-falcon [start|stop|restart|check|monitor|reload] module\n    ./open-falcon start agent\n    ./open-falcon check\n\n\n        falcon-graph         UP           53007\n          falcon-hbs         UP           53014\n        falcon-judge         UP           53020\n     falcon-transfer         UP           53026\n       falcon-nodata         UP           53032\n    falcon-aggregator         UP           53038\n        falcon-agent         UP           53044\n      falcon-gateway         UP           53050\n          falcon-api         UP           53056\n        falcon-alarm         UP           53063\n\n    For debugging , You can check $WorkDir/$moduleName/log/logs/xxx.log  \n\n## 部署前端\n\n### 创建工作目录   \n\n    export FRONTSPACE=/home/front/open-falcon\n    mkdir -p $FRONTSPACE\n\n###  获取前端代码\n\n    cd $FRONTSPACE\n    git clone https://github.com/open-falcon/dashboard.git\n\n###  安装依赖包\n\n    yum install -y python-virtualenv\n    yum install -y python-devel\n    yum install -y openldap-devel\n    yum install -y mysql-devel\n    yum groupinstall \"Development tools\" -y\n\n    cd $FRONTSPACE/dashboard/\n    virtualenv ./env\n\n    ./env/bin/pip install -r pip_requirements.txt\n\n###  修改配置\n\n根据本次记录的配置，dashboard的配置文件在/home/front/open-falcon/dashboard/rrd/config.py，需要根据实际情况对内部配置进行修改。  \n\n由于前端后台搭在一台虚拟机里，且暂时不接入LDAP，且数据库root的密码为空，故先不修改配置文件。\n\n###  开启8081端口  \n\n1）防火墙添加8081端口永久开放\n\n    firewall-cmd --add-port=8081/tcp --permanent    \n\n2）重新载入防火墙配置 \n  \n    firewall-cmd --reload\n\n###  在生产环境启动\n\n    bash control start\n\n由于虚拟机ip配置为192.168.3.1，故在浏览器中输入192.168.3.1:8081后跳转。\n\n###  以开发者模式启动 \n\n    ./env/bin/python wsgi.py\n\n## 安装agent端\n\n###  创建agent安装目录\n\n    mkdir -p $GOPATH/src/github.com/open-falcon\n    cd $GOPATH/src/github.com/open-falcon\n\n###  从git上下载agent分支\n\n    git clone https://github.com/open-falcon/agent.git\n\n###  源码编译安装启动\n\n    cd agent\n    go get ./...\n    ./control build\n    ./control start\n    ./control pack\n\n最后一步会pack出一个tar.gz的安装包，拿着这个包去部署服务即可。需要注意的是在源码编译时：\n\n1、需要主机配置GOPATH环境变量（一般可以配置为用户家家目录）；\n\n2、需要主机可以连接外网，通过go get下载相关源码包。\n\n3、编译pack 出的包，在其他agent主机上部署时，无需连接外网 ，pack出的包，可以类似的理解为由c源代码编译后得出的二进制文件。\n\n### 配置说明\n\n配置文件必须叫cfg.json，可以基于cfg.example.json修改，默认该文件并不存在，通过./control start时自动会从cfg.example.json复制一份为cfg.json 。\n\n> {  \n    \"debug\": true,  \n    \"hostname\": \"\",  \n    \"ip\": \"\",  \n    \"plugin\": {  \n        \"enabled\": false, # 默认不开启插件机制  \n        \"dir\": \"./plugin\",  \n        \"git\": \"https://coding.net/ulricqin/plugin.git\",  \n        \"logs\": \"./logs\"  \n    },  \n    \"heartbeat\": {  \n        \"enabled\": true, # 此处enabled要设置为true  \n        \"addr\": \"127.0.0.1:6030\", # hbs的地址，端口是hbs的rpc端口  \n        \"interval\": 60,  \n        \"timeout\": 1000  \n    },  \n    \"transfer\": {  \n        \"enabled\": true, # 此处enabled要设置为true  \n        \"addr\": \"127.0.0.1:8433\", # transfer的地址，端口是transfer的rpc端口  \n        \"interval\": 60,  \n        \"timeout\": 1000  \n    },  \n    \"http\": {  \n        \"enabled\": true,  \n        \"listen\": \":1988\"  \n    },  \n    \"collector\": {  \n        \"ifacePrefix\": [\"eth\", \"em\"] # 默认配置只会采集网卡名称前缀是eth、em的网卡流量，配置为空就会采集所有的，lo的也会采集。可以从/proc/net/dev看到各个网卡的流量信息  \n    },  \n    \"ignore\": { # 默认采集了200多个metric，可以通过ignore设置为不采集  \n        \"cpu.busy\": true,  \n        \"mem.swapfree\": true  \n    }  \n}  \n\n###  进程管理\n\n    ./control start 启动进程\n    ./control stop 停止进程\n    ./control restart 重启进程\n    ./control status 查看进程状态\n    ./control tail 用tail -f的方式查看var/app.log\n\n验证 \n\n看var目录下的log是否正常，或者浏览器访问其1988端口。另外agent提供了一个--check参数，可以检查agent是否可以正常跑在当前机器上。  \n\n    ./falcon-agent --check\n\n打url  http://IP:1988可以查看相关监控信息。  \n","slug":"open-falcon安装","published":1,"updated":"2019-06-18T08:07:01.117Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sma001whcb7fimbrts3","content":"<h2 id=\"环境准备\"><a href=\"#环境准备\" class=\"headerlink\" title=\"环境准备\"></a>环境准备</h2><h3 id=\"更换阿里yum\"><a href=\"#更换阿里yum\" class=\"headerlink\" title=\"更换阿里yum\"></a>更换阿里yum</h3><a id=\"more\"></a>\n<p> 步骤：<br>1）下载wget  </p>\n<pre><code>yum install -y wget\n</code></pre><p>2）备份默认的yum  </p>\n<pre><code>mv /etc/yum.repos.d /etc/yum.repos.d.backup\n</code></pre><p>3）设置新的yum目录  </p>\n<pre><code>mkdir /etc/yum.repos.d  \n</code></pre><p>4）下载阿里yum配置到该目录中   </p>\n<pre><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\n</code></pre><p>5）重建缓存  </p>\n<pre><code>yum clean all  \nyum makecache  \n</code></pre><p>6）升级所有包（改变软件设置和系统设置，系统版本内核都升级，故需要几分钟耐心等待）  </p>\n<pre><code>yum update -y  \n</code></pre><h3 id=\"安装vim\"><a href=\"#安装vim\" class=\"headerlink\" title=\"安装vim\"></a>安装vim</h3><pre><code>yum install -y vim  \n</code></pre><h3 id=\"安装git\"><a href=\"#安装git\" class=\"headerlink\" title=\"安装git\"></a>安装git</h3><pre><code>yum install -y git  \n</code></pre><p>安装结束后安全起见，确认是否满足官方要求的Git &gt;= 1.7.5  </p>\n<pre><code>git version\n</code></pre><h3 id=\"安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）\"><a href=\"#安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）\" class=\"headerlink\" title=\"安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）\"></a>安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）</h3><pre><code>yum install -y epel-release\nyum install golang -y\n</code></pre><p>安装结束后安全起见，确认是否满足官方要求的Go &gt;= 1.6  </p>\n<pre><code>go version\n</code></pre><h3 id=\"安装redis\"><a href=\"#安装redis\" class=\"headerlink\" title=\"安装redis\"></a>安装redis</h3><p>由于部署go时已经安装了epel，故直接执行下面的安装命令（如果没有装epel，会提示No package redis available，也就是没有安装包可用，因为官方yum和阿里yum都没有redis，故只能通过fedora的epel仓库来安装）  </p>\n<pre><code>yum install redis -y\n</code></pre><p>启动redis  </p>\n<pre><code>systemctl start redis  \n</code></pre><p>设置redis开机启动   </p>\n<pre><code>systemctl enable redis\n</code></pre><p>可以用下面的语句查看redis是否开启  </p>\n<pre><code>systemctl status redis  \n</code></pre><h3 id=\"安装mysql\"><a href=\"#安装mysql\" class=\"headerlink\" title=\"安装mysql\"></a>安装mysql</h3><p> 步骤：  </p>\n<p>1）下载repo源</p>\n<pre><code>wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm  \n</code></pre><p>2）安装该rpm包（安装这个包后，会获得两个mysql的yum repo源：/etc/yum.repos.d/mysql-community.repo，/etc/yum.repos.d/mysql-community-source.repo）  </p>\n<pre><code>rpm -ivh mysql-community-release-el7-5.noarch.rpm  \n</code></pre><p>3）安装mysql  </p>\n<pre><code>yum install mysql-server -y  \n</code></pre><p>4）启动mysql  </p>\n<pre><code>systemctl start mysql  \n</code></pre><p>可以用下面的语句查看mysql是否开启  </p>\n<pre><code>systemctl status mysql  \n</code></pre><h3 id=\"设置环境变量GOROOT和GOPATH\"><a href=\"#设置环境变量GOROOT和GOPATH\" class=\"headerlink\" title=\"设置环境变量GOROOT和GOPATH\"></a>设置环境变量GOROOT和GOPATH</h3><pre><code>export GOROOT=/usr/lib/golang\nexport GOPATH=/home  \n</code></pre><h3 id=\"将open-falcon的源码从github上get下来\"><a href=\"#将open-falcon的源码从github上get下来\" class=\"headerlink\" title=\"将open-falcon的源码从github上get下来\"></a>将open-falcon的源码从github上get下来</h3><p>步骤：</p>\n<p>1）创建GOPATH下的一个本地的路径  </p>\n<pre><code>mkdir -p $GOPATH/src/github.com/open-falcon  \n</code></pre><p>2）进入该路径  </p>\n<pre><code>cd $GOPATH/src/github.com/open-falcon  \n</code></pre><p>3）将源码get到本地  </p>\n<pre><code>git clone https://github.com/open-falcon/falcon-plus.git\n</code></pre><h3 id=\"初始化数据库\"><a href=\"#初始化数据库\" class=\"headerlink\" title=\"初始化数据库\"></a>初始化数据库</h3><pre><code>cd $GOPATH/src/github.com/open-falcon/falcon-plus/scripts/mysql/db_schema/\nmysql -h 127.0.0.1 -u root -p &lt; 1_uic-db-schema.sql\nmysql -h 127.0.0.1 -u root -p &lt; 2_portal-db-schema.sql\nmysql -h 127.0.0.1 -u root -p &lt; 3_dashboard-db-schema.sql\nmysql -h 127.0.0.1 -u root -p &lt; 4_graph-db-schema.sql\nmysql -h 127.0.0.1 -u root -p &lt; 5_alarms-db-schema.sql\n</code></pre><p>再运行“mysql -h………………”时会提示“Enter password”，如果mysql的root没有设置密码，回车即可。</p>\n<h3 id=\"编译源码并打包\"><a href=\"#编译源码并打包\" class=\"headerlink\" title=\"编译源码并打包\"></a>编译源码并打包</h3><p>步骤：  </p>\n<p>1）进入本地源码路径下  </p>\n<pre><code>cd $GOPATH/src/github.com/open-falcon/falcon-plus/\n</code></pre><p>2）使用go get获取rrdtool工具包（make过程卡壳的一个点）  </p>\n<pre><code>go get github.com/open-falcon/rrdlite\n</code></pre><p>这一步是官方教程没有提到的内容，如果不获取该工具包make的时候会报错  </p>\n<p>3）编译所有模块  </p>\n<pre><code>make all\n</code></pre><p> 4）打包</p>\n<pre><code>make pack  \n</code></pre><p>在$GOPATH/src/github.com/open-falcon/falcon-plus/目录下就多了刚才的压缩包“open-falcon-v0.2.0.tar.gz”。</p>\n<h3 id=\"官方提供的安装包\"><a href=\"#官方提供的安装包\" class=\"headerlink\" title=\"官方提供的安装包\"></a>官方提供的安装包</h3><p><a href=\"https://book.open-falcon.org/zh_0_2/quick_install/prepare.html中官方有提供编译包，如果编译过程不顺利可以直接下载编译包。\" target=\"_blank\" rel=\"noopener\">https://book.open-falcon.org/zh_0_2/quick_install/prepare.html中官方有提供编译包，如果编译过程不顺利可以直接下载编译包。</a></p>\n<h2 id=\"部署后端\"><a href=\"#部署后端\" class=\"headerlink\" title=\"部署后端\"></a>部署后端</h2><h3 id=\"创建工作目录\"><a href=\"#创建工作目录\" class=\"headerlink\" title=\"创建工作目录\"></a>创建工作目录</h3><pre><code>export WORKSPACE=/home/work\nmkdir -p $WORKSPACE\n</code></pre><h3 id=\"解压二进制包（包名根据实际进行修改）\"><a href=\"#解压二进制包（包名根据实际进行修改）\" class=\"headerlink\" title=\"解压二进制包（包名根据实际进行修改）\"></a>解压二进制包（包名根据实际进行修改）</h3><p>由于我是根据本教程编译源码获得的压缩包，故需要切换到“$GOPATH/src/github.com/open-falcon/falcon-plus/”路径下。</p>\n<p>包名由于make pack的时候就是open-falcon-v0.2.0.tar.gz，具体根据实际情况。</p>\n<pre><code>cd $GOPATH/src/github.com/open-falcon/falcon-plus/\ntar -xzvf open-falcon-v0.2.0.tar.gz -C $WORKSPACE\n</code></pre><h3 id=\"修改配置文件cfg-json\"><a href=\"#修改配置文件cfg-json\" class=\"headerlink\" title=\"修改配置文件cfg.json\"></a>修改配置文件cfg.json</h3><p>猜测部分模块依赖连接数据库，因为如果不修改配置文件，aggregator模块会出现无法启动，graph、hbs、nodata、api、alarm模块会出现开启不报错但是状态为开启失败的情况。（个人认为这块的设计值得作为open-falcon优化的一个点，连接本机mysql如果失败是可以收到错误提示的，第一时间有报错提示总比什么都不显示或显示开启但实际开启失败强，如果别人服务都不知道怎么开起来，系统功能再强大有多少人硬着头皮部署下去而不是选择换个系统试试呢）    </p>\n<p>如果需要每个模块都能正常启动，需要将上面模块的cfg.json的数据库信息进行修改。根据本教程的配置，需要修改配置文件所在的目录：   </p>\n<p>模块    配置文件所在路径  </p>\n<p>aggregator        /home/work/aggregator/config/cfg.json<br>graph             /home/work/graph/config/cfg.json<br>hbs                /home/work/hbs/config/cfg.json<br>nodata          /home/work/nodata/config/cfg.json<br>api                /home/work/api/config/cfg.json<br>alarm           /home/work/alarm/config/cfg.json  </p>\n<p>1）修改aggregator的配置文件  </p>\n<pre><code>vim /home/work/aggregator/config/cfg.json\n</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。   </p>\n<p>2）修改graph的配置文件  </p>\n<pre><code>vim /home/work/graph/config/cfg.json    \n</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  </p>\n<p>3）修改hbs的配置文件</p>\n<pre><code>vim /home/work/hbs/config/cfg.json  \n</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  </p>\n<p>4）修改nodata的配置文件  </p>\n<pre><code>vim /home/work/nodata/config/cfg.json  \n</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  </p>\n<p>5）修改api的配置文件  </p>\n<pre><code>vim /home/work/api/config/cfg.json  \n</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。</p>\n<p>6）修改alarm的配置文件  </p>\n<pre><code>vim /home/work/alarm/config/cfg.json  \n</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。   </p>\n<h3 id=\"启动后端模块\"><a href=\"#启动后端模块\" class=\"headerlink\" title=\"启动后端模块\"></a>启动后端模块</h3><pre><code>cd $WORKSPACE\n./open-falcon start  \n</code></pre><p>可以用下面的命令检查各个模块的启动情况  </p>\n<pre><code>./open-falcon check  \n</code></pre><p>更多命令的用法（命令的例子是启动agent模块）</p>\n<pre><code>./open-falcon [start|stop|restart|check|monitor|reload] module\n./open-falcon start agent\n./open-falcon check\n\n\n    falcon-graph         UP           53007\n      falcon-hbs         UP           53014\n    falcon-judge         UP           53020\n falcon-transfer         UP           53026\n   falcon-nodata         UP           53032\nfalcon-aggregator         UP           53038\n    falcon-agent         UP           53044\n  falcon-gateway         UP           53050\n      falcon-api         UP           53056\n    falcon-alarm         UP           53063\n\nFor debugging , You can check $WorkDir/$moduleName/log/logs/xxx.log  \n</code></pre><h2 id=\"部署前端\"><a href=\"#部署前端\" class=\"headerlink\" title=\"部署前端\"></a>部署前端</h2><h3 id=\"创建工作目录-1\"><a href=\"#创建工作目录-1\" class=\"headerlink\" title=\"创建工作目录\"></a>创建工作目录</h3><pre><code>export FRONTSPACE=/home/front/open-falcon\nmkdir -p $FRONTSPACE\n</code></pre><h3 id=\"获取前端代码\"><a href=\"#获取前端代码\" class=\"headerlink\" title=\"获取前端代码\"></a>获取前端代码</h3><pre><code>cd $FRONTSPACE\ngit clone https://github.com/open-falcon/dashboard.git\n</code></pre><h3 id=\"安装依赖包\"><a href=\"#安装依赖包\" class=\"headerlink\" title=\"安装依赖包\"></a>安装依赖包</h3><pre><code>yum install -y python-virtualenv\nyum install -y python-devel\nyum install -y openldap-devel\nyum install -y mysql-devel\nyum groupinstall &quot;Development tools&quot; -y\n\ncd $FRONTSPACE/dashboard/\nvirtualenv ./env\n\n./env/bin/pip install -r pip_requirements.txt\n</code></pre><h3 id=\"修改配置\"><a href=\"#修改配置\" class=\"headerlink\" title=\"修改配置\"></a>修改配置</h3><p>根据本次记录的配置，dashboard的配置文件在/home/front/open-falcon/dashboard/rrd/config.py，需要根据实际情况对内部配置进行修改。  </p>\n<p>由于前端后台搭在一台虚拟机里，且暂时不接入LDAP，且数据库root的密码为空，故先不修改配置文件。</p>\n<h3 id=\"开启8081端口\"><a href=\"#开启8081端口\" class=\"headerlink\" title=\"开启8081端口\"></a>开启8081端口</h3><p>1）防火墙添加8081端口永久开放</p>\n<pre><code>firewall-cmd --add-port=8081/tcp --permanent    \n</code></pre><p>2）重新载入防火墙配置 </p>\n<pre><code>firewall-cmd --reload\n</code></pre><h3 id=\"在生产环境启动\"><a href=\"#在生产环境启动\" class=\"headerlink\" title=\"在生产环境启动\"></a>在生产环境启动</h3><pre><code>bash control start\n</code></pre><p>由于虚拟机ip配置为192.168.3.1，故在浏览器中输入192.168.3.1:8081后跳转。</p>\n<h3 id=\"以开发者模式启动\"><a href=\"#以开发者模式启动\" class=\"headerlink\" title=\"以开发者模式启动\"></a>以开发者模式启动</h3><pre><code>./env/bin/python wsgi.py\n</code></pre><h2 id=\"安装agent端\"><a href=\"#安装agent端\" class=\"headerlink\" title=\"安装agent端\"></a>安装agent端</h2><h3 id=\"创建agent安装目录\"><a href=\"#创建agent安装目录\" class=\"headerlink\" title=\"创建agent安装目录\"></a>创建agent安装目录</h3><pre><code>mkdir -p $GOPATH/src/github.com/open-falcon\ncd $GOPATH/src/github.com/open-falcon\n</code></pre><h3 id=\"从git上下载agent分支\"><a href=\"#从git上下载agent分支\" class=\"headerlink\" title=\"从git上下载agent分支\"></a>从git上下载agent分支</h3><pre><code>git clone https://github.com/open-falcon/agent.git\n</code></pre><h3 id=\"源码编译安装启动\"><a href=\"#源码编译安装启动\" class=\"headerlink\" title=\"源码编译安装启动\"></a>源码编译安装启动</h3><pre><code>cd agent\ngo get ./...\n./control build\n./control start\n./control pack\n</code></pre><p>最后一步会pack出一个tar.gz的安装包，拿着这个包去部署服务即可。需要注意的是在源码编译时：</p>\n<p>1、需要主机配置GOPATH环境变量（一般可以配置为用户家家目录）；</p>\n<p>2、需要主机可以连接外网，通过go get下载相关源码包。</p>\n<p>3、编译pack 出的包，在其他agent主机上部署时，无需连接外网 ，pack出的包，可以类似的理解为由c源代码编译后得出的二进制文件。</p>\n<h3 id=\"配置说明\"><a href=\"#配置说明\" class=\"headerlink\" title=\"配置说明\"></a>配置说明</h3><p>配置文件必须叫cfg.json，可以基于cfg.example.json修改，默认该文件并不存在，通过./control start时自动会从cfg.example.json复制一份为cfg.json 。</p>\n<blockquote>\n<p>{<br>    “debug”: true,<br>    “hostname”: “”,<br>    “ip”: “”,<br>    “plugin”: {<br>        “enabled”: false, # 默认不开启插件机制<br>        “dir”: “./plugin”,<br>        “git”: “<a href=\"https://coding.net/ulricqin/plugin.git&quot;\" target=\"_blank\" rel=\"noopener\">https://coding.net/ulricqin/plugin.git&quot;</a>,<br>        “logs”: “./logs”<br>    },<br>    “heartbeat”: {<br>        “enabled”: true, # 此处enabled要设置为true<br>        “addr”: “127.0.0.1:6030”, # hbs的地址，端口是hbs的rpc端口<br>        “interval”: 60,<br>        “timeout”: 1000<br>    },<br>    “transfer”: {<br>        “enabled”: true, # 此处enabled要设置为true<br>        “addr”: “127.0.0.1:8433”, # transfer的地址，端口是transfer的rpc端口<br>        “interval”: 60,<br>        “timeout”: 1000<br>    },<br>    “http”: {<br>        “enabled”: true,<br>        “listen”: “:1988”<br>    },<br>    “collector”: {<br>        “ifacePrefix”: [“eth”, “em”] # 默认配置只会采集网卡名称前缀是eth、em的网卡流量，配置为空就会采集所有的，lo的也会采集。可以从/proc/net/dev看到各个网卡的流量信息<br>    },<br>    “ignore”: { # 默认采集了200多个metric，可以通过ignore设置为不采集<br>        “cpu.busy”: true,<br>        “mem.swapfree”: true<br>    }<br>}  </p>\n</blockquote>\n<h3 id=\"进程管理\"><a href=\"#进程管理\" class=\"headerlink\" title=\"进程管理\"></a>进程管理</h3><pre><code>./control start 启动进程\n./control stop 停止进程\n./control restart 重启进程\n./control status 查看进程状态\n./control tail 用tail -f的方式查看var/app.log\n</code></pre><p>验证 </p>\n<p>看var目录下的log是否正常，或者浏览器访问其1988端口。另外agent提供了一个–check参数，可以检查agent是否可以正常跑在当前机器上。  </p>\n<pre><code>./falcon-agent --check\n</code></pre><p>打url  <a href=\"http://IP:1988可以查看相关监控信息。\" target=\"_blank\" rel=\"noopener\">http://IP:1988可以查看相关监控信息。</a>  </p>\n","site":{"data":{}},"excerpt":"<h2 id=\"环境准备\"><a href=\"#环境准备\" class=\"headerlink\" title=\"环境准备\"></a>环境准备</h2><h3 id=\"更换阿里yum\"><a href=\"#更换阿里yum\" class=\"headerlink\" title=\"更换阿里yum\"></a>更换阿里yum</h3>","more":"<p> 步骤：<br>1）下载wget  </p>\n<pre><code>yum install -y wget\n</code></pre><p>2）备份默认的yum  </p>\n<pre><code>mv /etc/yum.repos.d /etc/yum.repos.d.backup\n</code></pre><p>3）设置新的yum目录  </p>\n<pre><code>mkdir /etc/yum.repos.d  \n</code></pre><p>4）下载阿里yum配置到该目录中   </p>\n<pre><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\n</code></pre><p>5）重建缓存  </p>\n<pre><code>yum clean all  \nyum makecache  \n</code></pre><p>6）升级所有包（改变软件设置和系统设置，系统版本内核都升级，故需要几分钟耐心等待）  </p>\n<pre><code>yum update -y  \n</code></pre><h3 id=\"安装vim\"><a href=\"#安装vim\" class=\"headerlink\" title=\"安装vim\"></a>安装vim</h3><pre><code>yum install -y vim  \n</code></pre><h3 id=\"安装git\"><a href=\"#安装git\" class=\"headerlink\" title=\"安装git\"></a>安装git</h3><pre><code>yum install -y git  \n</code></pre><p>安装结束后安全起见，确认是否满足官方要求的Git &gt;= 1.7.5  </p>\n<pre><code>git version\n</code></pre><h3 id=\"安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）\"><a href=\"#安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）\" class=\"headerlink\" title=\"安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）\"></a>安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）</h3><pre><code>yum install -y epel-release\nyum install golang -y\n</code></pre><p>安装结束后安全起见，确认是否满足官方要求的Go &gt;= 1.6  </p>\n<pre><code>go version\n</code></pre><h3 id=\"安装redis\"><a href=\"#安装redis\" class=\"headerlink\" title=\"安装redis\"></a>安装redis</h3><p>由于部署go时已经安装了epel，故直接执行下面的安装命令（如果没有装epel，会提示No package redis available，也就是没有安装包可用，因为官方yum和阿里yum都没有redis，故只能通过fedora的epel仓库来安装）  </p>\n<pre><code>yum install redis -y\n</code></pre><p>启动redis  </p>\n<pre><code>systemctl start redis  \n</code></pre><p>设置redis开机启动   </p>\n<pre><code>systemctl enable redis\n</code></pre><p>可以用下面的语句查看redis是否开启  </p>\n<pre><code>systemctl status redis  \n</code></pre><h3 id=\"安装mysql\"><a href=\"#安装mysql\" class=\"headerlink\" title=\"安装mysql\"></a>安装mysql</h3><p> 步骤：  </p>\n<p>1）下载repo源</p>\n<pre><code>wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm  \n</code></pre><p>2）安装该rpm包（安装这个包后，会获得两个mysql的yum repo源：/etc/yum.repos.d/mysql-community.repo，/etc/yum.repos.d/mysql-community-source.repo）  </p>\n<pre><code>rpm -ivh mysql-community-release-el7-5.noarch.rpm  \n</code></pre><p>3）安装mysql  </p>\n<pre><code>yum install mysql-server -y  \n</code></pre><p>4）启动mysql  </p>\n<pre><code>systemctl start mysql  \n</code></pre><p>可以用下面的语句查看mysql是否开启  </p>\n<pre><code>systemctl status mysql  \n</code></pre><h3 id=\"设置环境变量GOROOT和GOPATH\"><a href=\"#设置环境变量GOROOT和GOPATH\" class=\"headerlink\" title=\"设置环境变量GOROOT和GOPATH\"></a>设置环境变量GOROOT和GOPATH</h3><pre><code>export GOROOT=/usr/lib/golang\nexport GOPATH=/home  \n</code></pre><h3 id=\"将open-falcon的源码从github上get下来\"><a href=\"#将open-falcon的源码从github上get下来\" class=\"headerlink\" title=\"将open-falcon的源码从github上get下来\"></a>将open-falcon的源码从github上get下来</h3><p>步骤：</p>\n<p>1）创建GOPATH下的一个本地的路径  </p>\n<pre><code>mkdir -p $GOPATH/src/github.com/open-falcon  \n</code></pre><p>2）进入该路径  </p>\n<pre><code>cd $GOPATH/src/github.com/open-falcon  \n</code></pre><p>3）将源码get到本地  </p>\n<pre><code>git clone https://github.com/open-falcon/falcon-plus.git\n</code></pre><h3 id=\"初始化数据库\"><a href=\"#初始化数据库\" class=\"headerlink\" title=\"初始化数据库\"></a>初始化数据库</h3><pre><code>cd $GOPATH/src/github.com/open-falcon/falcon-plus/scripts/mysql/db_schema/\nmysql -h 127.0.0.1 -u root -p &lt; 1_uic-db-schema.sql\nmysql -h 127.0.0.1 -u root -p &lt; 2_portal-db-schema.sql\nmysql -h 127.0.0.1 -u root -p &lt; 3_dashboard-db-schema.sql\nmysql -h 127.0.0.1 -u root -p &lt; 4_graph-db-schema.sql\nmysql -h 127.0.0.1 -u root -p &lt; 5_alarms-db-schema.sql\n</code></pre><p>再运行“mysql -h………………”时会提示“Enter password”，如果mysql的root没有设置密码，回车即可。</p>\n<h3 id=\"编译源码并打包\"><a href=\"#编译源码并打包\" class=\"headerlink\" title=\"编译源码并打包\"></a>编译源码并打包</h3><p>步骤：  </p>\n<p>1）进入本地源码路径下  </p>\n<pre><code>cd $GOPATH/src/github.com/open-falcon/falcon-plus/\n</code></pre><p>2）使用go get获取rrdtool工具包（make过程卡壳的一个点）  </p>\n<pre><code>go get github.com/open-falcon/rrdlite\n</code></pre><p>这一步是官方教程没有提到的内容，如果不获取该工具包make的时候会报错  </p>\n<p>3）编译所有模块  </p>\n<pre><code>make all\n</code></pre><p> 4）打包</p>\n<pre><code>make pack  \n</code></pre><p>在$GOPATH/src/github.com/open-falcon/falcon-plus/目录下就多了刚才的压缩包“open-falcon-v0.2.0.tar.gz”。</p>\n<h3 id=\"官方提供的安装包\"><a href=\"#官方提供的安装包\" class=\"headerlink\" title=\"官方提供的安装包\"></a>官方提供的安装包</h3><p><a href=\"https://book.open-falcon.org/zh_0_2/quick_install/prepare.html中官方有提供编译包，如果编译过程不顺利可以直接下载编译包。\" target=\"_blank\" rel=\"noopener\">https://book.open-falcon.org/zh_0_2/quick_install/prepare.html中官方有提供编译包，如果编译过程不顺利可以直接下载编译包。</a></p>\n<h2 id=\"部署后端\"><a href=\"#部署后端\" class=\"headerlink\" title=\"部署后端\"></a>部署后端</h2><h3 id=\"创建工作目录\"><a href=\"#创建工作目录\" class=\"headerlink\" title=\"创建工作目录\"></a>创建工作目录</h3><pre><code>export WORKSPACE=/home/work\nmkdir -p $WORKSPACE\n</code></pre><h3 id=\"解压二进制包（包名根据实际进行修改）\"><a href=\"#解压二进制包（包名根据实际进行修改）\" class=\"headerlink\" title=\"解压二进制包（包名根据实际进行修改）\"></a>解压二进制包（包名根据实际进行修改）</h3><p>由于我是根据本教程编译源码获得的压缩包，故需要切换到“$GOPATH/src/github.com/open-falcon/falcon-plus/”路径下。</p>\n<p>包名由于make pack的时候就是open-falcon-v0.2.0.tar.gz，具体根据实际情况。</p>\n<pre><code>cd $GOPATH/src/github.com/open-falcon/falcon-plus/\ntar -xzvf open-falcon-v0.2.0.tar.gz -C $WORKSPACE\n</code></pre><h3 id=\"修改配置文件cfg-json\"><a href=\"#修改配置文件cfg-json\" class=\"headerlink\" title=\"修改配置文件cfg.json\"></a>修改配置文件cfg.json</h3><p>猜测部分模块依赖连接数据库，因为如果不修改配置文件，aggregator模块会出现无法启动，graph、hbs、nodata、api、alarm模块会出现开启不报错但是状态为开启失败的情况。（个人认为这块的设计值得作为open-falcon优化的一个点，连接本机mysql如果失败是可以收到错误提示的，第一时间有报错提示总比什么都不显示或显示开启但实际开启失败强，如果别人服务都不知道怎么开起来，系统功能再强大有多少人硬着头皮部署下去而不是选择换个系统试试呢）    </p>\n<p>如果需要每个模块都能正常启动，需要将上面模块的cfg.json的数据库信息进行修改。根据本教程的配置，需要修改配置文件所在的目录：   </p>\n<p>模块    配置文件所在路径  </p>\n<p>aggregator        /home/work/aggregator/config/cfg.json<br>graph             /home/work/graph/config/cfg.json<br>hbs                /home/work/hbs/config/cfg.json<br>nodata          /home/work/nodata/config/cfg.json<br>api                /home/work/api/config/cfg.json<br>alarm           /home/work/alarm/config/cfg.json  </p>\n<p>1）修改aggregator的配置文件  </p>\n<pre><code>vim /home/work/aggregator/config/cfg.json\n</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。   </p>\n<p>2）修改graph的配置文件  </p>\n<pre><code>vim /home/work/graph/config/cfg.json    \n</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  </p>\n<p>3）修改hbs的配置文件</p>\n<pre><code>vim /home/work/hbs/config/cfg.json  \n</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  </p>\n<p>4）修改nodata的配置文件  </p>\n<pre><code>vim /home/work/nodata/config/cfg.json  \n</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  </p>\n<p>5）修改api的配置文件  </p>\n<pre><code>vim /home/work/api/config/cfg.json  \n</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。</p>\n<p>6）修改alarm的配置文件  </p>\n<pre><code>vim /home/work/alarm/config/cfg.json  \n</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。   </p>\n<h3 id=\"启动后端模块\"><a href=\"#启动后端模块\" class=\"headerlink\" title=\"启动后端模块\"></a>启动后端模块</h3><pre><code>cd $WORKSPACE\n./open-falcon start  \n</code></pre><p>可以用下面的命令检查各个模块的启动情况  </p>\n<pre><code>./open-falcon check  \n</code></pre><p>更多命令的用法（命令的例子是启动agent模块）</p>\n<pre><code>./open-falcon [start|stop|restart|check|monitor|reload] module\n./open-falcon start agent\n./open-falcon check\n\n\n    falcon-graph         UP           53007\n      falcon-hbs         UP           53014\n    falcon-judge         UP           53020\n falcon-transfer         UP           53026\n   falcon-nodata         UP           53032\nfalcon-aggregator         UP           53038\n    falcon-agent         UP           53044\n  falcon-gateway         UP           53050\n      falcon-api         UP           53056\n    falcon-alarm         UP           53063\n\nFor debugging , You can check $WorkDir/$moduleName/log/logs/xxx.log  \n</code></pre><h2 id=\"部署前端\"><a href=\"#部署前端\" class=\"headerlink\" title=\"部署前端\"></a>部署前端</h2><h3 id=\"创建工作目录-1\"><a href=\"#创建工作目录-1\" class=\"headerlink\" title=\"创建工作目录\"></a>创建工作目录</h3><pre><code>export FRONTSPACE=/home/front/open-falcon\nmkdir -p $FRONTSPACE\n</code></pre><h3 id=\"获取前端代码\"><a href=\"#获取前端代码\" class=\"headerlink\" title=\"获取前端代码\"></a>获取前端代码</h3><pre><code>cd $FRONTSPACE\ngit clone https://github.com/open-falcon/dashboard.git\n</code></pre><h3 id=\"安装依赖包\"><a href=\"#安装依赖包\" class=\"headerlink\" title=\"安装依赖包\"></a>安装依赖包</h3><pre><code>yum install -y python-virtualenv\nyum install -y python-devel\nyum install -y openldap-devel\nyum install -y mysql-devel\nyum groupinstall &quot;Development tools&quot; -y\n\ncd $FRONTSPACE/dashboard/\nvirtualenv ./env\n\n./env/bin/pip install -r pip_requirements.txt\n</code></pre><h3 id=\"修改配置\"><a href=\"#修改配置\" class=\"headerlink\" title=\"修改配置\"></a>修改配置</h3><p>根据本次记录的配置，dashboard的配置文件在/home/front/open-falcon/dashboard/rrd/config.py，需要根据实际情况对内部配置进行修改。  </p>\n<p>由于前端后台搭在一台虚拟机里，且暂时不接入LDAP，且数据库root的密码为空，故先不修改配置文件。</p>\n<h3 id=\"开启8081端口\"><a href=\"#开启8081端口\" class=\"headerlink\" title=\"开启8081端口\"></a>开启8081端口</h3><p>1）防火墙添加8081端口永久开放</p>\n<pre><code>firewall-cmd --add-port=8081/tcp --permanent    \n</code></pre><p>2）重新载入防火墙配置 </p>\n<pre><code>firewall-cmd --reload\n</code></pre><h3 id=\"在生产环境启动\"><a href=\"#在生产环境启动\" class=\"headerlink\" title=\"在生产环境启动\"></a>在生产环境启动</h3><pre><code>bash control start\n</code></pre><p>由于虚拟机ip配置为192.168.3.1，故在浏览器中输入192.168.3.1:8081后跳转。</p>\n<h3 id=\"以开发者模式启动\"><a href=\"#以开发者模式启动\" class=\"headerlink\" title=\"以开发者模式启动\"></a>以开发者模式启动</h3><pre><code>./env/bin/python wsgi.py\n</code></pre><h2 id=\"安装agent端\"><a href=\"#安装agent端\" class=\"headerlink\" title=\"安装agent端\"></a>安装agent端</h2><h3 id=\"创建agent安装目录\"><a href=\"#创建agent安装目录\" class=\"headerlink\" title=\"创建agent安装目录\"></a>创建agent安装目录</h3><pre><code>mkdir -p $GOPATH/src/github.com/open-falcon\ncd $GOPATH/src/github.com/open-falcon\n</code></pre><h3 id=\"从git上下载agent分支\"><a href=\"#从git上下载agent分支\" class=\"headerlink\" title=\"从git上下载agent分支\"></a>从git上下载agent分支</h3><pre><code>git clone https://github.com/open-falcon/agent.git\n</code></pre><h3 id=\"源码编译安装启动\"><a href=\"#源码编译安装启动\" class=\"headerlink\" title=\"源码编译安装启动\"></a>源码编译安装启动</h3><pre><code>cd agent\ngo get ./...\n./control build\n./control start\n./control pack\n</code></pre><p>最后一步会pack出一个tar.gz的安装包，拿着这个包去部署服务即可。需要注意的是在源码编译时：</p>\n<p>1、需要主机配置GOPATH环境变量（一般可以配置为用户家家目录）；</p>\n<p>2、需要主机可以连接外网，通过go get下载相关源码包。</p>\n<p>3、编译pack 出的包，在其他agent主机上部署时，无需连接外网 ，pack出的包，可以类似的理解为由c源代码编译后得出的二进制文件。</p>\n<h3 id=\"配置说明\"><a href=\"#配置说明\" class=\"headerlink\" title=\"配置说明\"></a>配置说明</h3><p>配置文件必须叫cfg.json，可以基于cfg.example.json修改，默认该文件并不存在，通过./control start时自动会从cfg.example.json复制一份为cfg.json 。</p>\n<blockquote>\n<p>{<br>    “debug”: true,<br>    “hostname”: “”,<br>    “ip”: “”,<br>    “plugin”: {<br>        “enabled”: false, # 默认不开启插件机制<br>        “dir”: “./plugin”,<br>        “git”: “<a href=\"https://coding.net/ulricqin/plugin.git&quot;\" target=\"_blank\" rel=\"noopener\">https://coding.net/ulricqin/plugin.git&quot;</a>,<br>        “logs”: “./logs”<br>    },<br>    “heartbeat”: {<br>        “enabled”: true, # 此处enabled要设置为true<br>        “addr”: “127.0.0.1:6030”, # hbs的地址，端口是hbs的rpc端口<br>        “interval”: 60,<br>        “timeout”: 1000<br>    },<br>    “transfer”: {<br>        “enabled”: true, # 此处enabled要设置为true<br>        “addr”: “127.0.0.1:8433”, # transfer的地址，端口是transfer的rpc端口<br>        “interval”: 60,<br>        “timeout”: 1000<br>    },<br>    “http”: {<br>        “enabled”: true,<br>        “listen”: “:1988”<br>    },<br>    “collector”: {<br>        “ifacePrefix”: [“eth”, “em”] # 默认配置只会采集网卡名称前缀是eth、em的网卡流量，配置为空就会采集所有的，lo的也会采集。可以从/proc/net/dev看到各个网卡的流量信息<br>    },<br>    “ignore”: { # 默认采集了200多个metric，可以通过ignore设置为不采集<br>        “cpu.busy”: true,<br>        “mem.swapfree”: true<br>    }<br>}  </p>\n</blockquote>\n<h3 id=\"进程管理\"><a href=\"#进程管理\" class=\"headerlink\" title=\"进程管理\"></a>进程管理</h3><pre><code>./control start 启动进程\n./control stop 停止进程\n./control restart 重启进程\n./control status 查看进程状态\n./control tail 用tail -f的方式查看var/app.log\n</code></pre><p>验证 </p>\n<p>看var目录下的log是否正常，或者浏览器访问其1988端口。另外agent提供了一个–check参数，可以检查agent是否可以正常跑在当前机器上。  </p>\n<pre><code>./falcon-agent --check\n</code></pre><p>打url  <a href=\"http://IP:1988可以查看相关监控信息。\" target=\"_blank\" rel=\"noopener\">http://IP:1988可以查看相关监控信息。</a>  </p>"},{"title":"tcpdump抓包命令详解","date":"2016-11-03T04:00:00.000Z","_content":"TCPdump抓包命令 \ntcpdump是一个用于截取网络分组，并输出分组内容的工具。tcpdump凭借强大的功能和灵活的截取策略，使其成为类UNIX系统下用于网络分析和问题排查的首选工具。 \ntcpdump提供了源代码，公开了接口，因此具备很强的可扩展性，对于网络维护和入侵者都是非常有用的工具。tcpdump存在于基本的Linux系统中，由于它需要将网络界面设置为混杂模式，普通用户不能正常执行，但具备root权限的用户可以直接执行它来获取网络上的信息。因此系统中存在网络分析工具主要不是对本机安全的威胁，而是对网络上的其他计算机的安全存在威胁。\n<!--more-->\n一、概述\n顾名思义，tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。\n引用\n# tcpdump -vv\ntcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes\n11:53:21.444591 IP (tos 0x10, ttl 64, id 19324, offset 0, flags [DF], proto 6, length: 92) asptest.localdomain.ssh > 192.168.228.244.1858: P 3962132600:3962132652(52) ack 2726525936 win 1266\nasptest.localdomain.1077 > 192.168.228.153.domain: [bad udp cksum 166e!] 325+ PTR? 244.228.168.192.in-addr.arpa. (46)\n11:53:21.446929 IP (tos 0x0, ttl 64, id 42911, offset 0, flags [DF], proto 17, length: 151) 192.168.228.153.domain > asptest.localdomain.1077: 325 NXDomain q: PTR? 244.228.168.192.in-addr.arpa. 0/1/0 ns: 168.192.in-addr.arpa. (123)\n11:53:21.447408 IP (tos 0x10, ttl 64, id 19328, offset 0, flags [DF], proto 6, length: 172) asptest.localdomain.ssh > 192.168.228.244.1858: P 168:300(132) ack 1 win 1266\n347 packets captured\n1474 packets received by filter\n745 packets dropped by kernel\n不带参数的tcpdump会收集网络中所有的信息包头，数据量巨大，必须过滤。\n\n二、选项介绍\n引用\n-A 以ASCII格式打印出所有分组，并将链路层的头最小化。 \n-c 在收到指定的数量的分组后，tcpdump就会停止。 \n-C 在将一个原始分组写入文件之前，检查文件当前的大小是否超过了参数file_size 中指定的大小。如果超过了指定大小，则关闭当前文件，然后在打开一个新的文件。参数 file_size 的单位是兆字节（是1,000,000字节，而不是1,048,576字节）。 \n-d 将匹配信息包的代码以人们能够理解的汇编格式给出。 \n-dd 将匹配信息包的代码以C语言程序段的格式给出。 \n-ddd 将匹配信息包的代码以十进制的形式给出。 \n-D 打印出系统中所有可以用tcpdump截包的网络接口。 \n-e 在输出行打印出数据链路层的头部信息。 \n-E 用spi@ipaddr algo:secret解密那些以addr作为地址，并且包含了安全参数索引值spi的IPsec ESP分组。 \n-f 将外部的Internet地址以数字的形式打印出来。 \n-F 从指定的文件中读取表达式，忽略命令行中给出的表达式。 \n-i 指定监听的网络接口。 \n-l 使标准输出变为缓冲行形式，可以把数据导出到文件。 \n-L 列出网络接口的已知数据链路。 \n-m 从文件module中导入SMI MIB模块定义。该参数可以被使用多次，以导入多个MIB模块。 \n-M 如果tcp报文中存在TCP-MD5选项，则需要用secret作为共享的验证码用于验证TCP-MD5选选项摘要（详情可参考RFC 2385）。 \n-b 在数据-链路层上选择协议，包括ip、arp、rarp、ipx都是这一层的。\n-n 不把网络地址转换成名字。\n-nn 不进行端口名称的转换。\n-N 不输出主机名中的域名部分。例如，‘nic.ddn.mil‘只输出’nic‘。 \n-t 在输出的每一行不打印时间戳。 \n-O 不运行分组分组匹配（packet-matching）代码优化程序。 \n-P 不将网络接口设置成混杂模式。 \n-q 快速输出。只输出较少的协议信息。 \n-r 从指定的文件中读取包(这些包一般通过-w选项产生)。 \n-S 将tcp的序列号以绝对值形式输出，而不是相对值。 \n-s 从每个分组中读取最开始的snaplen个字节，而不是默认的68个字节。 \n-T 将监听到的包直接解释为指定的类型的报文，常见的类型有rpc远程过程调用）和snmp（简单网络管理协议；）。 \n-t 不在每一行中输出时间戳。 \n-tt 在每一行中输出非格式化的时间戳。 \n-ttt 输出本行和前面一行之间的时间差。 \n-tttt 在每一行中输出由date处理的默认格式的时间戳。 \n-u 输出未解码的NFS句柄。 \n-v 输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息。 \n-vv 输出详细的报文信息。 \n-w 直接将分组写入文件中，而不是不分析并打印出来。\n\n三、tcpdump的表达式介绍\n表达式是一个正则表达式，tcpdump利用它作为过滤报文的条件，如果一个报文满足表 达式的条件，则这个报文将会被捕获。如果没有给出任何条件，则网络上所有的信息包 将会被截获。 \n在表达式中一般如下几种类型的关键字： \n引用\n第一种是关于类型的关键字，主要包括host，net，port，例如 host 210.27.48.2， 指明 210.27.48.2是一台主机，net 202.0.0.0指明202.0.0.0是一个网络地址，port 23 指明端口号是23。如果没有指定类型，缺省的类型是host。 \n第二种是确定传输方向的关键字，主要包括src，dst，dst or src，dst and src， 这些关键字指明了传输的方向。举例说明，src 210.27.48.2 ，指明ip包中源地址是 210.27.48.2 ， dst net 202.0.0.0 指明目的网络地址是202.0.0.0。如果没有指明 方向关键字，则缺省是src or dst关键字。 \n第三种是协议的关键字，主要包括fddi，ip，arp，rarp，tcp，udp等类型。Fddi指明是在FDDI (分布式光纤数据接口网络)上的特定的网络协议，实际上它是”ether”的别名，fddi和ether 具有类似的源地址和目的地址，所以可以将fddi协议包当作ether的包进行处理和分析。 其他的几个关键字就是指明了监听的包的协议内容。如果没有指定任何协议，则tcpdump 将会 监听所有协议的信息包。\n除了这三种类型的关键字之外，其他重要的关键字如下：gateway， broadcast，less， greater， 还有三种逻辑运算，取非运算是 ‘not ' '! ‘， 与运算是’and’，’&&';或运算是’or’ ，’&#124;&#124;’； 这些关键字可以组合起来构成强大的组合条件来满足人们的需要。\n四、输出结果介绍\n下面我们介绍几种典型的tcpdump命令的输出信息 \n(1) 数据链路层头信息 \n使用命令： \n#tcpdump --e host ICE\nICE 是一台装有linux的主机。它的MAC地址是0：90：27：58：AF：1A H219是一台装有Solaris的SUN工作站。它的MAC地址是8：0：20：79：5B：46； 上一条命令的输出结果如下所示：\n引用\n21:50:12.847509 eth0 < 8:0:20:79:5b:46 0:90:27:58:af:1a ip 60: h219.33357 > ICE. telne t 0:0(0) ack 22535 win 8760 (DF)\n21：50：12是显示的时间， 847509是ID号，eth0 <表示从网络接口eth0接收该分组， eth0 >表示从网络接口设备发送分组， 8:0:20:79:5b:46是主机H219的MAC地址， 它表明是从源地址H219发来的分组. 0:90:27:58:af:1a是主机ICE的MAC地址， 表示该分组的目的地址是ICE。 ip 是表明该分组是IP分组，60 是分组的长度， h219.33357 > ICE. telnet 表明该分组是从主机H219的33357端口发往主机ICE的 TELNET(23)端口。 ack 22535 表明对序列号是222535的包进行响应。 win 8760表明发 送窗口的大小是8760。 \n(2) ARP包的tcpdump输出信息 \n使用命令： \n#tcpdump arp\n得到的输出结果是：\n引用\n22:32:42.802509 eth0 > arp who-has route tell ICE (0:90:27:58:af:1a)\n22:32:42.802902 eth0 < arp reply route is-at 0:90:27:12:10:66 (0:90:27:58:af:1a)\n22:32:42是时间戳， 802509是ID号， eth0 >表明从主机发出该分组，arp表明是ARP请求包， who-has route tell ICE表明是主机ICE请求主机route的MAC地址。 0:90:27:58:af:1a是主机 ICE的MAC地址。\n(3) TCP包的输出信息 \n用tcpdump捕获的TCP包的一般输出信息是： \n引用\nsrc > dst: flags data-seqno ack window urgent options\nsrc > dst:表明从源地址到目的地址， flags是TCP报文中的标志信息，S 是SYN标志， F (FIN)， P (PUSH) ， R (RST) \".\" (没有标记); data-seqno是报文中的数据 的顺序号， ack是下次期望的顺序号， window是接收缓存的窗口大小， urgent表明 报文中是否有紧急指针。 Options是选项。 \n(4) UDP包的输出信息\n用tcpdump捕获的UDP包的一般输出信息是： \n引用\nroute.port1 > ICE.port2: udp lenth\nUDP十分简单，上面的输出行表明从主机route的port1端口发出的一个UDP报文 到主机ICE的port2端口，类型是UDP， 包的长度是lenth。 \n五、举例\n(1) 想要截获所有210.27.48.1 的主机收到的和发出的所有的分组： \n#tcpdump host 210.27.48.1 \n(2) 想要截获主机210.27.48.1 和主机210.27.48.2或210.27.48.3的通信，使用命令（注意：括号前的反斜杠是必须的）： \n#tcpdump host 210.27.48.1 and 210.27.48.2or210.27.48.3\n(3) 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令： \n#tcpdump ip host 210.27.48.1 and ! 210.27.48.2\n(4) 如果想要获取主机192.168.228.246接收或发出的ssh包，并且不转换主机名使用如下命令： \n#tcpdump -nn -n src host 192.168.228.246 and port 22 and tcp\n(5) 获取主机192.168.228.246接收或发出的ssh包，并把mac地址也一同显示：\n# tcpdump -e src host 192.168.228.246 and port 22 and tcp -n -nn\n(6) 过滤的是源主机为192.168.0.1与目的网络为192.168.0.0的报头：\ntcpdump src host 192.168.0.1 and dst net 192.168.0.0/24 \n(7) 过滤源主机物理地址为XXX的报头：\ntcpdump ether src 00:50:04:BA:9B and dst……\n（为什么ether src后面没有host或者net？物理地址当然不可能有网络喽）。 \n(8) 过滤源主机192.168.0.1和目的端口不是telnet的报头，并导入到tes.t.txt文件中：\nTcpdump src host 192.168.0.1 and dst port not telnet -l > test.txt\nip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型。\ntcpdump采用命令行方式，它的命令格式为：\ntcpdump [-nn] [-i 接口] [-w 储存档名] [-c 次数] [-Ae]\n                        [-qX] [-r 文件] [所欲捕获的数据内容]\n参数：\n-nn，直接以 IP 及 Port Number 显示，而非主机名与服务名称。\n-i，后面接要「监听」的网络接口，例如 eth0, lo, ppp0 等等的接口。\n-w，如果你要将监听所得的数据包数据储存下来，用这个参数就对了。后面接文件名。\n-c，监听的数据包数，如果没有这个参数， tcpdump 会持续不断的监听，\n     直到用户输入 [ctrl]-c 为止。\n-A，数据包的内容以 ASCII 显示，通常用来捉取 WWW 的网页数据包资料。\n-e，使用资料连接层 (OSI 第二层) 的 MAC 数据包数据来显示。\n-q，仅列出较为简短的数据包信息，每一行的内容比较精简。\n-X，可以列出十六进制 (hex) 以及 ASCII 的数据包内容，对于监听数据包内容很有用。\n-r，从后面接的文件将数据包数据读出来。那个「文件」是已经存在的文件，\n     并且这个「文件」是由 -w 所制作出来的。\n所欲捕获的数据内容：我们可以专门针对某些通信协议或者是 IP 来源进行数据包捕获。\n     那就可以简化输出的结果，并取得最有用的信息。常见的表示方法有。\n    'host foo', 'host 127.0.0.1' ：针对单台主机来进行数据包捕获。\n     'net 192.168' ：针对某个网段来进行数据包的捕获。\n     'src host 127.0.0.1' 'dst net 192.168'：同时加上来源(src)或目标(dst)限制。\n     'tcp port 21'：还可以针对通信协议检测，如tcp、udp、arp、ether 等。\n     除了这三种类型的关键字之外，其他重要的关键字如下：gateway, broadcast,less,\ngreater,还有三种逻辑运算，取非运算是 'not ' '! ', 与运算是'and','&&';或运算 是'o\nr' ,'||'；\n\n范例一：以 IP 与 Port Number 捉下 eth0 这个网卡上的数据包，持续 3 秒\n[root@linux ~]# tcpdump -i eth0 -nn\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes\n01:33:40.41 IP 192.168.1.100.22 > 192.168.1.11.1190: P 116:232(116) ack 1 win \n9648\n01:33:40.41 IP 192.168.1.100.22 > 192.168.1.11.1190: P 232:364(132) ack 1 win \n9648\n<==按下 [ctrl]-c 之后结束\n6680 packets captured              <==捉取下来的数据包数量\n14250 packets received by filter   <==由过滤所得的总数据包数量\n7512 packets dropped by kernel     <==被核心所丢弃的数据包\n至于那个在范例一所产生的输出中，我们可以大概区分为几个字段，现以范例一当中那行特殊字体行来说明一下：\n· 01:33:40.41：这个是此数据包被捕获的时间，“时:分:秒”的单位。\n· IP：通过的通信协议是IP。\n· 192.168.1.100.22>：传送端是192.168.1.100这个IP，而传送的Port Number为22，那个大于（>）的符号指的是数据包的传输方向。\n· 192.168.1.11.1190：接收端的IP是192.168.1.11，且该主机开启port 1190来接收。\n· P 116:232(116)：这个数据包带有PUSH的数据传输标志，且传输的数据为整体数据的116~232 Byte，所以这个数据包带有116 Bytes的数据量。\n· ack 1 win 9648：ACK与Window size的相关资料。\n最简单的说法，就是该数据包是由192.168.1.100传到192.168.1.11，通过的port是由22到1190，且带有116 Bytes的数据量，使用的是PUSH的标记，而不是SYN之类的主动联机标志。\n接下来，在一个网络状态很忙的主机上面，你想要取得某台主机对你联机的数据包数据时，使用tcpdump配合管线命令与正则表达式也可以，不过，毕竟不好捕获。我们可以通过tcpdump的表达式功能，就能够轻易地将所需要的数据独立的取出来。在上面的范例一当中，我们仅针对eth0做监听，所以整个eth0接口上面的数据都会被显示到屏幕上，但这样不好分析，可以简化吗？例如，只取出port 21的联机数据包，可以这样做：\n[root@linux ~]# tcpdump -i eth0 -nn port 21\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes\n01:54:37.96 IP 192.168.1.11.1240 > 192.168.1.100.21:. ack 1 win 65535\n01:54:37.96 IP 192.168.1.100.21 > 192.168.1.11.1240:P 1:21(20) ack 1 win 5840\n01:54:38.12 IP 192.168.1.11.1240 > 192.168.1.100.21:. ack 21 win 65515\n01:54:42.79 IP 192.168.1.11.1240 > 192.168.1.100.21:P 1:17(16) ack 21 win 65515\n01:54:42.79 IP 192.168.1.100.21 > 192.168.1.11.1240: . ack 17 win 5840\n01:54:42.79 IP 192.168.1.100.21 > 192.168.1.11.1240: P 21:55(34) ack 17 win 5840\n看！这样就仅取出port 21的信息，如果仔细看的话，你会发现数据包的传递都是双向的，Client端发出请求而Server端则予以响应，所以，当然是有去有回了。而我们也就可以经过这个数据包的流向来了解到数据包运动的过程了。例如：\n· 我们先在一个终端机窗口输入“tcpdump-i lo-nn”的监听。\n· 再另开一个终端机窗口来对本机（127.0.0.1）登录“ssh localhost”，那么输出的结果会是如何？\n[root@linux ~]# tcpdump -i lo -nn\n 1 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode\n 2 listening on lo, link-type EN10MB (Ethernet), capture size 96 bytes\n 3 11:02:54.253777 IP 127.0.0.1.32936 > \n127.0.0.1.22: S 933696132:933696132(0) \n   win 32767 \n 4 11:02:54.253831 IP 127.0.0.1.22 > 127.0.0.1.32936: \nS 920046702:920046702(0) \n   ack 933696133 win 32767 \n 5 11:02:54.253871 IP 127.0.0.1.32936 > 127.0.0.1.22: . ack 1 win 8192 \n 6 11:02:54.272124 IP 127.0.0.1.22 > 127.0.0.1.32936: \nP 1:23(22) ack 1 win 8192 \n   \n 7 11:02:54.272375 IP 127.0.0.1.32936 > 127.0.0.1.22: . ack 23 win 8192\n代码显示的头两行是tcpdump的基本说明，然后：\n· 第3行显示的是来自Client端带有SYN主动联机的数据包。 \n· 第4行显示的是来自Server端，除了响应Client端之外（ACK），还带有SYN主动联机的标志。 \n· 第5行则显示Client端响应Server确定联机建立（ACK）。\n· 第6行以后则开始进入数据传输的步骤。\n从第3~5行的流程来看，熟不熟悉啊？没错。那就是3次握手的基础流程，有趣吧。不过tcpdump之所以被称为黑客软件之一远不止上面介绍的功能。上面介绍的功能可以用来作为我们主机的数据包联机与传输的流程分析，这将有助于我们了解到数据包的运作，同时了解到主机的防火墙设置规则是否有需要修订的地方。\n还有更神奇的用法。当我们使用tcpdump在Router上面监听明文的传输数据时，例如FTP传输协议，你觉得会发生什么问题呢？我们先在主机端执行“tcpdump -i lo port 21 -nn –X”，然后再以FTP登录本机，并输入账号与密码，结果你就可以发现如下的状况：\n[root@linux ~]# tcpdump -i lo -nn -X 'port 21'\n    0x0000:  4500 0048 2a28 4000 4006 1286 7f00 0001  E..H*(@.@.......\n    0x0010:  7f00 0001 0015 80ab 8355 2149 835c d825  .........U!I.\\.%\n    0x0020:  8018 2000 fe3c 0000 0101 080a 0e2e 0b67  .....<.........g\n    0x0030:  0e2e 0b61 3232 3020 2876 7346 5450 6420  ...a220.(vsFTPd.\n    0x0040:  322e 302e 3129 0d0a                      2.0.1)..\n\n    0x0000:  4510 0041 d34b 4000 4006 6959 7f00 0001  E..A.K@.@.iY....\n    0x0010:  7f00 0001 80ab 0015 835c d825 8355 215d  .........\\.%.U!]\n    0x0020:  8018 2000 fe35 0000 0101 080a 0e2e 1b37  .....5.........7\n    0x0030:  0e2e 0b67 5553 4552 2064 6d74 7361 690d  ...gUSER.dmtsai.\n    0x0040:  0a                                       .\n\n    0x0000:  4510 004a d34f 4000 4006 694c 7f00 0001  E..J.O@.@.iL....\n    0x0010:  7f00 0001 80ab 0015 835c d832 8355 217f  .........\\.2.U!.\n    0x0020:  8018 2000 fe3e 0000 0101 080a 0e2e 3227  .....>........2'\n    0x0030:  0e2e 1b38 5041 5353 206d 7970 6173 7377  ...8PASS.mypassw\n    0x0040:  6f72 6469 7379 6f75 0d0a                 ordisyou..\n上面的输出结果已经被简化过了，你需要自行在你的输出结果中搜索相关的字符串才行。从上面输出结果的特殊字体中，我们可以发现该FTP软件使用的是 vsFTPd，并且用户输入dmtsai这个账号名称，且密码是mypasswordisyou。如果使用的是明文方式来传输你的网络数据呢？\n另外你得了解，为了让网络接口可以让tcpdump监听，所以执行tcpdump时网络接口会启动在“混杂模式（promiscuous）”，所以你会在 /var/log/messages里面看到很多的警告信息，通知你说你的网卡被设置成为混杂模式。别担心，那是正常的。至于更多的应用，请参考man tcpdump了。\n\n例题：如何使用tcpdump监听来自eth0适配卡且通信协议为port 22，目标来源为192.168.1.100的数据包资料？\n答：tcpdump -i eth0 -nn 'port 22 and src host 192.168.1.100'。\n##############例子2#######################################\n \n普通情况下，直接启动tcpdump将监视第一个网络界面上所有流过的数据包。\n# tcpdump\ntcpdump: listening on fxp0\n11:58:47.873028 202.102.245.40.netbios-ns > 202.102.245.127.netbios-ns: udp 50\n11:58:47.974331 0:10:7b:8:3a:56 > 1:80:c2:0:0:0 802.1d ui/C len=43\n0000 0000 0080 0000 1007 cf08 0900 0000\n0e80 0000 902b 4695 0980 8701 0014 0002\n000f 0000 902b 4695 0008 00\n11:58:48.373134 0:0:e8:5b:6d:85 > Broadcast sap e0 ui/C len=97\nffff 0060 0004 ffff ffff ffff ffff ffff\n0452 ffff ffff 0000 e85b 6d85 4008 0002\n0640 4d41 5354 4552 5f57 4542 0000 0000\n0000 00\n使用-i参数指定tcpdump监听的网络界面，这在计算机具有多个网络界面时非常有用，\n使用-c参数指定要监听的数据包数量，\n使用-w参数指定将监听到的数据包写入文件中保存\nA想要截获所有210.27.48.1 的主机收到的和发出的所有的数据包：\n#tcpdump host 210.27.48.1\nB想要截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信，使用命令：（在命令行中适用　　　括号时，一定要\n#tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 \\)\nC如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：\n#tcpdump ip host 210.27.48.1 and ! 210.27.48.2\nD如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令：\n#tcpdump tcp port 23 host 210.27.48.1\nE 对本机的udp 123 端口进行监视 123 为ntp的服务端口\n# tcpdump udp port 123\nF 系统将只对名为hostname的主机的通信数据包进行监视。主机名可以是本地主机，也可以是网络上的任何一台计算机。下面的命令可以读取主机hostname发送的所有数据：\n#tcpdump -i eth0 src host hostname\nG 下面的命令可以监视所有送到主机hostname的数据包：\n#tcpdump -i eth0 dst host hostname\nH 我们还可以监视通过指定网关的数据包：\n#tcpdump -i eth0 gateway Gatewayname\nI 如果你还想监视编址到指定端口的TCP或UDP数据包，那么执行以下命令：\n#tcpdump -i eth0 host hostname and port 80\nJ 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包\n，使用命令：\n#tcpdump ip host 210.27.48.1 and ! 210.27.48.2\nK 想要截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信，使用命令\n：（在命令行中适用　　　括号时，一定要\n#tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 \\)\nL 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：\n#tcpdump ip host 210.27.48.1 and ! 210.27.48.2\nM 如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令：\n#tcpdump tcp port 23 host 210.27.48.1\n第三种是协议的关键字，主要包括fddi,ip ,arp,rarp,tcp,udp等类型\n除了这三种类型的关键字之外，其他重要的关键字如下：gateway, broadcast,less,\ngreater,还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘, 与运算是‘and‘,‘&&‘;或运算 是‘o\nr‘ ,‘||‘；\n第二种是确定传输方向的关键字，主要包括src , dst ,dst or src, dst and src ,\n如果我们只需要列出送到80端口的数据包，用dst port；如果我们只希望看到返回80端口的数据包，用src port。\n#tcpdump –i eth0 host hostname and dst port 80 目的端口是80\n或者\n#tcpdump –i eth0 host hostname and src port 80 源端口是80 一般是提供http的服务的主机\n如果条件很多的话 要在条件之前加and 或 or 或 not\n#tcpdump -i eth0 host ! 211.161.223.70 and ! 211.161.223.71 and dst port 80\n如果在ethernet 使用混杂模式 系统的日志将会记录\nMay 7 20:03:46 localhost kernel: eth0: Promiscuous mode enabled.\nMay 7 20:03:46 localhost kernel: device eth0 entered promiscuous mode\nMay 7 20:03:57 localhost kernel: device eth0 left promiscuous mode\ntcpdump对截获的数据并没有进行彻底解码，数据包内的大部分内容是使用十六进制的形式直接打印输出的。显然这不利于分析网络故障，通常的解决办法是先使用带-w参数的tcpdump 截获数据并保存到文件中，然后再使用其他程序进行解码分析。当然也应该定义过滤规则，以避免捕获的数据包填满整个硬盘。\n除了过滤语句，还有一个很重要的参数，也就是说，如果这个参数不设置正确，会导致包数据的丢失！\n它就是-s 参数，snaplen, 也就是数据包的截取长度，仔细看man就会明白的！默认截取长度为60个字节，但一般ethernet MTU都是1500字节。所以，要抓取大于60字节的包时，使用默认参数就会导致包数据丢失！\n只要使用-s 0就可以按包长，截取数据！\n","source":"_posts/tcpdump抓包命令详解.md","raw":"---\ntitle: tcpdump抓包命令详解\ndate: 2016-11-03\ntags: tcpdum\ncategories: linux\n---\nTCPdump抓包命令 \ntcpdump是一个用于截取网络分组，并输出分组内容的工具。tcpdump凭借强大的功能和灵活的截取策略，使其成为类UNIX系统下用于网络分析和问题排查的首选工具。 \ntcpdump提供了源代码，公开了接口，因此具备很强的可扩展性，对于网络维护和入侵者都是非常有用的工具。tcpdump存在于基本的Linux系统中，由于它需要将网络界面设置为混杂模式，普通用户不能正常执行，但具备root权限的用户可以直接执行它来获取网络上的信息。因此系统中存在网络分析工具主要不是对本机安全的威胁，而是对网络上的其他计算机的安全存在威胁。\n<!--more-->\n一、概述\n顾名思义，tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。\n引用\n# tcpdump -vv\ntcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes\n11:53:21.444591 IP (tos 0x10, ttl 64, id 19324, offset 0, flags [DF], proto 6, length: 92) asptest.localdomain.ssh > 192.168.228.244.1858: P 3962132600:3962132652(52) ack 2726525936 win 1266\nasptest.localdomain.1077 > 192.168.228.153.domain: [bad udp cksum 166e!] 325+ PTR? 244.228.168.192.in-addr.arpa. (46)\n11:53:21.446929 IP (tos 0x0, ttl 64, id 42911, offset 0, flags [DF], proto 17, length: 151) 192.168.228.153.domain > asptest.localdomain.1077: 325 NXDomain q: PTR? 244.228.168.192.in-addr.arpa. 0/1/0 ns: 168.192.in-addr.arpa. (123)\n11:53:21.447408 IP (tos 0x10, ttl 64, id 19328, offset 0, flags [DF], proto 6, length: 172) asptest.localdomain.ssh > 192.168.228.244.1858: P 168:300(132) ack 1 win 1266\n347 packets captured\n1474 packets received by filter\n745 packets dropped by kernel\n不带参数的tcpdump会收集网络中所有的信息包头，数据量巨大，必须过滤。\n\n二、选项介绍\n引用\n-A 以ASCII格式打印出所有分组，并将链路层的头最小化。 \n-c 在收到指定的数量的分组后，tcpdump就会停止。 \n-C 在将一个原始分组写入文件之前，检查文件当前的大小是否超过了参数file_size 中指定的大小。如果超过了指定大小，则关闭当前文件，然后在打开一个新的文件。参数 file_size 的单位是兆字节（是1,000,000字节，而不是1,048,576字节）。 \n-d 将匹配信息包的代码以人们能够理解的汇编格式给出。 \n-dd 将匹配信息包的代码以C语言程序段的格式给出。 \n-ddd 将匹配信息包的代码以十进制的形式给出。 \n-D 打印出系统中所有可以用tcpdump截包的网络接口。 \n-e 在输出行打印出数据链路层的头部信息。 \n-E 用spi@ipaddr algo:secret解密那些以addr作为地址，并且包含了安全参数索引值spi的IPsec ESP分组。 \n-f 将外部的Internet地址以数字的形式打印出来。 \n-F 从指定的文件中读取表达式，忽略命令行中给出的表达式。 \n-i 指定监听的网络接口。 \n-l 使标准输出变为缓冲行形式，可以把数据导出到文件。 \n-L 列出网络接口的已知数据链路。 \n-m 从文件module中导入SMI MIB模块定义。该参数可以被使用多次，以导入多个MIB模块。 \n-M 如果tcp报文中存在TCP-MD5选项，则需要用secret作为共享的验证码用于验证TCP-MD5选选项摘要（详情可参考RFC 2385）。 \n-b 在数据-链路层上选择协议，包括ip、arp、rarp、ipx都是这一层的。\n-n 不把网络地址转换成名字。\n-nn 不进行端口名称的转换。\n-N 不输出主机名中的域名部分。例如，‘nic.ddn.mil‘只输出’nic‘。 \n-t 在输出的每一行不打印时间戳。 \n-O 不运行分组分组匹配（packet-matching）代码优化程序。 \n-P 不将网络接口设置成混杂模式。 \n-q 快速输出。只输出较少的协议信息。 \n-r 从指定的文件中读取包(这些包一般通过-w选项产生)。 \n-S 将tcp的序列号以绝对值形式输出，而不是相对值。 \n-s 从每个分组中读取最开始的snaplen个字节，而不是默认的68个字节。 \n-T 将监听到的包直接解释为指定的类型的报文，常见的类型有rpc远程过程调用）和snmp（简单网络管理协议；）。 \n-t 不在每一行中输出时间戳。 \n-tt 在每一行中输出非格式化的时间戳。 \n-ttt 输出本行和前面一行之间的时间差。 \n-tttt 在每一行中输出由date处理的默认格式的时间戳。 \n-u 输出未解码的NFS句柄。 \n-v 输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息。 \n-vv 输出详细的报文信息。 \n-w 直接将分组写入文件中，而不是不分析并打印出来。\n\n三、tcpdump的表达式介绍\n表达式是一个正则表达式，tcpdump利用它作为过滤报文的条件，如果一个报文满足表 达式的条件，则这个报文将会被捕获。如果没有给出任何条件，则网络上所有的信息包 将会被截获。 \n在表达式中一般如下几种类型的关键字： \n引用\n第一种是关于类型的关键字，主要包括host，net，port，例如 host 210.27.48.2， 指明 210.27.48.2是一台主机，net 202.0.0.0指明202.0.0.0是一个网络地址，port 23 指明端口号是23。如果没有指定类型，缺省的类型是host。 \n第二种是确定传输方向的关键字，主要包括src，dst，dst or src，dst and src， 这些关键字指明了传输的方向。举例说明，src 210.27.48.2 ，指明ip包中源地址是 210.27.48.2 ， dst net 202.0.0.0 指明目的网络地址是202.0.0.0。如果没有指明 方向关键字，则缺省是src or dst关键字。 \n第三种是协议的关键字，主要包括fddi，ip，arp，rarp，tcp，udp等类型。Fddi指明是在FDDI (分布式光纤数据接口网络)上的特定的网络协议，实际上它是”ether”的别名，fddi和ether 具有类似的源地址和目的地址，所以可以将fddi协议包当作ether的包进行处理和分析。 其他的几个关键字就是指明了监听的包的协议内容。如果没有指定任何协议，则tcpdump 将会 监听所有协议的信息包。\n除了这三种类型的关键字之外，其他重要的关键字如下：gateway， broadcast，less， greater， 还有三种逻辑运算，取非运算是 ‘not ' '! ‘， 与运算是’and’，’&&';或运算是’or’ ，’&#124;&#124;’； 这些关键字可以组合起来构成强大的组合条件来满足人们的需要。\n四、输出结果介绍\n下面我们介绍几种典型的tcpdump命令的输出信息 \n(1) 数据链路层头信息 \n使用命令： \n#tcpdump --e host ICE\nICE 是一台装有linux的主机。它的MAC地址是0：90：27：58：AF：1A H219是一台装有Solaris的SUN工作站。它的MAC地址是8：0：20：79：5B：46； 上一条命令的输出结果如下所示：\n引用\n21:50:12.847509 eth0 < 8:0:20:79:5b:46 0:90:27:58:af:1a ip 60: h219.33357 > ICE. telne t 0:0(0) ack 22535 win 8760 (DF)\n21：50：12是显示的时间， 847509是ID号，eth0 <表示从网络接口eth0接收该分组， eth0 >表示从网络接口设备发送分组， 8:0:20:79:5b:46是主机H219的MAC地址， 它表明是从源地址H219发来的分组. 0:90:27:58:af:1a是主机ICE的MAC地址， 表示该分组的目的地址是ICE。 ip 是表明该分组是IP分组，60 是分组的长度， h219.33357 > ICE. telnet 表明该分组是从主机H219的33357端口发往主机ICE的 TELNET(23)端口。 ack 22535 表明对序列号是222535的包进行响应。 win 8760表明发 送窗口的大小是8760。 \n(2) ARP包的tcpdump输出信息 \n使用命令： \n#tcpdump arp\n得到的输出结果是：\n引用\n22:32:42.802509 eth0 > arp who-has route tell ICE (0:90:27:58:af:1a)\n22:32:42.802902 eth0 < arp reply route is-at 0:90:27:12:10:66 (0:90:27:58:af:1a)\n22:32:42是时间戳， 802509是ID号， eth0 >表明从主机发出该分组，arp表明是ARP请求包， who-has route tell ICE表明是主机ICE请求主机route的MAC地址。 0:90:27:58:af:1a是主机 ICE的MAC地址。\n(3) TCP包的输出信息 \n用tcpdump捕获的TCP包的一般输出信息是： \n引用\nsrc > dst: flags data-seqno ack window urgent options\nsrc > dst:表明从源地址到目的地址， flags是TCP报文中的标志信息，S 是SYN标志， F (FIN)， P (PUSH) ， R (RST) \".\" (没有标记); data-seqno是报文中的数据 的顺序号， ack是下次期望的顺序号， window是接收缓存的窗口大小， urgent表明 报文中是否有紧急指针。 Options是选项。 \n(4) UDP包的输出信息\n用tcpdump捕获的UDP包的一般输出信息是： \n引用\nroute.port1 > ICE.port2: udp lenth\nUDP十分简单，上面的输出行表明从主机route的port1端口发出的一个UDP报文 到主机ICE的port2端口，类型是UDP， 包的长度是lenth。 \n五、举例\n(1) 想要截获所有210.27.48.1 的主机收到的和发出的所有的分组： \n#tcpdump host 210.27.48.1 \n(2) 想要截获主机210.27.48.1 和主机210.27.48.2或210.27.48.3的通信，使用命令（注意：括号前的反斜杠是必须的）： \n#tcpdump host 210.27.48.1 and 210.27.48.2or210.27.48.3\n(3) 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令： \n#tcpdump ip host 210.27.48.1 and ! 210.27.48.2\n(4) 如果想要获取主机192.168.228.246接收或发出的ssh包，并且不转换主机名使用如下命令： \n#tcpdump -nn -n src host 192.168.228.246 and port 22 and tcp\n(5) 获取主机192.168.228.246接收或发出的ssh包，并把mac地址也一同显示：\n# tcpdump -e src host 192.168.228.246 and port 22 and tcp -n -nn\n(6) 过滤的是源主机为192.168.0.1与目的网络为192.168.0.0的报头：\ntcpdump src host 192.168.0.1 and dst net 192.168.0.0/24 \n(7) 过滤源主机物理地址为XXX的报头：\ntcpdump ether src 00:50:04:BA:9B and dst……\n（为什么ether src后面没有host或者net？物理地址当然不可能有网络喽）。 \n(8) 过滤源主机192.168.0.1和目的端口不是telnet的报头，并导入到tes.t.txt文件中：\nTcpdump src host 192.168.0.1 and dst port not telnet -l > test.txt\nip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型。\ntcpdump采用命令行方式，它的命令格式为：\ntcpdump [-nn] [-i 接口] [-w 储存档名] [-c 次数] [-Ae]\n                        [-qX] [-r 文件] [所欲捕获的数据内容]\n参数：\n-nn，直接以 IP 及 Port Number 显示，而非主机名与服务名称。\n-i，后面接要「监听」的网络接口，例如 eth0, lo, ppp0 等等的接口。\n-w，如果你要将监听所得的数据包数据储存下来，用这个参数就对了。后面接文件名。\n-c，监听的数据包数，如果没有这个参数， tcpdump 会持续不断的监听，\n     直到用户输入 [ctrl]-c 为止。\n-A，数据包的内容以 ASCII 显示，通常用来捉取 WWW 的网页数据包资料。\n-e，使用资料连接层 (OSI 第二层) 的 MAC 数据包数据来显示。\n-q，仅列出较为简短的数据包信息，每一行的内容比较精简。\n-X，可以列出十六进制 (hex) 以及 ASCII 的数据包内容，对于监听数据包内容很有用。\n-r，从后面接的文件将数据包数据读出来。那个「文件」是已经存在的文件，\n     并且这个「文件」是由 -w 所制作出来的。\n所欲捕获的数据内容：我们可以专门针对某些通信协议或者是 IP 来源进行数据包捕获。\n     那就可以简化输出的结果，并取得最有用的信息。常见的表示方法有。\n    'host foo', 'host 127.0.0.1' ：针对单台主机来进行数据包捕获。\n     'net 192.168' ：针对某个网段来进行数据包的捕获。\n     'src host 127.0.0.1' 'dst net 192.168'：同时加上来源(src)或目标(dst)限制。\n     'tcp port 21'：还可以针对通信协议检测，如tcp、udp、arp、ether 等。\n     除了这三种类型的关键字之外，其他重要的关键字如下：gateway, broadcast,less,\ngreater,还有三种逻辑运算，取非运算是 'not ' '! ', 与运算是'and','&&';或运算 是'o\nr' ,'||'；\n\n范例一：以 IP 与 Port Number 捉下 eth0 这个网卡上的数据包，持续 3 秒\n[root@linux ~]# tcpdump -i eth0 -nn\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes\n01:33:40.41 IP 192.168.1.100.22 > 192.168.1.11.1190: P 116:232(116) ack 1 win \n9648\n01:33:40.41 IP 192.168.1.100.22 > 192.168.1.11.1190: P 232:364(132) ack 1 win \n9648\n<==按下 [ctrl]-c 之后结束\n6680 packets captured              <==捉取下来的数据包数量\n14250 packets received by filter   <==由过滤所得的总数据包数量\n7512 packets dropped by kernel     <==被核心所丢弃的数据包\n至于那个在范例一所产生的输出中，我们可以大概区分为几个字段，现以范例一当中那行特殊字体行来说明一下：\n· 01:33:40.41：这个是此数据包被捕获的时间，“时:分:秒”的单位。\n· IP：通过的通信协议是IP。\n· 192.168.1.100.22>：传送端是192.168.1.100这个IP，而传送的Port Number为22，那个大于（>）的符号指的是数据包的传输方向。\n· 192.168.1.11.1190：接收端的IP是192.168.1.11，且该主机开启port 1190来接收。\n· P 116:232(116)：这个数据包带有PUSH的数据传输标志，且传输的数据为整体数据的116~232 Byte，所以这个数据包带有116 Bytes的数据量。\n· ack 1 win 9648：ACK与Window size的相关资料。\n最简单的说法，就是该数据包是由192.168.1.100传到192.168.1.11，通过的port是由22到1190，且带有116 Bytes的数据量，使用的是PUSH的标记，而不是SYN之类的主动联机标志。\n接下来，在一个网络状态很忙的主机上面，你想要取得某台主机对你联机的数据包数据时，使用tcpdump配合管线命令与正则表达式也可以，不过，毕竟不好捕获。我们可以通过tcpdump的表达式功能，就能够轻易地将所需要的数据独立的取出来。在上面的范例一当中，我们仅针对eth0做监听，所以整个eth0接口上面的数据都会被显示到屏幕上，但这样不好分析，可以简化吗？例如，只取出port 21的联机数据包，可以这样做：\n[root@linux ~]# tcpdump -i eth0 -nn port 21\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes\n01:54:37.96 IP 192.168.1.11.1240 > 192.168.1.100.21:. ack 1 win 65535\n01:54:37.96 IP 192.168.1.100.21 > 192.168.1.11.1240:P 1:21(20) ack 1 win 5840\n01:54:38.12 IP 192.168.1.11.1240 > 192.168.1.100.21:. ack 21 win 65515\n01:54:42.79 IP 192.168.1.11.1240 > 192.168.1.100.21:P 1:17(16) ack 21 win 65515\n01:54:42.79 IP 192.168.1.100.21 > 192.168.1.11.1240: . ack 17 win 5840\n01:54:42.79 IP 192.168.1.100.21 > 192.168.1.11.1240: P 21:55(34) ack 17 win 5840\n看！这样就仅取出port 21的信息，如果仔细看的话，你会发现数据包的传递都是双向的，Client端发出请求而Server端则予以响应，所以，当然是有去有回了。而我们也就可以经过这个数据包的流向来了解到数据包运动的过程了。例如：\n· 我们先在一个终端机窗口输入“tcpdump-i lo-nn”的监听。\n· 再另开一个终端机窗口来对本机（127.0.0.1）登录“ssh localhost”，那么输出的结果会是如何？\n[root@linux ~]# tcpdump -i lo -nn\n 1 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode\n 2 listening on lo, link-type EN10MB (Ethernet), capture size 96 bytes\n 3 11:02:54.253777 IP 127.0.0.1.32936 > \n127.0.0.1.22: S 933696132:933696132(0) \n   win 32767 \n 4 11:02:54.253831 IP 127.0.0.1.22 > 127.0.0.1.32936: \nS 920046702:920046702(0) \n   ack 933696133 win 32767 \n 5 11:02:54.253871 IP 127.0.0.1.32936 > 127.0.0.1.22: . ack 1 win 8192 \n 6 11:02:54.272124 IP 127.0.0.1.22 > 127.0.0.1.32936: \nP 1:23(22) ack 1 win 8192 \n   \n 7 11:02:54.272375 IP 127.0.0.1.32936 > 127.0.0.1.22: . ack 23 win 8192\n代码显示的头两行是tcpdump的基本说明，然后：\n· 第3行显示的是来自Client端带有SYN主动联机的数据包。 \n· 第4行显示的是来自Server端，除了响应Client端之外（ACK），还带有SYN主动联机的标志。 \n· 第5行则显示Client端响应Server确定联机建立（ACK）。\n· 第6行以后则开始进入数据传输的步骤。\n从第3~5行的流程来看，熟不熟悉啊？没错。那就是3次握手的基础流程，有趣吧。不过tcpdump之所以被称为黑客软件之一远不止上面介绍的功能。上面介绍的功能可以用来作为我们主机的数据包联机与传输的流程分析，这将有助于我们了解到数据包的运作，同时了解到主机的防火墙设置规则是否有需要修订的地方。\n还有更神奇的用法。当我们使用tcpdump在Router上面监听明文的传输数据时，例如FTP传输协议，你觉得会发生什么问题呢？我们先在主机端执行“tcpdump -i lo port 21 -nn –X”，然后再以FTP登录本机，并输入账号与密码，结果你就可以发现如下的状况：\n[root@linux ~]# tcpdump -i lo -nn -X 'port 21'\n    0x0000:  4500 0048 2a28 4000 4006 1286 7f00 0001  E..H*(@.@.......\n    0x0010:  7f00 0001 0015 80ab 8355 2149 835c d825  .........U!I.\\.%\n    0x0020:  8018 2000 fe3c 0000 0101 080a 0e2e 0b67  .....<.........g\n    0x0030:  0e2e 0b61 3232 3020 2876 7346 5450 6420  ...a220.(vsFTPd.\n    0x0040:  322e 302e 3129 0d0a                      2.0.1)..\n\n    0x0000:  4510 0041 d34b 4000 4006 6959 7f00 0001  E..A.K@.@.iY....\n    0x0010:  7f00 0001 80ab 0015 835c d825 8355 215d  .........\\.%.U!]\n    0x0020:  8018 2000 fe35 0000 0101 080a 0e2e 1b37  .....5.........7\n    0x0030:  0e2e 0b67 5553 4552 2064 6d74 7361 690d  ...gUSER.dmtsai.\n    0x0040:  0a                                       .\n\n    0x0000:  4510 004a d34f 4000 4006 694c 7f00 0001  E..J.O@.@.iL....\n    0x0010:  7f00 0001 80ab 0015 835c d832 8355 217f  .........\\.2.U!.\n    0x0020:  8018 2000 fe3e 0000 0101 080a 0e2e 3227  .....>........2'\n    0x0030:  0e2e 1b38 5041 5353 206d 7970 6173 7377  ...8PASS.mypassw\n    0x0040:  6f72 6469 7379 6f75 0d0a                 ordisyou..\n上面的输出结果已经被简化过了，你需要自行在你的输出结果中搜索相关的字符串才行。从上面输出结果的特殊字体中，我们可以发现该FTP软件使用的是 vsFTPd，并且用户输入dmtsai这个账号名称，且密码是mypasswordisyou。如果使用的是明文方式来传输你的网络数据呢？\n另外你得了解，为了让网络接口可以让tcpdump监听，所以执行tcpdump时网络接口会启动在“混杂模式（promiscuous）”，所以你会在 /var/log/messages里面看到很多的警告信息，通知你说你的网卡被设置成为混杂模式。别担心，那是正常的。至于更多的应用，请参考man tcpdump了。\n\n例题：如何使用tcpdump监听来自eth0适配卡且通信协议为port 22，目标来源为192.168.1.100的数据包资料？\n答：tcpdump -i eth0 -nn 'port 22 and src host 192.168.1.100'。\n##############例子2#######################################\n \n普通情况下，直接启动tcpdump将监视第一个网络界面上所有流过的数据包。\n# tcpdump\ntcpdump: listening on fxp0\n11:58:47.873028 202.102.245.40.netbios-ns > 202.102.245.127.netbios-ns: udp 50\n11:58:47.974331 0:10:7b:8:3a:56 > 1:80:c2:0:0:0 802.1d ui/C len=43\n0000 0000 0080 0000 1007 cf08 0900 0000\n0e80 0000 902b 4695 0980 8701 0014 0002\n000f 0000 902b 4695 0008 00\n11:58:48.373134 0:0:e8:5b:6d:85 > Broadcast sap e0 ui/C len=97\nffff 0060 0004 ffff ffff ffff ffff ffff\n0452 ffff ffff 0000 e85b 6d85 4008 0002\n0640 4d41 5354 4552 5f57 4542 0000 0000\n0000 00\n使用-i参数指定tcpdump监听的网络界面，这在计算机具有多个网络界面时非常有用，\n使用-c参数指定要监听的数据包数量，\n使用-w参数指定将监听到的数据包写入文件中保存\nA想要截获所有210.27.48.1 的主机收到的和发出的所有的数据包：\n#tcpdump host 210.27.48.1\nB想要截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信，使用命令：（在命令行中适用　　　括号时，一定要\n#tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 \\)\nC如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：\n#tcpdump ip host 210.27.48.1 and ! 210.27.48.2\nD如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令：\n#tcpdump tcp port 23 host 210.27.48.1\nE 对本机的udp 123 端口进行监视 123 为ntp的服务端口\n# tcpdump udp port 123\nF 系统将只对名为hostname的主机的通信数据包进行监视。主机名可以是本地主机，也可以是网络上的任何一台计算机。下面的命令可以读取主机hostname发送的所有数据：\n#tcpdump -i eth0 src host hostname\nG 下面的命令可以监视所有送到主机hostname的数据包：\n#tcpdump -i eth0 dst host hostname\nH 我们还可以监视通过指定网关的数据包：\n#tcpdump -i eth0 gateway Gatewayname\nI 如果你还想监视编址到指定端口的TCP或UDP数据包，那么执行以下命令：\n#tcpdump -i eth0 host hostname and port 80\nJ 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包\n，使用命令：\n#tcpdump ip host 210.27.48.1 and ! 210.27.48.2\nK 想要截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信，使用命令\n：（在命令行中适用　　　括号时，一定要\n#tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 \\)\nL 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：\n#tcpdump ip host 210.27.48.1 and ! 210.27.48.2\nM 如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令：\n#tcpdump tcp port 23 host 210.27.48.1\n第三种是协议的关键字，主要包括fddi,ip ,arp,rarp,tcp,udp等类型\n除了这三种类型的关键字之外，其他重要的关键字如下：gateway, broadcast,less,\ngreater,还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘, 与运算是‘and‘,‘&&‘;或运算 是‘o\nr‘ ,‘||‘；\n第二种是确定传输方向的关键字，主要包括src , dst ,dst or src, dst and src ,\n如果我们只需要列出送到80端口的数据包，用dst port；如果我们只希望看到返回80端口的数据包，用src port。\n#tcpdump –i eth0 host hostname and dst port 80 目的端口是80\n或者\n#tcpdump –i eth0 host hostname and src port 80 源端口是80 一般是提供http的服务的主机\n如果条件很多的话 要在条件之前加and 或 or 或 not\n#tcpdump -i eth0 host ! 211.161.223.70 and ! 211.161.223.71 and dst port 80\n如果在ethernet 使用混杂模式 系统的日志将会记录\nMay 7 20:03:46 localhost kernel: eth0: Promiscuous mode enabled.\nMay 7 20:03:46 localhost kernel: device eth0 entered promiscuous mode\nMay 7 20:03:57 localhost kernel: device eth0 left promiscuous mode\ntcpdump对截获的数据并没有进行彻底解码，数据包内的大部分内容是使用十六进制的形式直接打印输出的。显然这不利于分析网络故障，通常的解决办法是先使用带-w参数的tcpdump 截获数据并保存到文件中，然后再使用其他程序进行解码分析。当然也应该定义过滤规则，以避免捕获的数据包填满整个硬盘。\n除了过滤语句，还有一个很重要的参数，也就是说，如果这个参数不设置正确，会导致包数据的丢失！\n它就是-s 参数，snaplen, 也就是数据包的截取长度，仔细看man就会明白的！默认截取长度为60个字节，但一般ethernet MTU都是1500字节。所以，要抓取大于60字节的包时，使用默认参数就会导致包数据丢失！\n只要使用-s 0就可以按包长，截取数据！\n","slug":"tcpdump抓包命令详解","published":1,"updated":"2019-06-18T08:07:01.117Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sme001yhcb7jr8fg0m2","content":"<p>TCPdump抓包命令<br>tcpdump是一个用于截取网络分组，并输出分组内容的工具。tcpdump凭借强大的功能和灵活的截取策略，使其成为类UNIX系统下用于网络分析和问题排查的首选工具。<br>tcpdump提供了源代码，公开了接口，因此具备很强的可扩展性，对于网络维护和入侵者都是非常有用的工具。tcpdump存在于基本的Linux系统中，由于它需要将网络界面设置为混杂模式，普通用户不能正常执行，但具备root权限的用户可以直接执行它来获取网络上的信息。因此系统中存在网络分析工具主要不是对本机安全的威胁，而是对网络上的其他计算机的安全存在威胁。<br><a id=\"more\"></a><br>一、概述<br>顾名思义，tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。<br>引用</p>\n<h1 id=\"tcpdump-vv\"><a href=\"#tcpdump-vv\" class=\"headerlink\" title=\"tcpdump -vv\"></a>tcpdump -vv</h1><p>tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes<br>11:53:21.444591 IP (tos 0x10, ttl 64, id 19324, offset 0, flags [DF], proto 6, length: 92) asptest.localdomain.ssh &gt; 192.168.228.244.1858: P 3962132600:3962132652(52) ack 2726525936 win 1266<br>asptest.localdomain.1077 &gt; 192.168.228.153.domain: [bad udp cksum 166e!] 325+ PTR? 244.228.168.192.in-addr.arpa. (46)<br>11:53:21.446929 IP (tos 0x0, ttl 64, id 42911, offset 0, flags [DF], proto 17, length: 151) 192.168.228.153.domain &gt; asptest.localdomain.1077: 325 NXDomain q: PTR? 244.228.168.192.in-addr.arpa. 0/1/0 ns: 168.192.in-addr.arpa. (123)<br>11:53:21.447408 IP (tos 0x10, ttl 64, id 19328, offset 0, flags [DF], proto 6, length: 172) asptest.localdomain.ssh &gt; 192.168.228.244.1858: P 168:300(132) ack 1 win 1266<br>347 packets captured<br>1474 packets received by filter<br>745 packets dropped by kernel<br>不带参数的tcpdump会收集网络中所有的信息包头，数据量巨大，必须过滤。</p>\n<p>二、选项介绍<br>引用<br>-A 以ASCII格式打印出所有分组，并将链路层的头最小化。<br>-c 在收到指定的数量的分组后，tcpdump就会停止。<br>-C 在将一个原始分组写入文件之前，检查文件当前的大小是否超过了参数file_size 中指定的大小。如果超过了指定大小，则关闭当前文件，然后在打开一个新的文件。参数 file_size 的单位是兆字节（是1,000,000字节，而不是1,048,576字节）。<br>-d 将匹配信息包的代码以人们能够理解的汇编格式给出。<br>-dd 将匹配信息包的代码以C语言程序段的格式给出。<br>-ddd 将匹配信息包的代码以十进制的形式给出。<br>-D 打印出系统中所有可以用tcpdump截包的网络接口。<br>-e 在输出行打印出数据链路层的头部信息。<br>-E 用spi@ipaddr algo:secret解密那些以addr作为地址，并且包含了安全参数索引值spi的IPsec ESP分组。<br>-f 将外部的Internet地址以数字的形式打印出来。<br>-F 从指定的文件中读取表达式，忽略命令行中给出的表达式。<br>-i 指定监听的网络接口。<br>-l 使标准输出变为缓冲行形式，可以把数据导出到文件。<br>-L 列出网络接口的已知数据链路。<br>-m 从文件module中导入SMI MIB模块定义。该参数可以被使用多次，以导入多个MIB模块。<br>-M 如果tcp报文中存在TCP-MD5选项，则需要用secret作为共享的验证码用于验证TCP-MD5选选项摘要（详情可参考RFC 2385）。<br>-b 在数据-链路层上选择协议，包括ip、arp、rarp、ipx都是这一层的。<br>-n 不把网络地址转换成名字。<br>-nn 不进行端口名称的转换。<br>-N 不输出主机名中的域名部分。例如，‘nic.ddn.mil‘只输出’nic‘。<br>-t 在输出的每一行不打印时间戳。<br>-O 不运行分组分组匹配（packet-matching）代码优化程序。<br>-P 不将网络接口设置成混杂模式。<br>-q 快速输出。只输出较少的协议信息。<br>-r 从指定的文件中读取包(这些包一般通过-w选项产生)。<br>-S 将tcp的序列号以绝对值形式输出，而不是相对值。<br>-s 从每个分组中读取最开始的snaplen个字节，而不是默认的68个字节。<br>-T 将监听到的包直接解释为指定的类型的报文，常见的类型有rpc远程过程调用）和snmp（简单网络管理协议；）。<br>-t 不在每一行中输出时间戳。<br>-tt 在每一行中输出非格式化的时间戳。<br>-ttt 输出本行和前面一行之间的时间差。<br>-tttt 在每一行中输出由date处理的默认格式的时间戳。<br>-u 输出未解码的NFS句柄。<br>-v 输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息。<br>-vv 输出详细的报文信息。<br>-w 直接将分组写入文件中，而不是不分析并打印出来。</p>\n<p>三、tcpdump的表达式介绍<br>表达式是一个正则表达式，tcpdump利用它作为过滤报文的条件，如果一个报文满足表 达式的条件，则这个报文将会被捕获。如果没有给出任何条件，则网络上所有的信息包 将会被截获。<br>在表达式中一般如下几种类型的关键字：<br>引用<br>第一种是关于类型的关键字，主要包括host，net，port，例如 host 210.27.48.2， 指明 210.27.48.2是一台主机，net 202.0.0.0指明202.0.0.0是一个网络地址，port 23 指明端口号是23。如果没有指定类型，缺省的类型是host。<br>第二种是确定传输方向的关键字，主要包括src，dst，dst or src，dst and src， 这些关键字指明了传输的方向。举例说明，src 210.27.48.2 ，指明ip包中源地址是 210.27.48.2 ， dst net 202.0.0.0 指明目的网络地址是202.0.0.0。如果没有指明 方向关键字，则缺省是src or dst关键字。<br>第三种是协议的关键字，主要包括fddi，ip，arp，rarp，tcp，udp等类型。Fddi指明是在FDDI (分布式光纤数据接口网络)上的特定的网络协议，实际上它是”ether”的别名，fddi和ether 具有类似的源地址和目的地址，所以可以将fddi协议包当作ether的包进行处理和分析。 其他的几个关键字就是指明了监听的包的协议内容。如果没有指定任何协议，则tcpdump 将会 监听所有协议的信息包。<br>除了这三种类型的关键字之外，其他重要的关键字如下：gateway， broadcast，less， greater， 还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘， 与运算是’and’，’&amp;&amp;’;或运算是’or’ ，’&#124;&#124;’； 这些关键字可以组合起来构成强大的组合条件来满足人们的需要。<br>四、输出结果介绍<br>下面我们介绍几种典型的tcpdump命令的输出信息<br>(1) 数据链路层头信息<br>使用命令： </p>\n<p>#tcpdump –e host ICE<br>ICE 是一台装有linux的主机。它的MAC地址是0：90：27：58：AF：1A H219是一台装有Solaris的SUN工作站。它的MAC地址是8：0：20：79：5B：46； 上一条命令的输出结果如下所示：<br>引用<br>21:50:12.847509 eth0 &lt; 8:0:20:79:5b:46 0:90:27:58:af:1a ip 60: h219.33357 &gt; ICE. telne t 0:0(0) ack 22535 win 8760 (DF)<br>21：50：12是显示的时间， 847509是ID号，eth0 &lt;表示从网络接口eth0接收该分组， eth0 &gt;表示从网络接口设备发送分组， 8:0:20:79:5b:46是主机H219的MAC地址， 它表明是从源地址H219发来的分组. 0:90:27:58:af:1a是主机ICE的MAC地址， 表示该分组的目的地址是ICE。 ip 是表明该分组是IP分组，60 是分组的长度， h219.33357 &gt; ICE. telnet 表明该分组是从主机H219的33357端口发往主机ICE的 TELNET(23)端口。 ack 22535 表明对序列号是222535的包进行响应。 win 8760表明发 送窗口的大小是8760。<br>(2) ARP包的tcpdump输出信息<br>使用命令： </p>\n<p>#tcpdump arp<br>得到的输出结果是：<br>引用<br>22:32:42.802509 eth0 &gt; arp who-has route tell ICE (0:90:27:58:af:1a)<br>22:32:42.802902 eth0 &lt; arp reply route is-at 0:90:27:12:10:66 (0:90:27:58:af:1a)<br>22:32:42是时间戳， 802509是ID号， eth0 &gt;表明从主机发出该分组，arp表明是ARP请求包， who-has route tell ICE表明是主机ICE请求主机route的MAC地址。 0:90:27:58:af:1a是主机 ICE的MAC地址。<br>(3) TCP包的输出信息<br>用tcpdump捕获的TCP包的一般输出信息是：<br>引用<br>src &gt; dst: flags data-seqno ack window urgent options<br>src &gt; dst:表明从源地址到目的地址， flags是TCP报文中的标志信息，S 是SYN标志， F (FIN)， P (PUSH) ， R (RST) “.” (没有标记); data-seqno是报文中的数据 的顺序号， ack是下次期望的顺序号， window是接收缓存的窗口大小， urgent表明 报文中是否有紧急指针。 Options是选项。<br>(4) UDP包的输出信息<br>用tcpdump捕获的UDP包的一般输出信息是：<br>引用<br>route.port1 &gt; ICE.port2: udp lenth<br>UDP十分简单，上面的输出行表明从主机route的port1端口发出的一个UDP报文 到主机ICE的port2端口，类型是UDP， 包的长度是lenth。<br>五、举例<br>(1) 想要截获所有210.27.48.1 的主机收到的和发出的所有的分组： </p>\n<p>#tcpdump host 210.27.48.1<br>(2) 想要截获主机210.27.48.1 和主机210.27.48.2或210.27.48.3的通信，使用命令（注意：括号前的反斜杠是必须的）： </p>\n<p>#tcpdump host 210.27.48.1 and 210.27.48.2or210.27.48.3<br>(3) 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令： </p>\n<p>#tcpdump ip host 210.27.48.1 and ! 210.27.48.2<br>(4) 如果想要获取主机192.168.228.246接收或发出的ssh包，并且不转换主机名使用如下命令： </p>\n<p>#tcpdump -nn -n src host 192.168.228.246 and port 22 and tcp<br>(5) 获取主机192.168.228.246接收或发出的ssh包，并把mac地址也一同显示：</p>\n<h1 id=\"tcpdump-e-src-host-192-168-228-246-and-port-22-and-tcp-n-nn\"><a href=\"#tcpdump-e-src-host-192-168-228-246-and-port-22-and-tcp-n-nn\" class=\"headerlink\" title=\"tcpdump -e src host 192.168.228.246 and port 22 and tcp -n -nn\"></a>tcpdump -e src host 192.168.228.246 and port 22 and tcp -n -nn</h1><p>(6) 过滤的是源主机为192.168.0.1与目的网络为192.168.0.0的报头：<br>tcpdump src host 192.168.0.1 and dst net 192.168.0.0/24<br>(7) 过滤源主机物理地址为XXX的报头：<br>tcpdump ether src 00:50:04:BA:9B and dst……<br>（为什么ether src后面没有host或者net？物理地址当然不可能有网络喽）。<br>(8) 过滤源主机192.168.0.1和目的端口不是telnet的报头，并导入到tes.t.txt文件中：<br>Tcpdump src host 192.168.0.1 and dst port not telnet -l &gt; test.txt<br>ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型。<br>tcpdump采用命令行方式，它的命令格式为：<br>tcpdump [-nn] [-i 接口] [-w 储存档名] [-c 次数] [-Ae]<br>                        [-qX] [-r 文件] [所欲捕获的数据内容]<br>参数：<br>-nn，直接以 IP 及 Port Number 显示，而非主机名与服务名称。<br>-i，后面接要「监听」的网络接口，例如 eth0, lo, ppp0 等等的接口。<br>-w，如果你要将监听所得的数据包数据储存下来，用这个参数就对了。后面接文件名。<br>-c，监听的数据包数，如果没有这个参数， tcpdump 会持续不断的监听，<br>     直到用户输入 [ctrl]-c 为止。<br>-A，数据包的内容以 ASCII 显示，通常用来捉取 WWW 的网页数据包资料。<br>-e，使用资料连接层 (OSI 第二层) 的 MAC 数据包数据来显示。<br>-q，仅列出较为简短的数据包信息，每一行的内容比较精简。<br>-X，可以列出十六进制 (hex) 以及 ASCII 的数据包内容，对于监听数据包内容很有用。<br>-r，从后面接的文件将数据包数据读出来。那个「文件」是已经存在的文件，<br>     并且这个「文件」是由 -w 所制作出来的。<br>所欲捕获的数据内容：我们可以专门针对某些通信协议或者是 IP 来源进行数据包捕获。<br>     那就可以简化输出的结果，并取得最有用的信息。常见的表示方法有。<br>    ‘host foo’, ‘host 127.0.0.1’ ：针对单台主机来进行数据包捕获。<br>     ‘net 192.168’ ：针对某个网段来进行数据包的捕获。<br>     ‘src host 127.0.0.1’ ‘dst net 192.168’：同时加上来源(src)或目标(dst)限制。<br>     ‘tcp port 21’：还可以针对通信协议检测，如tcp、udp、arp、ether 等。<br>     除了这三种类型的关键字之外，其他重要的关键字如下：gateway, broadcast,less,<br>greater,还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘, 与运算是’and’,’&amp;&amp;’;或运算 是’o<br>r’ ,’||’；</p>\n<p>范例一：以 IP 与 Port Number 捉下 eth0 这个网卡上的数据包，持续 3 秒<br>[root@linux ~]# tcpdump -i eth0 -nn<br>tcpdump: verbose output suppressed, use -v or -vv for full protocol decode<br>listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes<br>01:33:40.41 IP 192.168.1.100.22 &gt; 192.168.1.11.1190: P 116:232(116) ack 1 win<br>9648<br>01:33:40.41 IP 192.168.1.100.22 &gt; 192.168.1.11.1190: P 232:364(132) ack 1 win<br>9648<br>&lt;==按下 [ctrl]-c 之后结束<br>6680 packets captured              &lt;==捉取下来的数据包数量<br>14250 packets received by filter   &lt;==由过滤所得的总数据包数量<br>7512 packets dropped by kernel     &lt;==被核心所丢弃的数据包<br>至于那个在范例一所产生的输出中，我们可以大概区分为几个字段，现以范例一当中那行特殊字体行来说明一下：<br>· 01:33:40.41：这个是此数据包被捕获的时间，“时:分:秒”的单位。<br>· IP：通过的通信协议是IP。<br>· 192.168.1.100.22&gt;：传送端是192.168.1.100这个IP，而传送的Port Number为22，那个大于（&gt;）的符号指的是数据包的传输方向。<br>· 192.168.1.11.1190：接收端的IP是192.168.1.11，且该主机开启port 1190来接收。<br>· P 116:232(116)：这个数据包带有PUSH的数据传输标志，且传输的数据为整体数据的116~232 Byte，所以这个数据包带有116 Bytes的数据量。<br>· ack 1 win 9648：ACK与Window size的相关资料。<br>最简单的说法，就是该数据包是由192.168.1.100传到192.168.1.11，通过的port是由22到1190，且带有116 Bytes的数据量，使用的是PUSH的标记，而不是SYN之类的主动联机标志。<br>接下来，在一个网络状态很忙的主机上面，你想要取得某台主机对你联机的数据包数据时，使用tcpdump配合管线命令与正则表达式也可以，不过，毕竟不好捕获。我们可以通过tcpdump的表达式功能，就能够轻易地将所需要的数据独立的取出来。在上面的范例一当中，我们仅针对eth0做监听，所以整个eth0接口上面的数据都会被显示到屏幕上，但这样不好分析，可以简化吗？例如，只取出port 21的联机数据包，可以这样做：<br>[root@linux ~]# tcpdump -i eth0 -nn port 21<br>tcpdump: verbose output suppressed, use -v or -vv for full protocol decode<br>listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes<br>01:54:37.96 IP 192.168.1.11.1240 &gt; 192.168.1.100.21:. ack 1 win 65535<br>01:54:37.96 IP 192.168.1.100.21 &gt; 192.168.1.11.1240:P 1:21(20) ack 1 win 5840<br>01:54:38.12 IP 192.168.1.11.1240 &gt; 192.168.1.100.21:. ack 21 win 65515<br>01:54:42.79 IP 192.168.1.11.1240 &gt; 192.168.1.100.21:P 1:17(16) ack 21 win 65515<br>01:54:42.79 IP 192.168.1.100.21 &gt; 192.168.1.11.1240: . ack 17 win 5840<br>01:54:42.79 IP 192.168.1.100.21 &gt; 192.168.1.11.1240: P 21:55(34) ack 17 win 5840<br>看！这样就仅取出port 21的信息，如果仔细看的话，你会发现数据包的传递都是双向的，Client端发出请求而Server端则予以响应，所以，当然是有去有回了。而我们也就可以经过这个数据包的流向来了解到数据包运动的过程了。例如：<br>· 我们先在一个终端机窗口输入“tcpdump-i lo-nn”的监听。<br>· 再另开一个终端机窗口来对本机（127.0.0.1）登录“ssh localhost”，那么输出的结果会是如何？<br>[root@linux ~]# tcpdump -i lo -nn<br> 1 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode<br> 2 listening on lo, link-type EN10MB (Ethernet), capture size 96 bytes<br> 3 11:02:54.253777 IP 127.0.0.1.32936 &gt;<br>127.0.0.1.22: S 933696132:933696132(0)<br>   win 32767<br> 4 11:02:54.253831 IP 127.0.0.1.22 &gt; 127.0.0.1.32936:<br>S 920046702:920046702(0)<br>   ack 933696133 win 32767<br> 5 11:02:54.253871 IP 127.0.0.1.32936 &gt; 127.0.0.1.22: . ack 1 win 8192<br> 6 11:02:54.272124 IP 127.0.0.1.22 &gt; 127.0.0.1.32936:<br>P 1:23(22) ack 1 win 8192 </p>\n<p> 7 11:02:54.272375 IP 127.0.0.1.32936 &gt; 127.0.0.1.22: . ack 23 win 8192<br>代码显示的头两行是tcpdump的基本说明，然后：<br>· 第3行显示的是来自Client端带有SYN主动联机的数据包。<br>· 第4行显示的是来自Server端，除了响应Client端之外（ACK），还带有SYN主动联机的标志。<br>· 第5行则显示Client端响应Server确定联机建立（ACK）。<br>· 第6行以后则开始进入数据传输的步骤。<br>从第3~5行的流程来看，熟不熟悉啊？没错。那就是3次握手的基础流程，有趣吧。不过tcpdump之所以被称为黑客软件之一远不止上面介绍的功能。上面介绍的功能可以用来作为我们主机的数据包联机与传输的流程分析，这将有助于我们了解到数据包的运作，同时了解到主机的防火墙设置规则是否有需要修订的地方。<br>还有更神奇的用法。当我们使用tcpdump在Router上面监听明文的传输数据时，例如FTP传输协议，你觉得会发生什么问题呢？我们先在主机端执行“tcpdump -i lo port 21 -nn –X”，然后再以FTP登录本机，并输入账号与密码，结果你就可以发现如下的状况：<br>[root@linux ~]# tcpdump -i lo -nn -X ‘port 21’<br>    0x0000:  4500 0048 2a28 4000 4006 1286 7f00 0001  E..H*(@.@…….<br>    0x0010:  7f00 0001 0015 80ab 8355 2149 835c d825  ………U!I..%<br>    0x0020:  8018 2000 fe3c 0000 0101 080a 0e2e 0b67  …..&lt;………g<br>    0x0030:  0e2e 0b61 3232 3020 2876 7346 5450 6420  …a220.(vsFTPd.<br>    0x0040:  322e 302e 3129 0d0a                      2.0.1)..</p>\n<pre><code>0x0000:  4510 0041 d34b 4000 4006 6959 7f00 0001  E..A.K@.@.iY....\n0x0010:  7f00 0001 80ab 0015 835c d825 8355 215d  .........\\.%.U!]\n0x0020:  8018 2000 fe35 0000 0101 080a 0e2e 1b37  .....5.........7\n0x0030:  0e2e 0b67 5553 4552 2064 6d74 7361 690d  ...gUSER.dmtsai.\n0x0040:  0a                                       .\n\n0x0000:  4510 004a d34f 4000 4006 694c 7f00 0001  E..J.O@.@.iL....\n0x0010:  7f00 0001 80ab 0015 835c d832 8355 217f  .........\\.2.U!.\n0x0020:  8018 2000 fe3e 0000 0101 080a 0e2e 3227  .....&gt;........2&apos;\n0x0030:  0e2e 1b38 5041 5353 206d 7970 6173 7377  ...8PASS.mypassw\n0x0040:  6f72 6469 7379 6f75 0d0a                 ordisyou..\n</code></pre><p>上面的输出结果已经被简化过了，你需要自行在你的输出结果中搜索相关的字符串才行。从上面输出结果的特殊字体中，我们可以发现该FTP软件使用的是 vsFTPd，并且用户输入dmtsai这个账号名称，且密码是mypasswordisyou。如果使用的是明文方式来传输你的网络数据呢？<br>另外你得了解，为了让网络接口可以让tcpdump监听，所以执行tcpdump时网络接口会启动在“混杂模式（promiscuous）”，所以你会在 /var/log/messages里面看到很多的警告信息，通知你说你的网卡被设置成为混杂模式。别担心，那是正常的。至于更多的应用，请参考man tcpdump了。</p>\n<p>例题：如何使用tcpdump监听来自eth0适配卡且通信协议为port 22，目标来源为192.168.1.100的数据包资料？<br>答：tcpdump -i eth0 -nn ‘port 22 and src host 192.168.1.100’。</p>\n<p>##############例子2#######################################</p>\n<p>普通情况下，直接启动tcpdump将监视第一个网络界面上所有流过的数据包。</p>\n<h1 id=\"tcpdump\"><a href=\"#tcpdump\" class=\"headerlink\" title=\"tcpdump\"></a>tcpdump</h1><p>tcpdump: listening on fxp0<br>11:58:47.873028 202.102.245.40.netbios-ns &gt; 202.102.245.127.netbios-ns: udp 50<br>11:58:47.974331 0:10:7b:8:3a:56 &gt; 1:80:c2:0:0:0 802.1d ui/C len=43<br>0000 0000 0080 0000 1007 cf08 0900 0000<br>0e80 0000 902b 4695 0980 8701 0014 0002<br>000f 0000 902b 4695 0008 00<br>11:58:48.373134 0:0:e8:5b:6d:85 &gt; Broadcast sap e0 ui/C len=97<br>ffff 0060 0004 ffff ffff ffff ffff ffff<br>0452 ffff ffff 0000 e85b 6d85 4008 0002<br>0640 4d41 5354 4552 5f57 4542 0000 0000<br>0000 00<br>使用-i参数指定tcpdump监听的网络界面，这在计算机具有多个网络界面时非常有用，<br>使用-c参数指定要监听的数据包数量，<br>使用-w参数指定将监听到的数据包写入文件中保存<br>A想要截获所有210.27.48.1 的主机收到的和发出的所有的数据包：</p>\n<p>#tcpdump host 210.27.48.1<br>B想要截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信，使用命令：（在命令行中适用　　　括号时，一定要</p>\n<p>#tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 )<br>C如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：</p>\n<p>#tcpdump ip host 210.27.48.1 and ! 210.27.48.2<br>D如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令：</p>\n<p>#tcpdump tcp port 23 host 210.27.48.1<br>E 对本机的udp 123 端口进行监视 123 为ntp的服务端口</p>\n<h1 id=\"tcpdump-udp-port-123\"><a href=\"#tcpdump-udp-port-123\" class=\"headerlink\" title=\"tcpdump udp port 123\"></a>tcpdump udp port 123</h1><p>F 系统将只对名为hostname的主机的通信数据包进行监视。主机名可以是本地主机，也可以是网络上的任何一台计算机。下面的命令可以读取主机hostname发送的所有数据：</p>\n<p>#tcpdump -i eth0 src host hostname<br>G 下面的命令可以监视所有送到主机hostname的数据包：</p>\n<p>#tcpdump -i eth0 dst host hostname<br>H 我们还可以监视通过指定网关的数据包：</p>\n<p>#tcpdump -i eth0 gateway Gatewayname<br>I 如果你还想监视编址到指定端口的TCP或UDP数据包，那么执行以下命令：</p>\n<p>#tcpdump -i eth0 host hostname and port 80<br>J 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包<br>，使用命令：</p>\n<p>#tcpdump ip host 210.27.48.1 and ! 210.27.48.2<br>K 想要截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信，使用命令<br>：（在命令行中适用　　　括号时，一定要</p>\n<p>#tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 )<br>L 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：</p>\n<p>#tcpdump ip host 210.27.48.1 and ! 210.27.48.2<br>M 如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令：</p>\n<p>#tcpdump tcp port 23 host 210.27.48.1<br>第三种是协议的关键字，主要包括fddi,ip ,arp,rarp,tcp,udp等类型<br>除了这三种类型的关键字之外，其他重要的关键字如下：gateway, broadcast,less,<br>greater,还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘, 与运算是‘and‘,‘&amp;&amp;‘;或运算 是‘o<br>r‘ ,‘||‘；<br>第二种是确定传输方向的关键字，主要包括src , dst ,dst or src, dst and src ,<br>如果我们只需要列出送到80端口的数据包，用dst port；如果我们只希望看到返回80端口的数据包，用src port。</p>\n<p>#tcpdump –i eth0 host hostname and dst port 80 目的端口是80<br>或者</p>\n<p>#tcpdump –i eth0 host hostname and src port 80 源端口是80 一般是提供http的服务的主机<br>如果条件很多的话 要在条件之前加and 或 or 或 not</p>\n<p>#tcpdump -i eth0 host ! 211.161.223.70 and ! 211.161.223.71 and dst port 80<br>如果在ethernet 使用混杂模式 系统的日志将会记录<br>May 7 20:03:46 localhost kernel: eth0: Promiscuous mode enabled.<br>May 7 20:03:46 localhost kernel: device eth0 entered promiscuous mode<br>May 7 20:03:57 localhost kernel: device eth0 left promiscuous mode<br>tcpdump对截获的数据并没有进行彻底解码，数据包内的大部分内容是使用十六进制的形式直接打印输出的。显然这不利于分析网络故障，通常的解决办法是先使用带-w参数的tcpdump 截获数据并保存到文件中，然后再使用其他程序进行解码分析。当然也应该定义过滤规则，以避免捕获的数据包填满整个硬盘。<br>除了过滤语句，还有一个很重要的参数，也就是说，如果这个参数不设置正确，会导致包数据的丢失！<br>它就是-s 参数，snaplen, 也就是数据包的截取长度，仔细看man就会明白的！默认截取长度为60个字节，但一般ethernet MTU都是1500字节。所以，要抓取大于60字节的包时，使用默认参数就会导致包数据丢失！<br>只要使用-s 0就可以按包长，截取数据！</p>\n","site":{"data":{}},"excerpt":"<p>TCPdump抓包命令<br>tcpdump是一个用于截取网络分组，并输出分组内容的工具。tcpdump凭借强大的功能和灵活的截取策略，使其成为类UNIX系统下用于网络分析和问题排查的首选工具。<br>tcpdump提供了源代码，公开了接口，因此具备很强的可扩展性，对于网络维护和入侵者都是非常有用的工具。tcpdump存在于基本的Linux系统中，由于它需要将网络界面设置为混杂模式，普通用户不能正常执行，但具备root权限的用户可以直接执行它来获取网络上的信息。因此系统中存在网络分析工具主要不是对本机安全的威胁，而是对网络上的其他计算机的安全存在威胁。<br>","more":"<br>一、概述<br>顾名思义，tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。<br>引用</p>\n<h1 id=\"tcpdump-vv\"><a href=\"#tcpdump-vv\" class=\"headerlink\" title=\"tcpdump -vv\"></a>tcpdump -vv</h1><p>tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes<br>11:53:21.444591 IP (tos 0x10, ttl 64, id 19324, offset 0, flags [DF], proto 6, length: 92) asptest.localdomain.ssh &gt; 192.168.228.244.1858: P 3962132600:3962132652(52) ack 2726525936 win 1266<br>asptest.localdomain.1077 &gt; 192.168.228.153.domain: [bad udp cksum 166e!] 325+ PTR? 244.228.168.192.in-addr.arpa. (46)<br>11:53:21.446929 IP (tos 0x0, ttl 64, id 42911, offset 0, flags [DF], proto 17, length: 151) 192.168.228.153.domain &gt; asptest.localdomain.1077: 325 NXDomain q: PTR? 244.228.168.192.in-addr.arpa. 0/1/0 ns: 168.192.in-addr.arpa. (123)<br>11:53:21.447408 IP (tos 0x10, ttl 64, id 19328, offset 0, flags [DF], proto 6, length: 172) asptest.localdomain.ssh &gt; 192.168.228.244.1858: P 168:300(132) ack 1 win 1266<br>347 packets captured<br>1474 packets received by filter<br>745 packets dropped by kernel<br>不带参数的tcpdump会收集网络中所有的信息包头，数据量巨大，必须过滤。</p>\n<p>二、选项介绍<br>引用<br>-A 以ASCII格式打印出所有分组，并将链路层的头最小化。<br>-c 在收到指定的数量的分组后，tcpdump就会停止。<br>-C 在将一个原始分组写入文件之前，检查文件当前的大小是否超过了参数file_size 中指定的大小。如果超过了指定大小，则关闭当前文件，然后在打开一个新的文件。参数 file_size 的单位是兆字节（是1,000,000字节，而不是1,048,576字节）。<br>-d 将匹配信息包的代码以人们能够理解的汇编格式给出。<br>-dd 将匹配信息包的代码以C语言程序段的格式给出。<br>-ddd 将匹配信息包的代码以十进制的形式给出。<br>-D 打印出系统中所有可以用tcpdump截包的网络接口。<br>-e 在输出行打印出数据链路层的头部信息。<br>-E 用spi@ipaddr algo:secret解密那些以addr作为地址，并且包含了安全参数索引值spi的IPsec ESP分组。<br>-f 将外部的Internet地址以数字的形式打印出来。<br>-F 从指定的文件中读取表达式，忽略命令行中给出的表达式。<br>-i 指定监听的网络接口。<br>-l 使标准输出变为缓冲行形式，可以把数据导出到文件。<br>-L 列出网络接口的已知数据链路。<br>-m 从文件module中导入SMI MIB模块定义。该参数可以被使用多次，以导入多个MIB模块。<br>-M 如果tcp报文中存在TCP-MD5选项，则需要用secret作为共享的验证码用于验证TCP-MD5选选项摘要（详情可参考RFC 2385）。<br>-b 在数据-链路层上选择协议，包括ip、arp、rarp、ipx都是这一层的。<br>-n 不把网络地址转换成名字。<br>-nn 不进行端口名称的转换。<br>-N 不输出主机名中的域名部分。例如，‘nic.ddn.mil‘只输出’nic‘。<br>-t 在输出的每一行不打印时间戳。<br>-O 不运行分组分组匹配（packet-matching）代码优化程序。<br>-P 不将网络接口设置成混杂模式。<br>-q 快速输出。只输出较少的协议信息。<br>-r 从指定的文件中读取包(这些包一般通过-w选项产生)。<br>-S 将tcp的序列号以绝对值形式输出，而不是相对值。<br>-s 从每个分组中读取最开始的snaplen个字节，而不是默认的68个字节。<br>-T 将监听到的包直接解释为指定的类型的报文，常见的类型有rpc远程过程调用）和snmp（简单网络管理协议；）。<br>-t 不在每一行中输出时间戳。<br>-tt 在每一行中输出非格式化的时间戳。<br>-ttt 输出本行和前面一行之间的时间差。<br>-tttt 在每一行中输出由date处理的默认格式的时间戳。<br>-u 输出未解码的NFS句柄。<br>-v 输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息。<br>-vv 输出详细的报文信息。<br>-w 直接将分组写入文件中，而不是不分析并打印出来。</p>\n<p>三、tcpdump的表达式介绍<br>表达式是一个正则表达式，tcpdump利用它作为过滤报文的条件，如果一个报文满足表 达式的条件，则这个报文将会被捕获。如果没有给出任何条件，则网络上所有的信息包 将会被截获。<br>在表达式中一般如下几种类型的关键字：<br>引用<br>第一种是关于类型的关键字，主要包括host，net，port，例如 host 210.27.48.2， 指明 210.27.48.2是一台主机，net 202.0.0.0指明202.0.0.0是一个网络地址，port 23 指明端口号是23。如果没有指定类型，缺省的类型是host。<br>第二种是确定传输方向的关键字，主要包括src，dst，dst or src，dst and src， 这些关键字指明了传输的方向。举例说明，src 210.27.48.2 ，指明ip包中源地址是 210.27.48.2 ， dst net 202.0.0.0 指明目的网络地址是202.0.0.0。如果没有指明 方向关键字，则缺省是src or dst关键字。<br>第三种是协议的关键字，主要包括fddi，ip，arp，rarp，tcp，udp等类型。Fddi指明是在FDDI (分布式光纤数据接口网络)上的特定的网络协议，实际上它是”ether”的别名，fddi和ether 具有类似的源地址和目的地址，所以可以将fddi协议包当作ether的包进行处理和分析。 其他的几个关键字就是指明了监听的包的协议内容。如果没有指定任何协议，则tcpdump 将会 监听所有协议的信息包。<br>除了这三种类型的关键字之外，其他重要的关键字如下：gateway， broadcast，less， greater， 还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘， 与运算是’and’，’&amp;&amp;’;或运算是’or’ ，’&#124;&#124;’； 这些关键字可以组合起来构成强大的组合条件来满足人们的需要。<br>四、输出结果介绍<br>下面我们介绍几种典型的tcpdump命令的输出信息<br>(1) 数据链路层头信息<br>使用命令： </p>\n<p>#tcpdump –e host ICE<br>ICE 是一台装有linux的主机。它的MAC地址是0：90：27：58：AF：1A H219是一台装有Solaris的SUN工作站。它的MAC地址是8：0：20：79：5B：46； 上一条命令的输出结果如下所示：<br>引用<br>21:50:12.847509 eth0 &lt; 8:0:20:79:5b:46 0:90:27:58:af:1a ip 60: h219.33357 &gt; ICE. telne t 0:0(0) ack 22535 win 8760 (DF)<br>21：50：12是显示的时间， 847509是ID号，eth0 &lt;表示从网络接口eth0接收该分组， eth0 &gt;表示从网络接口设备发送分组， 8:0:20:79:5b:46是主机H219的MAC地址， 它表明是从源地址H219发来的分组. 0:90:27:58:af:1a是主机ICE的MAC地址， 表示该分组的目的地址是ICE。 ip 是表明该分组是IP分组，60 是分组的长度， h219.33357 &gt; ICE. telnet 表明该分组是从主机H219的33357端口发往主机ICE的 TELNET(23)端口。 ack 22535 表明对序列号是222535的包进行响应。 win 8760表明发 送窗口的大小是8760。<br>(2) ARP包的tcpdump输出信息<br>使用命令： </p>\n<p>#tcpdump arp<br>得到的输出结果是：<br>引用<br>22:32:42.802509 eth0 &gt; arp who-has route tell ICE (0:90:27:58:af:1a)<br>22:32:42.802902 eth0 &lt; arp reply route is-at 0:90:27:12:10:66 (0:90:27:58:af:1a)<br>22:32:42是时间戳， 802509是ID号， eth0 &gt;表明从主机发出该分组，arp表明是ARP请求包， who-has route tell ICE表明是主机ICE请求主机route的MAC地址。 0:90:27:58:af:1a是主机 ICE的MAC地址。<br>(3) TCP包的输出信息<br>用tcpdump捕获的TCP包的一般输出信息是：<br>引用<br>src &gt; dst: flags data-seqno ack window urgent options<br>src &gt; dst:表明从源地址到目的地址， flags是TCP报文中的标志信息，S 是SYN标志， F (FIN)， P (PUSH) ， R (RST) “.” (没有标记); data-seqno是报文中的数据 的顺序号， ack是下次期望的顺序号， window是接收缓存的窗口大小， urgent表明 报文中是否有紧急指针。 Options是选项。<br>(4) UDP包的输出信息<br>用tcpdump捕获的UDP包的一般输出信息是：<br>引用<br>route.port1 &gt; ICE.port2: udp lenth<br>UDP十分简单，上面的输出行表明从主机route的port1端口发出的一个UDP报文 到主机ICE的port2端口，类型是UDP， 包的长度是lenth。<br>五、举例<br>(1) 想要截获所有210.27.48.1 的主机收到的和发出的所有的分组： </p>\n<p>#tcpdump host 210.27.48.1<br>(2) 想要截获主机210.27.48.1 和主机210.27.48.2或210.27.48.3的通信，使用命令（注意：括号前的反斜杠是必须的）： </p>\n<p>#tcpdump host 210.27.48.1 and 210.27.48.2or210.27.48.3<br>(3) 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令： </p>\n<p>#tcpdump ip host 210.27.48.1 and ! 210.27.48.2<br>(4) 如果想要获取主机192.168.228.246接收或发出的ssh包，并且不转换主机名使用如下命令： </p>\n<p>#tcpdump -nn -n src host 192.168.228.246 and port 22 and tcp<br>(5) 获取主机192.168.228.246接收或发出的ssh包，并把mac地址也一同显示：</p>\n<h1 id=\"tcpdump-e-src-host-192-168-228-246-and-port-22-and-tcp-n-nn\"><a href=\"#tcpdump-e-src-host-192-168-228-246-and-port-22-and-tcp-n-nn\" class=\"headerlink\" title=\"tcpdump -e src host 192.168.228.246 and port 22 and tcp -n -nn\"></a>tcpdump -e src host 192.168.228.246 and port 22 and tcp -n -nn</h1><p>(6) 过滤的是源主机为192.168.0.1与目的网络为192.168.0.0的报头：<br>tcpdump src host 192.168.0.1 and dst net 192.168.0.0/24<br>(7) 过滤源主机物理地址为XXX的报头：<br>tcpdump ether src 00:50:04:BA:9B and dst……<br>（为什么ether src后面没有host或者net？物理地址当然不可能有网络喽）。<br>(8) 过滤源主机192.168.0.1和目的端口不是telnet的报头，并导入到tes.t.txt文件中：<br>Tcpdump src host 192.168.0.1 and dst port not telnet -l &gt; test.txt<br>ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型。<br>tcpdump采用命令行方式，它的命令格式为：<br>tcpdump [-nn] [-i 接口] [-w 储存档名] [-c 次数] [-Ae]<br>                        [-qX] [-r 文件] [所欲捕获的数据内容]<br>参数：<br>-nn，直接以 IP 及 Port Number 显示，而非主机名与服务名称。<br>-i，后面接要「监听」的网络接口，例如 eth0, lo, ppp0 等等的接口。<br>-w，如果你要将监听所得的数据包数据储存下来，用这个参数就对了。后面接文件名。<br>-c，监听的数据包数，如果没有这个参数， tcpdump 会持续不断的监听，<br>     直到用户输入 [ctrl]-c 为止。<br>-A，数据包的内容以 ASCII 显示，通常用来捉取 WWW 的网页数据包资料。<br>-e，使用资料连接层 (OSI 第二层) 的 MAC 数据包数据来显示。<br>-q，仅列出较为简短的数据包信息，每一行的内容比较精简。<br>-X，可以列出十六进制 (hex) 以及 ASCII 的数据包内容，对于监听数据包内容很有用。<br>-r，从后面接的文件将数据包数据读出来。那个「文件」是已经存在的文件，<br>     并且这个「文件」是由 -w 所制作出来的。<br>所欲捕获的数据内容：我们可以专门针对某些通信协议或者是 IP 来源进行数据包捕获。<br>     那就可以简化输出的结果，并取得最有用的信息。常见的表示方法有。<br>    ‘host foo’, ‘host 127.0.0.1’ ：针对单台主机来进行数据包捕获。<br>     ‘net 192.168’ ：针对某个网段来进行数据包的捕获。<br>     ‘src host 127.0.0.1’ ‘dst net 192.168’：同时加上来源(src)或目标(dst)限制。<br>     ‘tcp port 21’：还可以针对通信协议检测，如tcp、udp、arp、ether 等。<br>     除了这三种类型的关键字之外，其他重要的关键字如下：gateway, broadcast,less,<br>greater,还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘, 与运算是’and’,’&amp;&amp;’;或运算 是’o<br>r’ ,’||’；</p>\n<p>范例一：以 IP 与 Port Number 捉下 eth0 这个网卡上的数据包，持续 3 秒<br>[root@linux ~]# tcpdump -i eth0 -nn<br>tcpdump: verbose output suppressed, use -v or -vv for full protocol decode<br>listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes<br>01:33:40.41 IP 192.168.1.100.22 &gt; 192.168.1.11.1190: P 116:232(116) ack 1 win<br>9648<br>01:33:40.41 IP 192.168.1.100.22 &gt; 192.168.1.11.1190: P 232:364(132) ack 1 win<br>9648<br>&lt;==按下 [ctrl]-c 之后结束<br>6680 packets captured              &lt;==捉取下来的数据包数量<br>14250 packets received by filter   &lt;==由过滤所得的总数据包数量<br>7512 packets dropped by kernel     &lt;==被核心所丢弃的数据包<br>至于那个在范例一所产生的输出中，我们可以大概区分为几个字段，现以范例一当中那行特殊字体行来说明一下：<br>· 01:33:40.41：这个是此数据包被捕获的时间，“时:分:秒”的单位。<br>· IP：通过的通信协议是IP。<br>· 192.168.1.100.22&gt;：传送端是192.168.1.100这个IP，而传送的Port Number为22，那个大于（&gt;）的符号指的是数据包的传输方向。<br>· 192.168.1.11.1190：接收端的IP是192.168.1.11，且该主机开启port 1190来接收。<br>· P 116:232(116)：这个数据包带有PUSH的数据传输标志，且传输的数据为整体数据的116~232 Byte，所以这个数据包带有116 Bytes的数据量。<br>· ack 1 win 9648：ACK与Window size的相关资料。<br>最简单的说法，就是该数据包是由192.168.1.100传到192.168.1.11，通过的port是由22到1190，且带有116 Bytes的数据量，使用的是PUSH的标记，而不是SYN之类的主动联机标志。<br>接下来，在一个网络状态很忙的主机上面，你想要取得某台主机对你联机的数据包数据时，使用tcpdump配合管线命令与正则表达式也可以，不过，毕竟不好捕获。我们可以通过tcpdump的表达式功能，就能够轻易地将所需要的数据独立的取出来。在上面的范例一当中，我们仅针对eth0做监听，所以整个eth0接口上面的数据都会被显示到屏幕上，但这样不好分析，可以简化吗？例如，只取出port 21的联机数据包，可以这样做：<br>[root@linux ~]# tcpdump -i eth0 -nn port 21<br>tcpdump: verbose output suppressed, use -v or -vv for full protocol decode<br>listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes<br>01:54:37.96 IP 192.168.1.11.1240 &gt; 192.168.1.100.21:. ack 1 win 65535<br>01:54:37.96 IP 192.168.1.100.21 &gt; 192.168.1.11.1240:P 1:21(20) ack 1 win 5840<br>01:54:38.12 IP 192.168.1.11.1240 &gt; 192.168.1.100.21:. ack 21 win 65515<br>01:54:42.79 IP 192.168.1.11.1240 &gt; 192.168.1.100.21:P 1:17(16) ack 21 win 65515<br>01:54:42.79 IP 192.168.1.100.21 &gt; 192.168.1.11.1240: . ack 17 win 5840<br>01:54:42.79 IP 192.168.1.100.21 &gt; 192.168.1.11.1240: P 21:55(34) ack 17 win 5840<br>看！这样就仅取出port 21的信息，如果仔细看的话，你会发现数据包的传递都是双向的，Client端发出请求而Server端则予以响应，所以，当然是有去有回了。而我们也就可以经过这个数据包的流向来了解到数据包运动的过程了。例如：<br>· 我们先在一个终端机窗口输入“tcpdump-i lo-nn”的监听。<br>· 再另开一个终端机窗口来对本机（127.0.0.1）登录“ssh localhost”，那么输出的结果会是如何？<br>[root@linux ~]# tcpdump -i lo -nn<br> 1 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode<br> 2 listening on lo, link-type EN10MB (Ethernet), capture size 96 bytes<br> 3 11:02:54.253777 IP 127.0.0.1.32936 &gt;<br>127.0.0.1.22: S 933696132:933696132(0)<br>   win 32767<br> 4 11:02:54.253831 IP 127.0.0.1.22 &gt; 127.0.0.1.32936:<br>S 920046702:920046702(0)<br>   ack 933696133 win 32767<br> 5 11:02:54.253871 IP 127.0.0.1.32936 &gt; 127.0.0.1.22: . ack 1 win 8192<br> 6 11:02:54.272124 IP 127.0.0.1.22 &gt; 127.0.0.1.32936:<br>P 1:23(22) ack 1 win 8192 </p>\n<p> 7 11:02:54.272375 IP 127.0.0.1.32936 &gt; 127.0.0.1.22: . ack 23 win 8192<br>代码显示的头两行是tcpdump的基本说明，然后：<br>· 第3行显示的是来自Client端带有SYN主动联机的数据包。<br>· 第4行显示的是来自Server端，除了响应Client端之外（ACK），还带有SYN主动联机的标志。<br>· 第5行则显示Client端响应Server确定联机建立（ACK）。<br>· 第6行以后则开始进入数据传输的步骤。<br>从第3~5行的流程来看，熟不熟悉啊？没错。那就是3次握手的基础流程，有趣吧。不过tcpdump之所以被称为黑客软件之一远不止上面介绍的功能。上面介绍的功能可以用来作为我们主机的数据包联机与传输的流程分析，这将有助于我们了解到数据包的运作，同时了解到主机的防火墙设置规则是否有需要修订的地方。<br>还有更神奇的用法。当我们使用tcpdump在Router上面监听明文的传输数据时，例如FTP传输协议，你觉得会发生什么问题呢？我们先在主机端执行“tcpdump -i lo port 21 -nn –X”，然后再以FTP登录本机，并输入账号与密码，结果你就可以发现如下的状况：<br>[root@linux ~]# tcpdump -i lo -nn -X ‘port 21’<br>    0x0000:  4500 0048 2a28 4000 4006 1286 7f00 0001  E..H*(@.@…….<br>    0x0010:  7f00 0001 0015 80ab 8355 2149 835c d825  ………U!I..%<br>    0x0020:  8018 2000 fe3c 0000 0101 080a 0e2e 0b67  …..&lt;………g<br>    0x0030:  0e2e 0b61 3232 3020 2876 7346 5450 6420  …a220.(vsFTPd.<br>    0x0040:  322e 302e 3129 0d0a                      2.0.1)..</p>\n<pre><code>0x0000:  4510 0041 d34b 4000 4006 6959 7f00 0001  E..A.K@.@.iY....\n0x0010:  7f00 0001 80ab 0015 835c d825 8355 215d  .........\\.%.U!]\n0x0020:  8018 2000 fe35 0000 0101 080a 0e2e 1b37  .....5.........7\n0x0030:  0e2e 0b67 5553 4552 2064 6d74 7361 690d  ...gUSER.dmtsai.\n0x0040:  0a                                       .\n\n0x0000:  4510 004a d34f 4000 4006 694c 7f00 0001  E..J.O@.@.iL....\n0x0010:  7f00 0001 80ab 0015 835c d832 8355 217f  .........\\.2.U!.\n0x0020:  8018 2000 fe3e 0000 0101 080a 0e2e 3227  .....&gt;........2&apos;\n0x0030:  0e2e 1b38 5041 5353 206d 7970 6173 7377  ...8PASS.mypassw\n0x0040:  6f72 6469 7379 6f75 0d0a                 ordisyou..\n</code></pre><p>上面的输出结果已经被简化过了，你需要自行在你的输出结果中搜索相关的字符串才行。从上面输出结果的特殊字体中，我们可以发现该FTP软件使用的是 vsFTPd，并且用户输入dmtsai这个账号名称，且密码是mypasswordisyou。如果使用的是明文方式来传输你的网络数据呢？<br>另外你得了解，为了让网络接口可以让tcpdump监听，所以执行tcpdump时网络接口会启动在“混杂模式（promiscuous）”，所以你会在 /var/log/messages里面看到很多的警告信息，通知你说你的网卡被设置成为混杂模式。别担心，那是正常的。至于更多的应用，请参考man tcpdump了。</p>\n<p>例题：如何使用tcpdump监听来自eth0适配卡且通信协议为port 22，目标来源为192.168.1.100的数据包资料？<br>答：tcpdump -i eth0 -nn ‘port 22 and src host 192.168.1.100’。</p>\n<p>##############例子2#######################################</p>\n<p>普通情况下，直接启动tcpdump将监视第一个网络界面上所有流过的数据包。</p>\n<h1 id=\"tcpdump\"><a href=\"#tcpdump\" class=\"headerlink\" title=\"tcpdump\"></a>tcpdump</h1><p>tcpdump: listening on fxp0<br>11:58:47.873028 202.102.245.40.netbios-ns &gt; 202.102.245.127.netbios-ns: udp 50<br>11:58:47.974331 0:10:7b:8:3a:56 &gt; 1:80:c2:0:0:0 802.1d ui/C len=43<br>0000 0000 0080 0000 1007 cf08 0900 0000<br>0e80 0000 902b 4695 0980 8701 0014 0002<br>000f 0000 902b 4695 0008 00<br>11:58:48.373134 0:0:e8:5b:6d:85 &gt; Broadcast sap e0 ui/C len=97<br>ffff 0060 0004 ffff ffff ffff ffff ffff<br>0452 ffff ffff 0000 e85b 6d85 4008 0002<br>0640 4d41 5354 4552 5f57 4542 0000 0000<br>0000 00<br>使用-i参数指定tcpdump监听的网络界面，这在计算机具有多个网络界面时非常有用，<br>使用-c参数指定要监听的数据包数量，<br>使用-w参数指定将监听到的数据包写入文件中保存<br>A想要截获所有210.27.48.1 的主机收到的和发出的所有的数据包：</p>\n<p>#tcpdump host 210.27.48.1<br>B想要截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信，使用命令：（在命令行中适用　　　括号时，一定要</p>\n<p>#tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 )<br>C如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：</p>\n<p>#tcpdump ip host 210.27.48.1 and ! 210.27.48.2<br>D如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令：</p>\n<p>#tcpdump tcp port 23 host 210.27.48.1<br>E 对本机的udp 123 端口进行监视 123 为ntp的服务端口</p>\n<h1 id=\"tcpdump-udp-port-123\"><a href=\"#tcpdump-udp-port-123\" class=\"headerlink\" title=\"tcpdump udp port 123\"></a>tcpdump udp port 123</h1><p>F 系统将只对名为hostname的主机的通信数据包进行监视。主机名可以是本地主机，也可以是网络上的任何一台计算机。下面的命令可以读取主机hostname发送的所有数据：</p>\n<p>#tcpdump -i eth0 src host hostname<br>G 下面的命令可以监视所有送到主机hostname的数据包：</p>\n<p>#tcpdump -i eth0 dst host hostname<br>H 我们还可以监视通过指定网关的数据包：</p>\n<p>#tcpdump -i eth0 gateway Gatewayname<br>I 如果你还想监视编址到指定端口的TCP或UDP数据包，那么执行以下命令：</p>\n<p>#tcpdump -i eth0 host hostname and port 80<br>J 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包<br>，使用命令：</p>\n<p>#tcpdump ip host 210.27.48.1 and ! 210.27.48.2<br>K 想要截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信，使用命令<br>：（在命令行中适用　　　括号时，一定要</p>\n<p>#tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 )<br>L 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：</p>\n<p>#tcpdump ip host 210.27.48.1 and ! 210.27.48.2<br>M 如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令：</p>\n<p>#tcpdump tcp port 23 host 210.27.48.1<br>第三种是协议的关键字，主要包括fddi,ip ,arp,rarp,tcp,udp等类型<br>除了这三种类型的关键字之外，其他重要的关键字如下：gateway, broadcast,less,<br>greater,还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘, 与运算是‘and‘,‘&amp;&amp;‘;或运算 是‘o<br>r‘ ,‘||‘；<br>第二种是确定传输方向的关键字，主要包括src , dst ,dst or src, dst and src ,<br>如果我们只需要列出送到80端口的数据包，用dst port；如果我们只希望看到返回80端口的数据包，用src port。</p>\n<p>#tcpdump –i eth0 host hostname and dst port 80 目的端口是80<br>或者</p>\n<p>#tcpdump –i eth0 host hostname and src port 80 源端口是80 一般是提供http的服务的主机<br>如果条件很多的话 要在条件之前加and 或 or 或 not</p>\n<p>#tcpdump -i eth0 host ! 211.161.223.70 and ! 211.161.223.71 and dst port 80<br>如果在ethernet 使用混杂模式 系统的日志将会记录<br>May 7 20:03:46 localhost kernel: eth0: Promiscuous mode enabled.<br>May 7 20:03:46 localhost kernel: device eth0 entered promiscuous mode<br>May 7 20:03:57 localhost kernel: device eth0 left promiscuous mode<br>tcpdump对截获的数据并没有进行彻底解码，数据包内的大部分内容是使用十六进制的形式直接打印输出的。显然这不利于分析网络故障，通常的解决办法是先使用带-w参数的tcpdump 截获数据并保存到文件中，然后再使用其他程序进行解码分析。当然也应该定义过滤规则，以避免捕获的数据包填满整个硬盘。<br>除了过滤语句，还有一个很重要的参数，也就是说，如果这个参数不设置正确，会导致包数据的丢失！<br>它就是-s 参数，snaplen, 也就是数据包的截取长度，仔细看man就会明白的！默认截取长度为60个字节，但一般ethernet MTU都是1500字节。所以，要抓取大于60字节的包时，使用默认参数就会导致包数据丢失！<br>只要使用-s 0就可以按包长，截取数据！</p>"},{"title":"tcpdump：理论、自动抓包及业务架构树的生成","date":"2017-03-02T05:00:00.000Z","_content":"###一、tcpdump基础\n\ntcpdump是一个对网络数据包进行截获的包分析工具。\n\ntcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、端口等的过滤，并支持与、或、非逻辑语句协助过滤有效信息。\n<!--more-->\n命令使用规则如下：\n\n    tcpdump version 4.1-PRE-CVS_2016_05_10\n    libpcap version 1.4.0\n    Usage: tcpdump [-aAdDefhIJKlLnNOpqRStuUvxX] [ -B size ] [ -c count ]\n    \t\t[ -C file_size ] [ -E algo:secret ] [ -F file ] [ -G seconds ]\n    \t\t[ -i interface ] [ -j tstamptype ] [ -M secret ]\n    \t\t[ -Q|-P in|out|inout ]\n    \t\t[ -r file ] [ -s snaplen ] [ -T type ] [ -w file ]\n    \t\t[ -W filecount ] [ -y datalinktype ] [ -z command ]\n    \t\t[ -Z user ] [ expression ]\n    \n过滤方式有很多，可以依据所需设置过滤条件，较常用的三种：\n####1、可以按host过滤，例如：\n\n    tcpdump -i eth0 -n -X src host 172.17.198.10\n####2、可以按port过滤，例如：\n    cpdump -i eth0 -n -X src host 172.17.198.10 and dst port 80\n\n####3、可以按protocol过滤，例如：\n\n    tcpdump -i eth0 -n -X src host 172.17.198.10 and dst port 80 and tcp\n下面来看一下tcpdump过滤规则的具体使用：\n\n我们在服务器10.219.153.215上搭建了一个http服务用来作为服务端，10.19.66.62作为客户端客户端对其发起访问。我们使用前面提到的按host 10.19.66.62、port 80以及protocol tcp的组合条件来执行tcpdump。\n\n    tcpdump -i eth0 -n  tcp port 80 and host 172.17.198.10\n    [root@ssy-turn1 ~]# tcpdump -i eth0 -n  tcp port 80 and host 172.17.198.10\n    tcpdump: verbose output suppressed, use -v or -vv for full protocol decode\n    listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes\n    11:39:05.355344 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [S], seq 636850073, win 65160, options [mss 1460,sackOK,TS val 2335946898 ecr 3699469428,nop,wscale 14], length 0\n    11:39:05.355397 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [S.], seq 4174661387, ack 636850074, win 65160, options [mss 1460,sackOK,TS val 3699486375 ecr 2335946898,nop,wscale 14], length 0\n    11:39:05.357024 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [.], ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 0\n    11:39:05.357062 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [P.], seq 1:193, ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 192\n    11:39:05.357071 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [.], ack 193, win 4, options [nop,nop,TS val 3699486376 ecr 2335946899], length 0\n    11:39:05.357403 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [P.], seq 1:765, ack 193, win 4, options [nop,nop,TS val 3699486377 ecr 2335946899], length 764\n    11:39:05.357766 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [.], ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n    11:39:05.359151 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [F.], seq 193, ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n    11:39:05.359329 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [F.], seq 765, ack 194, win 4, options [nop,nop,TS val 3699486379 ecr 2335946901], length 0\n    11:39:05.359613 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [.], ack 766, win 4, options [nop,nop,TS val 2335946903 ecr 3699486379], length 0\n    \n不同的协议类型有不同的数据包格式显示，以tcp包为例，通常tcpdump对tcp数据包的显示格式如下:\n\n    src > dst: flags data-seqno ack window urgent options\n    src ＞ dst：表明从源地址到目的地址\n    flags：TCP包中的标志信息，S 是SYN标志,，F (FIN)，P (PUSH)，R (RST)，”.” (没有标记）\n    data-seqno：是数据包中的数据的顺序号\n    ack：是下次期望的顺序号\n    window：是接收缓存的窗口大小\n    urgent：表明数据包中是否有紧急指针\n    options：选项\n执行抓包过程中输出的这八行数据其实包含了tcp三次握手和四次挥手的交互过程，详细分析下看看：\n\n    11:39:05.355344 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [S], seq 636850073, win 65160, options [mss 1460,sackOK,TS val 2335946898 ecr 3699469428,nop,wscale 14], length 0\n    11:39:05.355397 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [S.], seq 4174661387, ack 636850074, win 65160, options [mss 1460,sackOK,TS val 3699486375 ecr 2335946898,nop,wscale 14], length 0\n    11:39:05.357024 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [.], ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 0\n    11:39:05.357062 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [P.], seq 1:193, ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 192\n    11:39:05.357071 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [.], ack 193, win 4, options [nop,nop,TS val 3699486376 ecr 2335946899], length 0\n    11:39:05.357403 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [P.], seq 1:765, ack 193, win 4, options [nop,nop,TS val 3699486377 ecr 2335946899], length 764\n    11:39:05.357766 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [.], ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n    11:39:05.359151 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [F.], seq 193, ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n    11:39:05.359329 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [F.], seq 765, ack 194, win 4, options [nop,nop,TS val 3699486379 ecr 2335946901], length 0\n    11:39:05.359613 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [.], ack 766, win 4, options [nop,nop,TS val 2335946903 ecr 3699486379], length 0\n第一至三行为建立链接的三次握手过程，包状态为：[S]、[S.]、[.]，第四至七行为传输数据的过程，包状态为[P.]、[.]；第八至十行为关闭链接的四次挥手过程（ack延迟发送未禁用，所以这里只看到三个包），包状态为[F.]、[F.]、[.]。  \n\n####第一行：客户端10向服务器11发送了一个序号seq 636850073给服务端；\n\n####第二行：服务端收到后将序号加一返回ack 636850074；\n\n####第三行：客户端检查返回值正确，向服务端发ack 1，建立了链接；\n\n####第四行和第七行：具体的数据交互，tcpdump命令-x可以显示出具体内容；\n\n####第八行：客户端发一个序号seq 193，说明要断开链接；\n\n####第九行：服务端在收到后序号加一返回ack 194，同意断开链接；\n\n####第十行：客户端检查返回值正确，向服务端发ack，链接断开。\n\n\n\n","source":"_posts/tcpdump：理论、自动抓包及业务架构树的生成.md","raw":"---\ntitle: tcpdump：理论、自动抓包及业务架构树的生成\ndate: 2017-03-02\ntags: tcpdump\ncategories: linux\n---\n###一、tcpdump基础\n\ntcpdump是一个对网络数据包进行截获的包分析工具。\n\ntcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、端口等的过滤，并支持与、或、非逻辑语句协助过滤有效信息。\n<!--more-->\n命令使用规则如下：\n\n    tcpdump version 4.1-PRE-CVS_2016_05_10\n    libpcap version 1.4.0\n    Usage: tcpdump [-aAdDefhIJKlLnNOpqRStuUvxX] [ -B size ] [ -c count ]\n    \t\t[ -C file_size ] [ -E algo:secret ] [ -F file ] [ -G seconds ]\n    \t\t[ -i interface ] [ -j tstamptype ] [ -M secret ]\n    \t\t[ -Q|-P in|out|inout ]\n    \t\t[ -r file ] [ -s snaplen ] [ -T type ] [ -w file ]\n    \t\t[ -W filecount ] [ -y datalinktype ] [ -z command ]\n    \t\t[ -Z user ] [ expression ]\n    \n过滤方式有很多，可以依据所需设置过滤条件，较常用的三种：\n####1、可以按host过滤，例如：\n\n    tcpdump -i eth0 -n -X src host 172.17.198.10\n####2、可以按port过滤，例如：\n    cpdump -i eth0 -n -X src host 172.17.198.10 and dst port 80\n\n####3、可以按protocol过滤，例如：\n\n    tcpdump -i eth0 -n -X src host 172.17.198.10 and dst port 80 and tcp\n下面来看一下tcpdump过滤规则的具体使用：\n\n我们在服务器10.219.153.215上搭建了一个http服务用来作为服务端，10.19.66.62作为客户端客户端对其发起访问。我们使用前面提到的按host 10.19.66.62、port 80以及protocol tcp的组合条件来执行tcpdump。\n\n    tcpdump -i eth0 -n  tcp port 80 and host 172.17.198.10\n    [root@ssy-turn1 ~]# tcpdump -i eth0 -n  tcp port 80 and host 172.17.198.10\n    tcpdump: verbose output suppressed, use -v or -vv for full protocol decode\n    listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes\n    11:39:05.355344 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [S], seq 636850073, win 65160, options [mss 1460,sackOK,TS val 2335946898 ecr 3699469428,nop,wscale 14], length 0\n    11:39:05.355397 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [S.], seq 4174661387, ack 636850074, win 65160, options [mss 1460,sackOK,TS val 3699486375 ecr 2335946898,nop,wscale 14], length 0\n    11:39:05.357024 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [.], ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 0\n    11:39:05.357062 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [P.], seq 1:193, ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 192\n    11:39:05.357071 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [.], ack 193, win 4, options [nop,nop,TS val 3699486376 ecr 2335946899], length 0\n    11:39:05.357403 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [P.], seq 1:765, ack 193, win 4, options [nop,nop,TS val 3699486377 ecr 2335946899], length 764\n    11:39:05.357766 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [.], ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n    11:39:05.359151 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [F.], seq 193, ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n    11:39:05.359329 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [F.], seq 765, ack 194, win 4, options [nop,nop,TS val 3699486379 ecr 2335946901], length 0\n    11:39:05.359613 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [.], ack 766, win 4, options [nop,nop,TS val 2335946903 ecr 3699486379], length 0\n    \n不同的协议类型有不同的数据包格式显示，以tcp包为例，通常tcpdump对tcp数据包的显示格式如下:\n\n    src > dst: flags data-seqno ack window urgent options\n    src ＞ dst：表明从源地址到目的地址\n    flags：TCP包中的标志信息，S 是SYN标志,，F (FIN)，P (PUSH)，R (RST)，”.” (没有标记）\n    data-seqno：是数据包中的数据的顺序号\n    ack：是下次期望的顺序号\n    window：是接收缓存的窗口大小\n    urgent：表明数据包中是否有紧急指针\n    options：选项\n执行抓包过程中输出的这八行数据其实包含了tcp三次握手和四次挥手的交互过程，详细分析下看看：\n\n    11:39:05.355344 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [S], seq 636850073, win 65160, options [mss 1460,sackOK,TS val 2335946898 ecr 3699469428,nop,wscale 14], length 0\n    11:39:05.355397 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [S.], seq 4174661387, ack 636850074, win 65160, options [mss 1460,sackOK,TS val 3699486375 ecr 2335946898,nop,wscale 14], length 0\n    11:39:05.357024 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [.], ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 0\n    11:39:05.357062 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [P.], seq 1:193, ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 192\n    11:39:05.357071 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [.], ack 193, win 4, options [nop,nop,TS val 3699486376 ecr 2335946899], length 0\n    11:39:05.357403 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [P.], seq 1:765, ack 193, win 4, options [nop,nop,TS val 3699486377 ecr 2335946899], length 764\n    11:39:05.357766 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [.], ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n    11:39:05.359151 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [F.], seq 193, ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n    11:39:05.359329 IP 172.17.198.11.http > 172.17.198.10.solaris-audit: Flags [F.], seq 765, ack 194, win 4, options [nop,nop,TS val 3699486379 ecr 2335946901], length 0\n    11:39:05.359613 IP 172.17.198.10.solaris-audit > 172.17.198.11.http: Flags [.], ack 766, win 4, options [nop,nop,TS val 2335946903 ecr 3699486379], length 0\n第一至三行为建立链接的三次握手过程，包状态为：[S]、[S.]、[.]，第四至七行为传输数据的过程，包状态为[P.]、[.]；第八至十行为关闭链接的四次挥手过程（ack延迟发送未禁用，所以这里只看到三个包），包状态为[F.]、[F.]、[.]。  \n\n####第一行：客户端10向服务器11发送了一个序号seq 636850073给服务端；\n\n####第二行：服务端收到后将序号加一返回ack 636850074；\n\n####第三行：客户端检查返回值正确，向服务端发ack 1，建立了链接；\n\n####第四行和第七行：具体的数据交互，tcpdump命令-x可以显示出具体内容；\n\n####第八行：客户端发一个序号seq 193，说明要断开链接；\n\n####第九行：服务端在收到后序号加一返回ack 194，同意断开链接；\n\n####第十行：客户端检查返回值正确，向服务端发ack，链接断开。\n\n\n\n","slug":"tcpdump：理论、自动抓包及业务架构树的生成","published":1,"updated":"2019-06-18T08:07:01.117Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9smi0021hcb7bnim9j3x","content":"<p>###一、tcpdump基础</p>\n<p>tcpdump是一个对网络数据包进行截获的包分析工具。</p>\n<p>tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、端口等的过滤，并支持与、或、非逻辑语句协助过滤有效信息。<br><a id=\"more\"></a><br>命令使用规则如下：</p>\n<pre><code>tcpdump version 4.1-PRE-CVS_2016_05_10\nlibpcap version 1.4.0\nUsage: tcpdump [-aAdDefhIJKlLnNOpqRStuUvxX] [ -B size ] [ -c count ]\n        [ -C file_size ] [ -E algo:secret ] [ -F file ] [ -G seconds ]\n        [ -i interface ] [ -j tstamptype ] [ -M secret ]\n        [ -Q|-P in|out|inout ]\n        [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ]\n        [ -W filecount ] [ -y datalinktype ] [ -z command ]\n        [ -Z user ] [ expression ]\n</code></pre><p>过滤方式有很多，可以依据所需设置过滤条件，较常用的三种：</p>\n<p>####1、可以按host过滤，例如：</p>\n<pre><code>tcpdump -i eth0 -n -X src host 172.17.198.10\n</code></pre><p>####2、可以按port过滤，例如：<br>    cpdump -i eth0 -n -X src host 172.17.198.10 and dst port 80</p>\n<p>####3、可以按protocol过滤，例如：</p>\n<pre><code>tcpdump -i eth0 -n -X src host 172.17.198.10 and dst port 80 and tcp\n</code></pre><p>下面来看一下tcpdump过滤规则的具体使用：</p>\n<p>我们在服务器10.219.153.215上搭建了一个http服务用来作为服务端，10.19.66.62作为客户端客户端对其发起访问。我们使用前面提到的按host 10.19.66.62、port 80以及protocol tcp的组合条件来执行tcpdump。</p>\n<pre><code>tcpdump -i eth0 -n  tcp port 80 and host 172.17.198.10\n[root@ssy-turn1 ~]# tcpdump -i eth0 -n  tcp port 80 and host 172.17.198.10\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes\n11:39:05.355344 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [S], seq 636850073, win 65160, options [mss 1460,sackOK,TS val 2335946898 ecr 3699469428,nop,wscale 14], length 0\n11:39:05.355397 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [S.], seq 4174661387, ack 636850074, win 65160, options [mss 1460,sackOK,TS val 3699486375 ecr 2335946898,nop,wscale 14], length 0\n11:39:05.357024 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 0\n11:39:05.357062 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [P.], seq 1:193, ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 192\n11:39:05.357071 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [.], ack 193, win 4, options [nop,nop,TS val 3699486376 ecr 2335946899], length 0\n11:39:05.357403 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [P.], seq 1:765, ack 193, win 4, options [nop,nop,TS val 3699486377 ecr 2335946899], length 764\n11:39:05.357766 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n11:39:05.359151 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [F.], seq 193, ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n11:39:05.359329 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [F.], seq 765, ack 194, win 4, options [nop,nop,TS val 3699486379 ecr 2335946901], length 0\n11:39:05.359613 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 766, win 4, options [nop,nop,TS val 2335946903 ecr 3699486379], length 0\n</code></pre><p>不同的协议类型有不同的数据包格式显示，以tcp包为例，通常tcpdump对tcp数据包的显示格式如下:</p>\n<pre><code>src &gt; dst: flags data-seqno ack window urgent options\nsrc ＞ dst：表明从源地址到目的地址\nflags：TCP包中的标志信息，S 是SYN标志,，F (FIN)，P (PUSH)，R (RST)，”.” (没有标记）\ndata-seqno：是数据包中的数据的顺序号\nack：是下次期望的顺序号\nwindow：是接收缓存的窗口大小\nurgent：表明数据包中是否有紧急指针\noptions：选项\n</code></pre><p>执行抓包过程中输出的这八行数据其实包含了tcp三次握手和四次挥手的交互过程，详细分析下看看：</p>\n<pre><code>11:39:05.355344 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [S], seq 636850073, win 65160, options [mss 1460,sackOK,TS val 2335946898 ecr 3699469428,nop,wscale 14], length 0\n11:39:05.355397 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [S.], seq 4174661387, ack 636850074, win 65160, options [mss 1460,sackOK,TS val 3699486375 ecr 2335946898,nop,wscale 14], length 0\n11:39:05.357024 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 0\n11:39:05.357062 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [P.], seq 1:193, ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 192\n11:39:05.357071 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [.], ack 193, win 4, options [nop,nop,TS val 3699486376 ecr 2335946899], length 0\n11:39:05.357403 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [P.], seq 1:765, ack 193, win 4, options [nop,nop,TS val 3699486377 ecr 2335946899], length 764\n11:39:05.357766 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n11:39:05.359151 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [F.], seq 193, ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n11:39:05.359329 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [F.], seq 765, ack 194, win 4, options [nop,nop,TS val 3699486379 ecr 2335946901], length 0\n11:39:05.359613 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 766, win 4, options [nop,nop,TS val 2335946903 ecr 3699486379], length 0\n</code></pre><p>第一至三行为建立链接的三次握手过程，包状态为：[S]、[S.]、[.]，第四至七行为传输数据的过程，包状态为[P.]、[.]；第八至十行为关闭链接的四次挥手过程（ack延迟发送未禁用，所以这里只看到三个包），包状态为[F.]、[F.]、[.]。  </p>\n<p>####第一行：客户端10向服务器11发送了一个序号seq 636850073给服务端；</p>\n<p>####第二行：服务端收到后将序号加一返回ack 636850074；</p>\n<p>####第三行：客户端检查返回值正确，向服务端发ack 1，建立了链接；</p>\n<p>####第四行和第七行：具体的数据交互，tcpdump命令-x可以显示出具体内容；</p>\n<p>####第八行：客户端发一个序号seq 193，说明要断开链接；</p>\n<p>####第九行：服务端在收到后序号加一返回ack 194，同意断开链接；</p>\n<p>####第十行：客户端检查返回值正确，向服务端发ack，链接断开。</p>\n","site":{"data":{}},"excerpt":"<p>###一、tcpdump基础</p>\n<p>tcpdump是一个对网络数据包进行截获的包分析工具。</p>\n<p>tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、端口等的过滤，并支持与、或、非逻辑语句协助过滤有效信息。<br>","more":"<br>命令使用规则如下：</p>\n<pre><code>tcpdump version 4.1-PRE-CVS_2016_05_10\nlibpcap version 1.4.0\nUsage: tcpdump [-aAdDefhIJKlLnNOpqRStuUvxX] [ -B size ] [ -c count ]\n        [ -C file_size ] [ -E algo:secret ] [ -F file ] [ -G seconds ]\n        [ -i interface ] [ -j tstamptype ] [ -M secret ]\n        [ -Q|-P in|out|inout ]\n        [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ]\n        [ -W filecount ] [ -y datalinktype ] [ -z command ]\n        [ -Z user ] [ expression ]\n</code></pre><p>过滤方式有很多，可以依据所需设置过滤条件，较常用的三种：</p>\n<p>####1、可以按host过滤，例如：</p>\n<pre><code>tcpdump -i eth0 -n -X src host 172.17.198.10\n</code></pre><p>####2、可以按port过滤，例如：<br>    cpdump -i eth0 -n -X src host 172.17.198.10 and dst port 80</p>\n<p>####3、可以按protocol过滤，例如：</p>\n<pre><code>tcpdump -i eth0 -n -X src host 172.17.198.10 and dst port 80 and tcp\n</code></pre><p>下面来看一下tcpdump过滤规则的具体使用：</p>\n<p>我们在服务器10.219.153.215上搭建了一个http服务用来作为服务端，10.19.66.62作为客户端客户端对其发起访问。我们使用前面提到的按host 10.19.66.62、port 80以及protocol tcp的组合条件来执行tcpdump。</p>\n<pre><code>tcpdump -i eth0 -n  tcp port 80 and host 172.17.198.10\n[root@ssy-turn1 ~]# tcpdump -i eth0 -n  tcp port 80 and host 172.17.198.10\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes\n11:39:05.355344 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [S], seq 636850073, win 65160, options [mss 1460,sackOK,TS val 2335946898 ecr 3699469428,nop,wscale 14], length 0\n11:39:05.355397 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [S.], seq 4174661387, ack 636850074, win 65160, options [mss 1460,sackOK,TS val 3699486375 ecr 2335946898,nop,wscale 14], length 0\n11:39:05.357024 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 0\n11:39:05.357062 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [P.], seq 1:193, ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 192\n11:39:05.357071 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [.], ack 193, win 4, options [nop,nop,TS val 3699486376 ecr 2335946899], length 0\n11:39:05.357403 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [P.], seq 1:765, ack 193, win 4, options [nop,nop,TS val 3699486377 ecr 2335946899], length 764\n11:39:05.357766 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n11:39:05.359151 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [F.], seq 193, ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n11:39:05.359329 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [F.], seq 765, ack 194, win 4, options [nop,nop,TS val 3699486379 ecr 2335946901], length 0\n11:39:05.359613 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 766, win 4, options [nop,nop,TS val 2335946903 ecr 3699486379], length 0\n</code></pre><p>不同的协议类型有不同的数据包格式显示，以tcp包为例，通常tcpdump对tcp数据包的显示格式如下:</p>\n<pre><code>src &gt; dst: flags data-seqno ack window urgent options\nsrc ＞ dst：表明从源地址到目的地址\nflags：TCP包中的标志信息，S 是SYN标志,，F (FIN)，P (PUSH)，R (RST)，”.” (没有标记）\ndata-seqno：是数据包中的数据的顺序号\nack：是下次期望的顺序号\nwindow：是接收缓存的窗口大小\nurgent：表明数据包中是否有紧急指针\noptions：选项\n</code></pre><p>执行抓包过程中输出的这八行数据其实包含了tcp三次握手和四次挥手的交互过程，详细分析下看看：</p>\n<pre><code>11:39:05.355344 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [S], seq 636850073, win 65160, options [mss 1460,sackOK,TS val 2335946898 ecr 3699469428,nop,wscale 14], length 0\n11:39:05.355397 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [S.], seq 4174661387, ack 636850074, win 65160, options [mss 1460,sackOK,TS val 3699486375 ecr 2335946898,nop,wscale 14], length 0\n11:39:05.357024 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 0\n11:39:05.357062 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [P.], seq 1:193, ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 192\n11:39:05.357071 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [.], ack 193, win 4, options [nop,nop,TS val 3699486376 ecr 2335946899], length 0\n11:39:05.357403 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [P.], seq 1:765, ack 193, win 4, options [nop,nop,TS val 3699486377 ecr 2335946899], length 764\n11:39:05.357766 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n11:39:05.359151 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [F.], seq 193, ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 0\n11:39:05.359329 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [F.], seq 765, ack 194, win 4, options [nop,nop,TS val 3699486379 ecr 2335946901], length 0\n11:39:05.359613 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 766, win 4, options [nop,nop,TS val 2335946903 ecr 3699486379], length 0\n</code></pre><p>第一至三行为建立链接的三次握手过程，包状态为：[S]、[S.]、[.]，第四至七行为传输数据的过程，包状态为[P.]、[.]；第八至十行为关闭链接的四次挥手过程（ack延迟发送未禁用，所以这里只看到三个包），包状态为[F.]、[F.]、[.]。  </p>\n<p>####第一行：客户端10向服务器11发送了一个序号seq 636850073给服务端；</p>\n<p>####第二行：服务端收到后将序号加一返回ack 636850074；</p>\n<p>####第三行：客户端检查返回值正确，向服务端发ack 1，建立了链接；</p>\n<p>####第四行和第七行：具体的数据交互，tcpdump命令-x可以显示出具体内容；</p>\n<p>####第八行：客户端发一个序号seq 193，说明要断开链接；</p>\n<p>####第九行：服务端在收到后序号加一返回ack 194，同意断开链接；</p>\n<p>####第十行：客户端检查返回值正确，向服务端发ack，链接断开。</p>"},{"title":"tsung使用说明","date":"2017-01-08T05:00:00.000Z","_content":"\n1、tsung安装\n\ntsung 一个非常优秀的压力测试工具，在8核32G机器上可以轻易的产生每秒10000个并发请求，且占用的资源很少，当前版本1.5.0\n<!--more-->\n使用erlang开发，需要先安装erlang虚拟机。安装过程略\n\n2、tsung使用  \n$ tsung -f ./tsung/tsung.xml sta\n\n3、tusng.xml\n\n下面是我自己的tsung.xml\n\n        <?xml version=\"1.0\"?>\n    <!DOCTYPE tsung SYSTEM \"/usr/local/share/tsung/tsung-1.0.dtd\">\n    <!-- dumptraffic是调试模式，如果为true，就会打印详细的请求返回信息，一般设置为false， -->\n    <tsung loglevel=\"notice\" dumptraffic=\"false\" version=\"1.0\">\n    <!-- tsung所在的服务器，maxusers就是tsung产生的最大用户数 -->\n      <clients>\n    <client host=\"localhost\" use_controller_vm=\"true\"  maxusers=\"100000\" />\n      </clients>\n    <!-- 被测服务器的ip和端口号，type一般设为tcp ->\n      <servers>\n    <server host=\"@server\" port=\"@port\" type=\"tcp\"/>\n      </servers>\n    <!-- tsung产生的压力 -->\n    <load>\n    <!-- phase=\"1\" 第一阶段；duration：测试持续时间；unit：单位秒 -->\n    <arrivalphase phase=\"1\" duration=\"@duration\" unit=\"second\">\n    <!-- maxnumber：最大用户数；arrivalrate：每秒新增用户数；unit：单位秒-->\n      <users maxnumber=\"@maxuser\" arrivalrate=\"@user\" unit=\"second\"/>\n    </arrivalphase>\n      </load>\n    <!-- 外部变量 -->\n      <options>\n    <!-- 引入一个外部文件，类型为file_server，变量名为userfile，文件路径：/tmp/users-->\n    <!-- 文件是以逗号分隔的csv文件 -->\n    <option name=\"file_server\" id=\"userfile\" value=\"/tmp/users\"/>\n      </options>\n    <!-- 会话，每个用户都按照sessions中的配置发送请求 -->\n      <sessions>\n    <!--probability=“100”:这个session的请求概率是100%，如果要同时测多个api，可以设置请求概率；请求类型为http -->\n    <session name=\"test\" probability=\"100\" type=\"ts_http\">\n    <!-- 请求次数，to是最大请求数，如果设为100，就是每个用户请求100次 -->\n      <for from=\"1\" to=\"@loop\" incr=\"1\" var=\"counter\">\n    <!-- 解析前面引入的外部文件，以逗号做为分隔符，随机读取 -->\n    <setdynvars sourcetype=\"file\" fileid=\"userfile\" delimiter=\",\" order=\"random\">\n      <var name=\"user_id\" />\n      <var name=\"passwd\" />\n      <var name=\"auth_token\" />\n    </setdynvars>\n    <!-- 返回随机小数，变量名为decimal，code中可以写erlang函数 -->\n    <setdynvars sourcetype=\"eval\" code=\"fun({Pid,DynVars}) -> random:uniform() end.\">\n      <var name=\"decimal\" />\n    </setdynvars>\n    <!-- 返回随机数，从1到10000 -->\n    <setdynvars sourcetype=\"random_number\" start=\"1\" end=\"10000\">\n       <var name=\"int_1_10000\" />\n    </setdynvars>\n    <!-- 返回随机字符串，长度为10 -->\n    <setdynvars sourcetype=\"random_string\" length=\"10\">\n       <var name=\"string_10\" />\n    </setdynvars>\n    <!-- subst=\"true\"：如果在request中使用变量，需要设置subst -->\n    <request subst=\"true\">\n    <!-- url：被测试的url；method：GET、POST等；contents：POST请求的参数 -->\n      <http url=\"@api\" method=\"@method\" contents=\"@contents\" version=\"1.1\">\n    <!-- http header，可以添加Authorization、Cookie等，注意变量的使用格式：%%_xxx%% -->\n    <http_header name=\"Authorization\" value=\"111\"/>\n    <http_header name=\"Cookie\" value=\"authToken=%%_auth_token%%; Path=/\"/>\n    <!-- content-Type：POST请求参数的格式，如果是json格式可以这样写 -->\n    <http_header name=\"Content-Type\" value=\"application/json\"/>\n      </http>\n    </request>\n    <!-- thinktime：两次请求之间的间隔时间，一般小于10s -->\n    <thinktime value=\"1\"/>\n      </for>\n    </session>\n      </sessions>\n    </tsung> \n  \n\n如果被测接口需要登录跳转，可以指明跳转条件：   \n \n\n    <!-- if need login, http 302 will be return -->\n    <request subst=\"true\">\n      <dyn_variable name=\"redirect1\" re=\"Location: ((http|https)://.*)\\r\"/>\n      <http url=\"@api\" method=\"@method\" contents=\"@contents\" version=\"1.1\"></http>\n    </request>\n    \n    <if var=\"redirect1\" neq=\"\">\n      <request subst=\"true\">\n    <!-- 这里可以使用xpath提取页面中的元素值 -->\n    <dyn_variable name=\"lt\" xpath=\"//input[@name='lt']/@value\"/>\n    <dyn_variable name=\"s_uuid\" xpath=\"//input[@name='s_uuid']/@value\"/>\n    <dyn_variable name=\"eventId\" xpath=\"//input[@name='_eventId']/@value\"/>\n    <http url=\"%%_redirect1%%\" method=\"GET\"></http>\n      </request>\n    \n      <request subst=\"true\">\n    <dyn_variable name=\"redirect2\" re=\"Location: (http://.*)\\r\"/>\n    <http url=\"%%_redirect1%%\" method=\"POST\" contents=\"username=%%_username%%&amp;password=%%_password%%&amp;lt=%%_lt%%&amp;s_uuid=%%_s_uuid%%&amp;_eventId=%%_eventId%%&amp;j_captcha_response=''\"></http>\n      </request>\n    \n      <request subst=\"true\">\n    <dyn_variable name=\"redirect3\" re=\"Location: (http://.*)\\r\"/>\n    <http url=\"%%_redirect2%%\" method=\"GET\"></http>\n      </request>\n    \n      <request subst=\"true\">\n    <http url=\"%%_redirect3%%\" method=\"@method\" contents=\"@contents\"></http>\n      </request>\n    </if>\n    \n\n4、通过shell控制tsung\n\n如果每次使用tsung -f tsung.xml start运行tsung，那么每次修改测试接口或者压力改变都需要修改xml，非常麻烦，我写了一个shell脚本，替换上面的tsung.xml中以@开头的变量\n\n    #!/bin/bash\n    defaultTestFile=\"$HOME/tsung_test.xml\"\n    defaultUser=20\n    defaultDuration=100\n    # s\n    defaultThinktime=1\n    defaultServer=\"tomcat1\"\n    defaultPort=9000\n    defaultApi=\"/test\"\n    defaultMethod=\"POST\"\n    defaultLoopCount=50\n    defaultMaxuser=5000\n    \n    while [ $# -gt 0 ]; do\n      case \"$1\" in\n    -f|--testFile)\n    testFile=$2\n    shift \n    shift ;;\n    -u|--user)\n    user=$2\n    shift \n    shift ;;\n    -d|--duration)\n    duration=$2\n    shift \n    shift ;;\n    -t|--thinktime)\n    thinktime=$2\n    shift \n    shift ;;\n    -s|--server)\n    server=$2\n    shift \n    shift ;;\n    -p|--port)\n    port=$2\n    shift \n    shift ;;\n    -a|--api)\n    api=$2\n    shift \n    shift ;;\n    -m|--method)\n    method=$2\n    shift \n    shift ;;\n    -l|--loopCount)\n    loopCount=$2\n    shift \n    shift ;;\n    -x|--maxuser)\n    maxuser=$2\n    shift \n    shift ;;\n    -h|--help)\n    echo \"-f | --testFile: tsung test file xml,default $defaultTestFile\"\n    echo \"-u | --user: user number per second, default $defaultUser\"\n    echo \"-x | --maxuser: max user number, default $defaultMaxuser\"\n    echo \"-d | --duration: times used to generate user,default $defaultDuration s\"\n    echo \"-t | --thinktime: the inteval time between two request,default $defaultThinktime s\"\n    echo \"-l | --loopCount: Each user's request number,default $defaultLoopCount\"\n    echo \"-s | --server: play server,default $defaultServer\"\n    echo \"-p | --port: play server http port,default $defaultPort\"\n    echo \"-a | --api: api, default $defaultApi\"\n    echo \"-m | --method: POST/GET,default $defaultMethod\"\n    echo \"-h | --help: print this help\"\n    shift\n    exit 1\n    ;;\n    --)\n      shift\n      break\n      ;;\n    *)\n      echo \"wrong input:$1,use -h or --help see how to use\" 1>&2\n      exit 1\n      ;;\n      esac\n    done\n    \n    processName=\"tsung\"\n    pid=`ps aux | grep $processName | grep -v grep | awk '{print $2}'`\n    #convert from string to array\n    pid=($pid)\n    if [ ${#pid[*]} -gt 3 ]; then\n      echo \"warning!!! a $processName process is running,please wait\"\n      exit 1\n    fi\n    \n    #env\n    #set default parameters\n    testFile=${testFile:=$defaultTestFile}\n    user=${user:=$defaultUser}\n    duration=${duration:=$defaultDuration}\n    thinktime=${thinktime:=$defaultThinktime}\n    server=${server:=$defaultServer}\n    port=${port:=$defaultPort}\n    api=${api:=$defaultApi}\n    method=${method:=$defaultMethod}\n    loopCount=${loopCount:=$defaultLoopCount}\n    maxuser=${maxuser:=$defaultMaxuser}\n    \n    #key of params is nodname in tusng_test.xml file\n    declare -A params\n    params=( \\\n      [\"user\"]=$user \\\n      [\"maxuser\"]=$maxuser \\\n      [\"duration\"]=$duration \\\n      [\"thinktime\"]=$thinktime \\\n      [\"server\"]=$server \\\n      [\"port\"]=$port \\\n      [\"api\"]=$api \\\n      [\"method\"]=$method \\\n      [\"loopCount\"]=$loopCount \\\n      )\n    reportPath=\"$HOME/.tsung/log\"\n    currentTest=`date +%Y%m%d-%H%M`\n    reportPath=\"$reportPath/$currentTest\"\n    mkdir -p $reportPath\n    #deal with jmx file\n    cp $testFile $reportPath\n    currentTestFile=\"$reportPath/tsung_test.xml\"\n    function replace(){\n      echo \"$1:$2\" | tee -a \"$reportPath/test.env\"\n      #change / to \\/ for sed \n      local val=${2//\\//\\\\\\/}\n      sed -i \"s/@${1}/${val}/\" $currentTestFile\n    }\n    for key in ${!params[*]}\n    do\n      replace $key ${params[$key]}\n    done\n    #start tsung \n    tsung -f $currentTestFile start &\n    wait %1\n    cd $reportPath\n    /usr/local/lib/tsung/bin/tsung_stats.pl\n\n\n5、tsung结果分析\n\ntsung生成的测试报告都放在$HOME/.tsung/log下，以日期加时间的方式命名，如：`.tsung/log/20150407-1951`，其中最重要的几张图是\n\n- tsung产生的用户数曲线图 .tsung/log/20150407-1951/images/graphes-Users-simultaneous.png\n ![](http://static.oschina.net/uploads/space/2015/0706/135050_sSxO_780347.png)\n\nY轴代表每秒用户数，tsung每秒会产生一批用户，这个统计结果是每十秒统计一次，所有的图的起始位置显示的是0，其实是第一个10秒\n\n\n- http接口响应数曲线图（TPS） .tsung/log/20150407-1951/images/graphes-HTTP_CODE-rate.png\n ![](http://static.oschina.net/uploads/space/2015/0706/135106_dKTc_780347.png)\n \n Y轴是每秒响应数，右上角的200是http状态码，如果有多个状态码，会有多条不同颜色的曲线。\n\n- http接口响应时间曲线图 .tsung/log/20150407-1951/images/graphes-Perfs-mean.png\n\n![](http://static.oschina.net/uploads/space/2015/0706/135120_sPqf_780347.png)\n\n  Y轴是接口响应时间，单位是毫秒，request的线代表请求响应总耗时，connect的线代表tcp链接建立的时间。\n\n6、主要统计信息  \nTsung统计数据是平均每十秒重置一次，所以这里的响应时间（连接、请求、页面、会话）是指每十秒的平均响应时间；  \nconnect： 表示 每个连接持续时间；  \nHightest 10sec mean\t连接最长持续时间  \nLowest 10sec mean\t连接最短持续时间  \nHighest rate \t每秒最高建立连接速率  \nMean\t平均每个连接持续时间  \nCount\t总连接数  \npage： 表示 每个请求集合的响应时间,（一个页面表示一组没有被thinktime间隔的请求）  \nrequest： 表示 每个请求的响应时间；  \nHightest 10sec mean\t请求最长响应时间  \nLowest 10sec mean\t请求最短响应时间  \nHighest rate \t请求最快发送速率  \nMean\t平均每个请求响应时间  \nCount\t总请求数  \nsession： 表示 每个用户会话持续时间；  \nHightest 10sec mean\t会话最长持续时间  \nLowest 10sec mean\t会话最短持续时间  \nHighest rate \t每秒最高进行会话速率  \nMean\t平均每个会话持续时间  \nCount\t总会话数  \n \n7、数据流量统计  \nsize_rcv: 表示 响应请求数据量  \nsize_sent:表示 发送请求数据量  \nHightest rate\t每秒最高 响应/发送 请求数据量  \nTotal \t响应/发送 请求总数据量  \n \n8、计数统计  \nconnected\t表示会话开始且尚未结束，并且已建立连接的最大用户数  \nfinished_user_count\t表示已经完成会话的最大用户数  \nusers\t表示会话开始且尚未结束的最大用户数  \nusers_count\t表示Tsung总共生成的用户总数  \n \n9、错误统计  \nError_abort_max_conn_retries\t重新尝试连接错误  \nError_connect_timeout\t连接超时错误  \nError_connect_nxdomain\t不存在的域错误  \nError_unknown\t位置错误  \n \nHighest rate \t发生错误最高速率  \nTotal number\t发生该错误总个数  \n   \n10、http返回状态码统计  \n200：表示客户端请求已成功响应  \nHighest rate\t状态码返回最高速率  \nTotal number\t返回状态码的总个数  \n","source":"_posts/tsung说明文档.md","raw":"---\ntitle: tsung使用说明\ndate: 2017-01-08\ntags: tsung\ncategories: tsung\n---\n\n1、tsung安装\n\ntsung 一个非常优秀的压力测试工具，在8核32G机器上可以轻易的产生每秒10000个并发请求，且占用的资源很少，当前版本1.5.0\n<!--more-->\n使用erlang开发，需要先安装erlang虚拟机。安装过程略\n\n2、tsung使用  \n$ tsung -f ./tsung/tsung.xml sta\n\n3、tusng.xml\n\n下面是我自己的tsung.xml\n\n        <?xml version=\"1.0\"?>\n    <!DOCTYPE tsung SYSTEM \"/usr/local/share/tsung/tsung-1.0.dtd\">\n    <!-- dumptraffic是调试模式，如果为true，就会打印详细的请求返回信息，一般设置为false， -->\n    <tsung loglevel=\"notice\" dumptraffic=\"false\" version=\"1.0\">\n    <!-- tsung所在的服务器，maxusers就是tsung产生的最大用户数 -->\n      <clients>\n    <client host=\"localhost\" use_controller_vm=\"true\"  maxusers=\"100000\" />\n      </clients>\n    <!-- 被测服务器的ip和端口号，type一般设为tcp ->\n      <servers>\n    <server host=\"@server\" port=\"@port\" type=\"tcp\"/>\n      </servers>\n    <!-- tsung产生的压力 -->\n    <load>\n    <!-- phase=\"1\" 第一阶段；duration：测试持续时间；unit：单位秒 -->\n    <arrivalphase phase=\"1\" duration=\"@duration\" unit=\"second\">\n    <!-- maxnumber：最大用户数；arrivalrate：每秒新增用户数；unit：单位秒-->\n      <users maxnumber=\"@maxuser\" arrivalrate=\"@user\" unit=\"second\"/>\n    </arrivalphase>\n      </load>\n    <!-- 外部变量 -->\n      <options>\n    <!-- 引入一个外部文件，类型为file_server，变量名为userfile，文件路径：/tmp/users-->\n    <!-- 文件是以逗号分隔的csv文件 -->\n    <option name=\"file_server\" id=\"userfile\" value=\"/tmp/users\"/>\n      </options>\n    <!-- 会话，每个用户都按照sessions中的配置发送请求 -->\n      <sessions>\n    <!--probability=“100”:这个session的请求概率是100%，如果要同时测多个api，可以设置请求概率；请求类型为http -->\n    <session name=\"test\" probability=\"100\" type=\"ts_http\">\n    <!-- 请求次数，to是最大请求数，如果设为100，就是每个用户请求100次 -->\n      <for from=\"1\" to=\"@loop\" incr=\"1\" var=\"counter\">\n    <!-- 解析前面引入的外部文件，以逗号做为分隔符，随机读取 -->\n    <setdynvars sourcetype=\"file\" fileid=\"userfile\" delimiter=\",\" order=\"random\">\n      <var name=\"user_id\" />\n      <var name=\"passwd\" />\n      <var name=\"auth_token\" />\n    </setdynvars>\n    <!-- 返回随机小数，变量名为decimal，code中可以写erlang函数 -->\n    <setdynvars sourcetype=\"eval\" code=\"fun({Pid,DynVars}) -> random:uniform() end.\">\n      <var name=\"decimal\" />\n    </setdynvars>\n    <!-- 返回随机数，从1到10000 -->\n    <setdynvars sourcetype=\"random_number\" start=\"1\" end=\"10000\">\n       <var name=\"int_1_10000\" />\n    </setdynvars>\n    <!-- 返回随机字符串，长度为10 -->\n    <setdynvars sourcetype=\"random_string\" length=\"10\">\n       <var name=\"string_10\" />\n    </setdynvars>\n    <!-- subst=\"true\"：如果在request中使用变量，需要设置subst -->\n    <request subst=\"true\">\n    <!-- url：被测试的url；method：GET、POST等；contents：POST请求的参数 -->\n      <http url=\"@api\" method=\"@method\" contents=\"@contents\" version=\"1.1\">\n    <!-- http header，可以添加Authorization、Cookie等，注意变量的使用格式：%%_xxx%% -->\n    <http_header name=\"Authorization\" value=\"111\"/>\n    <http_header name=\"Cookie\" value=\"authToken=%%_auth_token%%; Path=/\"/>\n    <!-- content-Type：POST请求参数的格式，如果是json格式可以这样写 -->\n    <http_header name=\"Content-Type\" value=\"application/json\"/>\n      </http>\n    </request>\n    <!-- thinktime：两次请求之间的间隔时间，一般小于10s -->\n    <thinktime value=\"1\"/>\n      </for>\n    </session>\n      </sessions>\n    </tsung> \n  \n\n如果被测接口需要登录跳转，可以指明跳转条件：   \n \n\n    <!-- if need login, http 302 will be return -->\n    <request subst=\"true\">\n      <dyn_variable name=\"redirect1\" re=\"Location: ((http|https)://.*)\\r\"/>\n      <http url=\"@api\" method=\"@method\" contents=\"@contents\" version=\"1.1\"></http>\n    </request>\n    \n    <if var=\"redirect1\" neq=\"\">\n      <request subst=\"true\">\n    <!-- 这里可以使用xpath提取页面中的元素值 -->\n    <dyn_variable name=\"lt\" xpath=\"//input[@name='lt']/@value\"/>\n    <dyn_variable name=\"s_uuid\" xpath=\"//input[@name='s_uuid']/@value\"/>\n    <dyn_variable name=\"eventId\" xpath=\"//input[@name='_eventId']/@value\"/>\n    <http url=\"%%_redirect1%%\" method=\"GET\"></http>\n      </request>\n    \n      <request subst=\"true\">\n    <dyn_variable name=\"redirect2\" re=\"Location: (http://.*)\\r\"/>\n    <http url=\"%%_redirect1%%\" method=\"POST\" contents=\"username=%%_username%%&amp;password=%%_password%%&amp;lt=%%_lt%%&amp;s_uuid=%%_s_uuid%%&amp;_eventId=%%_eventId%%&amp;j_captcha_response=''\"></http>\n      </request>\n    \n      <request subst=\"true\">\n    <dyn_variable name=\"redirect3\" re=\"Location: (http://.*)\\r\"/>\n    <http url=\"%%_redirect2%%\" method=\"GET\"></http>\n      </request>\n    \n      <request subst=\"true\">\n    <http url=\"%%_redirect3%%\" method=\"@method\" contents=\"@contents\"></http>\n      </request>\n    </if>\n    \n\n4、通过shell控制tsung\n\n如果每次使用tsung -f tsung.xml start运行tsung，那么每次修改测试接口或者压力改变都需要修改xml，非常麻烦，我写了一个shell脚本，替换上面的tsung.xml中以@开头的变量\n\n    #!/bin/bash\n    defaultTestFile=\"$HOME/tsung_test.xml\"\n    defaultUser=20\n    defaultDuration=100\n    # s\n    defaultThinktime=1\n    defaultServer=\"tomcat1\"\n    defaultPort=9000\n    defaultApi=\"/test\"\n    defaultMethod=\"POST\"\n    defaultLoopCount=50\n    defaultMaxuser=5000\n    \n    while [ $# -gt 0 ]; do\n      case \"$1\" in\n    -f|--testFile)\n    testFile=$2\n    shift \n    shift ;;\n    -u|--user)\n    user=$2\n    shift \n    shift ;;\n    -d|--duration)\n    duration=$2\n    shift \n    shift ;;\n    -t|--thinktime)\n    thinktime=$2\n    shift \n    shift ;;\n    -s|--server)\n    server=$2\n    shift \n    shift ;;\n    -p|--port)\n    port=$2\n    shift \n    shift ;;\n    -a|--api)\n    api=$2\n    shift \n    shift ;;\n    -m|--method)\n    method=$2\n    shift \n    shift ;;\n    -l|--loopCount)\n    loopCount=$2\n    shift \n    shift ;;\n    -x|--maxuser)\n    maxuser=$2\n    shift \n    shift ;;\n    -h|--help)\n    echo \"-f | --testFile: tsung test file xml,default $defaultTestFile\"\n    echo \"-u | --user: user number per second, default $defaultUser\"\n    echo \"-x | --maxuser: max user number, default $defaultMaxuser\"\n    echo \"-d | --duration: times used to generate user,default $defaultDuration s\"\n    echo \"-t | --thinktime: the inteval time between two request,default $defaultThinktime s\"\n    echo \"-l | --loopCount: Each user's request number,default $defaultLoopCount\"\n    echo \"-s | --server: play server,default $defaultServer\"\n    echo \"-p | --port: play server http port,default $defaultPort\"\n    echo \"-a | --api: api, default $defaultApi\"\n    echo \"-m | --method: POST/GET,default $defaultMethod\"\n    echo \"-h | --help: print this help\"\n    shift\n    exit 1\n    ;;\n    --)\n      shift\n      break\n      ;;\n    *)\n      echo \"wrong input:$1,use -h or --help see how to use\" 1>&2\n      exit 1\n      ;;\n      esac\n    done\n    \n    processName=\"tsung\"\n    pid=`ps aux | grep $processName | grep -v grep | awk '{print $2}'`\n    #convert from string to array\n    pid=($pid)\n    if [ ${#pid[*]} -gt 3 ]; then\n      echo \"warning!!! a $processName process is running,please wait\"\n      exit 1\n    fi\n    \n    #env\n    #set default parameters\n    testFile=${testFile:=$defaultTestFile}\n    user=${user:=$defaultUser}\n    duration=${duration:=$defaultDuration}\n    thinktime=${thinktime:=$defaultThinktime}\n    server=${server:=$defaultServer}\n    port=${port:=$defaultPort}\n    api=${api:=$defaultApi}\n    method=${method:=$defaultMethod}\n    loopCount=${loopCount:=$defaultLoopCount}\n    maxuser=${maxuser:=$defaultMaxuser}\n    \n    #key of params is nodname in tusng_test.xml file\n    declare -A params\n    params=( \\\n      [\"user\"]=$user \\\n      [\"maxuser\"]=$maxuser \\\n      [\"duration\"]=$duration \\\n      [\"thinktime\"]=$thinktime \\\n      [\"server\"]=$server \\\n      [\"port\"]=$port \\\n      [\"api\"]=$api \\\n      [\"method\"]=$method \\\n      [\"loopCount\"]=$loopCount \\\n      )\n    reportPath=\"$HOME/.tsung/log\"\n    currentTest=`date +%Y%m%d-%H%M`\n    reportPath=\"$reportPath/$currentTest\"\n    mkdir -p $reportPath\n    #deal with jmx file\n    cp $testFile $reportPath\n    currentTestFile=\"$reportPath/tsung_test.xml\"\n    function replace(){\n      echo \"$1:$2\" | tee -a \"$reportPath/test.env\"\n      #change / to \\/ for sed \n      local val=${2//\\//\\\\\\/}\n      sed -i \"s/@${1}/${val}/\" $currentTestFile\n    }\n    for key in ${!params[*]}\n    do\n      replace $key ${params[$key]}\n    done\n    #start tsung \n    tsung -f $currentTestFile start &\n    wait %1\n    cd $reportPath\n    /usr/local/lib/tsung/bin/tsung_stats.pl\n\n\n5、tsung结果分析\n\ntsung生成的测试报告都放在$HOME/.tsung/log下，以日期加时间的方式命名，如：`.tsung/log/20150407-1951`，其中最重要的几张图是\n\n- tsung产生的用户数曲线图 .tsung/log/20150407-1951/images/graphes-Users-simultaneous.png\n ![](http://static.oschina.net/uploads/space/2015/0706/135050_sSxO_780347.png)\n\nY轴代表每秒用户数，tsung每秒会产生一批用户，这个统计结果是每十秒统计一次，所有的图的起始位置显示的是0，其实是第一个10秒\n\n\n- http接口响应数曲线图（TPS） .tsung/log/20150407-1951/images/graphes-HTTP_CODE-rate.png\n ![](http://static.oschina.net/uploads/space/2015/0706/135106_dKTc_780347.png)\n \n Y轴是每秒响应数，右上角的200是http状态码，如果有多个状态码，会有多条不同颜色的曲线。\n\n- http接口响应时间曲线图 .tsung/log/20150407-1951/images/graphes-Perfs-mean.png\n\n![](http://static.oschina.net/uploads/space/2015/0706/135120_sPqf_780347.png)\n\n  Y轴是接口响应时间，单位是毫秒，request的线代表请求响应总耗时，connect的线代表tcp链接建立的时间。\n\n6、主要统计信息  \nTsung统计数据是平均每十秒重置一次，所以这里的响应时间（连接、请求、页面、会话）是指每十秒的平均响应时间；  \nconnect： 表示 每个连接持续时间；  \nHightest 10sec mean\t连接最长持续时间  \nLowest 10sec mean\t连接最短持续时间  \nHighest rate \t每秒最高建立连接速率  \nMean\t平均每个连接持续时间  \nCount\t总连接数  \npage： 表示 每个请求集合的响应时间,（一个页面表示一组没有被thinktime间隔的请求）  \nrequest： 表示 每个请求的响应时间；  \nHightest 10sec mean\t请求最长响应时间  \nLowest 10sec mean\t请求最短响应时间  \nHighest rate \t请求最快发送速率  \nMean\t平均每个请求响应时间  \nCount\t总请求数  \nsession： 表示 每个用户会话持续时间；  \nHightest 10sec mean\t会话最长持续时间  \nLowest 10sec mean\t会话最短持续时间  \nHighest rate \t每秒最高进行会话速率  \nMean\t平均每个会话持续时间  \nCount\t总会话数  \n \n7、数据流量统计  \nsize_rcv: 表示 响应请求数据量  \nsize_sent:表示 发送请求数据量  \nHightest rate\t每秒最高 响应/发送 请求数据量  \nTotal \t响应/发送 请求总数据量  \n \n8、计数统计  \nconnected\t表示会话开始且尚未结束，并且已建立连接的最大用户数  \nfinished_user_count\t表示已经完成会话的最大用户数  \nusers\t表示会话开始且尚未结束的最大用户数  \nusers_count\t表示Tsung总共生成的用户总数  \n \n9、错误统计  \nError_abort_max_conn_retries\t重新尝试连接错误  \nError_connect_timeout\t连接超时错误  \nError_connect_nxdomain\t不存在的域错误  \nError_unknown\t位置错误  \n \nHighest rate \t发生错误最高速率  \nTotal number\t发生该错误总个数  \n   \n10、http返回状态码统计  \n200：表示客户端请求已成功响应  \nHighest rate\t状态码返回最高速率  \nTotal number\t返回状态码的总个数  \n","slug":"tsung说明文档","published":1,"updated":"2019-06-18T08:07:01.117Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9smq0024hcb7m8le2go9","content":"<p>1、tsung安装</p>\n<p>tsung 一个非常优秀的压力测试工具，在8核32G机器上可以轻易的产生每秒10000个并发请求，且占用的资源很少，当前版本1.5.0<br><a id=\"more\"></a><br>使用erlang开发，需要先安装erlang虚拟机。安装过程略</p>\n<p>2、tsung使用<br>$ tsung -f ./tsung/tsung.xml sta</p>\n<p>3、tusng.xml</p>\n<p>下面是我自己的tsung.xml</p>\n<pre><code>    &lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!DOCTYPE tsung SYSTEM &quot;/usr/local/share/tsung/tsung-1.0.dtd&quot;&gt;\n&lt;!-- dumptraffic是调试模式，如果为true，就会打印详细的请求返回信息，一般设置为false， --&gt;\n&lt;tsung loglevel=&quot;notice&quot; dumptraffic=&quot;false&quot; version=&quot;1.0&quot;&gt;\n&lt;!-- tsung所在的服务器，maxusers就是tsung产生的最大用户数 --&gt;\n  &lt;clients&gt;\n&lt;client host=&quot;localhost&quot; use_controller_vm=&quot;true&quot;  maxusers=&quot;100000&quot; /&gt;\n  &lt;/clients&gt;\n&lt;!-- 被测服务器的ip和端口号，type一般设为tcp -&gt;\n  &lt;servers&gt;\n&lt;server host=&quot;@server&quot; port=&quot;@port&quot; type=&quot;tcp&quot;/&gt;\n  &lt;/servers&gt;\n&lt;!-- tsung产生的压力 --&gt;\n&lt;load&gt;\n&lt;!-- phase=&quot;1&quot; 第一阶段；duration：测试持续时间；unit：单位秒 --&gt;\n&lt;arrivalphase phase=&quot;1&quot; duration=&quot;@duration&quot; unit=&quot;second&quot;&gt;\n&lt;!-- maxnumber：最大用户数；arrivalrate：每秒新增用户数；unit：单位秒--&gt;\n  &lt;users maxnumber=&quot;@maxuser&quot; arrivalrate=&quot;@user&quot; unit=&quot;second&quot;/&gt;\n&lt;/arrivalphase&gt;\n  &lt;/load&gt;\n&lt;!-- 外部变量 --&gt;\n  &lt;options&gt;\n&lt;!-- 引入一个外部文件，类型为file_server，变量名为userfile，文件路径：/tmp/users--&gt;\n&lt;!-- 文件是以逗号分隔的csv文件 --&gt;\n&lt;option name=&quot;file_server&quot; id=&quot;userfile&quot; value=&quot;/tmp/users&quot;/&gt;\n  &lt;/options&gt;\n&lt;!-- 会话，每个用户都按照sessions中的配置发送请求 --&gt;\n  &lt;sessions&gt;\n&lt;!--probability=“100”:这个session的请求概率是100%，如果要同时测多个api，可以设置请求概率；请求类型为http --&gt;\n&lt;session name=&quot;test&quot; probability=&quot;100&quot; type=&quot;ts_http&quot;&gt;\n&lt;!-- 请求次数，to是最大请求数，如果设为100，就是每个用户请求100次 --&gt;\n  &lt;for from=&quot;1&quot; to=&quot;@loop&quot; incr=&quot;1&quot; var=&quot;counter&quot;&gt;\n&lt;!-- 解析前面引入的外部文件，以逗号做为分隔符，随机读取 --&gt;\n&lt;setdynvars sourcetype=&quot;file&quot; fileid=&quot;userfile&quot; delimiter=&quot;,&quot; order=&quot;random&quot;&gt;\n  &lt;var name=&quot;user_id&quot; /&gt;\n  &lt;var name=&quot;passwd&quot; /&gt;\n  &lt;var name=&quot;auth_token&quot; /&gt;\n&lt;/setdynvars&gt;\n&lt;!-- 返回随机小数，变量名为decimal，code中可以写erlang函数 --&gt;\n&lt;setdynvars sourcetype=&quot;eval&quot; code=&quot;fun({Pid,DynVars}) -&gt; random:uniform() end.&quot;&gt;\n  &lt;var name=&quot;decimal&quot; /&gt;\n&lt;/setdynvars&gt;\n&lt;!-- 返回随机数，从1到10000 --&gt;\n&lt;setdynvars sourcetype=&quot;random_number&quot; start=&quot;1&quot; end=&quot;10000&quot;&gt;\n   &lt;var name=&quot;int_1_10000&quot; /&gt;\n&lt;/setdynvars&gt;\n&lt;!-- 返回随机字符串，长度为10 --&gt;\n&lt;setdynvars sourcetype=&quot;random_string&quot; length=&quot;10&quot;&gt;\n   &lt;var name=&quot;string_10&quot; /&gt;\n&lt;/setdynvars&gt;\n&lt;!-- subst=&quot;true&quot;：如果在request中使用变量，需要设置subst --&gt;\n&lt;request subst=&quot;true&quot;&gt;\n&lt;!-- url：被测试的url；method：GET、POST等；contents：POST请求的参数 --&gt;\n  &lt;http url=&quot;@api&quot; method=&quot;@method&quot; contents=&quot;@contents&quot; version=&quot;1.1&quot;&gt;\n&lt;!-- http header，可以添加Authorization、Cookie等，注意变量的使用格式：%%_xxx%% --&gt;\n&lt;http_header name=&quot;Authorization&quot; value=&quot;111&quot;/&gt;\n&lt;http_header name=&quot;Cookie&quot; value=&quot;authToken=%%_auth_token%%; Path=/&quot;/&gt;\n&lt;!-- content-Type：POST请求参数的格式，如果是json格式可以这样写 --&gt;\n&lt;http_header name=&quot;Content-Type&quot; value=&quot;application/json&quot;/&gt;\n  &lt;/http&gt;\n&lt;/request&gt;\n&lt;!-- thinktime：两次请求之间的间隔时间，一般小于10s --&gt;\n&lt;thinktime value=&quot;1&quot;/&gt;\n  &lt;/for&gt;\n&lt;/session&gt;\n  &lt;/sessions&gt;\n&lt;/tsung&gt; \n</code></pre><p>如果被测接口需要登录跳转，可以指明跳转条件：   </p>\n<pre><code>&lt;!-- if need login, http 302 will be return --&gt;\n&lt;request subst=&quot;true&quot;&gt;\n  &lt;dyn_variable name=&quot;redirect1&quot; re=&quot;Location: ((http|https)://.*)\\r&quot;/&gt;\n  &lt;http url=&quot;@api&quot; method=&quot;@method&quot; contents=&quot;@contents&quot; version=&quot;1.1&quot;&gt;&lt;/http&gt;\n&lt;/request&gt;\n\n&lt;if var=&quot;redirect1&quot; neq=&quot;&quot;&gt;\n  &lt;request subst=&quot;true&quot;&gt;\n&lt;!-- 这里可以使用xpath提取页面中的元素值 --&gt;\n&lt;dyn_variable name=&quot;lt&quot; xpath=&quot;//input[@name=&apos;lt&apos;]/@value&quot;/&gt;\n&lt;dyn_variable name=&quot;s_uuid&quot; xpath=&quot;//input[@name=&apos;s_uuid&apos;]/@value&quot;/&gt;\n&lt;dyn_variable name=&quot;eventId&quot; xpath=&quot;//input[@name=&apos;_eventId&apos;]/@value&quot;/&gt;\n&lt;http url=&quot;%%_redirect1%%&quot; method=&quot;GET&quot;&gt;&lt;/http&gt;\n  &lt;/request&gt;\n\n  &lt;request subst=&quot;true&quot;&gt;\n&lt;dyn_variable name=&quot;redirect2&quot; re=&quot;Location: (http://.*)\\r&quot;/&gt;\n&lt;http url=&quot;%%_redirect1%%&quot; method=&quot;POST&quot; contents=&quot;username=%%_username%%&amp;amp;password=%%_password%%&amp;amp;lt=%%_lt%%&amp;amp;s_uuid=%%_s_uuid%%&amp;amp;_eventId=%%_eventId%%&amp;amp;j_captcha_response=&apos;&apos;&quot;&gt;&lt;/http&gt;\n  &lt;/request&gt;\n\n  &lt;request subst=&quot;true&quot;&gt;\n&lt;dyn_variable name=&quot;redirect3&quot; re=&quot;Location: (http://.*)\\r&quot;/&gt;\n&lt;http url=&quot;%%_redirect2%%&quot; method=&quot;GET&quot;&gt;&lt;/http&gt;\n  &lt;/request&gt;\n\n  &lt;request subst=&quot;true&quot;&gt;\n&lt;http url=&quot;%%_redirect3%%&quot; method=&quot;@method&quot; contents=&quot;@contents&quot;&gt;&lt;/http&gt;\n  &lt;/request&gt;\n&lt;/if&gt;\n</code></pre><p>4、通过shell控制tsung</p>\n<p>如果每次使用tsung -f tsung.xml start运行tsung，那么每次修改测试接口或者压力改变都需要修改xml，非常麻烦，我写了一个shell脚本，替换上面的tsung.xml中以@开头的变量</p>\n<pre><code>#!/bin/bash\ndefaultTestFile=&quot;$HOME/tsung_test.xml&quot;\ndefaultUser=20\ndefaultDuration=100\n# s\ndefaultThinktime=1\ndefaultServer=&quot;tomcat1&quot;\ndefaultPort=9000\ndefaultApi=&quot;/test&quot;\ndefaultMethod=&quot;POST&quot;\ndefaultLoopCount=50\ndefaultMaxuser=5000\n\nwhile [ $# -gt 0 ]; do\n  case &quot;$1&quot; in\n-f|--testFile)\ntestFile=$2\nshift \nshift ;;\n-u|--user)\nuser=$2\nshift \nshift ;;\n-d|--duration)\nduration=$2\nshift \nshift ;;\n-t|--thinktime)\nthinktime=$2\nshift \nshift ;;\n-s|--server)\nserver=$2\nshift \nshift ;;\n-p|--port)\nport=$2\nshift \nshift ;;\n-a|--api)\napi=$2\nshift \nshift ;;\n-m|--method)\nmethod=$2\nshift \nshift ;;\n-l|--loopCount)\nloopCount=$2\nshift \nshift ;;\n-x|--maxuser)\nmaxuser=$2\nshift \nshift ;;\n-h|--help)\necho &quot;-f | --testFile: tsung test file xml,default $defaultTestFile&quot;\necho &quot;-u | --user: user number per second, default $defaultUser&quot;\necho &quot;-x | --maxuser: max user number, default $defaultMaxuser&quot;\necho &quot;-d | --duration: times used to generate user,default $defaultDuration s&quot;\necho &quot;-t | --thinktime: the inteval time between two request,default $defaultThinktime s&quot;\necho &quot;-l | --loopCount: Each user&apos;s request number,default $defaultLoopCount&quot;\necho &quot;-s | --server: play server,default $defaultServer&quot;\necho &quot;-p | --port: play server http port,default $defaultPort&quot;\necho &quot;-a | --api: api, default $defaultApi&quot;\necho &quot;-m | --method: POST/GET,default $defaultMethod&quot;\necho &quot;-h | --help: print this help&quot;\nshift\nexit 1\n;;\n--)\n  shift\n  break\n  ;;\n*)\n  echo &quot;wrong input:$1,use -h or --help see how to use&quot; 1&gt;&amp;2\n  exit 1\n  ;;\n  esac\ndone\n\nprocessName=&quot;tsung&quot;\npid=`ps aux | grep $processName | grep -v grep | awk &apos;{print $2}&apos;`\n#convert from string to array\npid=($pid)\nif [ ${#pid[*]} -gt 3 ]; then\n  echo &quot;warning!!! a $processName process is running,please wait&quot;\n  exit 1\nfi\n\n#env\n#set default parameters\ntestFile=${testFile:=$defaultTestFile}\nuser=${user:=$defaultUser}\nduration=${duration:=$defaultDuration}\nthinktime=${thinktime:=$defaultThinktime}\nserver=${server:=$defaultServer}\nport=${port:=$defaultPort}\napi=${api:=$defaultApi}\nmethod=${method:=$defaultMethod}\nloopCount=${loopCount:=$defaultLoopCount}\nmaxuser=${maxuser:=$defaultMaxuser}\n\n#key of params is nodname in tusng_test.xml file\ndeclare -A params\nparams=( \\\n  [&quot;user&quot;]=$user \\\n  [&quot;maxuser&quot;]=$maxuser \\\n  [&quot;duration&quot;]=$duration \\\n  [&quot;thinktime&quot;]=$thinktime \\\n  [&quot;server&quot;]=$server \\\n  [&quot;port&quot;]=$port \\\n  [&quot;api&quot;]=$api \\\n  [&quot;method&quot;]=$method \\\n  [&quot;loopCount&quot;]=$loopCount \\\n  )\nreportPath=&quot;$HOME/.tsung/log&quot;\ncurrentTest=`date +%Y%m%d-%H%M`\nreportPath=&quot;$reportPath/$currentTest&quot;\nmkdir -p $reportPath\n#deal with jmx file\ncp $testFile $reportPath\ncurrentTestFile=&quot;$reportPath/tsung_test.xml&quot;\nfunction replace(){\n  echo &quot;$1:$2&quot; | tee -a &quot;$reportPath/test.env&quot;\n  #change / to \\/ for sed \n  local val=${2//\\//\\\\\\/}\n  sed -i &quot;s/@${1}/${val}/&quot; $currentTestFile\n}\nfor key in ${!params[*]}\ndo\n  replace $key ${params[$key]}\ndone\n#start tsung \ntsung -f $currentTestFile start &amp;\nwait %1\ncd $reportPath\n/usr/local/lib/tsung/bin/tsung_stats.pl\n</code></pre><p>5、tsung结果分析</p>\n<p>tsung生成的测试报告都放在$HOME/.tsung/log下，以日期加时间的方式命名，如：<code>.tsung/log/20150407-1951</code>，其中最重要的几张图是</p>\n<ul>\n<li>tsung产生的用户数曲线图 .tsung/log/20150407-1951/images/graphes-Users-simultaneous.png<br><img src=\"http://static.oschina.net/uploads/space/2015/0706/135050_sSxO_780347.png\" alt=\"\"></li>\n</ul>\n<p>Y轴代表每秒用户数，tsung每秒会产生一批用户，这个统计结果是每十秒统计一次，所有的图的起始位置显示的是0，其实是第一个10秒</p>\n<ul>\n<li><p>http接口响应数曲线图（TPS） .tsung/log/20150407-1951/images/graphes-HTTP_CODE-rate.png<br><img src=\"http://static.oschina.net/uploads/space/2015/0706/135106_dKTc_780347.png\" alt=\"\"></p>\n<p>Y轴是每秒响应数，右上角的200是http状态码，如果有多个状态码，会有多条不同颜色的曲线。</p>\n</li>\n<li><p>http接口响应时间曲线图 .tsung/log/20150407-1951/images/graphes-Perfs-mean.png</p>\n</li>\n</ul>\n<p><img src=\"http://static.oschina.net/uploads/space/2015/0706/135120_sPqf_780347.png\" alt=\"\"></p>\n<p>  Y轴是接口响应时间，单位是毫秒，request的线代表请求响应总耗时，connect的线代表tcp链接建立的时间。</p>\n<p>6、主要统计信息<br>Tsung统计数据是平均每十秒重置一次，所以这里的响应时间（连接、请求、页面、会话）是指每十秒的平均响应时间；<br>connect： 表示 每个连接持续时间；<br>Hightest 10sec mean    连接最长持续时间<br>Lowest 10sec mean    连接最短持续时间<br>Highest rate     每秒最高建立连接速率<br>Mean    平均每个连接持续时间<br>Count    总连接数<br>page： 表示 每个请求集合的响应时间,（一个页面表示一组没有被thinktime间隔的请求）<br>request： 表示 每个请求的响应时间；<br>Hightest 10sec mean    请求最长响应时间<br>Lowest 10sec mean    请求最短响应时间<br>Highest rate     请求最快发送速率<br>Mean    平均每个请求响应时间<br>Count    总请求数<br>session： 表示 每个用户会话持续时间；<br>Hightest 10sec mean    会话最长持续时间<br>Lowest 10sec mean    会话最短持续时间<br>Highest rate     每秒最高进行会话速率<br>Mean    平均每个会话持续时间<br>Count    总会话数  </p>\n<p>7、数据流量统计<br>size_rcv: 表示 响应请求数据量<br>size_sent:表示 发送请求数据量<br>Hightest rate    每秒最高 响应/发送 请求数据量<br>Total     响应/发送 请求总数据量  </p>\n<p>8、计数统计<br>connected    表示会话开始且尚未结束，并且已建立连接的最大用户数<br>finished_user_count    表示已经完成会话的最大用户数<br>users    表示会话开始且尚未结束的最大用户数<br>users_count    表示Tsung总共生成的用户总数  </p>\n<p>9、错误统计<br>Error_abort_max_conn_retries    重新尝试连接错误<br>Error_connect_timeout    连接超时错误<br>Error_connect_nxdomain    不存在的域错误<br>Error_unknown    位置错误  </p>\n<p>Highest rate     发生错误最高速率<br>Total number    发生该错误总个数  </p>\n<p>10、http返回状态码统计<br>200：表示客户端请求已成功响应<br>Highest rate    状态码返回最高速率<br>Total number    返回状态码的总个数  </p>\n","site":{"data":{}},"excerpt":"<p>1、tsung安装</p>\n<p>tsung 一个非常优秀的压力测试工具，在8核32G机器上可以轻易的产生每秒10000个并发请求，且占用的资源很少，当前版本1.5.0<br>","more":"<br>使用erlang开发，需要先安装erlang虚拟机。安装过程略</p>\n<p>2、tsung使用<br>$ tsung -f ./tsung/tsung.xml sta</p>\n<p>3、tusng.xml</p>\n<p>下面是我自己的tsung.xml</p>\n<pre><code>    &lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!DOCTYPE tsung SYSTEM &quot;/usr/local/share/tsung/tsung-1.0.dtd&quot;&gt;\n&lt;!-- dumptraffic是调试模式，如果为true，就会打印详细的请求返回信息，一般设置为false， --&gt;\n&lt;tsung loglevel=&quot;notice&quot; dumptraffic=&quot;false&quot; version=&quot;1.0&quot;&gt;\n&lt;!-- tsung所在的服务器，maxusers就是tsung产生的最大用户数 --&gt;\n  &lt;clients&gt;\n&lt;client host=&quot;localhost&quot; use_controller_vm=&quot;true&quot;  maxusers=&quot;100000&quot; /&gt;\n  &lt;/clients&gt;\n&lt;!-- 被测服务器的ip和端口号，type一般设为tcp -&gt;\n  &lt;servers&gt;\n&lt;server host=&quot;@server&quot; port=&quot;@port&quot; type=&quot;tcp&quot;/&gt;\n  &lt;/servers&gt;\n&lt;!-- tsung产生的压力 --&gt;\n&lt;load&gt;\n&lt;!-- phase=&quot;1&quot; 第一阶段；duration：测试持续时间；unit：单位秒 --&gt;\n&lt;arrivalphase phase=&quot;1&quot; duration=&quot;@duration&quot; unit=&quot;second&quot;&gt;\n&lt;!-- maxnumber：最大用户数；arrivalrate：每秒新增用户数；unit：单位秒--&gt;\n  &lt;users maxnumber=&quot;@maxuser&quot; arrivalrate=&quot;@user&quot; unit=&quot;second&quot;/&gt;\n&lt;/arrivalphase&gt;\n  &lt;/load&gt;\n&lt;!-- 外部变量 --&gt;\n  &lt;options&gt;\n&lt;!-- 引入一个外部文件，类型为file_server，变量名为userfile，文件路径：/tmp/users--&gt;\n&lt;!-- 文件是以逗号分隔的csv文件 --&gt;\n&lt;option name=&quot;file_server&quot; id=&quot;userfile&quot; value=&quot;/tmp/users&quot;/&gt;\n  &lt;/options&gt;\n&lt;!-- 会话，每个用户都按照sessions中的配置发送请求 --&gt;\n  &lt;sessions&gt;\n&lt;!--probability=“100”:这个session的请求概率是100%，如果要同时测多个api，可以设置请求概率；请求类型为http --&gt;\n&lt;session name=&quot;test&quot; probability=&quot;100&quot; type=&quot;ts_http&quot;&gt;\n&lt;!-- 请求次数，to是最大请求数，如果设为100，就是每个用户请求100次 --&gt;\n  &lt;for from=&quot;1&quot; to=&quot;@loop&quot; incr=&quot;1&quot; var=&quot;counter&quot;&gt;\n&lt;!-- 解析前面引入的外部文件，以逗号做为分隔符，随机读取 --&gt;\n&lt;setdynvars sourcetype=&quot;file&quot; fileid=&quot;userfile&quot; delimiter=&quot;,&quot; order=&quot;random&quot;&gt;\n  &lt;var name=&quot;user_id&quot; /&gt;\n  &lt;var name=&quot;passwd&quot; /&gt;\n  &lt;var name=&quot;auth_token&quot; /&gt;\n&lt;/setdynvars&gt;\n&lt;!-- 返回随机小数，变量名为decimal，code中可以写erlang函数 --&gt;\n&lt;setdynvars sourcetype=&quot;eval&quot; code=&quot;fun({Pid,DynVars}) -&gt; random:uniform() end.&quot;&gt;\n  &lt;var name=&quot;decimal&quot; /&gt;\n&lt;/setdynvars&gt;\n&lt;!-- 返回随机数，从1到10000 --&gt;\n&lt;setdynvars sourcetype=&quot;random_number&quot; start=&quot;1&quot; end=&quot;10000&quot;&gt;\n   &lt;var name=&quot;int_1_10000&quot; /&gt;\n&lt;/setdynvars&gt;\n&lt;!-- 返回随机字符串，长度为10 --&gt;\n&lt;setdynvars sourcetype=&quot;random_string&quot; length=&quot;10&quot;&gt;\n   &lt;var name=&quot;string_10&quot; /&gt;\n&lt;/setdynvars&gt;\n&lt;!-- subst=&quot;true&quot;：如果在request中使用变量，需要设置subst --&gt;\n&lt;request subst=&quot;true&quot;&gt;\n&lt;!-- url：被测试的url；method：GET、POST等；contents：POST请求的参数 --&gt;\n  &lt;http url=&quot;@api&quot; method=&quot;@method&quot; contents=&quot;@contents&quot; version=&quot;1.1&quot;&gt;\n&lt;!-- http header，可以添加Authorization、Cookie等，注意变量的使用格式：%%_xxx%% --&gt;\n&lt;http_header name=&quot;Authorization&quot; value=&quot;111&quot;/&gt;\n&lt;http_header name=&quot;Cookie&quot; value=&quot;authToken=%%_auth_token%%; Path=/&quot;/&gt;\n&lt;!-- content-Type：POST请求参数的格式，如果是json格式可以这样写 --&gt;\n&lt;http_header name=&quot;Content-Type&quot; value=&quot;application/json&quot;/&gt;\n  &lt;/http&gt;\n&lt;/request&gt;\n&lt;!-- thinktime：两次请求之间的间隔时间，一般小于10s --&gt;\n&lt;thinktime value=&quot;1&quot;/&gt;\n  &lt;/for&gt;\n&lt;/session&gt;\n  &lt;/sessions&gt;\n&lt;/tsung&gt; \n</code></pre><p>如果被测接口需要登录跳转，可以指明跳转条件：   </p>\n<pre><code>&lt;!-- if need login, http 302 will be return --&gt;\n&lt;request subst=&quot;true&quot;&gt;\n  &lt;dyn_variable name=&quot;redirect1&quot; re=&quot;Location: ((http|https)://.*)\\r&quot;/&gt;\n  &lt;http url=&quot;@api&quot; method=&quot;@method&quot; contents=&quot;@contents&quot; version=&quot;1.1&quot;&gt;&lt;/http&gt;\n&lt;/request&gt;\n\n&lt;if var=&quot;redirect1&quot; neq=&quot;&quot;&gt;\n  &lt;request subst=&quot;true&quot;&gt;\n&lt;!-- 这里可以使用xpath提取页面中的元素值 --&gt;\n&lt;dyn_variable name=&quot;lt&quot; xpath=&quot;//input[@name=&apos;lt&apos;]/@value&quot;/&gt;\n&lt;dyn_variable name=&quot;s_uuid&quot; xpath=&quot;//input[@name=&apos;s_uuid&apos;]/@value&quot;/&gt;\n&lt;dyn_variable name=&quot;eventId&quot; xpath=&quot;//input[@name=&apos;_eventId&apos;]/@value&quot;/&gt;\n&lt;http url=&quot;%%_redirect1%%&quot; method=&quot;GET&quot;&gt;&lt;/http&gt;\n  &lt;/request&gt;\n\n  &lt;request subst=&quot;true&quot;&gt;\n&lt;dyn_variable name=&quot;redirect2&quot; re=&quot;Location: (http://.*)\\r&quot;/&gt;\n&lt;http url=&quot;%%_redirect1%%&quot; method=&quot;POST&quot; contents=&quot;username=%%_username%%&amp;amp;password=%%_password%%&amp;amp;lt=%%_lt%%&amp;amp;s_uuid=%%_s_uuid%%&amp;amp;_eventId=%%_eventId%%&amp;amp;j_captcha_response=&apos;&apos;&quot;&gt;&lt;/http&gt;\n  &lt;/request&gt;\n\n  &lt;request subst=&quot;true&quot;&gt;\n&lt;dyn_variable name=&quot;redirect3&quot; re=&quot;Location: (http://.*)\\r&quot;/&gt;\n&lt;http url=&quot;%%_redirect2%%&quot; method=&quot;GET&quot;&gt;&lt;/http&gt;\n  &lt;/request&gt;\n\n  &lt;request subst=&quot;true&quot;&gt;\n&lt;http url=&quot;%%_redirect3%%&quot; method=&quot;@method&quot; contents=&quot;@contents&quot;&gt;&lt;/http&gt;\n  &lt;/request&gt;\n&lt;/if&gt;\n</code></pre><p>4、通过shell控制tsung</p>\n<p>如果每次使用tsung -f tsung.xml start运行tsung，那么每次修改测试接口或者压力改变都需要修改xml，非常麻烦，我写了一个shell脚本，替换上面的tsung.xml中以@开头的变量</p>\n<pre><code>#!/bin/bash\ndefaultTestFile=&quot;$HOME/tsung_test.xml&quot;\ndefaultUser=20\ndefaultDuration=100\n# s\ndefaultThinktime=1\ndefaultServer=&quot;tomcat1&quot;\ndefaultPort=9000\ndefaultApi=&quot;/test&quot;\ndefaultMethod=&quot;POST&quot;\ndefaultLoopCount=50\ndefaultMaxuser=5000\n\nwhile [ $# -gt 0 ]; do\n  case &quot;$1&quot; in\n-f|--testFile)\ntestFile=$2\nshift \nshift ;;\n-u|--user)\nuser=$2\nshift \nshift ;;\n-d|--duration)\nduration=$2\nshift \nshift ;;\n-t|--thinktime)\nthinktime=$2\nshift \nshift ;;\n-s|--server)\nserver=$2\nshift \nshift ;;\n-p|--port)\nport=$2\nshift \nshift ;;\n-a|--api)\napi=$2\nshift \nshift ;;\n-m|--method)\nmethod=$2\nshift \nshift ;;\n-l|--loopCount)\nloopCount=$2\nshift \nshift ;;\n-x|--maxuser)\nmaxuser=$2\nshift \nshift ;;\n-h|--help)\necho &quot;-f | --testFile: tsung test file xml,default $defaultTestFile&quot;\necho &quot;-u | --user: user number per second, default $defaultUser&quot;\necho &quot;-x | --maxuser: max user number, default $defaultMaxuser&quot;\necho &quot;-d | --duration: times used to generate user,default $defaultDuration s&quot;\necho &quot;-t | --thinktime: the inteval time between two request,default $defaultThinktime s&quot;\necho &quot;-l | --loopCount: Each user&apos;s request number,default $defaultLoopCount&quot;\necho &quot;-s | --server: play server,default $defaultServer&quot;\necho &quot;-p | --port: play server http port,default $defaultPort&quot;\necho &quot;-a | --api: api, default $defaultApi&quot;\necho &quot;-m | --method: POST/GET,default $defaultMethod&quot;\necho &quot;-h | --help: print this help&quot;\nshift\nexit 1\n;;\n--)\n  shift\n  break\n  ;;\n*)\n  echo &quot;wrong input:$1,use -h or --help see how to use&quot; 1&gt;&amp;2\n  exit 1\n  ;;\n  esac\ndone\n\nprocessName=&quot;tsung&quot;\npid=`ps aux | grep $processName | grep -v grep | awk &apos;{print $2}&apos;`\n#convert from string to array\npid=($pid)\nif [ ${#pid[*]} -gt 3 ]; then\n  echo &quot;warning!!! a $processName process is running,please wait&quot;\n  exit 1\nfi\n\n#env\n#set default parameters\ntestFile=${testFile:=$defaultTestFile}\nuser=${user:=$defaultUser}\nduration=${duration:=$defaultDuration}\nthinktime=${thinktime:=$defaultThinktime}\nserver=${server:=$defaultServer}\nport=${port:=$defaultPort}\napi=${api:=$defaultApi}\nmethod=${method:=$defaultMethod}\nloopCount=${loopCount:=$defaultLoopCount}\nmaxuser=${maxuser:=$defaultMaxuser}\n\n#key of params is nodname in tusng_test.xml file\ndeclare -A params\nparams=( \\\n  [&quot;user&quot;]=$user \\\n  [&quot;maxuser&quot;]=$maxuser \\\n  [&quot;duration&quot;]=$duration \\\n  [&quot;thinktime&quot;]=$thinktime \\\n  [&quot;server&quot;]=$server \\\n  [&quot;port&quot;]=$port \\\n  [&quot;api&quot;]=$api \\\n  [&quot;method&quot;]=$method \\\n  [&quot;loopCount&quot;]=$loopCount \\\n  )\nreportPath=&quot;$HOME/.tsung/log&quot;\ncurrentTest=`date +%Y%m%d-%H%M`\nreportPath=&quot;$reportPath/$currentTest&quot;\nmkdir -p $reportPath\n#deal with jmx file\ncp $testFile $reportPath\ncurrentTestFile=&quot;$reportPath/tsung_test.xml&quot;\nfunction replace(){\n  echo &quot;$1:$2&quot; | tee -a &quot;$reportPath/test.env&quot;\n  #change / to \\/ for sed \n  local val=${2//\\//\\\\\\/}\n  sed -i &quot;s/@${1}/${val}/&quot; $currentTestFile\n}\nfor key in ${!params[*]}\ndo\n  replace $key ${params[$key]}\ndone\n#start tsung \ntsung -f $currentTestFile start &amp;\nwait %1\ncd $reportPath\n/usr/local/lib/tsung/bin/tsung_stats.pl\n</code></pre><p>5、tsung结果分析</p>\n<p>tsung生成的测试报告都放在$HOME/.tsung/log下，以日期加时间的方式命名，如：<code>.tsung/log/20150407-1951</code>，其中最重要的几张图是</p>\n<ul>\n<li>tsung产生的用户数曲线图 .tsung/log/20150407-1951/images/graphes-Users-simultaneous.png<br><img src=\"http://static.oschina.net/uploads/space/2015/0706/135050_sSxO_780347.png\" alt=\"\"></li>\n</ul>\n<p>Y轴代表每秒用户数，tsung每秒会产生一批用户，这个统计结果是每十秒统计一次，所有的图的起始位置显示的是0，其实是第一个10秒</p>\n<ul>\n<li><p>http接口响应数曲线图（TPS） .tsung/log/20150407-1951/images/graphes-HTTP_CODE-rate.png<br><img src=\"http://static.oschina.net/uploads/space/2015/0706/135106_dKTc_780347.png\" alt=\"\"></p>\n<p>Y轴是每秒响应数，右上角的200是http状态码，如果有多个状态码，会有多条不同颜色的曲线。</p>\n</li>\n<li><p>http接口响应时间曲线图 .tsung/log/20150407-1951/images/graphes-Perfs-mean.png</p>\n</li>\n</ul>\n<p><img src=\"http://static.oschina.net/uploads/space/2015/0706/135120_sPqf_780347.png\" alt=\"\"></p>\n<p>  Y轴是接口响应时间，单位是毫秒，request的线代表请求响应总耗时，connect的线代表tcp链接建立的时间。</p>\n<p>6、主要统计信息<br>Tsung统计数据是平均每十秒重置一次，所以这里的响应时间（连接、请求、页面、会话）是指每十秒的平均响应时间；<br>connect： 表示 每个连接持续时间；<br>Hightest 10sec mean    连接最长持续时间<br>Lowest 10sec mean    连接最短持续时间<br>Highest rate     每秒最高建立连接速率<br>Mean    平均每个连接持续时间<br>Count    总连接数<br>page： 表示 每个请求集合的响应时间,（一个页面表示一组没有被thinktime间隔的请求）<br>request： 表示 每个请求的响应时间；<br>Hightest 10sec mean    请求最长响应时间<br>Lowest 10sec mean    请求最短响应时间<br>Highest rate     请求最快发送速率<br>Mean    平均每个请求响应时间<br>Count    总请求数<br>session： 表示 每个用户会话持续时间；<br>Hightest 10sec mean    会话最长持续时间<br>Lowest 10sec mean    会话最短持续时间<br>Highest rate     每秒最高进行会话速率<br>Mean    平均每个会话持续时间<br>Count    总会话数  </p>\n<p>7、数据流量统计<br>size_rcv: 表示 响应请求数据量<br>size_sent:表示 发送请求数据量<br>Hightest rate    每秒最高 响应/发送 请求数据量<br>Total     响应/发送 请求总数据量  </p>\n<p>8、计数统计<br>connected    表示会话开始且尚未结束，并且已建立连接的最大用户数<br>finished_user_count    表示已经完成会话的最大用户数<br>users    表示会话开始且尚未结束的最大用户数<br>users_count    表示Tsung总共生成的用户总数  </p>\n<p>9、错误统计<br>Error_abort_max_conn_retries    重新尝试连接错误<br>Error_connect_timeout    连接超时错误<br>Error_connect_nxdomain    不存在的域错误<br>Error_unknown    位置错误  </p>\n<p>Highest rate     发生错误最高速率<br>Total number    发生该错误总个数  </p>\n<p>10、http返回状态码统计<br>200：表示客户端请求已成功响应<br>Highest rate    状态码返回最高速率<br>Total number    返回状态码的总个数  </p>"},{"title":"yum仓库搭建之RPM包制作","date":"2016-11-05T04:00:00.000Z","_content":" 常见的软件安装方式有以下几种  \n1.yum安装，可自动解决依赖，但不能自定义软件安装位置  \n2.编译安装，可指定安装路径，指定装模块，但编译参数冗长，且耗时较长，不能解决依赖问题。  \n<!--more-->\n3.rpm安装，安装速度较快，但不能自动解决依赖，尤其是遇到需要的依赖包较多时，特别费时。  \n本文主要介绍利用fpm工具制作个性化的rpm包，后期可放到yum仓库中，直接用yum安装。  \n【fpm介绍】  \n项目地址：https://github.com/jordansissel/fpm  \n作者把这个fpm称作Effing Package Management，翻译过来就是该死的包管理器，粗暴一点就是去他妈的包管理器。Ubuntu及CentOS的包管理及安装方式完全不同，要想同时掌握这两种平台下的软件包安装方法是很困难的，为了不再遭受这痛苦，fpm便应运而生了。fpm是由jordansissel于2011年开发的一套打包工具，可快速度地将你安装好的程序目录或包打包为rpm及deb等结尾软件包。与传统的打包工具(rpmbuild、dh_make)相比，制作起来更加简单、方便、快捷。  \n【fpm安装】  \n1.安装ruby及gcc    \n\n    yum install ruby-devel gcc  \n2.安装fpm    \n\n    gem install fpm  \n3.fpm打包   \n语法格式  \n\n    fpm -s <source type> -t <target type> [options]  \n其中源类型主要有：dir、gem、rpm、python等，目标类型主要有rpm,deb,puppet,solaris等。  \n-s指定输入的包类型  \n-t指定输出包的类型  \n-n, --name指定输出的包名  \n-v, --version指定版本号，默认为1.0  \n-d, --depends指定依赖包，可重复多次出现，通常以\"-d 'name' or -d 'name > version'\"的形式展现。  \n-f, --force强制输出，会覆盖掉旧包  \n-p, --package OUTPUT 指定输出目录  \n【打包实例】  \n定制cron初始化rpm包    \n\n    $fpm -s dir -t rpm -a noarch -p /root/ -n cron-init-script -v 1.0 /var/spool/cron/  \n    no value for epoch is set, defaulting to nil {:level=>:warn}  \n    no value for epoch is set, defaulting to nil {:level=>:warn}  \n    Created package {:path=>\"/root/cron-init-script-1.0-1.noarch.rpm\"}  \n    $ll /root/cron-init-script-1.0-1.noarch.rpm   \n    -rw-r--r-- 1 root root 1693 Nov  2 22:24 /root/cron-init-script-1.0-1.noarch.rpm  \n在客户端yum安装cron-init-script  \n\n    yum install cron-init-scipt\n\n【升级RPM包】  \n1.编辑cron任务  \n\n    $crontab -l  \n    */5 * * * * /usr/sbin/ntpdate pool.ntp.org >/dev/null 2>&1  \n    */10 * * * * /usr/sbin/ntpdate 1.pool.ntp.org >/dev/null 2>&1  \n\n2.重新生成包\n    \n    fpm -s dir -t rpm -a noarch -p /tools/fpm/ -n cron-init-script -v 1.1 /var/spool/cron/\n\n  \n\nyum仓库搭建之RPM包制作  \n3.传到yum仓库  \n\n    $cp cron-init-script-1.1-1.noarch.rpm /application/yum/centos6.6/x86_64/ \n\n4.更新yum仓库索引  \n\n    $createrepo --update /application/yum/centos6.6/x86_64/\n    Spawning worker 0 with 1 pkgs  \n    Workers Finished  \n    Gathering worker results  \n    Saving Primary metadata  \n    Saving file lists metadata  \n    Saving other metadata  \n    Generating sqlite DBs  \n    Sqlite DBs complete  \n5.客户端清空yum缓存    \n\n    ###yum clean all  \n    Loaded plugins: fastestmirror, security  \n    Cleaning repos: oldboy  \n    Cleaning up Everything   \n    Cleaning up list of fastest mirrors  \n6.查找cron包  \n\n    # yum list |grep cron-init  \n    cron-init-script.noarch 1.0-1  @oldboy#前面的@表示已经安装过，保留下来的信息   \n    cron-init-script.noarch 1.1-1  oldboy   \n7.更新cron包  \n    \n    # crontab -l  \n    */5 * * * * /usr/sbin/ntpdate pool.ntp.org >/dev/null 2>&1  \n    # yum update cron-init-script  \n    Is this ok [y/N]: y  \n    Running Transaction  \n      Updating  : cron-init-script-1.1-1.noarch1/2   \n      Cleanup: cron-init-script-1.0-1.noarch2/2   \n      Verifying  : cron-init-script-1.1-1.noarch1/2   \n      Verifying  : cron-init-script-1.0-1.noarch2/2  \n    Updated:  \n      cron-init-script.noarch 0:1.1-1 \n    Complete!  \n    # crontab -l  \n    */5 * * * * /usr/sbin/ntpdate pool.ntp.org >/dev/null 2>&1  \n    */10 * * * * /usr/sbin/ntpdate 1.pool.ntp.org >/dev/null 2>&1  \ncron任务已更新。  \n    \n    \n    fpm -f -s dir -t rpm -n easemob-sersync-ssy -v 2.5.4_64bit  --iteration 1.el6.centos -a native \\  \n    -C /tmp/easemob-serync \\  \n    --vendor 'sam@easemob.com' \\  \n    --description 'Ejabberd packager by easemob.com' \\  \n    --url 'https://github.com/easemob/serync/' \\  \n    --rpm-user easemob \\  \n    --rpm-group easemob \\  \n    --verbose \\  \n    --epoch 20160616  \n    \n    \n    \n    createrepo /data/apps/data/nginx/yum/ssy/ssy201606/x86_64/6/easemob-ssy/packages/\n    \n","source":"_posts/yum仓库搭建之RPM包制作.md","raw":"---\ntitle: yum仓库搭建之RPM包制作\ndate: 2016-11-05\ntags: rpm\ncategories: rpm\n---\n 常见的软件安装方式有以下几种  \n1.yum安装，可自动解决依赖，但不能自定义软件安装位置  \n2.编译安装，可指定安装路径，指定装模块，但编译参数冗长，且耗时较长，不能解决依赖问题。  \n<!--more-->\n3.rpm安装，安装速度较快，但不能自动解决依赖，尤其是遇到需要的依赖包较多时，特别费时。  \n本文主要介绍利用fpm工具制作个性化的rpm包，后期可放到yum仓库中，直接用yum安装。  \n【fpm介绍】  \n项目地址：https://github.com/jordansissel/fpm  \n作者把这个fpm称作Effing Package Management，翻译过来就是该死的包管理器，粗暴一点就是去他妈的包管理器。Ubuntu及CentOS的包管理及安装方式完全不同，要想同时掌握这两种平台下的软件包安装方法是很困难的，为了不再遭受这痛苦，fpm便应运而生了。fpm是由jordansissel于2011年开发的一套打包工具，可快速度地将你安装好的程序目录或包打包为rpm及deb等结尾软件包。与传统的打包工具(rpmbuild、dh_make)相比，制作起来更加简单、方便、快捷。  \n【fpm安装】  \n1.安装ruby及gcc    \n\n    yum install ruby-devel gcc  \n2.安装fpm    \n\n    gem install fpm  \n3.fpm打包   \n语法格式  \n\n    fpm -s <source type> -t <target type> [options]  \n其中源类型主要有：dir、gem、rpm、python等，目标类型主要有rpm,deb,puppet,solaris等。  \n-s指定输入的包类型  \n-t指定输出包的类型  \n-n, --name指定输出的包名  \n-v, --version指定版本号，默认为1.0  \n-d, --depends指定依赖包，可重复多次出现，通常以\"-d 'name' or -d 'name > version'\"的形式展现。  \n-f, --force强制输出，会覆盖掉旧包  \n-p, --package OUTPUT 指定输出目录  \n【打包实例】  \n定制cron初始化rpm包    \n\n    $fpm -s dir -t rpm -a noarch -p /root/ -n cron-init-script -v 1.0 /var/spool/cron/  \n    no value for epoch is set, defaulting to nil {:level=>:warn}  \n    no value for epoch is set, defaulting to nil {:level=>:warn}  \n    Created package {:path=>\"/root/cron-init-script-1.0-1.noarch.rpm\"}  \n    $ll /root/cron-init-script-1.0-1.noarch.rpm   \n    -rw-r--r-- 1 root root 1693 Nov  2 22:24 /root/cron-init-script-1.0-1.noarch.rpm  \n在客户端yum安装cron-init-script  \n\n    yum install cron-init-scipt\n\n【升级RPM包】  \n1.编辑cron任务  \n\n    $crontab -l  \n    */5 * * * * /usr/sbin/ntpdate pool.ntp.org >/dev/null 2>&1  \n    */10 * * * * /usr/sbin/ntpdate 1.pool.ntp.org >/dev/null 2>&1  \n\n2.重新生成包\n    \n    fpm -s dir -t rpm -a noarch -p /tools/fpm/ -n cron-init-script -v 1.1 /var/spool/cron/\n\n  \n\nyum仓库搭建之RPM包制作  \n3.传到yum仓库  \n\n    $cp cron-init-script-1.1-1.noarch.rpm /application/yum/centos6.6/x86_64/ \n\n4.更新yum仓库索引  \n\n    $createrepo --update /application/yum/centos6.6/x86_64/\n    Spawning worker 0 with 1 pkgs  \n    Workers Finished  \n    Gathering worker results  \n    Saving Primary metadata  \n    Saving file lists metadata  \n    Saving other metadata  \n    Generating sqlite DBs  \n    Sqlite DBs complete  \n5.客户端清空yum缓存    \n\n    ###yum clean all  \n    Loaded plugins: fastestmirror, security  \n    Cleaning repos: oldboy  \n    Cleaning up Everything   \n    Cleaning up list of fastest mirrors  \n6.查找cron包  \n\n    # yum list |grep cron-init  \n    cron-init-script.noarch 1.0-1  @oldboy#前面的@表示已经安装过，保留下来的信息   \n    cron-init-script.noarch 1.1-1  oldboy   \n7.更新cron包  \n    \n    # crontab -l  \n    */5 * * * * /usr/sbin/ntpdate pool.ntp.org >/dev/null 2>&1  \n    # yum update cron-init-script  \n    Is this ok [y/N]: y  \n    Running Transaction  \n      Updating  : cron-init-script-1.1-1.noarch1/2   \n      Cleanup: cron-init-script-1.0-1.noarch2/2   \n      Verifying  : cron-init-script-1.1-1.noarch1/2   \n      Verifying  : cron-init-script-1.0-1.noarch2/2  \n    Updated:  \n      cron-init-script.noarch 0:1.1-1 \n    Complete!  \n    # crontab -l  \n    */5 * * * * /usr/sbin/ntpdate pool.ntp.org >/dev/null 2>&1  \n    */10 * * * * /usr/sbin/ntpdate 1.pool.ntp.org >/dev/null 2>&1  \ncron任务已更新。  \n    \n    \n    fpm -f -s dir -t rpm -n easemob-sersync-ssy -v 2.5.4_64bit  --iteration 1.el6.centos -a native \\  \n    -C /tmp/easemob-serync \\  \n    --vendor 'sam@easemob.com' \\  \n    --description 'Ejabberd packager by easemob.com' \\  \n    --url 'https://github.com/easemob/serync/' \\  \n    --rpm-user easemob \\  \n    --rpm-group easemob \\  \n    --verbose \\  \n    --epoch 20160616  \n    \n    \n    \n    createrepo /data/apps/data/nginx/yum/ssy/ssy201606/x86_64/6/easemob-ssy/packages/\n    \n","slug":"yum仓库搭建之RPM包制作","published":1,"updated":"2019-06-18T08:07:01.118Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9smv0026hcb7nm6ap3fr","content":"<p> 常见的软件安装方式有以下几种<br>1.yum安装，可自动解决依赖，但不能自定义软件安装位置<br>2.编译安装，可指定安装路径，指定装模块，但编译参数冗长，且耗时较长，不能解决依赖问题。<br><a id=\"more\"></a><br>3.rpm安装，安装速度较快，但不能自动解决依赖，尤其是遇到需要的依赖包较多时，特别费时。<br>本文主要介绍利用fpm工具制作个性化的rpm包，后期可放到yum仓库中，直接用yum安装。<br>【fpm介绍】<br>项目地址：<a href=\"https://github.com/jordansissel/fpm\" target=\"_blank\" rel=\"noopener\">https://github.com/jordansissel/fpm</a><br>作者把这个fpm称作Effing Package Management，翻译过来就是该死的包管理器，粗暴一点就是去他妈的包管理器。Ubuntu及CentOS的包管理及安装方式完全不同，要想同时掌握这两种平台下的软件包安装方法是很困难的，为了不再遭受这痛苦，fpm便应运而生了。fpm是由jordansissel于2011年开发的一套打包工具，可快速度地将你安装好的程序目录或包打包为rpm及deb等结尾软件包。与传统的打包工具(rpmbuild、dh_make)相比，制作起来更加简单、方便、快捷。<br>【fpm安装】<br>1.安装ruby及gcc    </p>\n<pre><code>yum install ruby-devel gcc  \n</code></pre><p>2.安装fpm    </p>\n<pre><code>gem install fpm  \n</code></pre><p>3.fpm打包<br>语法格式  </p>\n<pre><code>fpm -s &lt;source type&gt; -t &lt;target type&gt; [options]  \n</code></pre><p>其中源类型主要有：dir、gem、rpm、python等，目标类型主要有rpm,deb,puppet,solaris等。<br>-s指定输入的包类型<br>-t指定输出包的类型<br>-n, –name指定输出的包名<br>-v, –version指定版本号，默认为1.0<br>-d, –depends指定依赖包，可重复多次出现，通常以”-d ‘name’ or -d ‘name &gt; version’”的形式展现。<br>-f, –force强制输出，会覆盖掉旧包<br>-p, –package OUTPUT 指定输出目录<br>【打包实例】<br>定制cron初始化rpm包    </p>\n<pre><code>$fpm -s dir -t rpm -a noarch -p /root/ -n cron-init-script -v 1.0 /var/spool/cron/  \nno value for epoch is set, defaulting to nil {:level=&gt;:warn}  \nno value for epoch is set, defaulting to nil {:level=&gt;:warn}  \nCreated package {:path=&gt;&quot;/root/cron-init-script-1.0-1.noarch.rpm&quot;}  \n$ll /root/cron-init-script-1.0-1.noarch.rpm   \n-rw-r--r-- 1 root root 1693 Nov  2 22:24 /root/cron-init-script-1.0-1.noarch.rpm  \n</code></pre><p>在客户端yum安装cron-init-script  </p>\n<pre><code>yum install cron-init-scipt\n</code></pre><p>【升级RPM包】<br>1.编辑cron任务  </p>\n<pre><code>$crontab -l  \n*/5 * * * * /usr/sbin/ntpdate pool.ntp.org &gt;/dev/null 2&gt;&amp;1  \n*/10 * * * * /usr/sbin/ntpdate 1.pool.ntp.org &gt;/dev/null 2&gt;&amp;1  \n</code></pre><p>2.重新生成包</p>\n<pre><code>fpm -s dir -t rpm -a noarch -p /tools/fpm/ -n cron-init-script -v 1.1 /var/spool/cron/\n</code></pre><p>yum仓库搭建之RPM包制作<br>3.传到yum仓库  </p>\n<pre><code>$cp cron-init-script-1.1-1.noarch.rpm /application/yum/centos6.6/x86_64/ \n</code></pre><p>4.更新yum仓库索引  </p>\n<pre><code>$createrepo --update /application/yum/centos6.6/x86_64/\nSpawning worker 0 with 1 pkgs  \nWorkers Finished  \nGathering worker results  \nSaving Primary metadata  \nSaving file lists metadata  \nSaving other metadata  \nGenerating sqlite DBs  \nSqlite DBs complete  \n</code></pre><p>5.客户端清空yum缓存    </p>\n<pre><code>###yum clean all  \nLoaded plugins: fastestmirror, security  \nCleaning repos: oldboy  \nCleaning up Everything   \nCleaning up list of fastest mirrors  \n</code></pre><p>6.查找cron包  </p>\n<pre><code># yum list |grep cron-init  \ncron-init-script.noarch 1.0-1  @oldboy#前面的@表示已经安装过，保留下来的信息   \ncron-init-script.noarch 1.1-1  oldboy   \n</code></pre><p>7.更新cron包  </p>\n<pre><code># crontab -l  \n*/5 * * * * /usr/sbin/ntpdate pool.ntp.org &gt;/dev/null 2&gt;&amp;1  \n# yum update cron-init-script  \nIs this ok [y/N]: y  \nRunning Transaction  \n  Updating  : cron-init-script-1.1-1.noarch1/2   \n  Cleanup: cron-init-script-1.0-1.noarch2/2   \n  Verifying  : cron-init-script-1.1-1.noarch1/2   \n  Verifying  : cron-init-script-1.0-1.noarch2/2  \nUpdated:  \n  cron-init-script.noarch 0:1.1-1 \nComplete!  \n# crontab -l  \n*/5 * * * * /usr/sbin/ntpdate pool.ntp.org &gt;/dev/null 2&gt;&amp;1  \n*/10 * * * * /usr/sbin/ntpdate 1.pool.ntp.org &gt;/dev/null 2&gt;&amp;1  \n</code></pre><p>cron任务已更新。  </p>\n<pre><code>fpm -f -s dir -t rpm -n easemob-sersync-ssy -v 2.5.4_64bit  --iteration 1.el6.centos -a native \\  \n-C /tmp/easemob-serync \\  \n--vendor &apos;sam@easemob.com&apos; \\  \n--description &apos;Ejabberd packager by easemob.com&apos; \\  \n--url &apos;https://github.com/easemob/serync/&apos; \\  \n--rpm-user easemob \\  \n--rpm-group easemob \\  \n--verbose \\  \n--epoch 20160616  \n\n\n\ncreaterepo /data/apps/data/nginx/yum/ssy/ssy201606/x86_64/6/easemob-ssy/packages/\n</code></pre>","site":{"data":{}},"excerpt":"<p> 常见的软件安装方式有以下几种<br>1.yum安装，可自动解决依赖，但不能自定义软件安装位置<br>2.编译安装，可指定安装路径，指定装模块，但编译参数冗长，且耗时较长，不能解决依赖问题。<br>","more":"<br>3.rpm安装，安装速度较快，但不能自动解决依赖，尤其是遇到需要的依赖包较多时，特别费时。<br>本文主要介绍利用fpm工具制作个性化的rpm包，后期可放到yum仓库中，直接用yum安装。<br>【fpm介绍】<br>项目地址：<a href=\"https://github.com/jordansissel/fpm\" target=\"_blank\" rel=\"noopener\">https://github.com/jordansissel/fpm</a><br>作者把这个fpm称作Effing Package Management，翻译过来就是该死的包管理器，粗暴一点就是去他妈的包管理器。Ubuntu及CentOS的包管理及安装方式完全不同，要想同时掌握这两种平台下的软件包安装方法是很困难的，为了不再遭受这痛苦，fpm便应运而生了。fpm是由jordansissel于2011年开发的一套打包工具，可快速度地将你安装好的程序目录或包打包为rpm及deb等结尾软件包。与传统的打包工具(rpmbuild、dh_make)相比，制作起来更加简单、方便、快捷。<br>【fpm安装】<br>1.安装ruby及gcc    </p>\n<pre><code>yum install ruby-devel gcc  \n</code></pre><p>2.安装fpm    </p>\n<pre><code>gem install fpm  \n</code></pre><p>3.fpm打包<br>语法格式  </p>\n<pre><code>fpm -s &lt;source type&gt; -t &lt;target type&gt; [options]  \n</code></pre><p>其中源类型主要有：dir、gem、rpm、python等，目标类型主要有rpm,deb,puppet,solaris等。<br>-s指定输入的包类型<br>-t指定输出包的类型<br>-n, –name指定输出的包名<br>-v, –version指定版本号，默认为1.0<br>-d, –depends指定依赖包，可重复多次出现，通常以”-d ‘name’ or -d ‘name &gt; version’”的形式展现。<br>-f, –force强制输出，会覆盖掉旧包<br>-p, –package OUTPUT 指定输出目录<br>【打包实例】<br>定制cron初始化rpm包    </p>\n<pre><code>$fpm -s dir -t rpm -a noarch -p /root/ -n cron-init-script -v 1.0 /var/spool/cron/  \nno value for epoch is set, defaulting to nil {:level=&gt;:warn}  \nno value for epoch is set, defaulting to nil {:level=&gt;:warn}  \nCreated package {:path=&gt;&quot;/root/cron-init-script-1.0-1.noarch.rpm&quot;}  \n$ll /root/cron-init-script-1.0-1.noarch.rpm   \n-rw-r--r-- 1 root root 1693 Nov  2 22:24 /root/cron-init-script-1.0-1.noarch.rpm  \n</code></pre><p>在客户端yum安装cron-init-script  </p>\n<pre><code>yum install cron-init-scipt\n</code></pre><p>【升级RPM包】<br>1.编辑cron任务  </p>\n<pre><code>$crontab -l  \n*/5 * * * * /usr/sbin/ntpdate pool.ntp.org &gt;/dev/null 2&gt;&amp;1  \n*/10 * * * * /usr/sbin/ntpdate 1.pool.ntp.org &gt;/dev/null 2&gt;&amp;1  \n</code></pre><p>2.重新生成包</p>\n<pre><code>fpm -s dir -t rpm -a noarch -p /tools/fpm/ -n cron-init-script -v 1.1 /var/spool/cron/\n</code></pre><p>yum仓库搭建之RPM包制作<br>3.传到yum仓库  </p>\n<pre><code>$cp cron-init-script-1.1-1.noarch.rpm /application/yum/centos6.6/x86_64/ \n</code></pre><p>4.更新yum仓库索引  </p>\n<pre><code>$createrepo --update /application/yum/centos6.6/x86_64/\nSpawning worker 0 with 1 pkgs  \nWorkers Finished  \nGathering worker results  \nSaving Primary metadata  \nSaving file lists metadata  \nSaving other metadata  \nGenerating sqlite DBs  \nSqlite DBs complete  \n</code></pre><p>5.客户端清空yum缓存    </p>\n<pre><code>###yum clean all  \nLoaded plugins: fastestmirror, security  \nCleaning repos: oldboy  \nCleaning up Everything   \nCleaning up list of fastest mirrors  \n</code></pre><p>6.查找cron包  </p>\n<pre><code># yum list |grep cron-init  \ncron-init-script.noarch 1.0-1  @oldboy#前面的@表示已经安装过，保留下来的信息   \ncron-init-script.noarch 1.1-1  oldboy   \n</code></pre><p>7.更新cron包  </p>\n<pre><code># crontab -l  \n*/5 * * * * /usr/sbin/ntpdate pool.ntp.org &gt;/dev/null 2&gt;&amp;1  \n# yum update cron-init-script  \nIs this ok [y/N]: y  \nRunning Transaction  \n  Updating  : cron-init-script-1.1-1.noarch1/2   \n  Cleanup: cron-init-script-1.0-1.noarch2/2   \n  Verifying  : cron-init-script-1.1-1.noarch1/2   \n  Verifying  : cron-init-script-1.0-1.noarch2/2  \nUpdated:  \n  cron-init-script.noarch 0:1.1-1 \nComplete!  \n# crontab -l  \n*/5 * * * * /usr/sbin/ntpdate pool.ntp.org &gt;/dev/null 2&gt;&amp;1  \n*/10 * * * * /usr/sbin/ntpdate 1.pool.ntp.org &gt;/dev/null 2&gt;&amp;1  \n</code></pre><p>cron任务已更新。  </p>\n<pre><code>fpm -f -s dir -t rpm -n easemob-sersync-ssy -v 2.5.4_64bit  --iteration 1.el6.centos -a native \\  \n-C /tmp/easemob-serync \\  \n--vendor &apos;sam@easemob.com&apos; \\  \n--description &apos;Ejabberd packager by easemob.com&apos; \\  \n--url &apos;https://github.com/easemob/serync/&apos; \\  \n--rpm-user easemob \\  \n--rpm-group easemob \\  \n--verbose \\  \n--epoch 20160616  \n\n\n\ncreaterepo /data/apps/data/nginx/yum/ssy/ssy201606/x86_64/6/easemob-ssy/packages/\n</code></pre>"},{"title":"zabbix2.6安装","date":"2016-09-02T04:00:00.000Z","_content":"\n\n1. 安装lnmp架构\n `yum -y install gcc gcc-c++ autoconf httpd php mysql mysql-server php-mysql httpd-manual mod_ssl mod_perl mod_auth_mysql php-gd php-xml php-mbstring php-ldap php-pear php-xmlrpc php-bcmath mysql-connector-odbc mysql-devel libdbi-dbd-mysql net-snmp-devel curl-devel`\n2. 启动服务\n    service mysqld start\n    service httpd start\n<!--more-->\n\n3. 创建zabbix用户和组\n    groupadd zabbix\n    useradd zabbix -g zabbix\n4. 进入mysql创建数据库\n    create database zabbix character set utf8;\n    grant all on zabbix.* to zabbix@localhost identified by ‘jszj201501’;\n5. 解压zabbix.tar包\n    > tar zxf zabbix-2.4.tar.gz\n    > cd zabbix-2.4.5/database/mysql/\n6. 导入数据库\n    mysql -uzabbix -pjszj201501 zabbix <schema.sql\n    mysql -uzabbix -pjszj201501 zabbix <images.sql\n7. 进行编译安装\n    cd ../..\n    ./configure –prefix=/usr/local/zabbix –enable-server –enable-agent –with-mysql –with-net-snmp –with-libcurl\n    make&&make install\n8. 添加zabbix服务对应的端口\n    cat >>/etc/services<<EOF\n    zabbix-agent 10050/tcp Zabbix Agent\n    zabbix-agent 10050/udp Zabbix Agent\n    zabbix-trapper 10051/tcp Zabbix Trapper\n    zabbix-trapper 10051/udp Zabbix Trapper\n    EOF\n9. 修改zabbix server 配置文件\n    vim /usr/local/zabbix/etc/zabbix_server.conf\n    LogFile=/tmp/zabbix_server.log ##日志位置，根据需求修改；\n    PidFile=/tmp/zabbix_server.pid ##PID 所在位置\n    DBHost=localhost ##如果不是在本机，请修改\n    DBName=zabbix ##数据库名称\n    DBUser=zabbix ##数据库用户名\n    DBPassword=redhat ##数据库密码\n10. 安装启动脚本,添加可执行权限\n    cp misc/init.d/fedora/core/zabbix_server /etc/init.d\n    chmod +x /etc/init.d/zabbix_server\n11. 查找zabbix_server.conf位置复制\n\n    find / -name zabbix_server.conf\n12. 修改启动脚本，启动zabbix server\n    vim /etc/init.d/zabbix_server\n    BASEDIR=/usr/local/zabbix ##修改这个，zabbix 的安装目录\n    CONFILE=$BASEDIR/etc/zabbix_server.conf ##添加这一行，定义配置文件位置\n    #搜索start,修改启动选项，默认是去/etc 下去找配置文件的\n    action $”Starting $BINARY_NAME: ” $FULLPATH -c $CONFILE\n    service zabbix_server start\n13. 安装邮件服务\n    yum install mailx\n    vi /etc/mail.rc\n    set from=xxx@163.com smtp=smtp.163.com\n    set smtp-auth-user=xxx@163.com smtp-auth-password=123456\n    set smtp-auth=login\n    :wq! #保存退出\n    echo “zabbix test mail” |mail -s “zabbix” yyy@163.com\n    linux客户端\n    mkdir /usr/local/zabbix\n    tar zxf zabbix_agents_2.0.6.linux2_6.amd64.tar.gz -C /usr/local/zabbix\n14. 编辑配置文件\n    find / -name zabbix_agentd.conf\n    vim zabbix_agentd.conf\n    LogFile=/tmp/zabbix_agentd.log\n    Server=202.108.1.52 ##服务器IP\n    ServerActive=202.108.1.52 ##主动模式服务器IP\n    Hostname=202.108.1.51 ##设定主机名\n    #加入mysql配置\n15. 安装修改启动脚本\n    scp misc/init.d/fedora/core/zabbix_agentd 202.108.1.51:/etc/init.d\n    vim /etc/init.d/zabbix_agentd\n    BASEDIR=/usr/local/zabbix ##修改这个\n    CONFILE=$BASEDIR/etc/zabbix_agentd.conf ##添加这行，搜索start 添加-c $CONFILE\n    action $”Starting $BINARY_NAME: ” $FULLPATH -c $CONFILE\n    service zabbix_agentd start\n16. 创建用户和用户组\n    groupadd zabbix\n    useradd zabbix -g zabbix\n    windows客户端\n    cmd\n    d:\\zabbix_agentd.exe -i -c d:\\zabbix\\zabbix_agentd.conf\n    services.msc\n17. 禁用内部邮件服务\n    service sendmail stop #关闭\n    chkconfig sendmail off #禁止开机启动\n    service postfix stop\n    chkconfig postfix off\n18. 事件触发器配置：\n    名称：Action-Email\n    默认接收人：故障{TRIGGER.STATUS},服务器:{HOSTNAME1}发生: {TRIGGER.NAME}故障!\n    默认信息：\n    告警主机:{HOSTNAME1}\n    告警时间:{EVENT.DATE} {EVENT.TIME}\n    告警等级:{TRIGGER.SEVERITY}\n    告警信息: {TRIGGER.NAME}\n    告警项目:{TRIGGER.KEY1}\n    问题详情:{ITEM.NAME}:{ITEM.VALUE}\n    当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1}\n    事件ID:{EVENT.ID}\n    恢复信息：打钩\n    恢复主旨：恢复{TRIGGER.STATUS}, 服务器:{HOSTNAME1}: {TRIGGER.NAME}已恢复!\n    恢复信息：\n    告警主机:{HOSTNAME1}\n    告警时间:{EVENT.DATE} {EVENT.TIME}\n    告警等级:{TRIGGER.SEVERITY}\n    告警信息: {TRIGGER.NAME}\n    告警项目:{TRIGGER.KEY1}\n    问题详情:{ITEM.NAME}:{ITEM.VALUE}\n    当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1}\n    事件ID:{EVENT.ID}\n    已启用：打钩\n19. 解决乱码和附件问题\n    vim /usr/local/zabbix/share/zabbix/alertscripts/sendmail.sh\n    #!/bin/bash\n    #export.UTF-8 //解决发送的中文变成了乱码的问题\n    FILE=/tmp/mailtmp.txt\n    echo “$3” >$FILE\n    dos2unix -k $FILE  //解决了发送的邮件内容变成附件的问题。\n    /bin/mail -s “$2” $1 < $FILE\n    touch /tmp/mailtmp.txt\n    chown  zabbix.zabbix /tmp/mailtmp.txt\n20. zabbix  mysql客户端\n    find / -name userparameter_mysql.conf\n    vi /usr/local/zabbixvim/etc/zabbix_agent.conf\n    Include=/usr/local/zabbix/conf/zabbix_agentd/ #加入mysql配置(find查找的路径)\n    vi /usr/local/zabbix/etc/zabbix_agentd.conf\n    Include=/usr/local/zabbix/conf/zabbix_agentd/ #加入mysql配置\n    mkdir /etc/zabbix\n    touch /etc/zabbix/.my.cnf\n    vim /etc/zabbix/.my.cnf\n    [mysql]\n    host = localhost\n    user = mysqlcheck\n    password = mysqlcheck\n    socket = /var/lib/mysql/mysql.sock(mysql.sock的位置)\n    [mysqladmin]\n    host = localhost\n    user = mysqlcheck\n    password = mysqlchechk\n    socket = /var/lib/mysql/mysql.sock(mysql.sock的位置)\n    vim userparameter_mysql.conf\n    UserParameter=mysql.status[*],echo “show global status where Variable_name=’$1′;” | mysql -uzabbix -pjszj201501 -N | awk ‘{print $$2}’ #取mysql状态\n    UserParameter=mysql.size[*],echo “select sum($(case “$3″ in both|””) echo “data_length+index_length”;; data|index) echo “$3_length”;; free) echo “data_free”;; esac)) from information_schema.tables$([[ “$1” = “all” || ! “$1″ ]] || echo ” where table_schema=’$1′”)$([[ “$2” = “all” || ! “$2” ]] || echo “and table_name=’$2′”);” | mysql -uzabbix -pjszj201501 -N\n     #取mysql操作状态\n    UserParameter=mysql.ping,HOME=/etc/zabbix mysqladmin -uzabbix -ppassword | grep -c alive\n    UserParameter=mysql.version,mysql -V #取mysql版本\n    chmod 777 userparameter_mysql.conf\n    service zabbix_agentd restart\n21. Zabbix配置email报警\n一、              使用msmtp这个命令行MUA\n    (1)./configure –prefix=/usr/local/msmtp\n    (2)make\n    (3)make install\n    (4)mkdir /usr/local/msmtp/etc\n    (5)touch /usr/local/msmtp/etc/msmtprc\n    (6)在/usr/local/msmtp/etc/msmtprc中写入如下内容：\n    defaults\n    account michael_zhou\n    host mail.chinadba.com\n    domain chinadba.com\n    from michael_zhou@chinadba.com\n    auth login\n    user michael_zhou@chinadba.com\n        password your_password\n    account default:michael_zhou\n    logfile /var/log/maillog\n    (7)测试一下：/usr/local/msmtp/bin/msmtp i@chinadba.com，输入内容后按ctrl+D发出。\n二、    在实际测试中发现直接使用msmtp命令发出去的邮件会看不到发件人和主题，只能看到邮件内容，所以我使用mutt挂接在msmtp上，mutt默认会安装，如果没有安装请yum install mutt*\n    (1)修改mutt的配置文件/etc/Muttrc, 不是/etc/muttrc  ，M要大写\n    1．set sendmail=”/usr/local/msmtp/bin/msmtp”\n    2．set use_from=yes\n    3．set realname=michael_zhou@chinadba.com  #发件人邮箱地址\n    4．set editor=”vi”\n    5．保存退出\n    (2)测试一下：echo “邮件报警测试” | mutt -s “测试” i@chinadba.com  #收件人地址\n三、    创建 zabbix用于发送邮件的脚本,脚本放在什么位置随便，但是要保证zabbix能找到！\n(1)vim /usr/bin/baojing,并写入如下内容：\n#!/bin/bash\necho “$3” | mutt -s “$2” $1       # $3表示邮件内容、$2表示邮件标题、$1表示收件人\n(2)chmod a+x /usr/bin/baojing\n四、    zabbix配置\n(1)创建meida types\n1．登录到zabbix，进入“Administration” >> ”Media types”，点击右上角“Create Media Type”。 Description填”mediatype-baojing”或其它名称，Type选择”Script”，Script填”baojing”。\n2．点击save保存\n(2)创建actions\n1.登录到zabbix，进入”Configation” >> “Actions”，点击右上角”Create Actions”。输入Name “action-baojing” ，其它都默认点击右侧“Action Operations”下的”New”按钮，”Operation Type”选择”Send message”，”Send Message to”选择一个或多个要发送消息的用户组，”Send only to”选择我们之前新增的mediatype-baojing。\n2.点击save保存\n(3) zabbix用户配置\n登录到zabbix, 进入”Adimistration” >> “Users”，在之前选定要发送消息的组里的Members栏位里选择一个用户，例如选择Admin用户。\n在用户信息修改界面最下方的”Media”处点击”Add”按钮。\nType选择”mediatype-baojing”，Send to填入收件人地址，点击Add添加。\n点击”Save”保存配置。\n至此配置完成，测试！\n不光是zabbix,nagios等监控平台的邮件报警都可以这样配置。当然转到139邮箱的话可以收到短信的，会更加及时的收到报警。\nzabbix企业应用之服务器硬件信息监控\nhttp://dl528888.blog.51cto.com/2382721/1403893\nzabbix企业应用之Mysql主从监控\nhttp://dl528888.blog.51cto.com/2382721/1434263\nZabbix监控MySQL数据库状态\nhttp://www.linuxidc.com/Linux/2015-04/116304.htm\nZabbix使用微信接口实现微信报警功能\nhttp://lcbk.net/zabbix/2022.html\nhttp://www.cnyunwei.com/thread-29593-1-1.html\n","source":"_posts/zabbix2.6安装.md","raw":"---\ntitle: zabbix2.6安装\ndate: 2016-09-02\ntags: zabbix\ncategories: zabbix\n---\n\n\n1. 安装lnmp架构\n `yum -y install gcc gcc-c++ autoconf httpd php mysql mysql-server php-mysql httpd-manual mod_ssl mod_perl mod_auth_mysql php-gd php-xml php-mbstring php-ldap php-pear php-xmlrpc php-bcmath mysql-connector-odbc mysql-devel libdbi-dbd-mysql net-snmp-devel curl-devel`\n2. 启动服务\n    service mysqld start\n    service httpd start\n<!--more-->\n\n3. 创建zabbix用户和组\n    groupadd zabbix\n    useradd zabbix -g zabbix\n4. 进入mysql创建数据库\n    create database zabbix character set utf8;\n    grant all on zabbix.* to zabbix@localhost identified by ‘jszj201501’;\n5. 解压zabbix.tar包\n    > tar zxf zabbix-2.4.tar.gz\n    > cd zabbix-2.4.5/database/mysql/\n6. 导入数据库\n    mysql -uzabbix -pjszj201501 zabbix <schema.sql\n    mysql -uzabbix -pjszj201501 zabbix <images.sql\n7. 进行编译安装\n    cd ../..\n    ./configure –prefix=/usr/local/zabbix –enable-server –enable-agent –with-mysql –with-net-snmp –with-libcurl\n    make&&make install\n8. 添加zabbix服务对应的端口\n    cat >>/etc/services<<EOF\n    zabbix-agent 10050/tcp Zabbix Agent\n    zabbix-agent 10050/udp Zabbix Agent\n    zabbix-trapper 10051/tcp Zabbix Trapper\n    zabbix-trapper 10051/udp Zabbix Trapper\n    EOF\n9. 修改zabbix server 配置文件\n    vim /usr/local/zabbix/etc/zabbix_server.conf\n    LogFile=/tmp/zabbix_server.log ##日志位置，根据需求修改；\n    PidFile=/tmp/zabbix_server.pid ##PID 所在位置\n    DBHost=localhost ##如果不是在本机，请修改\n    DBName=zabbix ##数据库名称\n    DBUser=zabbix ##数据库用户名\n    DBPassword=redhat ##数据库密码\n10. 安装启动脚本,添加可执行权限\n    cp misc/init.d/fedora/core/zabbix_server /etc/init.d\n    chmod +x /etc/init.d/zabbix_server\n11. 查找zabbix_server.conf位置复制\n\n    find / -name zabbix_server.conf\n12. 修改启动脚本，启动zabbix server\n    vim /etc/init.d/zabbix_server\n    BASEDIR=/usr/local/zabbix ##修改这个，zabbix 的安装目录\n    CONFILE=$BASEDIR/etc/zabbix_server.conf ##添加这一行，定义配置文件位置\n    #搜索start,修改启动选项，默认是去/etc 下去找配置文件的\n    action $”Starting $BINARY_NAME: ” $FULLPATH -c $CONFILE\n    service zabbix_server start\n13. 安装邮件服务\n    yum install mailx\n    vi /etc/mail.rc\n    set from=xxx@163.com smtp=smtp.163.com\n    set smtp-auth-user=xxx@163.com smtp-auth-password=123456\n    set smtp-auth=login\n    :wq! #保存退出\n    echo “zabbix test mail” |mail -s “zabbix” yyy@163.com\n    linux客户端\n    mkdir /usr/local/zabbix\n    tar zxf zabbix_agents_2.0.6.linux2_6.amd64.tar.gz -C /usr/local/zabbix\n14. 编辑配置文件\n    find / -name zabbix_agentd.conf\n    vim zabbix_agentd.conf\n    LogFile=/tmp/zabbix_agentd.log\n    Server=202.108.1.52 ##服务器IP\n    ServerActive=202.108.1.52 ##主动模式服务器IP\n    Hostname=202.108.1.51 ##设定主机名\n    #加入mysql配置\n15. 安装修改启动脚本\n    scp misc/init.d/fedora/core/zabbix_agentd 202.108.1.51:/etc/init.d\n    vim /etc/init.d/zabbix_agentd\n    BASEDIR=/usr/local/zabbix ##修改这个\n    CONFILE=$BASEDIR/etc/zabbix_agentd.conf ##添加这行，搜索start 添加-c $CONFILE\n    action $”Starting $BINARY_NAME: ” $FULLPATH -c $CONFILE\n    service zabbix_agentd start\n16. 创建用户和用户组\n    groupadd zabbix\n    useradd zabbix -g zabbix\n    windows客户端\n    cmd\n    d:\\zabbix_agentd.exe -i -c d:\\zabbix\\zabbix_agentd.conf\n    services.msc\n17. 禁用内部邮件服务\n    service sendmail stop #关闭\n    chkconfig sendmail off #禁止开机启动\n    service postfix stop\n    chkconfig postfix off\n18. 事件触发器配置：\n    名称：Action-Email\n    默认接收人：故障{TRIGGER.STATUS},服务器:{HOSTNAME1}发生: {TRIGGER.NAME}故障!\n    默认信息：\n    告警主机:{HOSTNAME1}\n    告警时间:{EVENT.DATE} {EVENT.TIME}\n    告警等级:{TRIGGER.SEVERITY}\n    告警信息: {TRIGGER.NAME}\n    告警项目:{TRIGGER.KEY1}\n    问题详情:{ITEM.NAME}:{ITEM.VALUE}\n    当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1}\n    事件ID:{EVENT.ID}\n    恢复信息：打钩\n    恢复主旨：恢复{TRIGGER.STATUS}, 服务器:{HOSTNAME1}: {TRIGGER.NAME}已恢复!\n    恢复信息：\n    告警主机:{HOSTNAME1}\n    告警时间:{EVENT.DATE} {EVENT.TIME}\n    告警等级:{TRIGGER.SEVERITY}\n    告警信息: {TRIGGER.NAME}\n    告警项目:{TRIGGER.KEY1}\n    问题详情:{ITEM.NAME}:{ITEM.VALUE}\n    当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1}\n    事件ID:{EVENT.ID}\n    已启用：打钩\n19. 解决乱码和附件问题\n    vim /usr/local/zabbix/share/zabbix/alertscripts/sendmail.sh\n    #!/bin/bash\n    #export.UTF-8 //解决发送的中文变成了乱码的问题\n    FILE=/tmp/mailtmp.txt\n    echo “$3” >$FILE\n    dos2unix -k $FILE  //解决了发送的邮件内容变成附件的问题。\n    /bin/mail -s “$2” $1 < $FILE\n    touch /tmp/mailtmp.txt\n    chown  zabbix.zabbix /tmp/mailtmp.txt\n20. zabbix  mysql客户端\n    find / -name userparameter_mysql.conf\n    vi /usr/local/zabbixvim/etc/zabbix_agent.conf\n    Include=/usr/local/zabbix/conf/zabbix_agentd/ #加入mysql配置(find查找的路径)\n    vi /usr/local/zabbix/etc/zabbix_agentd.conf\n    Include=/usr/local/zabbix/conf/zabbix_agentd/ #加入mysql配置\n    mkdir /etc/zabbix\n    touch /etc/zabbix/.my.cnf\n    vim /etc/zabbix/.my.cnf\n    [mysql]\n    host = localhost\n    user = mysqlcheck\n    password = mysqlcheck\n    socket = /var/lib/mysql/mysql.sock(mysql.sock的位置)\n    [mysqladmin]\n    host = localhost\n    user = mysqlcheck\n    password = mysqlchechk\n    socket = /var/lib/mysql/mysql.sock(mysql.sock的位置)\n    vim userparameter_mysql.conf\n    UserParameter=mysql.status[*],echo “show global status where Variable_name=’$1′;” | mysql -uzabbix -pjszj201501 -N | awk ‘{print $$2}’ #取mysql状态\n    UserParameter=mysql.size[*],echo “select sum($(case “$3″ in both|””) echo “data_length+index_length”;; data|index) echo “$3_length”;; free) echo “data_free”;; esac)) from information_schema.tables$([[ “$1” = “all” || ! “$1″ ]] || echo ” where table_schema=’$1′”)$([[ “$2” = “all” || ! “$2” ]] || echo “and table_name=’$2′”);” | mysql -uzabbix -pjszj201501 -N\n     #取mysql操作状态\n    UserParameter=mysql.ping,HOME=/etc/zabbix mysqladmin -uzabbix -ppassword | grep -c alive\n    UserParameter=mysql.version,mysql -V #取mysql版本\n    chmod 777 userparameter_mysql.conf\n    service zabbix_agentd restart\n21. Zabbix配置email报警\n一、              使用msmtp这个命令行MUA\n    (1)./configure –prefix=/usr/local/msmtp\n    (2)make\n    (3)make install\n    (4)mkdir /usr/local/msmtp/etc\n    (5)touch /usr/local/msmtp/etc/msmtprc\n    (6)在/usr/local/msmtp/etc/msmtprc中写入如下内容：\n    defaults\n    account michael_zhou\n    host mail.chinadba.com\n    domain chinadba.com\n    from michael_zhou@chinadba.com\n    auth login\n    user michael_zhou@chinadba.com\n        password your_password\n    account default:michael_zhou\n    logfile /var/log/maillog\n    (7)测试一下：/usr/local/msmtp/bin/msmtp i@chinadba.com，输入内容后按ctrl+D发出。\n二、    在实际测试中发现直接使用msmtp命令发出去的邮件会看不到发件人和主题，只能看到邮件内容，所以我使用mutt挂接在msmtp上，mutt默认会安装，如果没有安装请yum install mutt*\n    (1)修改mutt的配置文件/etc/Muttrc, 不是/etc/muttrc  ，M要大写\n    1．set sendmail=”/usr/local/msmtp/bin/msmtp”\n    2．set use_from=yes\n    3．set realname=michael_zhou@chinadba.com  #发件人邮箱地址\n    4．set editor=”vi”\n    5．保存退出\n    (2)测试一下：echo “邮件报警测试” | mutt -s “测试” i@chinadba.com  #收件人地址\n三、    创建 zabbix用于发送邮件的脚本,脚本放在什么位置随便，但是要保证zabbix能找到！\n(1)vim /usr/bin/baojing,并写入如下内容：\n#!/bin/bash\necho “$3” | mutt -s “$2” $1       # $3表示邮件内容、$2表示邮件标题、$1表示收件人\n(2)chmod a+x /usr/bin/baojing\n四、    zabbix配置\n(1)创建meida types\n1．登录到zabbix，进入“Administration” >> ”Media types”，点击右上角“Create Media Type”。 Description填”mediatype-baojing”或其它名称，Type选择”Script”，Script填”baojing”。\n2．点击save保存\n(2)创建actions\n1.登录到zabbix，进入”Configation” >> “Actions”，点击右上角”Create Actions”。输入Name “action-baojing” ，其它都默认点击右侧“Action Operations”下的”New”按钮，”Operation Type”选择”Send message”，”Send Message to”选择一个或多个要发送消息的用户组，”Send only to”选择我们之前新增的mediatype-baojing。\n2.点击save保存\n(3) zabbix用户配置\n登录到zabbix, 进入”Adimistration” >> “Users”，在之前选定要发送消息的组里的Members栏位里选择一个用户，例如选择Admin用户。\n在用户信息修改界面最下方的”Media”处点击”Add”按钮。\nType选择”mediatype-baojing”，Send to填入收件人地址，点击Add添加。\n点击”Save”保存配置。\n至此配置完成，测试！\n不光是zabbix,nagios等监控平台的邮件报警都可以这样配置。当然转到139邮箱的话可以收到短信的，会更加及时的收到报警。\nzabbix企业应用之服务器硬件信息监控\nhttp://dl528888.blog.51cto.com/2382721/1403893\nzabbix企业应用之Mysql主从监控\nhttp://dl528888.blog.51cto.com/2382721/1434263\nZabbix监控MySQL数据库状态\nhttp://www.linuxidc.com/Linux/2015-04/116304.htm\nZabbix使用微信接口实现微信报警功能\nhttp://lcbk.net/zabbix/2022.html\nhttp://www.cnyunwei.com/thread-29593-1-1.html\n","slug":"zabbix2.6安装","published":1,"updated":"2019-06-18T08:07:01.118Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sn0002ahcb7lk5yo9rn","content":"<ol>\n<li>安装lnmp架构<br><code>yum -y install gcc gcc-c++ autoconf httpd php mysql mysql-server php-mysql httpd-manual mod_ssl mod_perl mod_auth_mysql php-gd php-xml php-mbstring php-ldap php-pear php-xmlrpc php-bcmath mysql-connector-odbc mysql-devel libdbi-dbd-mysql net-snmp-devel curl-devel</code></li>\n<li><p>启动服务<br> service mysqld start<br> service httpd start</p>\n<a id=\"more\"></a>\n</li>\n<li><p>创建zabbix用户和组<br> groupadd zabbix<br> useradd zabbix -g zabbix</p>\n</li>\n<li>进入mysql创建数据库<br> create database zabbix character set utf8;<br> grant all on zabbix.* to zabbix@localhost identified by ‘jszj201501’;</li>\n<li>解压zabbix.tar包<blockquote>\n<p>tar zxf zabbix-2.4.tar.gz<br>cd zabbix-2.4.5/database/mysql/</p>\n</blockquote>\n</li>\n<li>导入数据库<br> mysql -uzabbix -pjszj201501 zabbix &lt;schema.sql<br> mysql -uzabbix -pjszj201501 zabbix &lt;images.sql</li>\n<li>进行编译安装<br> cd ../..<br> ./configure –prefix=/usr/local/zabbix –enable-server –enable-agent –with-mysql –with-net-snmp –with-libcurl<br> make&amp;&amp;make install</li>\n<li>添加zabbix服务对应的端口<br> cat &gt;&gt;/etc/services&lt;&lt;EOF<br> zabbix-agent 10050/tcp Zabbix Agent<br> zabbix-agent 10050/udp Zabbix Agent<br> zabbix-trapper 10051/tcp Zabbix Trapper<br> zabbix-trapper 10051/udp Zabbix Trapper<br> EOF</li>\n<li>修改zabbix server 配置文件<br> vim /usr/local/zabbix/etc/zabbix_server.conf<br> LogFile=/tmp/zabbix_server.log ##日志位置，根据需求修改；<br> PidFile=/tmp/zabbix_server.pid ##PID 所在位置<br> DBHost=localhost ##如果不是在本机，请修改<br> DBName=zabbix ##数据库名称<br> DBUser=zabbix ##数据库用户名<br> DBPassword=redhat ##数据库密码</li>\n<li>安装启动脚本,添加可执行权限<br>cp misc/init.d/fedora/core/zabbix_server /etc/init.d<br>chmod +x /etc/init.d/zabbix_server</li>\n<li><p>查找zabbix_server.conf位置复制</p>\n<p>find / -name zabbix_server.conf</p>\n</li>\n<li>修改启动脚本，启动zabbix server<br>vim /etc/init.d/zabbix_server<br>BASEDIR=/usr/local/zabbix ##修改这个，zabbix 的安装目录<br>CONFILE=$BASEDIR/etc/zabbix_server.conf ##添加这一行，定义配置文件位置<br>#搜索start,修改启动选项，默认是去/etc 下去找配置文件的<br>action $”Starting $BINARY_NAME: ” $FULLPATH -c $CONFILE<br>service zabbix_server start</li>\n<li>安装邮件服务<br>yum install mailx<br>vi /etc/mail.rc<br>set <a href=\"mailto:from=xxx@163.com\" target=\"_blank\" rel=\"noopener\">from=xxx@163.com</a> smtp=smtp.163.com<br>set <a href=\"mailto:smtp-auth-user=xxx@163.com\" target=\"_blank\" rel=\"noopener\">smtp-auth-user=xxx@163.com</a> smtp-auth-password=123456<br>set smtp-auth=login<br>:wq! #保存退出<br>echo “zabbix test mail” |mail -s “zabbix” <a href=\"mailto:yyy@163.com\" target=\"_blank\" rel=\"noopener\">yyy@163.com</a><br>linux客户端<br>mkdir /usr/local/zabbix<br>tar zxf zabbix_agents_2.0.6.linux2_6.amd64.tar.gz -C /usr/local/zabbix</li>\n<li>编辑配置文件<br>find / -name zabbix_agentd.conf<br>vim zabbix_agentd.conf<br>LogFile=/tmp/zabbix_agentd.log<br>Server=202.108.1.52 ##服务器IP<br>ServerActive=202.108.1.52 ##主动模式服务器IP<br>Hostname=202.108.1.51 ##设定主机名<br>#加入mysql配置</li>\n<li>安装修改启动脚本<br>scp misc/init.d/fedora/core/zabbix_agentd 202.108.1.51:/etc/init.d<br>vim /etc/init.d/zabbix_agentd<br>BASEDIR=/usr/local/zabbix ##修改这个<br>CONFILE=$BASEDIR/etc/zabbix_agentd.conf ##添加这行，搜索start 添加-c $CONFILE<br>action $”Starting $BINARY_NAME: ” $FULLPATH -c $CONFILE<br>service zabbix_agentd start</li>\n<li>创建用户和用户组<br>groupadd zabbix<br>useradd zabbix -g zabbix<br>windows客户端<br>cmd<br>d:\\zabbix_agentd.exe -i -c d:\\zabbix\\zabbix_agentd.conf<br>services.msc</li>\n<li>禁用内部邮件服务<br>service sendmail stop #关闭<br>chkconfig sendmail off #禁止开机启动<br>service postfix stop<br>chkconfig postfix off</li>\n<li>事件触发器配置：<br>名称：Action-Email<br>默认接收人：故障{TRIGGER.STATUS},服务器:{HOSTNAME1}发生: {TRIGGER.NAME}故障!<br>默认信息：<br>告警主机:{HOSTNAME1}<br>告警时间:{EVENT.DATE} {EVENT.TIME}<br>告警等级:{TRIGGER.SEVERITY}<br>告警信息: {TRIGGER.NAME}<br>告警项目:{TRIGGER.KEY1}<br>问题详情:{ITEM.NAME}:{ITEM.VALUE}<br>当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1}<br>事件ID:{EVENT.ID}<br>恢复信息：打钩<br>恢复主旨：恢复{TRIGGER.STATUS}, 服务器:{HOSTNAME1}: {TRIGGER.NAME}已恢复!<br>恢复信息：<br>告警主机:{HOSTNAME1}<br>告警时间:{EVENT.DATE} {EVENT.TIME}<br>告警等级:{TRIGGER.SEVERITY}<br>告警信息: {TRIGGER.NAME}<br>告警项目:{TRIGGER.KEY1}<br>问题详情:{ITEM.NAME}:{ITEM.VALUE}<br>当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1}<br>事件ID:{EVENT.ID}<br>已启用：打钩</li>\n<li>解决乱码和附件问题<br>vim /usr/local/zabbix/share/zabbix/alertscripts/sendmail.sh<br>#!/bin/bash<br>#export.UTF-8 //解决发送的中文变成了乱码的问题<br>FILE=/tmp/mailtmp.txt<br>echo “$3” &gt;$FILE<br>dos2unix -k $FILE  //解决了发送的邮件内容变成附件的问题。<br>/bin/mail -s “$2” $1 &lt; $FILE<br>touch /tmp/mailtmp.txt<br>chown  zabbix.zabbix /tmp/mailtmp.txt</li>\n<li>zabbix  mysql客户端<br>find / -name userparameter_mysql.conf<br>vi /usr/local/zabbixvim/etc/zabbix_agent.conf<br>Include=/usr/local/zabbix/conf/zabbix_agentd/ #加入mysql配置(find查找的路径)<br>vi /usr/local/zabbix/etc/zabbix_agentd.conf<br>Include=/usr/local/zabbix/conf/zabbix_agentd/ #加入mysql配置<br>mkdir /etc/zabbix<br>touch /etc/zabbix/.my.cnf<br>vim /etc/zabbix/.my.cnf<br>[mysql]<br>host = localhost<br>user = mysqlcheck<br>password = mysqlcheck<br>socket = /var/lib/mysql/mysql.sock(mysql.sock的位置)<br>[mysqladmin]<br>host = localhost<br>user = mysqlcheck<br>password = mysqlchechk<br>socket = /var/lib/mysql/mysql.sock(mysql.sock的位置)<br>vim userparameter_mysql.conf<br>UserParameter=mysql.status[<em>],echo “show global status where Variable_name=’$1′;” | mysql -uzabbix -pjszj201501 -N | awk ‘{print $$2}’ #取mysql状态<br>UserParameter=mysql.size[</em>],echo “select sum($(case “$3″ in both|””) echo “data_length+index_length”;; data|index) echo “$3_length”;; free) echo “data_free”;; esac)) from information_schema.tables$([[ “$1” = “all” || ! “$1″ ]] || echo ” where table_schema=’$1′”)$([[ “$2” = “all” || ! “$2” ]] || echo “and table_name=’$2′”);” | mysql -uzabbix -pjszj201501 -N<br> #取mysql操作状态<br>UserParameter=mysql.ping,HOME=/etc/zabbix mysqladmin -uzabbix -ppassword | grep -c alive<br>UserParameter=mysql.version,mysql -V #取mysql版本<br>chmod 777 userparameter_mysql.conf<br>service zabbix_agentd restart</li>\n<li>Zabbix配置email报警<br>一、              使用msmtp这个命令行MUA<br>(1)./configure –prefix=/usr/local/msmtp<br>(2)make<br>(3)make install<br>(4)mkdir /usr/local/msmtp/etc<br>(5)touch /usr/local/msmtp/etc/msmtprc<br>(6)在/usr/local/msmtp/etc/msmtprc中写入如下内容：<br>defaults<br>account michael_zhou<br>host mail.chinadba.com<br>domain chinadba.com<br>from <a href=\"mailto:michael_zhou@chinadba.com\" target=\"_blank\" rel=\"noopener\">michael_zhou@chinadba.com</a><br>auth login<br>user <a href=\"mailto:michael_zhou@chinadba.com\" target=\"_blank\" rel=\"noopener\">michael_zhou@chinadba.com</a><pre><code>password your_password\n</code></pre>account default:michael_zhou<br>logfile /var/log/maillog<br>(7)测试一下：/usr/local/msmtp/bin/msmtp <a href=\"mailto:i@chinadba.com\" target=\"_blank\" rel=\"noopener\">i@chinadba.com</a>，输入内容后按ctrl+D发出。<br>二、    在实际测试中发现直接使用msmtp命令发出去的邮件会看不到发件人和主题，只能看到邮件内容，所以我使用mutt挂接在msmtp上，mutt默认会安装，如果没有安装请yum install mutt*<br>(1)修改mutt的配置文件/etc/Muttrc, 不是/etc/muttrc  ，M要大写<br>1．set sendmail=”/usr/local/msmtp/bin/msmtp”<br>2．set use_from=yes<br>3．set <a href=\"mailto:realname=michael_zhou@chinadba.com\" target=\"_blank\" rel=\"noopener\">realname=michael_zhou@chinadba.com</a>  #发件人邮箱地址<br>4．set editor=”vi”<br>5．保存退出<br>(2)测试一下：echo “邮件报警测试” | mutt -s “测试” <a href=\"mailto:i@chinadba.com\" target=\"_blank\" rel=\"noopener\">i@chinadba.com</a>  #收件人地址<br>三、    创建 zabbix用于发送邮件的脚本,脚本放在什么位置随便，但是要保证zabbix能找到！<br>(1)vim /usr/bin/baojing,并写入如下内容：<br>#!/bin/bash<br>echo “$3” | mutt -s “$2” $1       # $3表示邮件内容、$2表示邮件标题、$1表示收件人<br>(2)chmod a+x /usr/bin/baojing<br>四、    zabbix配置<br>(1)创建meida types<br>1．登录到zabbix，进入“Administration” &gt;&gt; ”Media types”，点击右上角“Create Media Type”。 Description填”mediatype-baojing”或其它名称，Type选择”Script”，Script填”baojing”。<br>2．点击save保存<br>(2)创建actions<br>1.登录到zabbix，进入”Configation” &gt;&gt; “Actions”，点击右上角”Create Actions”。输入Name “action-baojing” ，其它都默认点击右侧“Action Operations”下的”New”按钮，”Operation Type”选择”Send message”，”Send Message to”选择一个或多个要发送消息的用户组，”Send only to”选择我们之前新增的mediatype-baojing。<br>2.点击save保存<br>(3) zabbix用户配置<br>登录到zabbix, 进入”Adimistration” &gt;&gt; “Users”，在之前选定要发送消息的组里的Members栏位里选择一个用户，例如选择Admin用户。<br>在用户信息修改界面最下方的”Media”处点击”Add”按钮。<br>Type选择”mediatype-baojing”，Send to填入收件人地址，点击Add添加。<br>点击”Save”保存配置。<br>至此配置完成，测试！<br>不光是zabbix,nagios等监控平台的邮件报警都可以这样配置。当然转到139邮箱的话可以收到短信的，会更加及时的收到报警。<br>zabbix企业应用之服务器硬件信息监控<br><a href=\"http://dl528888.blog.51cto.com/2382721/1403893\" target=\"_blank\" rel=\"noopener\">http://dl528888.blog.51cto.com/2382721/1403893</a><br>zabbix企业应用之Mysql主从监控<br><a href=\"http://dl528888.blog.51cto.com/2382721/1434263\" target=\"_blank\" rel=\"noopener\">http://dl528888.blog.51cto.com/2382721/1434263</a><br>Zabbix监控MySQL数据库状态<br><a href=\"http://www.linuxidc.com/Linux/2015-04/116304.htm\" target=\"_blank\" rel=\"noopener\">http://www.linuxidc.com/Linux/2015-04/116304.htm</a><br>Zabbix使用微信接口实现微信报警功能<br><a href=\"http://lcbk.net/zabbix/2022.html\" target=\"_blank\" rel=\"noopener\">http://lcbk.net/zabbix/2022.html</a><br><a href=\"http://www.cnyunwei.com/thread-29593-1-1.html\" target=\"_blank\" rel=\"noopener\">http://www.cnyunwei.com/thread-29593-1-1.html</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>安装lnmp架构<br><code>yum -y install gcc gcc-c++ autoconf httpd php mysql mysql-server php-mysql httpd-manual mod_ssl mod_perl mod_auth_mysql php-gd php-xml php-mbstring php-ldap php-pear php-xmlrpc php-bcmath mysql-connector-odbc mysql-devel libdbi-dbd-mysql net-snmp-devel curl-devel</code></li>\n<li><p>启动服务<br> service mysqld start<br> service httpd start</p>","more":"</li>\n<li><p>创建zabbix用户和组<br> groupadd zabbix<br> useradd zabbix -g zabbix</p>\n</li>\n<li>进入mysql创建数据库<br> create database zabbix character set utf8;<br> grant all on zabbix.* to zabbix@localhost identified by ‘jszj201501’;</li>\n<li>解压zabbix.tar包<blockquote>\n<p>tar zxf zabbix-2.4.tar.gz<br>cd zabbix-2.4.5/database/mysql/</p>\n</blockquote>\n</li>\n<li>导入数据库<br> mysql -uzabbix -pjszj201501 zabbix &lt;schema.sql<br> mysql -uzabbix -pjszj201501 zabbix &lt;images.sql</li>\n<li>进行编译安装<br> cd ../..<br> ./configure –prefix=/usr/local/zabbix –enable-server –enable-agent –with-mysql –with-net-snmp –with-libcurl<br> make&amp;&amp;make install</li>\n<li>添加zabbix服务对应的端口<br> cat &gt;&gt;/etc/services&lt;&lt;EOF<br> zabbix-agent 10050/tcp Zabbix Agent<br> zabbix-agent 10050/udp Zabbix Agent<br> zabbix-trapper 10051/tcp Zabbix Trapper<br> zabbix-trapper 10051/udp Zabbix Trapper<br> EOF</li>\n<li>修改zabbix server 配置文件<br> vim /usr/local/zabbix/etc/zabbix_server.conf<br> LogFile=/tmp/zabbix_server.log ##日志位置，根据需求修改；<br> PidFile=/tmp/zabbix_server.pid ##PID 所在位置<br> DBHost=localhost ##如果不是在本机，请修改<br> DBName=zabbix ##数据库名称<br> DBUser=zabbix ##数据库用户名<br> DBPassword=redhat ##数据库密码</li>\n<li>安装启动脚本,添加可执行权限<br>cp misc/init.d/fedora/core/zabbix_server /etc/init.d<br>chmod +x /etc/init.d/zabbix_server</li>\n<li><p>查找zabbix_server.conf位置复制</p>\n<p>find / -name zabbix_server.conf</p>\n</li>\n<li>修改启动脚本，启动zabbix server<br>vim /etc/init.d/zabbix_server<br>BASEDIR=/usr/local/zabbix ##修改这个，zabbix 的安装目录<br>CONFILE=$BASEDIR/etc/zabbix_server.conf ##添加这一行，定义配置文件位置<br>#搜索start,修改启动选项，默认是去/etc 下去找配置文件的<br>action $”Starting $BINARY_NAME: ” $FULLPATH -c $CONFILE<br>service zabbix_server start</li>\n<li>安装邮件服务<br>yum install mailx<br>vi /etc/mail.rc<br>set <a href=\"mailto:from=xxx@163.com\" target=\"_blank\" rel=\"noopener\">from=xxx@163.com</a> smtp=smtp.163.com<br>set <a href=\"mailto:smtp-auth-user=xxx@163.com\" target=\"_blank\" rel=\"noopener\">smtp-auth-user=xxx@163.com</a> smtp-auth-password=123456<br>set smtp-auth=login<br>:wq! #保存退出<br>echo “zabbix test mail” |mail -s “zabbix” <a href=\"mailto:yyy@163.com\" target=\"_blank\" rel=\"noopener\">yyy@163.com</a><br>linux客户端<br>mkdir /usr/local/zabbix<br>tar zxf zabbix_agents_2.0.6.linux2_6.amd64.tar.gz -C /usr/local/zabbix</li>\n<li>编辑配置文件<br>find / -name zabbix_agentd.conf<br>vim zabbix_agentd.conf<br>LogFile=/tmp/zabbix_agentd.log<br>Server=202.108.1.52 ##服务器IP<br>ServerActive=202.108.1.52 ##主动模式服务器IP<br>Hostname=202.108.1.51 ##设定主机名<br>#加入mysql配置</li>\n<li>安装修改启动脚本<br>scp misc/init.d/fedora/core/zabbix_agentd 202.108.1.51:/etc/init.d<br>vim /etc/init.d/zabbix_agentd<br>BASEDIR=/usr/local/zabbix ##修改这个<br>CONFILE=$BASEDIR/etc/zabbix_agentd.conf ##添加这行，搜索start 添加-c $CONFILE<br>action $”Starting $BINARY_NAME: ” $FULLPATH -c $CONFILE<br>service zabbix_agentd start</li>\n<li>创建用户和用户组<br>groupadd zabbix<br>useradd zabbix -g zabbix<br>windows客户端<br>cmd<br>d:\\zabbix_agentd.exe -i -c d:\\zabbix\\zabbix_agentd.conf<br>services.msc</li>\n<li>禁用内部邮件服务<br>service sendmail stop #关闭<br>chkconfig sendmail off #禁止开机启动<br>service postfix stop<br>chkconfig postfix off</li>\n<li>事件触发器配置：<br>名称：Action-Email<br>默认接收人：故障{TRIGGER.STATUS},服务器:{HOSTNAME1}发生: {TRIGGER.NAME}故障!<br>默认信息：<br>告警主机:{HOSTNAME1}<br>告警时间:{EVENT.DATE} {EVENT.TIME}<br>告警等级:{TRIGGER.SEVERITY}<br>告警信息: {TRIGGER.NAME}<br>告警项目:{TRIGGER.KEY1}<br>问题详情:{ITEM.NAME}:{ITEM.VALUE}<br>当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1}<br>事件ID:{EVENT.ID}<br>恢复信息：打钩<br>恢复主旨：恢复{TRIGGER.STATUS}, 服务器:{HOSTNAME1}: {TRIGGER.NAME}已恢复!<br>恢复信息：<br>告警主机:{HOSTNAME1}<br>告警时间:{EVENT.DATE} {EVENT.TIME}<br>告警等级:{TRIGGER.SEVERITY}<br>告警信息: {TRIGGER.NAME}<br>告警项目:{TRIGGER.KEY1}<br>问题详情:{ITEM.NAME}:{ITEM.VALUE}<br>当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1}<br>事件ID:{EVENT.ID}<br>已启用：打钩</li>\n<li>解决乱码和附件问题<br>vim /usr/local/zabbix/share/zabbix/alertscripts/sendmail.sh<br>#!/bin/bash<br>#export.UTF-8 //解决发送的中文变成了乱码的问题<br>FILE=/tmp/mailtmp.txt<br>echo “$3” &gt;$FILE<br>dos2unix -k $FILE  //解决了发送的邮件内容变成附件的问题。<br>/bin/mail -s “$2” $1 &lt; $FILE<br>touch /tmp/mailtmp.txt<br>chown  zabbix.zabbix /tmp/mailtmp.txt</li>\n<li>zabbix  mysql客户端<br>find / -name userparameter_mysql.conf<br>vi /usr/local/zabbixvim/etc/zabbix_agent.conf<br>Include=/usr/local/zabbix/conf/zabbix_agentd/ #加入mysql配置(find查找的路径)<br>vi /usr/local/zabbix/etc/zabbix_agentd.conf<br>Include=/usr/local/zabbix/conf/zabbix_agentd/ #加入mysql配置<br>mkdir /etc/zabbix<br>touch /etc/zabbix/.my.cnf<br>vim /etc/zabbix/.my.cnf<br>[mysql]<br>host = localhost<br>user = mysqlcheck<br>password = mysqlcheck<br>socket = /var/lib/mysql/mysql.sock(mysql.sock的位置)<br>[mysqladmin]<br>host = localhost<br>user = mysqlcheck<br>password = mysqlchechk<br>socket = /var/lib/mysql/mysql.sock(mysql.sock的位置)<br>vim userparameter_mysql.conf<br>UserParameter=mysql.status[<em>],echo “show global status where Variable_name=’$1′;” | mysql -uzabbix -pjszj201501 -N | awk ‘{print $$2}’ #取mysql状态<br>UserParameter=mysql.size[</em>],echo “select sum($(case “$3″ in both|””) echo “data_length+index_length”;; data|index) echo “$3_length”;; free) echo “data_free”;; esac)) from information_schema.tables$([[ “$1” = “all” || ! “$1″ ]] || echo ” where table_schema=’$1′”)$([[ “$2” = “all” || ! “$2” ]] || echo “and table_name=’$2′”);” | mysql -uzabbix -pjszj201501 -N<br> #取mysql操作状态<br>UserParameter=mysql.ping,HOME=/etc/zabbix mysqladmin -uzabbix -ppassword | grep -c alive<br>UserParameter=mysql.version,mysql -V #取mysql版本<br>chmod 777 userparameter_mysql.conf<br>service zabbix_agentd restart</li>\n<li>Zabbix配置email报警<br>一、              使用msmtp这个命令行MUA<br>(1)./configure –prefix=/usr/local/msmtp<br>(2)make<br>(3)make install<br>(4)mkdir /usr/local/msmtp/etc<br>(5)touch /usr/local/msmtp/etc/msmtprc<br>(6)在/usr/local/msmtp/etc/msmtprc中写入如下内容：<br>defaults<br>account michael_zhou<br>host mail.chinadba.com<br>domain chinadba.com<br>from <a href=\"mailto:michael_zhou@chinadba.com\" target=\"_blank\" rel=\"noopener\">michael_zhou@chinadba.com</a><br>auth login<br>user <a href=\"mailto:michael_zhou@chinadba.com\" target=\"_blank\" rel=\"noopener\">michael_zhou@chinadba.com</a><pre><code>password your_password\n</code></pre>account default:michael_zhou<br>logfile /var/log/maillog<br>(7)测试一下：/usr/local/msmtp/bin/msmtp <a href=\"mailto:i@chinadba.com\" target=\"_blank\" rel=\"noopener\">i@chinadba.com</a>，输入内容后按ctrl+D发出。<br>二、    在实际测试中发现直接使用msmtp命令发出去的邮件会看不到发件人和主题，只能看到邮件内容，所以我使用mutt挂接在msmtp上，mutt默认会安装，如果没有安装请yum install mutt*<br>(1)修改mutt的配置文件/etc/Muttrc, 不是/etc/muttrc  ，M要大写<br>1．set sendmail=”/usr/local/msmtp/bin/msmtp”<br>2．set use_from=yes<br>3．set <a href=\"mailto:realname=michael_zhou@chinadba.com\" target=\"_blank\" rel=\"noopener\">realname=michael_zhou@chinadba.com</a>  #发件人邮箱地址<br>4．set editor=”vi”<br>5．保存退出<br>(2)测试一下：echo “邮件报警测试” | mutt -s “测试” <a href=\"mailto:i@chinadba.com\" target=\"_blank\" rel=\"noopener\">i@chinadba.com</a>  #收件人地址<br>三、    创建 zabbix用于发送邮件的脚本,脚本放在什么位置随便，但是要保证zabbix能找到！<br>(1)vim /usr/bin/baojing,并写入如下内容：<br>#!/bin/bash<br>echo “$3” | mutt -s “$2” $1       # $3表示邮件内容、$2表示邮件标题、$1表示收件人<br>(2)chmod a+x /usr/bin/baojing<br>四、    zabbix配置<br>(1)创建meida types<br>1．登录到zabbix，进入“Administration” &gt;&gt; ”Media types”，点击右上角“Create Media Type”。 Description填”mediatype-baojing”或其它名称，Type选择”Script”，Script填”baojing”。<br>2．点击save保存<br>(2)创建actions<br>1.登录到zabbix，进入”Configation” &gt;&gt; “Actions”，点击右上角”Create Actions”。输入Name “action-baojing” ，其它都默认点击右侧“Action Operations”下的”New”按钮，”Operation Type”选择”Send message”，”Send Message to”选择一个或多个要发送消息的用户组，”Send only to”选择我们之前新增的mediatype-baojing。<br>2.点击save保存<br>(3) zabbix用户配置<br>登录到zabbix, 进入”Adimistration” &gt;&gt; “Users”，在之前选定要发送消息的组里的Members栏位里选择一个用户，例如选择Admin用户。<br>在用户信息修改界面最下方的”Media”处点击”Add”按钮。<br>Type选择”mediatype-baojing”，Send to填入收件人地址，点击Add添加。<br>点击”Save”保存配置。<br>至此配置完成，测试！<br>不光是zabbix,nagios等监控平台的邮件报警都可以这样配置。当然转到139邮箱的话可以收到短信的，会更加及时的收到报警。<br>zabbix企业应用之服务器硬件信息监控<br><a href=\"http://dl528888.blog.51cto.com/2382721/1403893\" target=\"_blank\" rel=\"noopener\">http://dl528888.blog.51cto.com/2382721/1403893</a><br>zabbix企业应用之Mysql主从监控<br><a href=\"http://dl528888.blog.51cto.com/2382721/1434263\" target=\"_blank\" rel=\"noopener\">http://dl528888.blog.51cto.com/2382721/1434263</a><br>Zabbix监控MySQL数据库状态<br><a href=\"http://www.linuxidc.com/Linux/2015-04/116304.htm\" target=\"_blank\" rel=\"noopener\">http://www.linuxidc.com/Linux/2015-04/116304.htm</a><br>Zabbix使用微信接口实现微信报警功能<br><a href=\"http://lcbk.net/zabbix/2022.html\" target=\"_blank\" rel=\"noopener\">http://lcbk.net/zabbix/2022.html</a><br><a href=\"http://www.cnyunwei.com/thread-29593-1-1.html\" target=\"_blank\" rel=\"noopener\">http://www.cnyunwei.com/thread-29593-1-1.html</a></li>\n</ol>"},{"title":"搭建WordPress","date":"2016-09-02T04:00:00.000Z","_content":"\n1.搭建LAMP环境\n<!--more-->\n    service iptables stop\n    setenforce 0\n    yum install httpd mysql mysql-server php php-mysql php-gd php-xml\n    service httpd start\n    service mysqld start\n    chkconfig httpd on //开机启动\n    chkconfig –list |grep httpd\n    chkconfig mysqld on\n    chkconfig –list |grep mysql\n    mysqladmin -u root -p password ‘123’ //为mysql设置用户和密码\n    Enter password: //此处回车即可。\n    mysql -u root -p\n    create database wordpress; //创建wordpress数据库，为下面安装wordpress做准备。\n    show databases;\n\n2.安装WordPress\n\n    unzip wordpress-3.9-zh_CN.zip //解压缩\n    mv wordpress /var/www/html/\n    cd /var/www/html/wordpress/\n    vim wp-config.php\n","source":"_posts/搭建WordPress.md","raw":"---\ntitle: 搭建WordPress\ndate: 2016-09-02\ntags: wordpress\ncategories: woedpress\n---\n\n1.搭建LAMP环境\n<!--more-->\n    service iptables stop\n    setenforce 0\n    yum install httpd mysql mysql-server php php-mysql php-gd php-xml\n    service httpd start\n    service mysqld start\n    chkconfig httpd on //开机启动\n    chkconfig –list |grep httpd\n    chkconfig mysqld on\n    chkconfig –list |grep mysql\n    mysqladmin -u root -p password ‘123’ //为mysql设置用户和密码\n    Enter password: //此处回车即可。\n    mysql -u root -p\n    create database wordpress; //创建wordpress数据库，为下面安装wordpress做准备。\n    show databases;\n\n2.安装WordPress\n\n    unzip wordpress-3.9-zh_CN.zip //解压缩\n    mv wordpress /var/www/html/\n    cd /var/www/html/wordpress/\n    vim wp-config.php\n","slug":"搭建WordPress","published":1,"updated":"2019-06-18T08:07:01.118Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9snc002dhcb71wi6obkj","content":"<p>1.搭建LAMP环境<br><a id=\"more\"></a><br>    service iptables stop<br>    setenforce 0<br>    yum install httpd mysql mysql-server php php-mysql php-gd php-xml<br>    service httpd start<br>    service mysqld start<br>    chkconfig httpd on //开机启动<br>    chkconfig –list |grep httpd<br>    chkconfig mysqld on<br>    chkconfig –list |grep mysql<br>    mysqladmin -u root -p password ‘123’ //为mysql设置用户和密码<br>    Enter password: //此处回车即可。<br>    mysql -u root -p<br>    create database wordpress; //创建wordpress数据库，为下面安装wordpress做准备。<br>    show databases;</p>\n<p>2.安装WordPress</p>\n<pre><code>unzip wordpress-3.9-zh_CN.zip //解压缩\nmv wordpress /var/www/html/\ncd /var/www/html/wordpress/\nvim wp-config.php\n</code></pre>","site":{"data":{}},"excerpt":"<p>1.搭建LAMP环境<br>","more":"<br>    service iptables stop<br>    setenforce 0<br>    yum install httpd mysql mysql-server php php-mysql php-gd php-xml<br>    service httpd start<br>    service mysqld start<br>    chkconfig httpd on //开机启动<br>    chkconfig –list |grep httpd<br>    chkconfig mysqld on<br>    chkconfig –list |grep mysql<br>    mysqladmin -u root -p password ‘123’ //为mysql设置用户和密码<br>    Enter password: //此处回车即可。<br>    mysql -u root -p<br>    create database wordpress; //创建wordpress数据库，为下面安装wordpress做准备。<br>    show databases;</p>\n<p>2.安装WordPress</p>\n<pre><code>unzip wordpress-3.9-zh_CN.zip //解压缩\nmv wordpress /var/www/html/\ncd /var/www/html/wordpress/\nvim wp-config.php\n</code></pre>"},{"title":"用Kibana和logstash快速搭建实时日志查询、收集与分析系统","date":"2017-03-03T05:00:00.000Z","_content":" Logstash是一个完全开源的工具，他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索），您可以使用它。说到搜索，logstash带有一个web界面，搜索和展示所有日志。\nkibana 也是一个开源和免费的工具，他可以帮助您汇总、分析和搜索重要数据日志并提供友好的web界面。他可以为 Logstash 和 ElasticSearch 提供的日志分析的 Web 界面\n<!--more-->\n说到这里，我们看看 kibana 和 logstash到底能为我们做些什么呢？下面是kibana的界面\n![](http://img1.51cto.com/attachment/201303/131035239.png)\n\n简单来讲他具体的工作流程就是 logstash agent 监控并过滤日志，将过滤后的日志内容发给redis(这里的redis只处理队列不做存储)，logstash index将日志收集在一起交给\n全文搜索服务ElasticSearch 可以用ElasticSearch进行自定义搜索 通过Kibana 来结合 自定义搜索进行页面展示，下图是 Kibana官网上的流程图\n![](http://img1.51cto.com/attachment/201303/131135111.png)\n\n好了 让我们一步步的把这套环境搭建起来吧，先看看都需要安装什么软件包\nruby 运行Kibana 必须，  \nrubygems 安装ruby扩展必须  \nbundler 功能类似于yum  \nJDK 运行java程序必须   \nredis 用来处理日志队列    \nlogstash 收集、过滤日志  \nElasticSearch 全文搜索服务(logstash集成了一个)  \nkibana 页面展示    \n这里有三台服务器    \n192.168.233.128 logstash index，ElasticSearch，kibana，JDK    \n192.168.233.129 logstash agent，JDK  \n192.168.233.130 redis  \n\n首先到 logstash index服务器上面，logstash分为 index和aget ，agent负责监控、过滤日志，index负责收集日志并将日志交给ElasticSearch 做搜索,此外 logstash 的收集方式分为 standalone 和 centralized。  \nstandalone 是所有功能都在一个服务器上面，自发自收，centralized 就是集中收集，一台服务器接收所有shipper(个人理解就是logstash agent)的日志。  \n其实 logstash本身不分 什么 shipper 和 collector ，只不过就是配置文件不同而已，我们这次按照集中的方式来测试.\n\n在 logstash index上安装基础的软件环境\n\n    [192.168.233.128 root@nodec:~] \n    # cd /soft/ \n    [192.168.233.128 root@nodec:/soft] \n    # wget http://down1.chinaunix.net/distfiles/jdk-6u13-dlj-linux-i586.bin \n    从oracle下载实在是太慢了，从CU下载会快一些，如果需要最新版本请访问这里 \n    http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html \n    [192.168.233.128 root@nodec:/soft] \n    # sh jdk-6u13-dlj-linux-i586.bin \n    输入yes 便开始安装了 \n    安装完成后设置一下 JAVA_HOME \n    [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n    # vim /etc/profile \n    export JAVA_HOME=/usr/java \n    export PATH=$JAVA_HOME/bin:$PATH \n    export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$CLASSPATH \n     \n    安装ruby 就比较简单了(Kibana需要ruby 1.8.7以上版本) \n    [192.168.233.128 root@nodec:/soft] \n    # yum install ruby rubygems \n    ..... 安装内容省略 \n    安装完成后用 rubygems 来安装bundler \n    [192.168.233.128 root@nodec:/soft] \n    # /usr/bin/gem install bundler \n    ..... \n     \n    ok 这样基本的环境就已经有了，下面就是安装kibana 和 logstash \n    其实logstash 就是一个java脚本，不需要安装... 下载即用 \n    [192.168.233.128 root@nodec:/soft] \n    # wget http://logstash.objects.dreamhost.com/release/logstash-1.1.0-monolithic.jar \n    现在看看 这个脚本应该怎么去执行 \n    [192.168.233.128 root@nodec:/soft] \n    # java -jar /soft/logstash-1.1.0-monolithic.jar -h \n    No such command \"-h\" \n    Available commands: \n      -v \n      -V \n      --version \n      agent \n      web \n      test \n    显然没有 -h 参数，不过列出了能用的参数，但是logstash的参数可不止这些， \n    java -jar /soft/logstash-1.1.0-monolithic.jar agent --help \n    这些是在agent模式下的命令参数 \n    -f, --config CONFIGFILE \n    Load the logstash config from a specific file, directory, or a wildcard. If given a directory or wildcard, config files will be read in order lexigraphically. \n    -e CONFIGSTRING \n    Use the given string as the configuration data. Same syntax as the config file. If not input is specified, 'stdin { type => stdin }' is default. If no output is specified, 'stdout { debug => true }}' is default. \n    -w, --filterworks COUNT \n    Run COUNT filter workers (default: 1) \n    --watchdog-timeout TIMEOUT \n    Set watchdog timeout value. \n    -l, --log FILE \n    Log to a given path. Default is to log to stdout \n    -v \n    Increase verbosity. There are multiple levels of verbosity available with '-vv' currently being the highest \n    --pluginpath PLUGIN_PATH \n    A colon-delimted path to find other logstash plugins in \n    java -jar /soft/logstash-1.1.0-monolithic.jar web --help \n    下面的是在web界面的参数 \n    --log FILE \n    Log to a given path. Default is stdout. \n    --address ADDRESS \n    Address on which to start webserver. Default is 0.0.0.0. \n    --port PORT \n    Port on which to start webserver. Default is 9292. \n    -B, --elasticsearch-bind-host ADDRESS \n    Address on which to bind elastic search node. \n    -b, --backend URL \n    The backend URL to use. Default is elasticsearch:/// (assumes multicast discovery). You can specify elasticsearch://[host][:port]/[clustername] \n\n如果上面的这些命令都能执行正常的话就表示 logstash可以使用了，但要让他启动还需要一个配置文件\n\n\n    [192.168.233.128 root@nodec:/soft] \n     \n    # vim redis.conf \n     \n    input {\n    redis { \n      host => '192.168.233.130' \n      data_type => 'list' \n      port => \"6379\" \n      key => 'logstash:redis' \n      type => 'redis-input' \n       } \n       }\n     \n    output { \n    elasticsearch { \n    embedded => true \n      } \n       } \n\n解释一下 logstash的配置文件由 input filter output 等几个基本的部分组成，顾名思义 input 就是在那收集数据，output就是输出到哪，filter代表一个过滤规则意思是什么内容\n会被收集。  \n上面这段是让 logstash 去192.168.233.130 这个redis服务器上去收集日志 redis端口为6379，key是 logstash:redis 类型为 redis-input ，（注意:这几个值必须跟logstash agent的\noutput 所对应），收集完成后输出到 elasticsearch ,embedded => true 的意思是使用logstash 内嵌的 elasticsearch。如果有独立的elasticsearch服务器，需要将 这条改为  \nhost => 'elasticsearch的ip' port => 端口  \n好了，这个简单的配置文件可以让logstash开始启动了  \n\n    [192.168.233.128 root@nodec:/soft] \n    # java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf -- web --backend elasticsearch:///?local & \n    [1] 5205 \n    ...这里要等待约5秒钟... 为什么？去问开发者吧 \n    [192.168.233.128 root@nodec:/soft] \n    # I, [2013-03-19T03:23:10.749000 #5205]  INFO -- : Using beta plugin 'redis'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {\"timestamp\":\"2013-03-19T03:23:10.732000 -0700\",\"message\":\"Using beta plugin 'redis'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status \",\"level\":\"info\"} \n    file:/soft/logstash-1.1.0-monolithic.jar!/gems/rack-1.3.4/lib/rack/backports/uri/common_192.rb:53 warning: already initialized constant WFKV_ \n    Mizuno 0.5.0 (Jetty 8.0.y.z-SNAPSHOT) listening on 0.0.0.0:9292 \n    解释一下 上面的命令 agent 代理模式 -f 指定配置文件 --web 其实是个分隔符等于又启动了一个命令，后面的参数就是开启一个web页面默认端口是9292,这个命令如果拆成两个就是这个样子 \n    java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf & \n    java -jar /soft/logstash-1.1.0-monolithic.jar web --backend elasticsearch:///?local & (其实如果用kibana来做web界面的话这一步完全可以省掉了)\n\n好了，看到9292 端口启动就代表 启动成功了，检查一下\n\n    [192.168.233.128 root@nodec:/soft] \n    # lsof -i:9292 \n    COMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME \n    java5205 root  465u  IPv4 130805   TCP *:armtechdaemon (LISTEN) \n    其实logstash还启动了一个端口9200，因为启动了内嵌的 elasticsearch，这个9200是 elasticsearch在监听 \n    [192.168.233.128 root@nodec:/soft] \n    # lsof -i:9200 \n    COMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME \n    java5205 root  160u  IPv4 130682   TCP *:wap-wsp (LISTEN) \n现在可以通过浏览器访问一下 http://192.168.233.128:9292 看看logstash是的页面是个什么样子\n![](http://img1.51cto.com/attachment/201303/133957451.jpg)\n\n现在还不能搜索因为现在还没有数据，其实这个时候 http://192.168.233.128:9200 也是可以访问的，\n很多开发自己写代码来调用elasticsearch 来实现他们自己的需要，这里就不多说了\n192.168.233.128 这台logstash index的操作暂时告一段落，下面开始配置logstash的agent\n登录到 服务器 192.168.233.129 安装基本软件包和logstash\n\n    [192.168.233.129 root@noded:~] \n    # cd /soft/ \n    [192.168.233.129 root@noded:/soft] \n    # wget http://down1.chinaunix.net/distfiles/jdk-6u13-dlj-linux-i586.bin \n    [192.168.233.129 root@noded:/soft] \n    # sh jdk-6u13-dlj-linux-i586.bin \n    设置 JAVA_HOME \n    [192.168.233.129 root@noded:/soft] \n    # vim /etc/profile \n    export JAVA_HOME=/usr/java \n    export PATH=$JAVA_HOME/bin:$PATH \n    export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$CLASSPATH \n    [192.168.233.129 root@noded:/soft] \n    # yum install ruby \n    192.168.233.129 root@noded:/soft] \n    # wget http://logstash.objects.dreamhost.com/release/logstash-1.1.0-monolithic.jar \n    [192.168.233.129 root@noded:/soft] \n    # vim redis.conf \n    input { \n    file { \n    type => \"producer\" \n    path => \"/soft/apache.log\" \n    } \n    file { \n    type => \"php-log\" \n    path => \"/soft/php.log\" \n    } \n    } \n    filter { \n       grep { \n       match => [ \"@message\", \"mysql|GET|error\" ] \n    } \n       } \n     \n    output { \n      redis { \n      host => '192.168.233.130' \n      data_type => 'list' \n      key => 'logstash:redis' \n       } \n       } \n大概说一下这个配置文件 input 里的file就是要监视的文件了 这里我监视了两个文件，如果这两个文件有追加的内容就会通过下面的output设置发给 redis服务器\nfilter 里的grep 意思就是 grep...  后面这段就是 日志内容里面只要有匹配 mysql或GET或error的内容就会被过滤出来，发送到 logstash index\n以上就是一个比较简单的配置文件了，让我们启动他\n\n    [192.168.233.129 root@noded:/soft] \n    # java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf & \n    I, [2013-03-19T19:45:35.762000 #2721]  INFO -- : Using beta plugin 'file'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {\"timestamp\":\"2013-03-19T19:45:35.752000 -0700\",\"message\":\"Using beta plugin 'file'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status \",\"level\":\"info\"} \n    I, [2013-03-19T19:45:35.778000 #2721]  INFO -- : Using beta plugin 'file'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {\"timestamp\":\"2013-03-19T19:45:35.778000 -0700\",\"message\":\"Using beta plugin 'file'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status \",\"level\":\"info\"} \n    I, [2013-03-19T19:45:35.804000 #2721]  INFO -- : Using beta plugin 'grep'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {\"timestamp\":\"2013-03-19T19:45:35.803000 -0700\",\"message\":\"Using beta plugin 'grep'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status \",\"level\":\"info\"} \n    I, [2013-03-19T19:45:35.854000 #2721]  INFO -- : Using beta plugin 'redis'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {\"timestamp\":\"2013-03-19T19:45:35.853000 -0700\",\"message\":\"Using beta plugin 'redis'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status \",\"level\":\"info\"} \n\n只要没有 warning 和 error就算是正常启动了\n启动之前请确定 192.168.233.130的 redis服务器已经启动，不然会报错\n下面登录到 192.168.233.130 上看看 redis服务的状态\n\n    [192.168.233.130 root@nodea:/data/redis/etc] \n    # lsof -i:6379 \n    COMMANDPID USER   FD   TYPE DEVICE SIZE NODE NAME \n    redis-ser 2732 root4u  IPv4   7946   TCP *:6379 (LISTEN) \n    redis-ser 2732 root5u  IPv4   7963   TCP localhost.localdomain:6379->localhost.localdomain:19214 (ESTABLISHED) \n    java  2733 root9u  IPv4   7959   TCP localhost.localdomain:19214->localhost.localdomain:6379 (ESTABLISHED) \n    状态正常，端口处于监听状态，我用的是最简单的 配置， \n    [192.168.233.130 root@nodea:/data/redis/etc] \n    # vim redis.conf \n    #this is the config file for redis \n    pidfile /var/run/redis.pid \n    port 6379 \n    timeout 0 \n    loglevel verbose \n    logfile /data/redis/log/redis.log \n    dbfilename dump.rdb \n    dir /data/redis/db/ \n    vm-swap-file /tmp/redis.swap \n    activerehashing yes \n    启动命令如下 \n    [192.168.233.130 root@nodea:/data/redis/etc] \n    # redis-server /data/redis/etc/redis.conf & \n下载安装就比较简单了\n\n    [192.168.233.130 root@nodea:/soft] \n    # wget http://redis.googlecode.com/files/redis-2.4.14.tar.gz \n    [192.168.233.130 root@nodea:/data/redis/etc] \n    # make –j24 \n    [192.168.233.130 root@nodea:/data/redis/etc] \n    # make install \n配置文件里的那几个路径要提前建好\n\n最后我们回到 logstash agent 上面测试一下\n    \n    [192.168.233.129 root@noded:/soft] \n    # echo GET12313 >> apache.log \n    [192.168.233.129 root@noded:/soft] \n    # echo errorabcd >> apache.log \nok 到 http://192.168.233.128:9292 去搜索一下 刚才的两个内容\n![](http://img1.51cto.com/attachment/201303/132952247.jpg)\n![](http://img1.51cto.com/attachment/201303/133019112.jpg)\n嗯，就是这样了，我现在找个php的错误日志给他追加到php.log文件里 \n\n    [192.168.233.129 root@noded:/soft]\n    # cat php-error.log >> php.log\n在看看 logstash的页面 搜索一下 error\n\n![](http://img1.51cto.com/attachment/201303/202133777.jpg)\nOK，最后就是 Kibana了 ，我把Kibana装在了 logstash index上面\n下载地址为 http://kibana.org/intro.html\n\n    [192.168.233.128 root@nodec:/soft] \n    # tar xf Kibana-0.2.0.tar.gz \n    [192.168.233.128 root@nodec:/soft] \n    # cd Kibana-0.2.0 \n    [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n    # bundle install \n    直接安装就好了，非常简单，因为之前咱们已经安装好了 bundle \n    编辑配置文件，指定 elasticsearch 的位置 \n    [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n    # vim KibanaConfig.rb \n    ..... \n      Elasticsearch = \"localhost:9200\" \n      KibanaPort = 5601 \n      KibanaHost = '0.0.0.0' \n    ..... \n    主要是这几个参数 \n    启动的话需要ruby \n    [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n    # /usr/bin/ruby kibana.rb & \n    [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n    # == Sinatra/1.3.5 has taken the stage on 5601 for development with backup from Thin \n    >> Thin web server (v1.5.0 codename Knife) \n    >> Maximum connections set to 1024 \n    >> Listening on 0.0.0.0:5601, CTRL+C to stop \n    如果ruby的东西都不缺的话，启动会很顺利，ok 现在看看5601端口的状态 \n    [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n    # lsof -i:5601 \n    COMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME \n    ruby3116 root5u  IPv4  28947   TCP *:esmagent (LISTEN) \n\n访问一下 试试看 http://192.168.233.128:5601 尝试搜索一下php的错误日志，比如mysql\n![](http://img1.51cto.com/attachment/201303/133220759.jpg)\n呵呵，要的就是这个效果，日志会实时的汇总到 logstash index 上供我们查询，当然这只是开始使用logstash的第一步而已，更多的高级功能可以看看官方文档\nhttp://logstash.net/docs/1.1.9/\n如果有问题大家可以一起探讨，我也是刚开始接触这个东东，收集日志是相当方便啊，据说还能跟nagios结合. 呵呵\n","source":"_posts/用Kibana和logstash快速搭建实时日志查询、收集与分析系统.md","raw":"---\ntitle: 用Kibana和logstash快速搭建实时日志查询、收集与分析系统\ndate: 2017-03-03\ntags: elk\ncategories: elk\n---\n Logstash是一个完全开源的工具，他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索），您可以使用它。说到搜索，logstash带有一个web界面，搜索和展示所有日志。\nkibana 也是一个开源和免费的工具，他可以帮助您汇总、分析和搜索重要数据日志并提供友好的web界面。他可以为 Logstash 和 ElasticSearch 提供的日志分析的 Web 界面\n<!--more-->\n说到这里，我们看看 kibana 和 logstash到底能为我们做些什么呢？下面是kibana的界面\n![](http://img1.51cto.com/attachment/201303/131035239.png)\n\n简单来讲他具体的工作流程就是 logstash agent 监控并过滤日志，将过滤后的日志内容发给redis(这里的redis只处理队列不做存储)，logstash index将日志收集在一起交给\n全文搜索服务ElasticSearch 可以用ElasticSearch进行自定义搜索 通过Kibana 来结合 自定义搜索进行页面展示，下图是 Kibana官网上的流程图\n![](http://img1.51cto.com/attachment/201303/131135111.png)\n\n好了 让我们一步步的把这套环境搭建起来吧，先看看都需要安装什么软件包\nruby 运行Kibana 必须，  \nrubygems 安装ruby扩展必须  \nbundler 功能类似于yum  \nJDK 运行java程序必须   \nredis 用来处理日志队列    \nlogstash 收集、过滤日志  \nElasticSearch 全文搜索服务(logstash集成了一个)  \nkibana 页面展示    \n这里有三台服务器    \n192.168.233.128 logstash index，ElasticSearch，kibana，JDK    \n192.168.233.129 logstash agent，JDK  \n192.168.233.130 redis  \n\n首先到 logstash index服务器上面，logstash分为 index和aget ，agent负责监控、过滤日志，index负责收集日志并将日志交给ElasticSearch 做搜索,此外 logstash 的收集方式分为 standalone 和 centralized。  \nstandalone 是所有功能都在一个服务器上面，自发自收，centralized 就是集中收集，一台服务器接收所有shipper(个人理解就是logstash agent)的日志。  \n其实 logstash本身不分 什么 shipper 和 collector ，只不过就是配置文件不同而已，我们这次按照集中的方式来测试.\n\n在 logstash index上安装基础的软件环境\n\n    [192.168.233.128 root@nodec:~] \n    # cd /soft/ \n    [192.168.233.128 root@nodec:/soft] \n    # wget http://down1.chinaunix.net/distfiles/jdk-6u13-dlj-linux-i586.bin \n    从oracle下载实在是太慢了，从CU下载会快一些，如果需要最新版本请访问这里 \n    http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html \n    [192.168.233.128 root@nodec:/soft] \n    # sh jdk-6u13-dlj-linux-i586.bin \n    输入yes 便开始安装了 \n    安装完成后设置一下 JAVA_HOME \n    [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n    # vim /etc/profile \n    export JAVA_HOME=/usr/java \n    export PATH=$JAVA_HOME/bin:$PATH \n    export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$CLASSPATH \n     \n    安装ruby 就比较简单了(Kibana需要ruby 1.8.7以上版本) \n    [192.168.233.128 root@nodec:/soft] \n    # yum install ruby rubygems \n    ..... 安装内容省略 \n    安装完成后用 rubygems 来安装bundler \n    [192.168.233.128 root@nodec:/soft] \n    # /usr/bin/gem install bundler \n    ..... \n     \n    ok 这样基本的环境就已经有了，下面就是安装kibana 和 logstash \n    其实logstash 就是一个java脚本，不需要安装... 下载即用 \n    [192.168.233.128 root@nodec:/soft] \n    # wget http://logstash.objects.dreamhost.com/release/logstash-1.1.0-monolithic.jar \n    现在看看 这个脚本应该怎么去执行 \n    [192.168.233.128 root@nodec:/soft] \n    # java -jar /soft/logstash-1.1.0-monolithic.jar -h \n    No such command \"-h\" \n    Available commands: \n      -v \n      -V \n      --version \n      agent \n      web \n      test \n    显然没有 -h 参数，不过列出了能用的参数，但是logstash的参数可不止这些， \n    java -jar /soft/logstash-1.1.0-monolithic.jar agent --help \n    这些是在agent模式下的命令参数 \n    -f, --config CONFIGFILE \n    Load the logstash config from a specific file, directory, or a wildcard. If given a directory or wildcard, config files will be read in order lexigraphically. \n    -e CONFIGSTRING \n    Use the given string as the configuration data. Same syntax as the config file. If not input is specified, 'stdin { type => stdin }' is default. If no output is specified, 'stdout { debug => true }}' is default. \n    -w, --filterworks COUNT \n    Run COUNT filter workers (default: 1) \n    --watchdog-timeout TIMEOUT \n    Set watchdog timeout value. \n    -l, --log FILE \n    Log to a given path. Default is to log to stdout \n    -v \n    Increase verbosity. There are multiple levels of verbosity available with '-vv' currently being the highest \n    --pluginpath PLUGIN_PATH \n    A colon-delimted path to find other logstash plugins in \n    java -jar /soft/logstash-1.1.0-monolithic.jar web --help \n    下面的是在web界面的参数 \n    --log FILE \n    Log to a given path. Default is stdout. \n    --address ADDRESS \n    Address on which to start webserver. Default is 0.0.0.0. \n    --port PORT \n    Port on which to start webserver. Default is 9292. \n    -B, --elasticsearch-bind-host ADDRESS \n    Address on which to bind elastic search node. \n    -b, --backend URL \n    The backend URL to use. Default is elasticsearch:/// (assumes multicast discovery). You can specify elasticsearch://[host][:port]/[clustername] \n\n如果上面的这些命令都能执行正常的话就表示 logstash可以使用了，但要让他启动还需要一个配置文件\n\n\n    [192.168.233.128 root@nodec:/soft] \n     \n    # vim redis.conf \n     \n    input {\n    redis { \n      host => '192.168.233.130' \n      data_type => 'list' \n      port => \"6379\" \n      key => 'logstash:redis' \n      type => 'redis-input' \n       } \n       }\n     \n    output { \n    elasticsearch { \n    embedded => true \n      } \n       } \n\n解释一下 logstash的配置文件由 input filter output 等几个基本的部分组成，顾名思义 input 就是在那收集数据，output就是输出到哪，filter代表一个过滤规则意思是什么内容\n会被收集。  \n上面这段是让 logstash 去192.168.233.130 这个redis服务器上去收集日志 redis端口为6379，key是 logstash:redis 类型为 redis-input ，（注意:这几个值必须跟logstash agent的\noutput 所对应），收集完成后输出到 elasticsearch ,embedded => true 的意思是使用logstash 内嵌的 elasticsearch。如果有独立的elasticsearch服务器，需要将 这条改为  \nhost => 'elasticsearch的ip' port => 端口  \n好了，这个简单的配置文件可以让logstash开始启动了  \n\n    [192.168.233.128 root@nodec:/soft] \n    # java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf -- web --backend elasticsearch:///?local & \n    [1] 5205 \n    ...这里要等待约5秒钟... 为什么？去问开发者吧 \n    [192.168.233.128 root@nodec:/soft] \n    # I, [2013-03-19T03:23:10.749000 #5205]  INFO -- : Using beta plugin 'redis'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {\"timestamp\":\"2013-03-19T03:23:10.732000 -0700\",\"message\":\"Using beta plugin 'redis'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status \",\"level\":\"info\"} \n    file:/soft/logstash-1.1.0-monolithic.jar!/gems/rack-1.3.4/lib/rack/backports/uri/common_192.rb:53 warning: already initialized constant WFKV_ \n    Mizuno 0.5.0 (Jetty 8.0.y.z-SNAPSHOT) listening on 0.0.0.0:9292 \n    解释一下 上面的命令 agent 代理模式 -f 指定配置文件 --web 其实是个分隔符等于又启动了一个命令，后面的参数就是开启一个web页面默认端口是9292,这个命令如果拆成两个就是这个样子 \n    java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf & \n    java -jar /soft/logstash-1.1.0-monolithic.jar web --backend elasticsearch:///?local & (其实如果用kibana来做web界面的话这一步完全可以省掉了)\n\n好了，看到9292 端口启动就代表 启动成功了，检查一下\n\n    [192.168.233.128 root@nodec:/soft] \n    # lsof -i:9292 \n    COMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME \n    java5205 root  465u  IPv4 130805   TCP *:armtechdaemon (LISTEN) \n    其实logstash还启动了一个端口9200，因为启动了内嵌的 elasticsearch，这个9200是 elasticsearch在监听 \n    [192.168.233.128 root@nodec:/soft] \n    # lsof -i:9200 \n    COMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME \n    java5205 root  160u  IPv4 130682   TCP *:wap-wsp (LISTEN) \n现在可以通过浏览器访问一下 http://192.168.233.128:9292 看看logstash是的页面是个什么样子\n![](http://img1.51cto.com/attachment/201303/133957451.jpg)\n\n现在还不能搜索因为现在还没有数据，其实这个时候 http://192.168.233.128:9200 也是可以访问的，\n很多开发自己写代码来调用elasticsearch 来实现他们自己的需要，这里就不多说了\n192.168.233.128 这台logstash index的操作暂时告一段落，下面开始配置logstash的agent\n登录到 服务器 192.168.233.129 安装基本软件包和logstash\n\n    [192.168.233.129 root@noded:~] \n    # cd /soft/ \n    [192.168.233.129 root@noded:/soft] \n    # wget http://down1.chinaunix.net/distfiles/jdk-6u13-dlj-linux-i586.bin \n    [192.168.233.129 root@noded:/soft] \n    # sh jdk-6u13-dlj-linux-i586.bin \n    设置 JAVA_HOME \n    [192.168.233.129 root@noded:/soft] \n    # vim /etc/profile \n    export JAVA_HOME=/usr/java \n    export PATH=$JAVA_HOME/bin:$PATH \n    export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$CLASSPATH \n    [192.168.233.129 root@noded:/soft] \n    # yum install ruby \n    192.168.233.129 root@noded:/soft] \n    # wget http://logstash.objects.dreamhost.com/release/logstash-1.1.0-monolithic.jar \n    [192.168.233.129 root@noded:/soft] \n    # vim redis.conf \n    input { \n    file { \n    type => \"producer\" \n    path => \"/soft/apache.log\" \n    } \n    file { \n    type => \"php-log\" \n    path => \"/soft/php.log\" \n    } \n    } \n    filter { \n       grep { \n       match => [ \"@message\", \"mysql|GET|error\" ] \n    } \n       } \n     \n    output { \n      redis { \n      host => '192.168.233.130' \n      data_type => 'list' \n      key => 'logstash:redis' \n       } \n       } \n大概说一下这个配置文件 input 里的file就是要监视的文件了 这里我监视了两个文件，如果这两个文件有追加的内容就会通过下面的output设置发给 redis服务器\nfilter 里的grep 意思就是 grep...  后面这段就是 日志内容里面只要有匹配 mysql或GET或error的内容就会被过滤出来，发送到 logstash index\n以上就是一个比较简单的配置文件了，让我们启动他\n\n    [192.168.233.129 root@noded:/soft] \n    # java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf & \n    I, [2013-03-19T19:45:35.762000 #2721]  INFO -- : Using beta plugin 'file'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {\"timestamp\":\"2013-03-19T19:45:35.752000 -0700\",\"message\":\"Using beta plugin 'file'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status \",\"level\":\"info\"} \n    I, [2013-03-19T19:45:35.778000 #2721]  INFO -- : Using beta plugin 'file'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {\"timestamp\":\"2013-03-19T19:45:35.778000 -0700\",\"message\":\"Using beta plugin 'file'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status \",\"level\":\"info\"} \n    I, [2013-03-19T19:45:35.804000 #2721]  INFO -- : Using beta plugin 'grep'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {\"timestamp\":\"2013-03-19T19:45:35.803000 -0700\",\"message\":\"Using beta plugin 'grep'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status \",\"level\":\"info\"} \n    I, [2013-03-19T19:45:35.854000 #2721]  INFO -- : Using beta plugin 'redis'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {\"timestamp\":\"2013-03-19T19:45:35.853000 -0700\",\"message\":\"Using beta plugin 'redis'. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status \",\"level\":\"info\"} \n\n只要没有 warning 和 error就算是正常启动了\n启动之前请确定 192.168.233.130的 redis服务器已经启动，不然会报错\n下面登录到 192.168.233.130 上看看 redis服务的状态\n\n    [192.168.233.130 root@nodea:/data/redis/etc] \n    # lsof -i:6379 \n    COMMANDPID USER   FD   TYPE DEVICE SIZE NODE NAME \n    redis-ser 2732 root4u  IPv4   7946   TCP *:6379 (LISTEN) \n    redis-ser 2732 root5u  IPv4   7963   TCP localhost.localdomain:6379->localhost.localdomain:19214 (ESTABLISHED) \n    java  2733 root9u  IPv4   7959   TCP localhost.localdomain:19214->localhost.localdomain:6379 (ESTABLISHED) \n    状态正常，端口处于监听状态，我用的是最简单的 配置， \n    [192.168.233.130 root@nodea:/data/redis/etc] \n    # vim redis.conf \n    #this is the config file for redis \n    pidfile /var/run/redis.pid \n    port 6379 \n    timeout 0 \n    loglevel verbose \n    logfile /data/redis/log/redis.log \n    dbfilename dump.rdb \n    dir /data/redis/db/ \n    vm-swap-file /tmp/redis.swap \n    activerehashing yes \n    启动命令如下 \n    [192.168.233.130 root@nodea:/data/redis/etc] \n    # redis-server /data/redis/etc/redis.conf & \n下载安装就比较简单了\n\n    [192.168.233.130 root@nodea:/soft] \n    # wget http://redis.googlecode.com/files/redis-2.4.14.tar.gz \n    [192.168.233.130 root@nodea:/data/redis/etc] \n    # make –j24 \n    [192.168.233.130 root@nodea:/data/redis/etc] \n    # make install \n配置文件里的那几个路径要提前建好\n\n最后我们回到 logstash agent 上面测试一下\n    \n    [192.168.233.129 root@noded:/soft] \n    # echo GET12313 >> apache.log \n    [192.168.233.129 root@noded:/soft] \n    # echo errorabcd >> apache.log \nok 到 http://192.168.233.128:9292 去搜索一下 刚才的两个内容\n![](http://img1.51cto.com/attachment/201303/132952247.jpg)\n![](http://img1.51cto.com/attachment/201303/133019112.jpg)\n嗯，就是这样了，我现在找个php的错误日志给他追加到php.log文件里 \n\n    [192.168.233.129 root@noded:/soft]\n    # cat php-error.log >> php.log\n在看看 logstash的页面 搜索一下 error\n\n![](http://img1.51cto.com/attachment/201303/202133777.jpg)\nOK，最后就是 Kibana了 ，我把Kibana装在了 logstash index上面\n下载地址为 http://kibana.org/intro.html\n\n    [192.168.233.128 root@nodec:/soft] \n    # tar xf Kibana-0.2.0.tar.gz \n    [192.168.233.128 root@nodec:/soft] \n    # cd Kibana-0.2.0 \n    [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n    # bundle install \n    直接安装就好了，非常简单，因为之前咱们已经安装好了 bundle \n    编辑配置文件，指定 elasticsearch 的位置 \n    [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n    # vim KibanaConfig.rb \n    ..... \n      Elasticsearch = \"localhost:9200\" \n      KibanaPort = 5601 \n      KibanaHost = '0.0.0.0' \n    ..... \n    主要是这几个参数 \n    启动的话需要ruby \n    [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n    # /usr/bin/ruby kibana.rb & \n    [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n    # == Sinatra/1.3.5 has taken the stage on 5601 for development with backup from Thin \n    >> Thin web server (v1.5.0 codename Knife) \n    >> Maximum connections set to 1024 \n    >> Listening on 0.0.0.0:5601, CTRL+C to stop \n    如果ruby的东西都不缺的话，启动会很顺利，ok 现在看看5601端口的状态 \n    [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n    # lsof -i:5601 \n    COMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME \n    ruby3116 root5u  IPv4  28947   TCP *:esmagent (LISTEN) \n\n访问一下 试试看 http://192.168.233.128:5601 尝试搜索一下php的错误日志，比如mysql\n![](http://img1.51cto.com/attachment/201303/133220759.jpg)\n呵呵，要的就是这个效果，日志会实时的汇总到 logstash index 上供我们查询，当然这只是开始使用logstash的第一步而已，更多的高级功能可以看看官方文档\nhttp://logstash.net/docs/1.1.9/\n如果有问题大家可以一起探讨，我也是刚开始接触这个东东，收集日志是相当方便啊，据说还能跟nagios结合. 呵呵\n","slug":"用Kibana和logstash快速搭建实时日志查询、收集与分析系统","published":1,"updated":"2019-06-18T08:07:01.118Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clakg9sni002hhcb7nb94vsyu","content":"<p> Logstash是一个完全开源的工具，他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索），您可以使用它。说到搜索，logstash带有一个web界面，搜索和展示所有日志。<br>kibana 也是一个开源和免费的工具，他可以帮助您汇总、分析和搜索重要数据日志并提供友好的web界面。他可以为 Logstash 和 ElasticSearch 提供的日志分析的 Web 界面<br><a id=\"more\"></a><br>说到这里，我们看看 kibana 和 logstash到底能为我们做些什么呢？下面是kibana的界面<br><img src=\"http://img1.51cto.com/attachment/201303/131035239.png\" alt=\"\"></p>\n<p>简单来讲他具体的工作流程就是 logstash agent 监控并过滤日志，将过滤后的日志内容发给redis(这里的redis只处理队列不做存储)，logstash index将日志收集在一起交给<br>全文搜索服务ElasticSearch 可以用ElasticSearch进行自定义搜索 通过Kibana 来结合 自定义搜索进行页面展示，下图是 Kibana官网上的流程图<br><img src=\"http://img1.51cto.com/attachment/201303/131135111.png\" alt=\"\"></p>\n<p>好了 让我们一步步的把这套环境搭建起来吧，先看看都需要安装什么软件包<br>ruby 运行Kibana 必须，<br>rubygems 安装ruby扩展必须<br>bundler 功能类似于yum<br>JDK 运行java程序必须<br>redis 用来处理日志队列<br>logstash 收集、过滤日志<br>ElasticSearch 全文搜索服务(logstash集成了一个)<br>kibana 页面展示<br>这里有三台服务器<br>192.168.233.128 logstash index，ElasticSearch，kibana，JDK<br>192.168.233.129 logstash agent，JDK<br>192.168.233.130 redis  </p>\n<p>首先到 logstash index服务器上面，logstash分为 index和aget ，agent负责监控、过滤日志，index负责收集日志并将日志交给ElasticSearch 做搜索,此外 logstash 的收集方式分为 standalone 和 centralized。<br>standalone 是所有功能都在一个服务器上面，自发自收，centralized 就是集中收集，一台服务器接收所有shipper(个人理解就是logstash agent)的日志。<br>其实 logstash本身不分 什么 shipper 和 collector ，只不过就是配置文件不同而已，我们这次按照集中的方式来测试.</p>\n<p>在 logstash index上安装基础的软件环境</p>\n<pre><code>[192.168.233.128 root@nodec:~] \n# cd /soft/ \n[192.168.233.128 root@nodec:/soft] \n# wget http://down1.chinaunix.net/distfiles/jdk-6u13-dlj-linux-i586.bin \n从oracle下载实在是太慢了，从CU下载会快一些，如果需要最新版本请访问这里 \nhttp://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html \n[192.168.233.128 root@nodec:/soft] \n# sh jdk-6u13-dlj-linux-i586.bin \n输入yes 便开始安装了 \n安装完成后设置一下 JAVA_HOME \n[192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n# vim /etc/profile \nexport JAVA_HOME=/usr/java \nexport PATH=$JAVA_HOME/bin:$PATH \nexport CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$CLASSPATH \n\n安装ruby 就比较简单了(Kibana需要ruby 1.8.7以上版本) \n[192.168.233.128 root@nodec:/soft] \n# yum install ruby rubygems \n..... 安装内容省略 \n安装完成后用 rubygems 来安装bundler \n[192.168.233.128 root@nodec:/soft] \n# /usr/bin/gem install bundler \n..... \n\nok 这样基本的环境就已经有了，下面就是安装kibana 和 logstash \n其实logstash 就是一个java脚本，不需要安装... 下载即用 \n[192.168.233.128 root@nodec:/soft] \n# wget http://logstash.objects.dreamhost.com/release/logstash-1.1.0-monolithic.jar \n现在看看 这个脚本应该怎么去执行 \n[192.168.233.128 root@nodec:/soft] \n# java -jar /soft/logstash-1.1.0-monolithic.jar -h \nNo such command &quot;-h&quot; \nAvailable commands: \n  -v \n  -V \n  --version \n  agent \n  web \n  test \n显然没有 -h 参数，不过列出了能用的参数，但是logstash的参数可不止这些， \njava -jar /soft/logstash-1.1.0-monolithic.jar agent --help \n这些是在agent模式下的命令参数 \n-f, --config CONFIGFILE \nLoad the logstash config from a specific file, directory, or a wildcard. If given a directory or wildcard, config files will be read in order lexigraphically. \n-e CONFIGSTRING \nUse the given string as the configuration data. Same syntax as the config file. If not input is specified, &apos;stdin { type =&gt; stdin }&apos; is default. If no output is specified, &apos;stdout { debug =&gt; true }}&apos; is default. \n-w, --filterworks COUNT \nRun COUNT filter workers (default: 1) \n--watchdog-timeout TIMEOUT \nSet watchdog timeout value. \n-l, --log FILE \nLog to a given path. Default is to log to stdout \n-v \nIncrease verbosity. There are multiple levels of verbosity available with &apos;-vv&apos; currently being the highest \n--pluginpath PLUGIN_PATH \nA colon-delimted path to find other logstash plugins in \njava -jar /soft/logstash-1.1.0-monolithic.jar web --help \n下面的是在web界面的参数 \n--log FILE \nLog to a given path. Default is stdout. \n--address ADDRESS \nAddress on which to start webserver. Default is 0.0.0.0. \n--port PORT \nPort on which to start webserver. Default is 9292. \n-B, --elasticsearch-bind-host ADDRESS \nAddress on which to bind elastic search node. \n-b, --backend URL \nThe backend URL to use. Default is elasticsearch:/// (assumes multicast discovery). You can specify elasticsearch://[host][:port]/[clustername] \n</code></pre><p>如果上面的这些命令都能执行正常的话就表示 logstash可以使用了，但要让他启动还需要一个配置文件</p>\n<pre><code>[192.168.233.128 root@nodec:/soft] \n\n# vim redis.conf \n\ninput {\nredis { \n  host =&gt; &apos;192.168.233.130&apos; \n  data_type =&gt; &apos;list&apos; \n  port =&gt; &quot;6379&quot; \n  key =&gt; &apos;logstash:redis&apos; \n  type =&gt; &apos;redis-input&apos; \n   } \n   }\n\noutput { \nelasticsearch { \nembedded =&gt; true \n  } \n   } \n</code></pre><p>解释一下 logstash的配置文件由 input filter output 等几个基本的部分组成，顾名思义 input 就是在那收集数据，output就是输出到哪，filter代表一个过滤规则意思是什么内容<br>会被收集。<br>上面这段是让 logstash 去192.168.233.130 这个redis服务器上去收集日志 redis端口为6379，key是 logstash:redis 类型为 redis-input ，（注意:这几个值必须跟logstash agent的<br>output 所对应），收集完成后输出到 elasticsearch ,embedded =&gt; true 的意思是使用logstash 内嵌的 elasticsearch。如果有独立的elasticsearch服务器，需要将 这条改为<br>host =&gt; ‘elasticsearch的ip’ port =&gt; 端口<br>好了，这个简单的配置文件可以让logstash开始启动了  </p>\n<pre><code>[192.168.233.128 root@nodec:/soft] \n# java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf -- web --backend elasticsearch:///?local &amp; \n[1] 5205 \n...这里要等待约5秒钟... 为什么？去问开发者吧 \n[192.168.233.128 root@nodec:/soft] \n# I, [2013-03-19T03:23:10.749000 #5205]  INFO -- : Using beta plugin &apos;redis&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T03:23:10.732000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;redis&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} \nfile:/soft/logstash-1.1.0-monolithic.jar!/gems/rack-1.3.4/lib/rack/backports/uri/common_192.rb:53 warning: already initialized constant WFKV_ \nMizuno 0.5.0 (Jetty 8.0.y.z-SNAPSHOT) listening on 0.0.0.0:9292 \n解释一下 上面的命令 agent 代理模式 -f 指定配置文件 --web 其实是个分隔符等于又启动了一个命令，后面的参数就是开启一个web页面默认端口是9292,这个命令如果拆成两个就是这个样子 \njava -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf &amp; \njava -jar /soft/logstash-1.1.0-monolithic.jar web --backend elasticsearch:///?local &amp; (其实如果用kibana来做web界面的话这一步完全可以省掉了)\n</code></pre><p>好了，看到9292 端口启动就代表 启动成功了，检查一下</p>\n<pre><code>[192.168.233.128 root@nodec:/soft] \n# lsof -i:9292 \nCOMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME \njava5205 root  465u  IPv4 130805   TCP *:armtechdaemon (LISTEN) \n其实logstash还启动了一个端口9200，因为启动了内嵌的 elasticsearch，这个9200是 elasticsearch在监听 \n[192.168.233.128 root@nodec:/soft] \n# lsof -i:9200 \nCOMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME \njava5205 root  160u  IPv4 130682   TCP *:wap-wsp (LISTEN) \n</code></pre><p>现在可以通过浏览器访问一下 <a href=\"http://192.168.233.128:9292\" target=\"_blank\" rel=\"noopener\">http://192.168.233.128:9292</a> 看看logstash是的页面是个什么样子<br><img src=\"http://img1.51cto.com/attachment/201303/133957451.jpg\" alt=\"\"></p>\n<p>现在还不能搜索因为现在还没有数据，其实这个时候 <a href=\"http://192.168.233.128:9200\" target=\"_blank\" rel=\"noopener\">http://192.168.233.128:9200</a> 也是可以访问的，<br>很多开发自己写代码来调用elasticsearch 来实现他们自己的需要，这里就不多说了<br>192.168.233.128 这台logstash index的操作暂时告一段落，下面开始配置logstash的agent<br>登录到 服务器 192.168.233.129 安装基本软件包和logstash</p>\n<pre><code>[192.168.233.129 root@noded:~] \n# cd /soft/ \n[192.168.233.129 root@noded:/soft] \n# wget http://down1.chinaunix.net/distfiles/jdk-6u13-dlj-linux-i586.bin \n[192.168.233.129 root@noded:/soft] \n# sh jdk-6u13-dlj-linux-i586.bin \n设置 JAVA_HOME \n[192.168.233.129 root@noded:/soft] \n# vim /etc/profile \nexport JAVA_HOME=/usr/java \nexport PATH=$JAVA_HOME/bin:$PATH \nexport CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$CLASSPATH \n[192.168.233.129 root@noded:/soft] \n# yum install ruby \n192.168.233.129 root@noded:/soft] \n# wget http://logstash.objects.dreamhost.com/release/logstash-1.1.0-monolithic.jar \n[192.168.233.129 root@noded:/soft] \n# vim redis.conf \ninput { \nfile { \ntype =&gt; &quot;producer&quot; \npath =&gt; &quot;/soft/apache.log&quot; \n} \nfile { \ntype =&gt; &quot;php-log&quot; \npath =&gt; &quot;/soft/php.log&quot; \n} \n} \nfilter { \n   grep { \n   match =&gt; [ &quot;@message&quot;, &quot;mysql|GET|error&quot; ] \n} \n   } \n\noutput { \n  redis { \n  host =&gt; &apos;192.168.233.130&apos; \n  data_type =&gt; &apos;list&apos; \n  key =&gt; &apos;logstash:redis&apos; \n   } \n   } \n</code></pre><p>大概说一下这个配置文件 input 里的file就是要监视的文件了 这里我监视了两个文件，如果这两个文件有追加的内容就会通过下面的output设置发给 redis服务器<br>filter 里的grep 意思就是 grep…  后面这段就是 日志内容里面只要有匹配 mysql或GET或error的内容就会被过滤出来，发送到 logstash index<br>以上就是一个比较简单的配置文件了，让我们启动他</p>\n<pre><code>[192.168.233.129 root@noded:/soft] \n# java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf &amp; \nI, [2013-03-19T19:45:35.762000 #2721]  INFO -- : Using beta plugin &apos;file&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T19:45:35.752000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;file&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} \nI, [2013-03-19T19:45:35.778000 #2721]  INFO -- : Using beta plugin &apos;file&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T19:45:35.778000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;file&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} \nI, [2013-03-19T19:45:35.804000 #2721]  INFO -- : Using beta plugin &apos;grep&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T19:45:35.803000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;grep&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} \nI, [2013-03-19T19:45:35.854000 #2721]  INFO -- : Using beta plugin &apos;redis&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T19:45:35.853000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;redis&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} \n</code></pre><p>只要没有 warning 和 error就算是正常启动了<br>启动之前请确定 192.168.233.130的 redis服务器已经启动，不然会报错<br>下面登录到 192.168.233.130 上看看 redis服务的状态</p>\n<pre><code>[192.168.233.130 root@nodea:/data/redis/etc] \n# lsof -i:6379 \nCOMMANDPID USER   FD   TYPE DEVICE SIZE NODE NAME \nredis-ser 2732 root4u  IPv4   7946   TCP *:6379 (LISTEN) \nredis-ser 2732 root5u  IPv4   7963   TCP localhost.localdomain:6379-&gt;localhost.localdomain:19214 (ESTABLISHED) \njava  2733 root9u  IPv4   7959   TCP localhost.localdomain:19214-&gt;localhost.localdomain:6379 (ESTABLISHED) \n状态正常，端口处于监听状态，我用的是最简单的 配置， \n[192.168.233.130 root@nodea:/data/redis/etc] \n# vim redis.conf \n#this is the config file for redis \npidfile /var/run/redis.pid \nport 6379 \ntimeout 0 \nloglevel verbose \nlogfile /data/redis/log/redis.log \ndbfilename dump.rdb \ndir /data/redis/db/ \nvm-swap-file /tmp/redis.swap \nactiverehashing yes \n启动命令如下 \n[192.168.233.130 root@nodea:/data/redis/etc] \n# redis-server /data/redis/etc/redis.conf &amp; \n</code></pre><p>下载安装就比较简单了</p>\n<pre><code>[192.168.233.130 root@nodea:/soft] \n# wget http://redis.googlecode.com/files/redis-2.4.14.tar.gz \n[192.168.233.130 root@nodea:/data/redis/etc] \n# make –j24 \n[192.168.233.130 root@nodea:/data/redis/etc] \n# make install \n</code></pre><p>配置文件里的那几个路径要提前建好</p>\n<p>最后我们回到 logstash agent 上面测试一下</p>\n<pre><code>[192.168.233.129 root@noded:/soft] \n# echo GET12313 &gt;&gt; apache.log \n[192.168.233.129 root@noded:/soft] \n# echo errorabcd &gt;&gt; apache.log \n</code></pre><p>ok 到 <a href=\"http://192.168.233.128:9292\" target=\"_blank\" rel=\"noopener\">http://192.168.233.128:9292</a> 去搜索一下 刚才的两个内容<br><img src=\"http://img1.51cto.com/attachment/201303/132952247.jpg\" alt=\"\"><br><img src=\"http://img1.51cto.com/attachment/201303/133019112.jpg\" alt=\"\"><br>嗯，就是这样了，我现在找个php的错误日志给他追加到php.log文件里 </p>\n<pre><code>[192.168.233.129 root@noded:/soft]\n# cat php-error.log &gt;&gt; php.log\n</code></pre><p>在看看 logstash的页面 搜索一下 error</p>\n<p><img src=\"http://img1.51cto.com/attachment/201303/202133777.jpg\" alt=\"\"><br>OK，最后就是 Kibana了 ，我把Kibana装在了 logstash index上面<br>下载地址为 <a href=\"http://kibana.org/intro.html\" target=\"_blank\" rel=\"noopener\">http://kibana.org/intro.html</a></p>\n<pre><code>[192.168.233.128 root@nodec:/soft] \n# tar xf Kibana-0.2.0.tar.gz \n[192.168.233.128 root@nodec:/soft] \n# cd Kibana-0.2.0 \n[192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n# bundle install \n直接安装就好了，非常简单，因为之前咱们已经安装好了 bundle \n编辑配置文件，指定 elasticsearch 的位置 \n[192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n# vim KibanaConfig.rb \n..... \n  Elasticsearch = &quot;localhost:9200&quot; \n  KibanaPort = 5601 \n  KibanaHost = &apos;0.0.0.0&apos; \n..... \n主要是这几个参数 \n启动的话需要ruby \n[192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n# /usr/bin/ruby kibana.rb &amp; \n[192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n# == Sinatra/1.3.5 has taken the stage on 5601 for development with backup from Thin \n&gt;&gt; Thin web server (v1.5.0 codename Knife) \n&gt;&gt; Maximum connections set to 1024 \n&gt;&gt; Listening on 0.0.0.0:5601, CTRL+C to stop \n如果ruby的东西都不缺的话，启动会很顺利，ok 现在看看5601端口的状态 \n[192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n# lsof -i:5601 \nCOMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME \nruby3116 root5u  IPv4  28947   TCP *:esmagent (LISTEN) \n</code></pre><p>访问一下 试试看 <a href=\"http://192.168.233.128:5601\" target=\"_blank\" rel=\"noopener\">http://192.168.233.128:5601</a> 尝试搜索一下php的错误日志，比如mysql<br><img src=\"http://img1.51cto.com/attachment/201303/133220759.jpg\" alt=\"\"><br>呵呵，要的就是这个效果，日志会实时的汇总到 logstash index 上供我们查询，当然这只是开始使用logstash的第一步而已，更多的高级功能可以看看官方文档<br><a href=\"http://logstash.net/docs/1.1.9/\" target=\"_blank\" rel=\"noopener\">http://logstash.net/docs/1.1.9/</a><br>如果有问题大家可以一起探讨，我也是刚开始接触这个东东，收集日志是相当方便啊，据说还能跟nagios结合. 呵呵</p>\n","site":{"data":{}},"excerpt":"<p> Logstash是一个完全开源的工具，他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索），您可以使用它。说到搜索，logstash带有一个web界面，搜索和展示所有日志。<br>kibana 也是一个开源和免费的工具，他可以帮助您汇总、分析和搜索重要数据日志并提供友好的web界面。他可以为 Logstash 和 ElasticSearch 提供的日志分析的 Web 界面<br>","more":"<br>说到这里，我们看看 kibana 和 logstash到底能为我们做些什么呢？下面是kibana的界面<br><img src=\"http://img1.51cto.com/attachment/201303/131035239.png\" alt=\"\"></p>\n<p>简单来讲他具体的工作流程就是 logstash agent 监控并过滤日志，将过滤后的日志内容发给redis(这里的redis只处理队列不做存储)，logstash index将日志收集在一起交给<br>全文搜索服务ElasticSearch 可以用ElasticSearch进行自定义搜索 通过Kibana 来结合 自定义搜索进行页面展示，下图是 Kibana官网上的流程图<br><img src=\"http://img1.51cto.com/attachment/201303/131135111.png\" alt=\"\"></p>\n<p>好了 让我们一步步的把这套环境搭建起来吧，先看看都需要安装什么软件包<br>ruby 运行Kibana 必须，<br>rubygems 安装ruby扩展必须<br>bundler 功能类似于yum<br>JDK 运行java程序必须<br>redis 用来处理日志队列<br>logstash 收集、过滤日志<br>ElasticSearch 全文搜索服务(logstash集成了一个)<br>kibana 页面展示<br>这里有三台服务器<br>192.168.233.128 logstash index，ElasticSearch，kibana，JDK<br>192.168.233.129 logstash agent，JDK<br>192.168.233.130 redis  </p>\n<p>首先到 logstash index服务器上面，logstash分为 index和aget ，agent负责监控、过滤日志，index负责收集日志并将日志交给ElasticSearch 做搜索,此外 logstash 的收集方式分为 standalone 和 centralized。<br>standalone 是所有功能都在一个服务器上面，自发自收，centralized 就是集中收集，一台服务器接收所有shipper(个人理解就是logstash agent)的日志。<br>其实 logstash本身不分 什么 shipper 和 collector ，只不过就是配置文件不同而已，我们这次按照集中的方式来测试.</p>\n<p>在 logstash index上安装基础的软件环境</p>\n<pre><code>[192.168.233.128 root@nodec:~] \n# cd /soft/ \n[192.168.233.128 root@nodec:/soft] \n# wget http://down1.chinaunix.net/distfiles/jdk-6u13-dlj-linux-i586.bin \n从oracle下载实在是太慢了，从CU下载会快一些，如果需要最新版本请访问这里 \nhttp://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html \n[192.168.233.128 root@nodec:/soft] \n# sh jdk-6u13-dlj-linux-i586.bin \n输入yes 便开始安装了 \n安装完成后设置一下 JAVA_HOME \n[192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n# vim /etc/profile \nexport JAVA_HOME=/usr/java \nexport PATH=$JAVA_HOME/bin:$PATH \nexport CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$CLASSPATH \n\n安装ruby 就比较简单了(Kibana需要ruby 1.8.7以上版本) \n[192.168.233.128 root@nodec:/soft] \n# yum install ruby rubygems \n..... 安装内容省略 \n安装完成后用 rubygems 来安装bundler \n[192.168.233.128 root@nodec:/soft] \n# /usr/bin/gem install bundler \n..... \n\nok 这样基本的环境就已经有了，下面就是安装kibana 和 logstash \n其实logstash 就是一个java脚本，不需要安装... 下载即用 \n[192.168.233.128 root@nodec:/soft] \n# wget http://logstash.objects.dreamhost.com/release/logstash-1.1.0-monolithic.jar \n现在看看 这个脚本应该怎么去执行 \n[192.168.233.128 root@nodec:/soft] \n# java -jar /soft/logstash-1.1.0-monolithic.jar -h \nNo such command &quot;-h&quot; \nAvailable commands: \n  -v \n  -V \n  --version \n  agent \n  web \n  test \n显然没有 -h 参数，不过列出了能用的参数，但是logstash的参数可不止这些， \njava -jar /soft/logstash-1.1.0-monolithic.jar agent --help \n这些是在agent模式下的命令参数 \n-f, --config CONFIGFILE \nLoad the logstash config from a specific file, directory, or a wildcard. If given a directory or wildcard, config files will be read in order lexigraphically. \n-e CONFIGSTRING \nUse the given string as the configuration data. Same syntax as the config file. If not input is specified, &apos;stdin { type =&gt; stdin }&apos; is default. If no output is specified, &apos;stdout { debug =&gt; true }}&apos; is default. \n-w, --filterworks COUNT \nRun COUNT filter workers (default: 1) \n--watchdog-timeout TIMEOUT \nSet watchdog timeout value. \n-l, --log FILE \nLog to a given path. Default is to log to stdout \n-v \nIncrease verbosity. There are multiple levels of verbosity available with &apos;-vv&apos; currently being the highest \n--pluginpath PLUGIN_PATH \nA colon-delimted path to find other logstash plugins in \njava -jar /soft/logstash-1.1.0-monolithic.jar web --help \n下面的是在web界面的参数 \n--log FILE \nLog to a given path. Default is stdout. \n--address ADDRESS \nAddress on which to start webserver. Default is 0.0.0.0. \n--port PORT \nPort on which to start webserver. Default is 9292. \n-B, --elasticsearch-bind-host ADDRESS \nAddress on which to bind elastic search node. \n-b, --backend URL \nThe backend URL to use. Default is elasticsearch:/// (assumes multicast discovery). You can specify elasticsearch://[host][:port]/[clustername] \n</code></pre><p>如果上面的这些命令都能执行正常的话就表示 logstash可以使用了，但要让他启动还需要一个配置文件</p>\n<pre><code>[192.168.233.128 root@nodec:/soft] \n\n# vim redis.conf \n\ninput {\nredis { \n  host =&gt; &apos;192.168.233.130&apos; \n  data_type =&gt; &apos;list&apos; \n  port =&gt; &quot;6379&quot; \n  key =&gt; &apos;logstash:redis&apos; \n  type =&gt; &apos;redis-input&apos; \n   } \n   }\n\noutput { \nelasticsearch { \nembedded =&gt; true \n  } \n   } \n</code></pre><p>解释一下 logstash的配置文件由 input filter output 等几个基本的部分组成，顾名思义 input 就是在那收集数据，output就是输出到哪，filter代表一个过滤规则意思是什么内容<br>会被收集。<br>上面这段是让 logstash 去192.168.233.130 这个redis服务器上去收集日志 redis端口为6379，key是 logstash:redis 类型为 redis-input ，（注意:这几个值必须跟logstash agent的<br>output 所对应），收集完成后输出到 elasticsearch ,embedded =&gt; true 的意思是使用logstash 内嵌的 elasticsearch。如果有独立的elasticsearch服务器，需要将 这条改为<br>host =&gt; ‘elasticsearch的ip’ port =&gt; 端口<br>好了，这个简单的配置文件可以让logstash开始启动了  </p>\n<pre><code>[192.168.233.128 root@nodec:/soft] \n# java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf -- web --backend elasticsearch:///?local &amp; \n[1] 5205 \n...这里要等待约5秒钟... 为什么？去问开发者吧 \n[192.168.233.128 root@nodec:/soft] \n# I, [2013-03-19T03:23:10.749000 #5205]  INFO -- : Using beta plugin &apos;redis&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T03:23:10.732000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;redis&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} \nfile:/soft/logstash-1.1.0-monolithic.jar!/gems/rack-1.3.4/lib/rack/backports/uri/common_192.rb:53 warning: already initialized constant WFKV_ \nMizuno 0.5.0 (Jetty 8.0.y.z-SNAPSHOT) listening on 0.0.0.0:9292 \n解释一下 上面的命令 agent 代理模式 -f 指定配置文件 --web 其实是个分隔符等于又启动了一个命令，后面的参数就是开启一个web页面默认端口是9292,这个命令如果拆成两个就是这个样子 \njava -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf &amp; \njava -jar /soft/logstash-1.1.0-monolithic.jar web --backend elasticsearch:///?local &amp; (其实如果用kibana来做web界面的话这一步完全可以省掉了)\n</code></pre><p>好了，看到9292 端口启动就代表 启动成功了，检查一下</p>\n<pre><code>[192.168.233.128 root@nodec:/soft] \n# lsof -i:9292 \nCOMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME \njava5205 root  465u  IPv4 130805   TCP *:armtechdaemon (LISTEN) \n其实logstash还启动了一个端口9200，因为启动了内嵌的 elasticsearch，这个9200是 elasticsearch在监听 \n[192.168.233.128 root@nodec:/soft] \n# lsof -i:9200 \nCOMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME \njava5205 root  160u  IPv4 130682   TCP *:wap-wsp (LISTEN) \n</code></pre><p>现在可以通过浏览器访问一下 <a href=\"http://192.168.233.128:9292\" target=\"_blank\" rel=\"noopener\">http://192.168.233.128:9292</a> 看看logstash是的页面是个什么样子<br><img src=\"http://img1.51cto.com/attachment/201303/133957451.jpg\" alt=\"\"></p>\n<p>现在还不能搜索因为现在还没有数据，其实这个时候 <a href=\"http://192.168.233.128:9200\" target=\"_blank\" rel=\"noopener\">http://192.168.233.128:9200</a> 也是可以访问的，<br>很多开发自己写代码来调用elasticsearch 来实现他们自己的需要，这里就不多说了<br>192.168.233.128 这台logstash index的操作暂时告一段落，下面开始配置logstash的agent<br>登录到 服务器 192.168.233.129 安装基本软件包和logstash</p>\n<pre><code>[192.168.233.129 root@noded:~] \n# cd /soft/ \n[192.168.233.129 root@noded:/soft] \n# wget http://down1.chinaunix.net/distfiles/jdk-6u13-dlj-linux-i586.bin \n[192.168.233.129 root@noded:/soft] \n# sh jdk-6u13-dlj-linux-i586.bin \n设置 JAVA_HOME \n[192.168.233.129 root@noded:/soft] \n# vim /etc/profile \nexport JAVA_HOME=/usr/java \nexport PATH=$JAVA_HOME/bin:$PATH \nexport CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$CLASSPATH \n[192.168.233.129 root@noded:/soft] \n# yum install ruby \n192.168.233.129 root@noded:/soft] \n# wget http://logstash.objects.dreamhost.com/release/logstash-1.1.0-monolithic.jar \n[192.168.233.129 root@noded:/soft] \n# vim redis.conf \ninput { \nfile { \ntype =&gt; &quot;producer&quot; \npath =&gt; &quot;/soft/apache.log&quot; \n} \nfile { \ntype =&gt; &quot;php-log&quot; \npath =&gt; &quot;/soft/php.log&quot; \n} \n} \nfilter { \n   grep { \n   match =&gt; [ &quot;@message&quot;, &quot;mysql|GET|error&quot; ] \n} \n   } \n\noutput { \n  redis { \n  host =&gt; &apos;192.168.233.130&apos; \n  data_type =&gt; &apos;list&apos; \n  key =&gt; &apos;logstash:redis&apos; \n   } \n   } \n</code></pre><p>大概说一下这个配置文件 input 里的file就是要监视的文件了 这里我监视了两个文件，如果这两个文件有追加的内容就会通过下面的output设置发给 redis服务器<br>filter 里的grep 意思就是 grep…  后面这段就是 日志内容里面只要有匹配 mysql或GET或error的内容就会被过滤出来，发送到 logstash index<br>以上就是一个比较简单的配置文件了，让我们启动他</p>\n<pre><code>[192.168.233.129 root@noded:/soft] \n# java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf &amp; \nI, [2013-03-19T19:45:35.762000 #2721]  INFO -- : Using beta plugin &apos;file&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T19:45:35.752000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;file&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} \nI, [2013-03-19T19:45:35.778000 #2721]  INFO -- : Using beta plugin &apos;file&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T19:45:35.778000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;file&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} \nI, [2013-03-19T19:45:35.804000 #2721]  INFO -- : Using beta plugin &apos;grep&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T19:45:35.803000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;grep&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} \nI, [2013-03-19T19:45:35.854000 #2721]  INFO -- : Using beta plugin &apos;redis&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T19:45:35.853000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;redis&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} \n</code></pre><p>只要没有 warning 和 error就算是正常启动了<br>启动之前请确定 192.168.233.130的 redis服务器已经启动，不然会报错<br>下面登录到 192.168.233.130 上看看 redis服务的状态</p>\n<pre><code>[192.168.233.130 root@nodea:/data/redis/etc] \n# lsof -i:6379 \nCOMMANDPID USER   FD   TYPE DEVICE SIZE NODE NAME \nredis-ser 2732 root4u  IPv4   7946   TCP *:6379 (LISTEN) \nredis-ser 2732 root5u  IPv4   7963   TCP localhost.localdomain:6379-&gt;localhost.localdomain:19214 (ESTABLISHED) \njava  2733 root9u  IPv4   7959   TCP localhost.localdomain:19214-&gt;localhost.localdomain:6379 (ESTABLISHED) \n状态正常，端口处于监听状态，我用的是最简单的 配置， \n[192.168.233.130 root@nodea:/data/redis/etc] \n# vim redis.conf \n#this is the config file for redis \npidfile /var/run/redis.pid \nport 6379 \ntimeout 0 \nloglevel verbose \nlogfile /data/redis/log/redis.log \ndbfilename dump.rdb \ndir /data/redis/db/ \nvm-swap-file /tmp/redis.swap \nactiverehashing yes \n启动命令如下 \n[192.168.233.130 root@nodea:/data/redis/etc] \n# redis-server /data/redis/etc/redis.conf &amp; \n</code></pre><p>下载安装就比较简单了</p>\n<pre><code>[192.168.233.130 root@nodea:/soft] \n# wget http://redis.googlecode.com/files/redis-2.4.14.tar.gz \n[192.168.233.130 root@nodea:/data/redis/etc] \n# make –j24 \n[192.168.233.130 root@nodea:/data/redis/etc] \n# make install \n</code></pre><p>配置文件里的那几个路径要提前建好</p>\n<p>最后我们回到 logstash agent 上面测试一下</p>\n<pre><code>[192.168.233.129 root@noded:/soft] \n# echo GET12313 &gt;&gt; apache.log \n[192.168.233.129 root@noded:/soft] \n# echo errorabcd &gt;&gt; apache.log \n</code></pre><p>ok 到 <a href=\"http://192.168.233.128:9292\" target=\"_blank\" rel=\"noopener\">http://192.168.233.128:9292</a> 去搜索一下 刚才的两个内容<br><img src=\"http://img1.51cto.com/attachment/201303/132952247.jpg\" alt=\"\"><br><img src=\"http://img1.51cto.com/attachment/201303/133019112.jpg\" alt=\"\"><br>嗯，就是这样了，我现在找个php的错误日志给他追加到php.log文件里 </p>\n<pre><code>[192.168.233.129 root@noded:/soft]\n# cat php-error.log &gt;&gt; php.log\n</code></pre><p>在看看 logstash的页面 搜索一下 error</p>\n<p><img src=\"http://img1.51cto.com/attachment/201303/202133777.jpg\" alt=\"\"><br>OK，最后就是 Kibana了 ，我把Kibana装在了 logstash index上面<br>下载地址为 <a href=\"http://kibana.org/intro.html\" target=\"_blank\" rel=\"noopener\">http://kibana.org/intro.html</a></p>\n<pre><code>[192.168.233.128 root@nodec:/soft] \n# tar xf Kibana-0.2.0.tar.gz \n[192.168.233.128 root@nodec:/soft] \n# cd Kibana-0.2.0 \n[192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n# bundle install \n直接安装就好了，非常简单，因为之前咱们已经安装好了 bundle \n编辑配置文件，指定 elasticsearch 的位置 \n[192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n# vim KibanaConfig.rb \n..... \n  Elasticsearch = &quot;localhost:9200&quot; \n  KibanaPort = 5601 \n  KibanaHost = &apos;0.0.0.0&apos; \n..... \n主要是这几个参数 \n启动的话需要ruby \n[192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n# /usr/bin/ruby kibana.rb &amp; \n[192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n# == Sinatra/1.3.5 has taken the stage on 5601 for development with backup from Thin \n&gt;&gt; Thin web server (v1.5.0 codename Knife) \n&gt;&gt; Maximum connections set to 1024 \n&gt;&gt; Listening on 0.0.0.0:5601, CTRL+C to stop \n如果ruby的东西都不缺的话，启动会很顺利，ok 现在看看5601端口的状态 \n[192.168.233.128 root@nodec:/soft/Kibana-0.2.0] \n# lsof -i:5601 \nCOMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME \nruby3116 root5u  IPv4  28947   TCP *:esmagent (LISTEN) \n</code></pre><p>访问一下 试试看 <a href=\"http://192.168.233.128:5601\" target=\"_blank\" rel=\"noopener\">http://192.168.233.128:5601</a> 尝试搜索一下php的错误日志，比如mysql<br><img src=\"http://img1.51cto.com/attachment/201303/133220759.jpg\" alt=\"\"><br>呵呵，要的就是这个效果，日志会实时的汇总到 logstash index 上供我们查询，当然这只是开始使用logstash的第一步而已，更多的高级功能可以看看官方文档<br><a href=\"http://logstash.net/docs/1.1.9/\" target=\"_blank\" rel=\"noopener\">http://logstash.net/docs/1.1.9/</a><br>如果有问题大家可以一起探讨，我也是刚开始接触这个东东，收集日志是相当方便啊，据说还能跟nagios结合. 呵呵</p>"}],"PostAsset":[],"PostCategory":[{"post_id":"clakg9sgl0000hcb7dfzse2v9","category_id":"clakg9shs0004hcb7c626nh29","_id":"clakg9sjc000ehcb761322xt8"},{"post_id":"clakg9shd0002hcb7aro7i2j4","category_id":"clakg9sit0009hcb7d34xls7f","_id":"clakg9sjn000khcb71oj1m3q6"},{"post_id":"clakg9si90006hcb7webzep3k","category_id":"clakg9sjd000fhcb7bmc33hnm","_id":"clakg9sjy000qhcb7b3o79ehk"},{"post_id":"clakg9sii0007hcb71vse8n35","category_id":"clakg9sjn000lhcb7w8e75wun","_id":"clakg9sk6000whcb7sxu3d0t2"},{"post_id":"clakg9sio0008hcb75bql7c4z","category_id":"clakg9sjy000rhcb7c6ezzdsx","_id":"clakg9sko0014hcb7a8cmnp51"},{"post_id":"clakg9sj0000chcb7g5zki9pm","category_id":"clakg9sjy000rhcb7c6ezzdsx","_id":"clakg9skz001ahcb7l08gweny"},{"post_id":"clakg9sj8000dhcb794iug0by","category_id":"clakg9sjy000rhcb7c6ezzdsx","_id":"clakg9slg001fhcb7obstsqbn"},{"post_id":"clakg9sl1001dhcb70kfb7860","category_id":"clakg9skx0019hcb7anu8ytug","_id":"clakg9sls001mhcb7f93wps4p"},{"post_id":"clakg9sjq000nhcb7c3a1znis","category_id":"clakg9skx0019hcb7anu8ytug","_id":"clakg9slx001qhcb7e83lku6g"},{"post_id":"clakg9sjt000phcb7u2yqjgy9","category_id":"clakg9slh001ghcb7jaedd4qj","_id":"clakg9sm8001thcb7stuosrpn"},{"post_id":"clakg9sjz000thcb7jvik8ieh","category_id":"clakg9slt001nhcb74bpxm4u4","_id":"clakg9smh0020hcb77ykbr2de"},{"post_id":"clakg9sk7000xhcb76ot0mwl2","category_id":"clakg9skx0019hcb7anu8ytug","_id":"clakg9smv0025hcb7uphh5q8q"},{"post_id":"clakg9sme001yhcb7jr8fg0m2","category_id":"clakg9skx0019hcb7anu8ytug","_id":"clakg9sn00029hcb7oj8icjqh"},{"post_id":"clakg9smi0021hcb7bnim9j3x","category_id":"clakg9skx0019hcb7anu8ytug","_id":"clakg9snb002chcb7pu3jqz3z"},{"post_id":"clakg9skf0011hcb7v6503ksg","category_id":"clakg9smh001zhcb75keax31e","_id":"clakg9sni002ghcb7atx5dz29"},{"post_id":"clakg9skj0012hcb7klwf0dba","category_id":"clakg9smh001zhcb75keax31e","_id":"clakg9snm002khcb7yr11dlsi"},{"post_id":"clakg9skq0017hcb7twki3xo5","category_id":"clakg9skx0019hcb7anu8ytug","_id":"clakg9sno002ohcb729kablbb"},{"post_id":"clakg9skt0018hcb7qm7ja1gp","category_id":"clakg9skx0019hcb7anu8ytug","_id":"clakg9snq002rhcb75940ygea"},{"post_id":"clakg9sla001ehcb7efldu6mz","category_id":"clakg9sno002nhcb7yai4blkc","_id":"clakg9snt002whcb7wig1hgo3"},{"post_id":"clakg9sll001jhcb70h0b1dhj","category_id":"clakg9sno002nhcb7yai4blkc","_id":"clakg9snv002zhcb76yd6x7cp"},{"post_id":"clakg9slo001lhcb7wys86y75","category_id":"clakg9sns002vhcb71zpyd1cc","_id":"clakg9snx0033hcb7kv4k4xt6"},{"post_id":"clakg9slv001phcb72y8almt0","category_id":"clakg9snv0030hcb79qfgtx2f","_id":"clakg9so00038hcb7swv5ejio"},{"post_id":"clakg9sm1001shcb794swp09t","category_id":"clakg9snv0030hcb79qfgtx2f","_id":"clakg9so1003bhcb7ouozmh05"},{"post_id":"clakg9sma001whcb7fimbrts3","category_id":"clakg9so00037hcb7gqh20amv","_id":"clakg9so3003fhcb7a7oh4p1v"},{"post_id":"clakg9smq0024hcb7m8le2go9","category_id":"clakg9so2003chcb7u5292syo","_id":"clakg9so5003jhcb77jsi84ro"},{"post_id":"clakg9smv0026hcb7nm6ap3fr","category_id":"clakg9so3003ghcb7sxa4ifa0","_id":"clakg9so9003nhcb7jt84s010"},{"post_id":"clakg9sn0002ahcb7lk5yo9rn","category_id":"clakg9so5003khcb7wd5hkaaz","_id":"clakg9sog003rhcb7yq01xwzq"},{"post_id":"clakg9snc002dhcb71wi6obkj","category_id":"clakg9soa003ohcb77z7bvlft","_id":"clakg9soi003vhcb76l0fgkpa"},{"post_id":"clakg9sni002hhcb7nb94vsyu","category_id":"clakg9sog003shcb7i6j487er","_id":"clakg9soj003yhcb7itrbstwt"}],"PostTag":[{"post_id":"clakg9sgl0000hcb7dfzse2v9","tag_id":"clakg9si70005hcb79wxtz2qc","_id":"clakg9six000bhcb7t2kvf8pe"},{"post_id":"clakg9shd0002hcb7aro7i2j4","tag_id":"clakg9siv000ahcb71dbkgddu","_id":"clakg9sjj000ihcb700xjq27s"},{"post_id":"clakg9si90006hcb7webzep3k","tag_id":"clakg9sjd000ghcb74gt9lk0v","_id":"clakg9sjt000ohcb7rzn5mq12"},{"post_id":"clakg9sii0007hcb71vse8n35","tag_id":"clakg9sjo000mhcb7y2uu6hdg","_id":"clakg9sk3000uhcb7hr7b2ct0"},{"post_id":"clakg9sio0008hcb75bql7c4z","tag_id":"clakg9sjz000shcb7t2cnpayw","_id":"clakg9ske0010hcb7cezmd52h"},{"post_id":"clakg9sj0000chcb7g5zki9pm","tag_id":"clakg9sjz000shcb7t2cnpayw","_id":"clakg9skq0016hcb7fm71z4fk"},{"post_id":"clakg9sj8000dhcb794iug0by","tag_id":"clakg9sjz000shcb7t2cnpayw","_id":"clakg9sl0001chcb7fj4v581h"},{"post_id":"clakg9sl1001dhcb70kfb7860","tag_id":"clakg9skz001bhcb7n92hrcls","_id":"clakg9slk001ihcb7owkfu80d"},{"post_id":"clakg9sjq000nhcb7c3a1znis","tag_id":"clakg9skz001bhcb7n92hrcls","_id":"clakg9slo001khcb71odby2zx"},{"post_id":"clakg9sjt000phcb7u2yqjgy9","tag_id":"clakg9sli001hhcb7uq1t987g","_id":"clakg9sm0001rhcb7nlwbpven"},{"post_id":"clakg9sjz000thcb7jvik8ieh","tag_id":"clakg9slt001ohcb76qsbhm2q","_id":"clakg9smd001xhcb77v1f9nye"},{"post_id":"clakg9sk7000xhcb76ot0mwl2","tag_id":"clakg9sm9001vhcb7pxmlv097","_id":"clakg9smp0023hcb7l5eq229w"},{"post_id":"clakg9skf0011hcb7v6503ksg","tag_id":"clakg9smo0022hcb7i85pde6r","_id":"clakg9sn9002bhcb7pa4jstd4"},{"post_id":"clakg9skj0012hcb7klwf0dba","tag_id":"clakg9smo0022hcb7i85pde6r","_id":"clakg9snl002ihcb7bato7b2i"},{"post_id":"clakg9skq0017hcb7twki3xo5","tag_id":"clakg9snh002fhcb7fi2bfudn","_id":"clakg9snn002mhcb7xgrxlhh8"},{"post_id":"clakg9skt0018hcb7qm7ja1gp","tag_id":"clakg9snh002fhcb7fi2bfudn","_id":"clakg9snp002qhcb7nagnx8mi"},{"post_id":"clakg9sla001ehcb7efldu6mz","tag_id":"clakg9snp002phcb78e48wsh9","_id":"clakg9sns002uhcb7r52lb1js"},{"post_id":"clakg9sll001jhcb70h0b1dhj","tag_id":"clakg9snp002phcb78e48wsh9","_id":"clakg9snu002yhcb7uo8bs1yx"},{"post_id":"clakg9slo001lhcb7wys86y75","tag_id":"clakg9snt002xhcb7t1ce0d6g","_id":"clakg9snx0032hcb75vpi0jys"},{"post_id":"clakg9slv001phcb72y8almt0","tag_id":"clakg9snw0031hcb7ore0qb7c","_id":"clakg9snz0036hcb763b72o08"},{"post_id":"clakg9sm1001shcb794swp09t","tag_id":"clakg9snw0031hcb7ore0qb7c","_id":"clakg9so1003ahcb7qpqn7lxz"},{"post_id":"clakg9sma001whcb7fimbrts3","tag_id":"clakg9so00039hcb7ljhnezyk","_id":"clakg9so3003ehcb7qiai1nyl"},{"post_id":"clakg9sme001yhcb7jr8fg0m2","tag_id":"clakg9so2003dhcb7vc3jaeeh","_id":"clakg9so4003ihcb7ax4em26s"},{"post_id":"clakg9smi0021hcb7bnim9j3x","tag_id":"clakg9so4003hhcb7lo5cvljv","_id":"clakg9so6003mhcb740oa7fq3"},{"post_id":"clakg9smq0024hcb7m8le2go9","tag_id":"clakg9so5003lhcb7g0lih94t","_id":"clakg9sof003qhcb7llb7gusl"},{"post_id":"clakg9smv0026hcb7nm6ap3fr","tag_id":"clakg9soc003phcb7y8kiq3sy","_id":"clakg9soi003uhcb7trj04uy6"},{"post_id":"clakg9sn0002ahcb7lk5yo9rn","tag_id":"clakg9soh003thcb7k9930zs4","_id":"clakg9soj003xhcb7v4zzdpqy"},{"post_id":"clakg9snc002dhcb71wi6obkj","tag_id":"clakg9soj003whcb7wjgahdd5","_id":"clakg9sok0040hcb7ybki4lim"},{"post_id":"clakg9sni002hhcb7nb94vsyu","tag_id":"clakg9sok003zhcb7lnmcgkxc","_id":"clakg9sok0041hcb737wl9y3c"}],"Tag":[{"name":"Glances","_id":"clakg9si70005hcb79wxtz2qc"},{"name":"k8s","_id":"clakg9siv000ahcb71dbkgddu"},{"name":"python","_id":"clakg9sjd000ghcb74gt9lk0v"},{"name":"ingress","_id":"clakg9sjo000mhcb7y2uu6hdg"},{"name":"git","_id":"clakg9sjz000shcb7t2cnpayw"},{"name":"linux","_id":"clakg9skz001bhcb7n92hrcls"},{"name":"jira","_id":"clakg9sli001hhcb7uq1t987g"},{"name":"nginx","_id":"clakg9slt001ohcb76qsbhm2q"},{"name":"traceroute","_id":"clakg9sm9001vhcb7pxmlv097"},{"name":"rsync","_id":"clakg9smo0022hcb7i85pde6r"},{"name":"ssh","_id":"clakg9snh002fhcb7fi2bfudn"},{"name":"lsync","_id":"clakg9snp002phcb78e48wsh9"},{"name":"mtr","_id":"clakg9snt002xhcb7t1ce0d6g"},{"name":"mysql","_id":"clakg9snw0031hcb7ore0qb7c"},{"name":"open-falcon","_id":"clakg9so00039hcb7ljhnezyk"},{"name":"tcpdum","_id":"clakg9so2003dhcb7vc3jaeeh"},{"name":"tcpdump","_id":"clakg9so4003hhcb7lo5cvljv"},{"name":"tsung","_id":"clakg9so5003lhcb7g0lih94t"},{"name":"rpm","_id":"clakg9soc003phcb7y8kiq3sy"},{"name":"zabbix","_id":"clakg9soh003thcb7k9930zs4"},{"name":"wordpress","_id":"clakg9soj003whcb7wjgahdd5"},{"name":"elk","_id":"clakg9sok003zhcb7lnmcgkxc"}]}}