<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Datura</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://datura.me/"/>
  <updated>2018-12-18T03:58:18.724Z</updated>
  <id>http://datura.me/</id>
  
  <author>
    <name>Datura</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>mysql使用binlog日志恢复</title>
    <link href="http://datura.me/2018/11/07/mysql%E4%BD%BF%E7%94%A8binlog%E6%97%A5%E5%BF%97%E6%81%A2%E5%A4%8D/"/>
    <id>http://datura.me/2018/11/07/mysql使用binlog日志恢复/</id>
    <published>2018-11-07T05:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.724Z</updated>
    
    <content type="html"><![CDATA[<p>众所周知，binlog日志对于mysql数据库来说是十分重要的。在数据丢失的紧急情况下，我们往往会想到用binlog日志功能进行数据恢复（定时全备份+binlog日志恢复增量数据部分），化险为夷！<br><a id="more"></a><br>废话不多说，下面是梳理的binlog日志操作解说：</p><h2 id="一、初步了解binlog"><a href="#一、初步了解binlog" class="headerlink" title="一、初步了解binlog"></a>一、初步了解binlog</h2><p>MySQL的二进制日志binlog可以说是MySQL最重要的日志，它记录了所有的DDL和DML语句（除了数据查询语句select），以事件形式记录，还包含语句所执行的消耗的时间，MySQL的二进制日志是事务安全型的。</p><hr><p>DDL</p><p>—-Data Definition Language 数据库定义语言 </p><p>主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表（TABLE）的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用。</p><p>DML</p><p>—-Data Manipulation Language 数据操纵语言</p><p>主要的命令是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言</p><hr><p>mysqlbinlog常见的选项有以下几个：<br>–start-datetime：从二进制日志中读取指定等于时间戳或者晚于本地计算机的时间<br>–stop-datetime：从二进制日志中读取指定小于时间戳或者等于本地计算机的时间 取值和上述一样<br>–start-position：从二进制日志中读取指定position 事件位置作为开始。<br>–stop-position：从二进制日志中读取指定position 事件位置作为事件截至</p><hr><p>一般来说开启binlog日志大概会有1%的性能损耗。</p><h3 id="binlog日志有两个最重要的使用场景"><a href="#binlog日志有两个最重要的使用场景" class="headerlink" title="binlog日志有两个最重要的使用场景:"></a>binlog日志有两个最重要的使用场景:</h3><p> 1）MySQL主从复制：MySQL Replication在Master端开启binlog，Master把它的二进制日志传递给slaves来达到<br>master-slave数据一致的目的。<br> 2）自然就是数据恢复了，通过使用mysqlbinlog工具来使恢复数据。</p><h3 id="binlog日志包括两类文件："><a href="#binlog日志包括两类文件：" class="headerlink" title="binlog日志包括两类文件："></a>binlog日志包括两类文件：</h3><p> 1）二进制日志索引文件（文件名后缀为.index）用于记录所有的二进制文件<br> 2）二进制日志文件（文件名后缀为.00000*）记录数据库所有的DDL和DML(除了数据查询语句select)语句事件。</p><h2 id="二、开启binlog日志："><a href="#二、开启binlog日志：" class="headerlink" title="二、开启binlog日志："></a>二、开启binlog日志：</h2><p> 1）编辑打开mysql配置文件/etc/mys.cnf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 ~]# vim /etc/my.cnf</span><br><span class="line"></span><br><span class="line">在[mysqld] 区块添加 </span><br><span class="line">log-bin=mysql-bin 确认是打开状态(mysql-bin 是日志的基本名或前缀名)；</span><br></pre></td></tr></table></figure><p> 2）重启mysqld服务使配置生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 ~]# /etc/init.d/mysqld stop</span><br><span class="line">[root@vm-002 ~]# /etc/init.d/mysqld restart</span><br><span class="line">Stopping mysqld: [ OK ]</span><br><span class="line">Starting mysqld: [ OK ]</span><br></pre></td></tr></table></figure><p> 3）查看binlog日志是否开启<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &apos;log_%&apos;; </span><br><span class="line">+---------------------------------+---------------------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------------------------+---------------------+</span><br><span class="line">| log_bin | ON |</span><br><span class="line">| log_bin_trust_function_creators | OFF |</span><br><span class="line">| log_bin_trust_routine_creators | OFF |</span><br><span class="line">| log_error | /var/log/mysqld.log |</span><br><span class="line">| log_output | FILE |</span><br><span class="line">| log_queries_not_using_indexes | OFF |</span><br><span class="line">| log_slave_updates | OFF |</span><br><span class="line">| log_slow_queries | OFF |</span><br><span class="line">| log_warnings | 1 |</span><br><span class="line">+---------------------------------+---------------------+</span><br><span class="line">9 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><h2 id="三、常用的binlog日志操作命令"><a href="#三、常用的binlog日志操作命令" class="headerlink" title="三、常用的binlog日志操作命令"></a>三、常用的binlog日志操作命令</h2><p> 1）查看所有binlog日志列表<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show master logs;</span><br><span class="line">+------------------+-----------+</span><br><span class="line">| Log_name | File_size |</span><br><span class="line">+------------------+-----------+</span><br><span class="line">| mysql-bin.000001 | 149 |</span><br><span class="line">| mysql-bin.000002 | 4102 |</span><br><span class="line">+------------------+-----------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p> 2）查看master状态，即最后(最新)一个binlog日志的编号名称，及其最后一个操作事件pos结束点(Position)值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show master status;</span><br><span class="line">+------------------+----------+--------------+------------------+</span><br><span class="line">| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |</span><br><span class="line">+------------------+----------+--------------+------------------+</span><br><span class="line">| mysql-bin.000002 | 4102 | | |</span><br><span class="line">+------------------+----------+--------------+------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p> 3）flush刷新log日志，自此刻开始产生一个新编号的binlog日志文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; flush logs; </span><br><span class="line">Query OK, 0 rows affected (0.13 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show master logs; </span><br><span class="line">+------------------+-----------+</span><br><span class="line">| Log_name | File_size |</span><br><span class="line">+------------------+-----------+</span><br><span class="line">| mysql-bin.000001 | 149 |</span><br><span class="line">| mysql-bin.000002 | 4145 |</span><br><span class="line">| mysql-bin.000003 | 106 |</span><br><span class="line">+------------------+-----------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>注意：<br>每当mysqld服务重启时，会自动执行此命令，刷新binlog日志；在mysqldump备份数据时加 -F 选项也会刷新binlog日志；</p><p> 4）重置(清空)所有binlog日志<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; reset master;</span><br><span class="line">Query OK, 0 rows affected (0.12 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show master logs; </span><br><span class="line">+------------------+-----------+</span><br><span class="line">| Log_name | File_size |</span><br><span class="line">+------------------+-----------+</span><br><span class="line">| mysql-bin.000001 | 106 |</span><br><span class="line">+------------------+-----------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><h2 id="四、查看binlog日志内容，常用有两种方式："><a href="#四、查看binlog日志内容，常用有两种方式：" class="headerlink" title="四、查看binlog日志内容，常用有两种方式："></a>四、查看binlog日志内容，常用有两种方式：</h2><p> 1）使用mysqlbinlog自带查看命令法：<br>注意：<br>–&gt;binlog是二进制文件，普通文件查看器cat、more、vim等都无法打开，必须使用自带的mysqlbinlog命令查看<br>–&gt;binlog日志与数据库文件在同目录中<br>–&gt;在MySQL5.5以下版本使用mysqlbinlog命令时如果报错，就加上 “–no-defaults”选项</p><p>查看mysql的数据存放目录，从下面结果可知是/var/lib//mysql<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 ~]# ps -ef|grep mysql</span><br><span class="line">root 9791 1 0 21:18 pts/0 00:00:00 /bin/sh /usr/bin/mysqld_safe --datadir=/var/lib/mysql --socket=/var/lib/mysql/mysql.sock --pid-file=/var/run/mysqld/mysqld.pid --basedir=/usr --user=mysql</span><br><span class="line">mysql 9896 9791 0 21:18 pts/0 00:00:00 /usr/libexec/mysqld --basedir=/usr --datadir=/var/lib/mysql --user=mysql --log-error=/var/log/mysqld.log --pid-file=/var/run/mysqld/mysqld.pid --socket=/var/lib/mysql/mysql.sock</span><br><span class="line">root 9916 9699 0 21:18 pts/0 00:00:00 mysql -px xxxx</span><br><span class="line">root 9919 9715 0 21:23 pts/1 00:00:00 grep --color mysql</span><br><span class="line"></span><br><span class="line">[root@vm-002 ~]# cd /var/lib/mysql/</span><br><span class="line">[root@vm-002 mysql]# ls</span><br><span class="line">ibdata1 ib_logfile0 ib_logfile1 mysql mysql-bin.000001 mysql-bin.000002 mysql-bin.index mysql.sock ops test</span><br><span class="line"></span><br><span class="line">使用mysqlbinlog命令查看binlog日志内容，下面截取其中的一个片段分析：</span><br><span class="line">[root@vm-002 mysql]# mysqlbinlog mysql-bin.000002</span><br><span class="line">..............</span><br><span class="line"># at 624</span><br><span class="line">#160925 21:29:53 server id 1 end_log_pos 796 Querythread_id=3exec_time=0error_code=0</span><br><span class="line">SET TIMESTAMP=1474810193/*!*/;</span><br><span class="line">insert into member(`name`,`sex`,`age`,`classid`) values(&apos;wangshibo&apos;,&apos;m&apos;,27,&apos;cls1&apos;),(&apos;guohuihui&apos;,&apos;w&apos;,27,&apos;cls2&apos;)        #执行的sql语句</span><br><span class="line">/*!*/;</span><br><span class="line">#at 796</span><br><span class="line">#160925 21:29:53 server id 1 end_log_pos 823 Xid = 17                  #执行的时间</span><br><span class="line">.............</span><br></pre></td></tr></table></figure></p><p>解释：<br>server id 1 ： 数据库主机的服务号；<br>end_log_pos 796： sql结束时的pos节点<br>thread_id=11： 线程号</p><p> 2）上面这种办法读取出binlog日志的全文内容比较多，不容易分辨查看到pos点信息<br>下面介绍一种更为方便的查询命令：<br>命令格式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show binlog events [IN &apos;log_name&apos;] [FROM pos] [LIMIT [offset,] row_count];</span><br></pre></td></tr></table></figure></p><p>参数解释：<br>IN ‘log_name’ ：指定要查询的binlog文件名(不指定就是第一个binlog文件)<br>FROM pos ：指定从哪个pos起始点开始查起(不指定就是从整个文件首个pos点开始算)<br>LIMIT [offset,] ：偏移量(不指定就是0)<br>row_count ：查询总条数(不指定就是所有行)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show master logs;</span><br><span class="line">+------------------+-----------+</span><br><span class="line">| Log_name | File_size |</span><br><span class="line">+------------------+-----------+</span><br><span class="line">| mysql-bin.000001 | 125 |</span><br><span class="line">| mysql-bin.000002 | 823 |</span><br><span class="line">+------------------+-----------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos;\G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">Log_name: mysql-bin.000002</span><br><span class="line">Pos: 4</span><br><span class="line">Event_type: Format_desc</span><br><span class="line">Server_id: 1</span><br><span class="line">End_log_pos: 106</span><br><span class="line">Info: Server ver: 5.1.73-log, Binlog ver: 4</span><br><span class="line">*************************** 2. row ***************************</span><br><span class="line">Log_name: mysql-bin.000002</span><br><span class="line">Pos: 106</span><br><span class="line">Event_type: Query</span><br><span class="line">Server_id: 1</span><br><span class="line">End_log_pos: 188</span><br><span class="line">Info: use `ops`; drop table customers</span><br><span class="line">*************************** 3. row ***************************</span><br><span class="line">Log_name: mysql-bin.000002</span><br><span class="line">Pos: 188</span><br><span class="line">Event_type: Query</span><br><span class="line">Server_id: 1</span><br><span class="line">End_log_pos: 529</span><br><span class="line">Info: use `ops`; CREATE TABLE IF NOT EXISTS `member` (</span><br><span class="line">`id` int(10) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class="line">`name` varchar(16) NOT NULL,</span><br><span class="line">`sex` enum(&apos;m&apos;,&apos;w&apos;) NOT NULL DEFAULT &apos;m&apos;,</span><br><span class="line">`age` tinyint(3) unsigned NOT NULL,</span><br><span class="line">`classid` char(6) DEFAULT NULL,</span><br><span class="line">PRIMARY KEY (`id`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8</span><br><span class="line">*************************** 4. row ***************************</span><br><span class="line">Log_name: mysql-bin.000002</span><br><span class="line">Pos: 529</span><br><span class="line">Event_type: Query</span><br><span class="line">Server_id: 1</span><br><span class="line">End_log_pos: 596</span><br><span class="line">Info: BEGIN</span><br><span class="line">*************************** 5. row ***************************</span><br><span class="line">Log_name: mysql-bin.000002</span><br><span class="line">Pos: 596</span><br><span class="line">Event_type: Intvar</span><br><span class="line">Server_id: 1</span><br><span class="line">End_log_pos: 624</span><br><span class="line">Info: INSERT_ID=1</span><br><span class="line">*************************** 6. row ***************************</span><br><span class="line">Log_name: mysql-bin.000002</span><br><span class="line">Pos: 624</span><br><span class="line">Event_type: Query</span><br><span class="line">Server_id: 1</span><br><span class="line">End_log_pos: 796</span><br><span class="line">Info: use `ops`; insert into member(`name`,`sex`,`age`,`classid`) values(&apos;wangshibo&apos;,&apos;m&apos;,27,&apos;cls1&apos;),(&apos;guohuihui&apos;,&apos;w&apos;,27,&apos;cls2&apos;)</span><br><span class="line">*************************** 7. row ***************************</span><br><span class="line">Log_name: mysql-bin.000002</span><br><span class="line">Pos: 796</span><br><span class="line">Event_type: Xid</span><br><span class="line">Server_id: 1</span><br><span class="line">End_log_pos: 823</span><br><span class="line">Info: COMMIT /* xid=17 */</span><br><span class="line">7 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">ERROR: </span><br><span class="line">No query specified</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure></p><p>上面这条语句可以将指定的binlog日志文件，分成有效事件行的方式返回，并可使用limit指定pos点的起始偏移，查询条数！<br>如下操作示例：<br> a）查询第一个(最早)的binlog日志：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show binlog events\G;</span><br></pre></td></tr></table></figure></p><p> b）指定查询 mysql-bin.000002这个文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos;\G;</span><br></pre></td></tr></table></figure></p><p>c）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos; from 624\G;</span><br></pre></td></tr></table></figure></p><p>d）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起，查询10条（即10条语句）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos; from 624 limit 10\G;</span><br></pre></td></tr></table></figure></p><p>e）指定查询 mysql-bin.000002这个文件，从pos点:624开始查起，偏移2行（即中间跳过2个），查询10条<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show binlog events in &apos;mysql-bin.000002&apos; from 624 limit 2,10\G;</span><br></pre></td></tr></table></figure></p><h2 id="五、利用binlog日志恢复mysql数据"><a href="#五、利用binlog日志恢复mysql数据" class="headerlink" title="五、利用binlog日志恢复mysql数据"></a>五、利用binlog日志恢复mysql数据</h2><p>以下对ops库的member表进行操作<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use ops；</span><br><span class="line">mysql&gt; CREATE TABLE IF NOT EXISTS `member` (</span><br><span class="line">-&gt; `id` int(10) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class="line">-&gt; `name` varchar(16) NOT NULL,</span><br><span class="line">-&gt; `sex` enum(&apos;m&apos;,&apos;w&apos;) NOT NULL DEFAULT &apos;m&apos;,</span><br><span class="line">-&gt; `age` tinyint(3) unsigned NOT NULL,</span><br><span class="line">-&gt; `classid` char(6) DEFAULT NULL,</span><br><span class="line">-&gt; PRIMARY KEY (`id`)</span><br><span class="line">-&gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8;</span><br><span class="line">Query OK, 0 rows affected (0.10 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show tables;</span><br><span class="line">+---------------+</span><br><span class="line">| Tables_in_ops |</span><br><span class="line">+---------------+</span><br><span class="line">| member |</span><br><span class="line">+---------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc member;</span><br><span class="line">+---------+---------------------+------+-----+---------+----------------+</span><br><span class="line">| Field | Type | Null | Key | Default | Extra |</span><br><span class="line">+---------+---------------------+------+-----+---------+----------------+</span><br><span class="line">| id | int(10) unsigned | NO | PRI | NULL | auto_increment |</span><br><span class="line">| name | varchar(16) | NO | | NULL | |</span><br><span class="line">| sex | enum(&apos;m&apos;,&apos;w&apos;) | NO | | m | |</span><br><span class="line">| age | tinyint(3) unsigned | NO | | NULL | |</span><br><span class="line">| classid | char(6) | YES | | NULL | |</span><br><span class="line">+---------+---------------------+------+-----+---------+----------------+</span><br><span class="line">5 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>事先插入两条数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; insert into member(`name`,`sex`,`age`,`classid`) values(&apos;wangshibo&apos;,&apos;m&apos;,27,&apos;cls1&apos;),(&apos;guohuihui&apos;,&apos;w&apos;,27,&apos;cls2&apos;);</span><br><span class="line">Query OK, 2 rows affected (0.08 sec)</span><br><span class="line">Records: 2 Duplicates: 0 Warnings: 0</span><br><span class="line">mysql&gt; select * from member;</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| id | name | sex | age | classid |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class="line">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>下面开始进行场景模拟：<br>1）<br>ops库会在每天凌晨4点进行一次完全备份的定时计划任务，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 ~]# crontab -l</span><br><span class="line">0 4 * * * /usr/bin/mysqldump -uroot -p -B -F -R -x --master-data=2 ops|gzip &gt;/opt/backup/ops_$(date +%F).sql.gz</span><br></pre></td></tr></table></figure></p><p>这里手动执行下，将ops数据库备份到/opt/backup/ops_$(date +%F).sql.gz文件中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 ~]# mysqldump -uroot -p -B -F -R -x --master-data=2 ops|gzip &gt;/opt/backup/ops_$(date +%F).sql.gz</span><br><span class="line">Enter password: </span><br><span class="line">[root@vm-002 ~]# ls /opt/backup/</span><br><span class="line">ops_2016-09-25.sql.gz</span><br></pre></td></tr></table></figure></p><hr><p>参数说明：<br>-B：指定数据库<br>-F：刷新日志<br>-R：备份存储过程等<br>-x：锁表<br>–master-data：在备份语句里添加CHANGE MASTER语句以及binlog文件及位置点信息</p><hr><p>待到数据库备份完成，就不用担心数据丢失了，因为有完全备份数据在！！</p><p>由于上面在全备份的时候使用了-F选项，那么当数据备份操作刚开始的时候系统就会自动刷新log，这样就会自动产生<br>一个新的binlog日志，这个新的binlog日志就会用来记录备份之后的数据库“增删改”操作<br>查看一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show master status;</span><br><span class="line">+------------------+----------+--------------+------------------+</span><br><span class="line">| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |</span><br><span class="line">+------------------+----------+--------------+------------------+</span><br><span class="line">| mysql-bin.000003 | 106 | | |</span><br><span class="line">+------------------+----------+--------------+------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>也就是说， mysql-bin.000003 是用来记录4:00之后对数据库的所有“增删改”操作。</p><p>2）<br>早上9点上班了，由于业务的需求会对数据库进行各种“增删改”操作。<br>比如：在ops库下member表内插入、修改了数据等等：</p><p>先是早上进行插入数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; insert into ops.member(`name`,`sex`,`age`,`classid`) values(&apos;yiyi&apos;,&apos;w&apos;,20,&apos;cls1&apos;),(&apos;xiaoer&apos;,&apos;m&apos;,22,&apos;cls3&apos;),(&apos;zhangsan&apos;,&apos;w&apos;,21,&apos;cls5&apos;),(&apos;lisi&apos;,&apos;m&apos;,20,&apos;cls4&apos;),(&apos;wangwu&apos;,&apos;w&apos;,26,&apos;cls6&apos;);</span><br><span class="line">Query OK, 5 rows affected (0.08 sec)</span><br><span class="line">Records: 5 Duplicates: 0 Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from member;</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| id | name | sex | age | classid |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class="line">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class="line">| 3 | yiyi | w | 20 | cls1 |</span><br><span class="line">| 4 | xiaoer | m | 22 | cls3 |</span><br><span class="line">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class="line">| 6 | lisi | m | 20 | cls4 |</span><br><span class="line">| 7 | wangwu | w | 26 | cls6 |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>3）<br>中午又执行了修改数据操作：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update ops.member set name=&apos;李四&apos; where id=4;</span><br><span class="line">Query OK, 1 row affected (0.07 sec)</span><br><span class="line">Rows matched: 1 Changed: 1 Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; update ops.member set name=&apos;小二&apos; where id=2;</span><br><span class="line">Query OK, 1 row affected (0.06 sec)</span><br><span class="line">Rows matched: 1 Changed: 1 Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from member;</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| id | name | sex | age | classid |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class="line">| 2 | 小二 | w | 27 | cls2 |</span><br><span class="line">| 3 | yiyi | w | 20 | cls1 |</span><br><span class="line">| 4 | 李四 | m | 22 | cls3 |</span><br><span class="line">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class="line">| 6 | lisi | m | 20 | cls4 |</span><br><span class="line">| 7 | wangwu | w | 26 | cls6 |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>4）<br>在下午18:00的时候，悲剧莫名其妙的出现了！<br>手贱执行了drop语句，直接删除了ops库！吓尿！<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; drop database ops;</span><br><span class="line">Query OK, 1 row affected (0.02 sec)</span><br></pre></td></tr></table></figure></p><p>5）<br>这种时候，一定不要慌张！！！<br>先仔细查看最后一个binlog日志，并记录下关键的pos点，到底是哪个pos点的操作导致了数据库的破坏(通常在最后几步)；</p><p>先备份一下最后一个binlog日志文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 ~]# cd /var/lib/mysql/</span><br><span class="line">[root@vm-002 mysql]# cp -v mysql-bin.000003 /opt/backup/</span><br><span class="line">`mysql-bin.000003&apos; -&gt; `/opt/backup/mysql-bin.000003&apos;</span><br><span class="line">[root@vm-002 mysql]# ls /opt/backup/</span><br><span class="line">mysql-bin.000003 ops_2016-09-25.sql.gz</span><br></pre></td></tr></table></figure></p><p>接着执行一次刷新日志索引操作，重新开始新的binlog日志记录文件。按理说mysql-bin.000003<br>这个文件不会再有后续写入了，因为便于我们分析原因及查找ops节点，以后所有数据库操作都会写入到下一个日志文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; flush logs;</span><br><span class="line">Query OK, 0 rows affected (0.13 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show master status;</span><br><span class="line">+------------------+----------+--------------+------------------+</span><br><span class="line">| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |</span><br><span class="line">+------------------+----------+--------------+------------------+</span><br><span class="line">| mysql-bin.000004 | 106 | | |</span><br><span class="line">+------------------+----------+--------------+------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>6）<br>读取binlog日志，分析问题。<br>读取binlog日志的方法上面已经说到。<br>方法一：使用mysqlbinlog读取binlog日志：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 ~]# cd /var/lib/mysql/</span><br><span class="line">[root@vm-002 mysql]# mysqlbinlog mysql-bin.000003</span><br></pre></td></tr></table></figure></p><p>方法二：登录服务器，并查看(推荐此种方法)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show binlog events in &apos;mysql-bin.000003&apos;;</span><br><span class="line"></span><br><span class="line">+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |</span><br><span class="line">+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| mysql-bin.000003 | 4 | Format_desc | 1 | 106 | Server ver: 5.1.73-log, Binlog ver: 4 |</span><br><span class="line">| mysql-bin.000003 | 106 | Query | 1 | 173 | BEGIN |</span><br><span class="line">| mysql-bin.000003 | 173 | Intvar | 1 | 201 | INSERT_ID=3 |</span><br><span class="line">| mysql-bin.000003 | 201 | Query | 1 | 444 | use `ops`; insert into ops.member(`name`,`sex`,`age`,`gsan&apos;,&apos;w&apos;,21,&apos;cls5&apos;),(&apos;lisi&apos;,&apos;m&apos;,20,&apos;cls4&apos;),(&apos;wangwu&apos;,&apos;w&apos;,26,&apos;cls6&apos;) |</span><br><span class="line">| mysql-bin.000003 | 444 | Xid | 1 | 471 | COMMIT /* xid=66 */ |</span><br><span class="line">| mysql-bin.000003 | 471 | Query | 1 | 538 | BEGIN |</span><br><span class="line">| mysql-bin.000003 | 538 | Query | 1 | 646 | use `ops`; update ops.member set name=&apos;李四&apos; where id= |</span><br><span class="line">| mysql-bin.000003 | 646 | Xid | 1 | 673 | COMMIT /* xid=68 */ |</span><br><span class="line">| mysql-bin.000003 | 673 | Query | 1 | 740 | BEGIN |</span><br><span class="line">| mysql-bin.000003 | 740 | Query | 1 | 848 | use `ops`; update ops.member set name=&apos;小二&apos; where id= |</span><br><span class="line">| mysql-bin.000003 | 848 | Xid | 1 | 875 | COMMIT /* xid=69 */ |</span><br><span class="line">| mysql-bin.000003 | 875 | Query | 1 | 954 | drop database ops |</span><br><span class="line">| mysql-bin.000003 | 954 | Rotate | 1 | 997 | mysql-bin.000004;pos=4 |</span><br><span class="line">+------------------+-----+-------------+-----------+-------------+----------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">13 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">或者：</span><br><span class="line"></span><br><span class="line">mysql&gt; show binlog events in &apos;mysql-bin.000003&apos;\G;</span><br><span class="line">.........</span><br><span class="line">.........</span><br><span class="line">*************************** 12. row ***************************</span><br><span class="line">Log_name: mysql-bin.000003</span><br><span class="line">Pos: 875</span><br><span class="line">Event_type: Query</span><br><span class="line">Server_id: 1</span><br><span class="line">End_log_pos: 954</span><br><span class="line">Info: drop database ops</span><br><span class="line">*************************** 13. row ***************************</span><br><span class="line">Log_name: mysql-bin.000003</span><br><span class="line">Pos: 954</span><br><span class="line">Event_type: Rotate</span><br><span class="line">Server_id: 1</span><br><span class="line">End_log_pos: 997</span><br><span class="line">Info: mysql-bin.000004;pos=4</span><br><span class="line">13 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>通过分析，造成数据库破坏的pos点区间是介于 875–954 之间（这是按照日志区间的pos节点算的），只要恢复到875前就可。</p><p>7）<br>先把凌晨4点全备份的数据恢复：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 ~]# cd /opt/backup/</span><br><span class="line">[root@vm-002 backup]# ls</span><br><span class="line">mysql-bin.000003 ops_2016-09-25.sql.gz</span><br><span class="line">[root@vm-002 backup]# gzip -d ops_2016-09-25.sql.gz </span><br><span class="line">[root@vm-002 backup]# mysql -uroot -p -v &lt; ops_2016-09-25.sql </span><br><span class="line">Enter password: </span><br><span class="line">--------------</span><br><span class="line">/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */</span><br><span class="line">--------------</span><br><span class="line"></span><br><span class="line">--------------</span><br><span class="line">/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */</span><br><span class="line">--------------</span><br><span class="line"></span><br><span class="line">.............</span><br><span class="line">.............</span><br><span class="line"></span><br><span class="line">--------------</span><br><span class="line">/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */</span><br><span class="line">--------------</span><br><span class="line"></span><br><span class="line">这样就恢复了截至当日凌晨(4:00)前的备份数据都恢复了。</span><br><span class="line"></span><br><span class="line">mysql&gt; show databases;                        #发现ops库已经恢复回来了</span><br><span class="line">mysql&gt; use ops;</span><br><span class="line">Reading table information for completion of table and column names</span><br><span class="line">You can turn off this feature to get a quicker startup with -A</span><br><span class="line"></span><br><span class="line">Database changed</span><br><span class="line">mysql&gt; show tables;</span><br><span class="line">+---------------+</span><br><span class="line">| Tables_in_ops |</span><br><span class="line">+---------------+</span><br><span class="line">| member |</span><br><span class="line">+---------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from member;</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| id | name | sex | age | classid |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class="line">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure></p><p>但是这仅仅只是恢复了当天凌晨4点之前的数据，在4:00–18:00之间的数据还没有恢复回来！！<br>怎么办呢？<br>莫慌！这可以根据前面提到的mysql-bin.000003的新binlog日志进行恢复。</p><p>8）<br>从binlog日志恢复数据<br>恢复命令的语法格式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqlbinlog mysql-bin.0000xx | mysql -u用户名 -p密码 数据库名</span><br></pre></td></tr></table></figure></p><hr><p>常用参数选项解释：<br>–start-position=875 起始pos点<br>–stop-position=954 结束pos点<br>–start-datetime=”2016-9-25 22:01:08” 起始时间点<br>–stop-datetime=”2019-9-25 22:09:46” 结束时间点<br>–database=zyyshop 指定只恢复zyyshop数据库(一台主机上往往有多个数据库，只限本地log日志)</p><hr><p>不常用选项：<br>-u –user=name 连接到远程主机的用户名<br>-p –password[=name] 连接到远程主机的密码<br>-h –host=name 从远程主机上获取binlog日志<br>–read-from-remote-server 从某个MySQL服务器上读取binlog日志</p><hr><p>小结：实际是将读出的binlog日志内容，通过管道符传递给mysql命令。这些命令、文件尽量写成绝对路径；</p><p>a）完全恢复(需要手动vim编辑mysql-bin.000003，将那条drop语句剔除掉)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 backup]# /usr/bin/mysqlbinlog /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br></pre></td></tr></table></figure></p><p>b）指定pos结束点恢复(部分恢复)：<br>–stop-position=471 pos结束节点（按照事务区间算，是471）</p><p>注意：<br>此pos结束节点介于“member表原始数据”与更新“name=’李四’”之前的数据，这样就可以恢复到更改“name=’李四’”之前的数据了。<br>操作如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 ~]# /usr/bin/mysqlbinlog --stop-position=471 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from member;</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| id | name | sex | age | classid |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class="line">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class="line">| 3 | yiyi | w | 20 | cls1 |</span><br><span class="line">| 4 | xiaoer | m | 22 | cls3 |</span><br><span class="line">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class="line">| 6 | lisi | m | 20 | cls4 |</span><br><span class="line">| 7 | wangwu | w | 26 | cls6 |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">7 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">恢复截止到更改“name=&apos;李四&apos;”之间的数据（按照事务区间算，是673）</span><br><span class="line">[root@vm-002 ~]# /usr/bin/mysqlbinlog --stop-position=673 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from member;</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| id | name | sex | age | classid |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class="line">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class="line">| 3 | yiyi | w | 20 | cls1 |</span><br><span class="line">| 4 | 李四 | m | 22 | cls3 |</span><br><span class="line">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class="line">| 6 | lisi | m | 20 | cls4 |</span><br><span class="line">| 7 | wangwu | w | 26 | cls6 |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>c）指定pso点区间恢复(部分恢复)：<br>更新 name=’李四’ 这条数据，日志区间是Pos[538] –&gt; End_log_pos[646]，按事务区间是：Pos[471] –&gt; End_log_pos[673]</p><p>更新 name=’小二’ 这条数据，日志区间是Pos[740] –&gt; End_log_pos[848]，按事务区间是：Pos[673] –&gt; End_log_pos[875]</p><p>c1）<br>单独恢复 name=’李四’ 这步操作，可这样：<br>按照binlog日志区间单独恢复：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=538 --stop-position=646 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class="line"></span><br><span class="line">按照事务区间单独恢复</span><br><span class="line">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=471 --stop-position=673 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br></pre></td></tr></table></figure></p><p>c2）<br>单独恢复 name=’小二’ 这步操作，可这样：<br>按照binlog日志区间单独恢复：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=740 --stop-position=848 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class="line"></span><br><span class="line">按照事务区间单独恢复</span><br><span class="line">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=673 --stop-position=875 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br></pre></td></tr></table></figure></p><p>c3）<br>将 name=’李四’、name=’小二’ 多步操作一起恢复，需要按事务区间，可这样：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-position=471 --stop-position=875 --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class="line"></span><br><span class="line">查看数据库：</span><br><span class="line">mysql&gt; select * from member;</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| id | name | sex | age | classid |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class="line">| 2 | 小二 | w | 27 | cls2 |</span><br><span class="line">| 3 | yiyi | w | 20 | cls1 |</span><br><span class="line">| 4 | 李四 | m | 22 | cls3 |</span><br><span class="line">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class="line">| 6 | lisi | m | 20 | cls4 |</span><br><span class="line">| 7 | wangwu | w | 26 | cls6 |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>这样，就恢复了删除前的数据状态了！！</p><hr><p>另外：<br>也可指定时间节点区间恢复(部分恢复)：<br>除了用pos节点的办法进行恢复，也可以通过指定时间节点区间进行恢复，按时间恢复需要用mysqlbinlog命令读取binlog日志内容，找时间节点。</p><p>如上，误删除ops库后：<br>先进行全备份恢复<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-002 backup]# mysql -uroot -p -v &lt; ops_2016-09-25.sql</span><br></pre></td></tr></table></figure></p><p>查看ops数据库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from member;</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| id | name | sex | age | classid |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class="line">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br><span class="line"></span><br><span class="line">查看mysq-bin00003日志，找出时间节点</span><br><span class="line">[root@vm-002 ~]# cd /var/lib/mysql</span><br><span class="line">[root@vm-002 mysql]# mysqlbinlog mysql-bin.000003 </span><br><span class="line">.............</span><br><span class="line">.............</span><br><span class="line">BEGIN</span><br><span class="line">/*!*/;</span><br><span class="line"># at 173</span><br><span class="line">#160925 21:57:19 server id 1 end_log_pos 201 Intvar</span><br><span class="line">SET INSERT_ID=3/*!*/;</span><br><span class="line"># at 201</span><br><span class="line">#160925 21:57:19 server id 1 end_log_pos 444 Query thread_id=3 exec_time=0 error_code=0</span><br><span class="line">use `ops`/*!*/;</span><br><span class="line">SET TIMESTAMP=1474811839/*!*/;</span><br><span class="line">insert into ops.member(`name`,`sex`,`age`,`classid`) values(&apos;yiyi&apos;,&apos;w&apos;,20,&apos;cls1&apos;),(&apos;xiaoer&apos;,&apos;m&apos;,22,&apos;cls3&apos;),(&apos;zhangsan&apos;,&apos;w&apos;,21,&apos;cls5&apos;),(&apos;lisi&apos;,&apos;m&apos;,20,&apos;cls4&apos;),(&apos;wangwu&apos;,&apos;w&apos;,26,&apos;cls6&apos;)                               #执行的sql语句</span><br><span class="line">/*!*/;</span><br><span class="line"># at 444</span><br><span class="line">#160925 21:57:19 server id 1 end_log_pos 471 Xid = 66    #开始执行的时间</span><br><span class="line">COMMIT/*!*/;</span><br><span class="line"># at 471</span><br><span class="line">#160925 21:58:41 server id 1 end_log_pos 538 Query thread_id=3 exec_time=0 error_code=0    #结束时间</span><br><span class="line">SET TIMESTAMP=1474811921/*!*/;</span><br><span class="line">BEGIN</span><br><span class="line">/*!*/;</span><br><span class="line"># at 538</span><br><span class="line">#160925 21:58:41 server id 1 end_log_pos 646 Query thread_id=3 exec_time=0 error_code=0</span><br><span class="line">SET TIMESTAMP=1474811921/*!*/;</span><br><span class="line">update ops.member set name=&apos;李四&apos; where id=4     #执行的sql语句</span><br><span class="line">/*!*/;</span><br><span class="line"># at 646</span><br><span class="line">#160925 21:58:41 server id 1 end_log_pos 673 Xid = 68    #开始执行的时间</span><br><span class="line">COMMIT/*!*/;</span><br><span class="line"># at 673</span><br><span class="line">#160925 21:58:56 server id 1 end_log_pos 740 Query thread_id=3 exec_time=0 error_code=0   #结束时间</span><br><span class="line">SET TIMESTAMP=1474811936/*!*/;</span><br><span class="line">BEGIN</span><br><span class="line">/*!*/;</span><br><span class="line"># at 740</span><br><span class="line">#160925 21:58:56 server id 1 end_log_pos 848 Query thread_id=3 exec_time=0 error_code=0</span><br><span class="line">SET TIMESTAMP=1474811936/*!*/;</span><br><span class="line">update ops.member set name=&apos;小二&apos; where id=2      #执行的sql语句</span><br><span class="line">/*!*/;</span><br><span class="line"># at 848</span><br><span class="line">#160925 21:58:56 server id 1 end_log_pos 875 Xid = 69   #开始执行的时间</span><br><span class="line">COMMIT/*!*/;</span><br><span class="line"># at 875</span><br><span class="line">#160925 22:01:08 server id 1 end_log_pos 954 Query thread_id=3 exec_time=0 error_code=0    #结束时间</span><br><span class="line">SET TIMESTAMP=1474812068/*!*/;</span><br><span class="line">drop database ops</span><br><span class="line">/*!*/;</span><br><span class="line"># at 954</span><br><span class="line">#160925 22:09:46 server id 1 end_log_pos 997 Rotate to mysql-bin.000004 pos: 4</span><br><span class="line">DELIMITER ;</span><br><span class="line"># End of log file</span><br><span class="line">ROLLBACK /* added by mysqlbinlog */;</span><br><span class="line">/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;</span><br><span class="line"></span><br><span class="line">恢复到更改“name=&apos;李四&apos;”之前的数据</span><br><span class="line">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=&quot;2016-09-25 21:57:19&quot; --stop-datetime=&quot;2016-09-25 21:58:41&quot; --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from member;</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| id | name | sex | age | classid |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class="line">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class="line">| 3 | yiyi | w | 20 | cls1 |</span><br><span class="line">| 4 | xiaoer | m | 22 | cls3 |</span><br><span class="line">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class="line">| 6 | lisi | m | 20 | cls4 |</span><br><span class="line">| 7 | wangwu | w | 26 | cls6 |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">7 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=&quot;2016-09-25 21:58:41&quot; --stop-datetime=&quot;2016-09-25 21:58:56&quot; --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class="line">mysql&gt; select * from member;</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| id | name | sex | age | classid |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class="line">| 2 | guohuihui | w | 27 | cls2 |</span><br><span class="line">| 3 | yiyi | w | 20 | cls1 |</span><br><span class="line">| 4 | 李四 | m | 22 | cls3 |</span><br><span class="line">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class="line">| 6 | lisi | m | 20 | cls4 |</span><br><span class="line">| 7 | wangwu | w | 26 | cls6 |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">7 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">[root@vm-002 ~]# /usr/bin/mysqlbinlog --start-datetime=&quot;2016-09-25 21:58:56&quot; --stop-datetime=&quot;2016-09-25 22:01:08&quot; --database=ops /var/lib/mysql/mysql-bin.000003 | /usr/bin/mysql -uroot -p123456 -v ops</span><br><span class="line">mysql&gt; select * from member;</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| id | name | sex | age | classid |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">| 1 | wangshibo | m | 27 | cls1 |</span><br><span class="line">| 2 | 小二 | w | 27 | cls2 |</span><br><span class="line">| 3 | yiyi | w | 20 | cls1 |</span><br><span class="line">| 4 | 李四 | m | 22 | cls3 |</span><br><span class="line">| 5 | zhangsan | w | 21 | cls5 |</span><br><span class="line">| 6 | lisi | m | 20 | cls4 |</span><br><span class="line">| 7 | wangwu | w | 26 | cls6 |</span><br><span class="line">+----+-----------+-----+-----+---------+</span><br><span class="line">7 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>这样，就恢复了删除前的状态了！</p><p>总结：<br>所谓恢复，就是让mysql将保存在binlog日志中指定段落区间的sql语句逐个重新执行一次而已。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;众所周知，binlog日志对于mysql数据库来说是十分重要的。在数据丢失的紧急情况下，我们往往会想到用binlog日志功能进行数据恢复（定时全备份+binlog日志恢复增量数据部分），化险为夷！&lt;br&gt;
    
    </summary>
    
      <category term="mysql" scheme="http://datura.me/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://datura.me/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes如何使用kube-dns实现服务发现</title>
    <link href="http://datura.me/2018/04/10/Kubernetes%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8kube-dns%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/"/>
    <id>http://datura.me/2018/04/10/Kubernetes如何使用kube-dns实现服务发现/</id>
    <published>2018-04-10T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.722Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kubernetes中如何发现服务"><a href="#Kubernetes中如何发现服务" class="headerlink" title="Kubernetes中如何发现服务"></a>Kubernetes中如何发现服务</h1><a id="more"></a><h2 id="发现Pod提供的服务"><a href="#发现Pod提供的服务" class="headerlink" title="发现Pod提供的服务"></a>发现Pod提供的服务</h2><p>首先使用nginx-deployment.yaml文件创建一个Nginx Deployment，文件内容如图所示：<br>首先创建两个运行Nginx服务的Pod：<br><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/1.png" alt="http://blog.tenxcloud.com/wp-content/uploads/2016/10/1.png"></p><p>使用kubectl create -f nginx-deployment.yaml指令创建，这样便可以得到两个运行nginx服务的Pod。待Pod运行之后查看一下它们的IP，并在k8s集群内通过podIP和containerPort来访问Nginx服务：</p><h3 id="获取Pod-IP："><a href="#获取Pod-IP：" class="headerlink" title="获取Pod IP："></a>获取Pod IP：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -o yaml -l run=myy-nginx|grep podIP</span><br></pre></td></tr></table></figure><p><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/2.png" alt="http://blog.tenxcloud.com/wp-content/uploads/2016/10/2.png"></p><h3 id="在集群内访问Nginx服务："><a href="#在集群内访问Nginx服务：" class="headerlink" title="在集群内访问Nginx服务："></a>在集群内访问Nginx服务：</h3><p><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/3.png" alt="http://blog.tenxcloud.com/wp-content/uploads/2016/10/3.png"></p><p>看到这里相信很多人会有以下疑问：</p><blockquote><ol><li>每次收到获取podIP太扯了，总不能每次都要手动改程序或者配置才能访问服务吧，要怎么提前知道podIP呢？</li><li>Pod在运行中可能会重建，IP变了怎么解？</li><li>如何在多个Pod中实现负载均衡嘞？</li></ol></blockquote><p>这些问题使用k8s Service就可以解决。</p><h2 id="使用Service发现服务"><a href="#使用Service发现服务" class="headerlink" title="使用Service发现服务"></a>使用Service发现服务</h2><p>下面为两个Nginx Pod创建一个Service。使用nginx-service.yaml文件进行创建，文件内容如下：<br><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/4.png" alt="http://blog.tenxcloud.com/wp-content/uploads/2016/10/4.png"><br>创建之后，仍需要获取Service的Cluster-IP，再结合Port访问Nginx服务。</p><p>Service可以将pod  IP封装起来，即使Pod发生重建，依然可以通过Service来访问Pod提供的服务。此外，Service还解决了负载均衡的问题，大家可以多访问几次Service，然后通过kubectl logs 来查看两个Nginx Pod的访问日志来确认。</p><h3 id="获取IP："><a href="#获取IP：" class="headerlink" title="获取IP："></a>获取IP：</h3><p><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/5.png" alt=""></p><h3 id="在集群内访问Service："><a href="#在集群内访问Service：" class="headerlink" title="在集群内访问Service："></a>在集群内访问Service：</h3><p><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/6.png" alt=""></p><p>虽然Service解决了Pod的服务发现和负载均衡问题，但存在着类似的问题：不提前知道Service的IP，还是需要改程序或配置啊。看到这里有没有感觉身体被掏空？</p><p>接下来聊聊kube-dns是如何解决上面这个问题的。</p><h2 id="使用kube-dns发现服务"><a href="#使用kube-dns发现服务" class="headerlink" title="使用kube-dns发现服务"></a>使用kube-dns发现服务</h2><p>kube-dns可以解决Service的发现问题，k8s将Service的名称当做域名注册到kube-dns中，通过Service的名称就可以访问其提供的服务。</p><p>可能有人会问如果集群中没有部署kube-dns怎么办？没关系，实际上kube-dns插件只是运行在kube-system命名空间下的Pod，完全可以手动创建它。可以在k8s源码（v1.2）的cluster/addons/dns目录下找到两个模板（skydns-rc.yaml.in和skydns-svc.yaml.in）来创建，为大家准备的完整示例文件会在分享结束后提供获取方式，PPT中只截取了部分内容。</p><p>通过skydns-rc.yaml文件创建kube-dns Pod，其中包含了四个containers，这里开始简单过一下文件的主要部分，稍后做详细介绍。</p><p>第一部分可以看到kube-dns使用了RC来管理Pod，可以提供最基本的故障重启功能。</p><p>创建kube-dns Pod，其中包含了4个containers<br><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/7.png" alt=""></p><p>接下来是第一个容器  etcd  ，它的用途是保存DNS规则。<br><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/8.png" alt=""></p><p>第二个容器  kube2sky ，作用是写入DNS规则。<br><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/9.png" alt=""></p><p>第三个容器是  skydns ，提供DNS解析服务。<br><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/10.png" alt=""></p><p>最后一个容器是  healthz ，提供健康检查功能。<br><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/11.png" alt=""></p><p>有了Pod之后，还需要创建一个Service以便集群中的其他Pod访问DNS查询服务。通过skydns-svc.yaml创建Service，内容如下：<br><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/12.png" alt=""></p><p>创建完kube-dns Pod和Service，并且Pod运行后，便可以访问kube-dns服务。</p><p>下面创建一个Pod，并在该Pod中访问Nginx服务：</p><p>创建之后等待kube-dns处于运行状态<br><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/13.png" alt=""></p><p>再新建一个Pod，通过其访问Nginx服务<br><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/14.png" alt=""></p><p>在curl-util Pod中通过Service名称访问my-nginx Service：<br><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/15.png" alt=""></p><p>只要知道需要的服务名称就可以访问，使用kube-dns发现服务就是那么简单。</p><p>虽然领略了使用kube-dns发现服务的便利性，但相信有很多人也是一头雾水：kube-dns到底怎么工作的？在集群中启用了kube-dns插件，怎么就能通过名称访问Service了呢？</p><h1 id="kube-dns原理"><a href="#kube-dns原理" class="headerlink" title="kube-dns原理"></a>kube-dns原理</h1><h2 id="Kube-dns组成"><a href="#Kube-dns组成" class="headerlink" title="Kube-dns组成"></a>Kube-dns组成</h2><p>之前已经了解到kube-dns是由四个容器组成的，它们扮演的角色可以通过下面这张图来理解。<br><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/kube-dns%E6%9E%B6%E6%9E%84.png" alt=""></p><p>其中：</p><p>●  SkyDNS是用于服务发现的开源框架，构建于etcd之上。作用是为k8s集群中的Pod提供DNS查询接口。项目托管于<a href="https://github.com/skynetservices/skydns" target="_blank" rel="noopener">https://github.com/skynetservices/skydns</a></p><p>●  etcd是一种开源的分布式key-value存储，其功能与ZooKeeper类似。在kube-dns中的作用为存储SkyDNS需要的各种数据，写入方为kube2sky，读取方为SkyDNS。项目托管于<a href="https://github.com/coreos/etcd。" target="_blank" rel="noopener">https://github.com/coreos/etcd。</a></p><p>●   kube2sky是k8s实现的一个适配程序，它通过名为kubernetes的Service（通过kubectl get svc可以查看到该Service，由集群自动创建）调用k8s的list和watch API来监听k8s Service资源的变更，从而修改etcd中的SkyDNS记录。代码可以在k8s源码（v1.2）的cluster/addons/dns/kube2sky/目录中找到。</p><p>●   exec-healthz是k8s提供的一种辅助容器，多用于side car模式中。它的原理是定期执行指定的Linux指令，从而判断当前Pod中关键容器的健康状态。在kube-dns中的作用就是通过nslookup指令检查DNS查询服务的健康状态，k8s livenessProbe通过访问exec-healthz提供的Http API了解健康状态，并在出现故障时重启容器。其源码位于<a href="https://github.com/kubernetes/contrib/tree/master/exec-healthz。" target="_blank" rel="noopener">https://github.com/kubernetes/contrib/tree/master/exec-healthz。</a></p><p>●  从图中可以发现，Pod查询DNS是通过ServiceName.Namespace子域名来查询的，但在之前的示例中只用了Service名称，什么原理呢？其实当我们只使用Service名称时会默认Namespace为default，而上面示例中的my-nginx Service就是在default Namespace中，因此是可以正常运行的。关于这一点，后续再深入介绍。</p><p>●  skydns-rc.yaml中可以发现livenessProbe是设置在kube2sky容器中的，其意图应该是希望通过重启kube2sky来重新写入DNS规则</p><h2 id="域名格式"><a href="#域名格式" class="headerlink" title="域名格式"></a>域名格式</h2><p>接下来了解一下kube-dns支持的域名格式，具体为：..svc.。</p><p>其中cluster_domain可以使用kubelet的–cluster-domain=SomeDomain参数进行设置，同时也要保证kube2sky容器的启动参数中–domain参数设置了相同的值。通常设置为cluster.local。那么之前示例中的my-nginx Service对应的完整域名就是my-nginx.default.svc.cluster.local。看到这里，相信很多人会有疑问，既然完整域名是这样的，那为什么在Pod中只通过Service名称和Namespace就能访问Service呢？下面来解释其中原因。</p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><h2 id="域名解析配置"><a href="#域名解析配置" class="headerlink" title="域名解析配置"></a>域名解析配置</h2><p>为了在Pod中调用其他Service，kubelet会自动在容器中创建域名解析配置（/etc/resolv.conf），内容为：</p><p><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/16.png" alt=""></p><p>感兴趣的可以在网上查找一些resolv.conf的资料来了解具体的含义。之所以能够通过Service名称和Namespace就能访问Service，就是因为search配置的规则。在解析域名时会自动拼接成完整域名去查询DNS。</p><p>刚才提到的kubelet –cluster-domain参数与search的具体配置是相对应的。而kube2sky容器的–domain参数影响的是写入到etcd中的域名，kube2sky会获取Service的名称和Namespace，并使用–domain参数拼接完整域名。这也就是让两个参数保持一致的原因。</p><h2 id="NS-相关配置"><a href="#NS-相关配置" class="headerlink" title="NS 相关配置"></a>NS 相关配置</h2><p>kube-dns可以让Pod发现其他Service，那Pod又是如何自动发现kube-dns的呢？在上一节中的/etc/resolv.conf中可以看到nameserver，这个配置就会告诉Pod去哪访问域名解析服务器。</p><p><img src="http://blog.tenxcloud.com/wp-content/uploads/2016/10/17.png" alt=""></p><p>相应的，可以在之前提到的skydns-svc.yaml中看到spec.clusterIP配置了相同的值。通常来说创建一个Service并不需要指定clusterIP，k8s会自动为其分配，但kube-dns比较特殊，需要指定clusterIP使其与/etc/resolv.conf中的nameserver保持一致。</p><p>修改nameserver配置同样需要修改两个地方，一个是kubelet的–cluster-dns参数，另一个就是kube-dns Service的clusterIP。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>接下来重新梳理一下本文的主要内容：</p><blockquote><p>●    在k8s集群中，服务是运行在Pod中的，Pod的发现和副本间负载均衡是我们面临的问题。<br>●    通过Service可以解决这两个问题，但访问Service也需要对应的IP，因此又引入了Service发现的问题。<br>●    得益于kube-dns插件，我们可以通过域名来访问集群内的Service，解决了Service发现的问题。<br>●    为了让Pod中的容器可以使用kube-dns来解析域名，k8s会修改容器的/etc/resolv.conf配置。</p></blockquote><p>有了以上机制的保证，就可以在Pod中通过Service名称和namespace非常方便地访问对应的服务了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Kubernetes中如何发现服务&quot;&gt;&lt;a href=&quot;#Kubernetes中如何发现服务&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes中如何发现服务&quot;&gt;&lt;/a&gt;Kubernetes中如何发现服务&lt;/h1&gt;
    
    </summary>
    
      <category term="k8s" scheme="http://datura.me/categories/k8s/"/>
    
    
      <category term="k8s" scheme="http://datura.me/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>centos 7 lsyncd实时同步</title>
    <link href="http://datura.me/2017/09/22/lsyncd%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E5%90%8C%E6%AD%A5%E7%AE%80%E8%A6%81%E8%AF%B4%E6%98%8E/"/>
    <id>http://datura.me/2017/09/22/lsyncd实现文件目录同步简要说明/</id>
    <published>2017-09-22T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.724Z</updated>
    
    <content type="html"><![CDATA[<h2 id="lsyncd实时同步"><a href="#lsyncd实时同步" class="headerlink" title="lsyncd实时同步"></a>lsyncd实时同步</h2><h3 id="lsyncd简介"><a href="#lsyncd简介" class="headerlink" title="lsyncd简介"></a>lsyncd简介</h3><a id="more"></a><p>Lysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。<br>实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。</p><h3 id="首先客户端和服务端都需要安装rsync"><a href="#首先客户端和服务端都需要安装rsync" class="headerlink" title="首先客户端和服务端都需要安装rsync"></a>首先客户端和服务端都需要安装rsync</h3><pre><code>yum -y install rsync</code></pre><h3 id="lsyncd的安装"><a href="#lsyncd的安装" class="headerlink" title="lsyncd的安装"></a>lsyncd的安装</h3><pre><code>rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmyum install lsyncd</code></pre><h3 id="创建lsyncd的工作目录"><a href="#创建lsyncd的工作目录" class="headerlink" title="创建lsyncd的工作目录"></a>创建lsyncd的工作目录</h3><pre><code>mkdir -p /usr/local/lsyncd-2.1.5/etc/mkdir -p /usr/local/lsyncd-2.1.5/var/</code></pre><h3 id="创建lsyncd的配置文件"><a href="#创建lsyncd的配置文件" class="headerlink" title="创建lsyncd的配置文件"></a>创建lsyncd的配置文件</h3><pre><code>vim /usr/local/lsyncd-2.1.5/etc/lsyncd.confsettings {    logfile      = &quot;/usr/local/lsyncd-2.1.5/var/lsyncd.log&quot;,    statusFile   = &quot;/usr/local/lsyncd-2.1.5/var/lsyncd.status&quot;,    inotifyMode  = &quot;CloseWrite&quot;,    maxProcesses = 7,}sync {    default.rsync,      source    = &quot;/var/opt/gitlab/backups&quot;,      target    = &quot;root@10.1.10.101:/var/opt/gitlab/  backups-BF&quot;,      maxDelays = 5,      delay = 30,      rsync     = {          binary = &quot;/bin/rsync&quot;,          archive = true,         compress = true,         bwlimit   = 2000    }}</code></pre><h3 id="lsyncd-conf配置文件说明"><a href="#lsyncd-conf配置文件说明" class="headerlink" title="lsyncd.conf配置文件说明"></a>lsyncd.conf配置文件说明</h3><h4 id="settings"><a href="#settings" class="headerlink" title="settings"></a>settings</h4><p>里面是全局配置，-开头表示注释</p><pre><code>&gt;logfile 定义日志文件&gt;stausFile 定义状态文件&gt;inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify&gt;maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而&gt;maxProcesses = 7，则最大能看到有7个rysnc进程</code></pre><h4 id="sync"><a href="#sync" class="headerlink" title="sync"></a>sync</h4><p>里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式：</p><pre><code>&gt;default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程；&gt;default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份；&gt;default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证source 同步的源目录，使用绝对路径。arget 定义目的地址</code></pre><h4 id="rsync"><a href="#rsync" class="headerlink" title="rsync"></a>rsync</h4><pre><code>binary 定义rsync位置，位置有可能不一样</code></pre><h3 id="做公私钥认证"><a href="#做公私钥认证" class="headerlink" title="做公私钥认证"></a>做公私钥认证</h3><p>将服务的的公钥写到客户端的<code>root/.ssh/authorized_keys</code>文件中</p><p>使用ssh验证ssh访问是否正常</p><h3 id="在服务端启动lsyncd服务"><a href="#在服务端启动lsyncd服务" class="headerlink" title="在服务端启动lsyncd服务"></a>在服务端启动lsyncd服务</h3><pre><code>lsyncd -log Exec /usr/local/lsyncd-2.1.5/etc/lsyncd.conf</code></pre><h3 id="观察客户端同步目录是否正确"><a href="#观察客户端同步目录是否正确" class="headerlink" title="观察客户端同步目录是否正确"></a>观察客户端同步目录是否正确</h3><h3 id="在服务端写入定时任务备份文件"><a href="#在服务端写入定时任务备份文件" class="headerlink" title="在服务端写入定时任务备份文件"></a>在服务端写入定时任务备份文件</h3><pre><code>crontab -e0 0 * * *  /bin/gitlab-rake gitlab:backup:create0 1 */2 * * find /var/opt/gitlab/backups -mtime +7 -name &quot;*_gitlab_backup.tar&quot;|xargs rm -rf</code></pre><p>我这里写的是每周二会清理<code>/var/opt/gitlab/backups</code>文件中gitlab的备份文件，该时间可以由自己需求进行更改</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;lsyncd实时同步&quot;&gt;&lt;a href=&quot;#lsyncd实时同步&quot; class=&quot;headerlink&quot; title=&quot;lsyncd实时同步&quot;&gt;&lt;/a&gt;lsyncd实时同步&lt;/h2&gt;&lt;h3 id=&quot;lsyncd简介&quot;&gt;&lt;a href=&quot;#lsyncd简介&quot; class=&quot;headerlink&quot; title=&quot;lsyncd简介&quot;&gt;&lt;/a&gt;lsyncd简介&lt;/h3&gt;
    
    </summary>
    
      <category term="lsync" scheme="http://datura.me/categories/lsync/"/>
    
    
      <category term="lsync" scheme="http://datura.me/tags/lsync/"/>
    
  </entry>
  
  <entry>
    <title>centos 7 部署 lsyncd 实时同步</title>
    <link href="http://datura.me/2017/09/13/lsyncd%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5/"/>
    <id>http://datura.me/2017/09/13/lsyncd实时同步/</id>
    <published>2017-09-13T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.724Z</updated>
    
    <content type="html"><![CDATA[<h2 id="几大实时同步工具比较"><a href="#几大实时同步工具比较" class="headerlink" title="几大实时同步工具比较"></a>几大实时同步工具比较</h2><a id="more"></a><h3 id="inotify-rsync"><a href="#inotify-rsync" class="headerlink" title="inotify + rsync"></a>inotify + rsync</h3><p>最近一直在寻求生产服务服务器上的同步替代方案，原先使用的是inotify + rsync，但随着文件数量的增大到100W+，目录下的文件列表就达20M，在网络状况不佳或者限速的情况下，变更的文件可能10来个才几M，却因此要发送的文件列表就达20M，严重减低的带宽的使用效率以及同步效率；更为要紧的是，加入inotifywait在5s内监控到10个小文件发生变化，便会触发10个rsync同步操作，结果就是真正需要传输的才2-3M的文件，比对的文件列表就达200M。使用这两个组合的好处在于，它们都是最基本的软件，可以通过不同选项做到很精确的控制，比如排除同步的目录，同步多个模块或同步到多个主机。  </p><p>搭建过程参考<a href="http://www.datura.me/2017/09/13/linux_下同步工具inotify_+_rsync_使用详解/" target="_blank" rel="noopener">linux 下同步工具inotify + rsync 使用详解</a></p><h3 id="sersync"><a href="#sersync" class="headerlink" title="sersync"></a>sersync</h3><p>后来听同事说 sersync 这么个工具可以提高同步的性能，也解决了同步大文件时出现异常的问题，所以就尝试了一下。sersync是国内的一个开发者开源出来的，使用c++编写，采用多线程的方式进行同步，失败后还有重传机制，对临时文件过滤，自带crontab定时同步功能。网上看到有人说性能还不错，说一下我的观点：</p><blockquote><p>国产开源，文档不是很全，在2011年之后就没更新了（googlecode都要快关闭了，其实可以转交其他人维护），网上关于它的使用和讨论都止于10年了<br>采用xml配置文件的方式，可读性比较好，但是有些原生的有些功能没有实现就没法使用了<br>无法实现多目录同步，只能通过多个配置文件启动多个进程<br>文件排除功能太弱。这个要看需求，不是每个人都需要排除子目录。而对于我的环境中，这个功能很重要，而且排除的规则较多<br>虽然提供插件的功能，但很鸡肋，因为软件本身没有持续更新，也没有看到贡献有其它插件出现（可能是我知识面不够，还用不到里面的refreshCDN plugin）。</p></blockquote><h3 id="lsyncd"><a href="#lsyncd" class="headerlink" title="lsyncd"></a>lsyncd</h3><p>废话说这么多，本文就是介绍它了。有些博客说lsyncd是谷歌开源的，实际不是了，只是托管在了googlecode上而已，幸运的是已经迁移到github了：  <a href="https://github.com/826167518/lsyncd" target="_blank" rel="noopener">[https://github.com/826167518/lsyncd]</a></p><p>Lysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。</p><p>实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。</p><h2 id="使用-lsyncd-本地目录实时备份"><a href="#使用-lsyncd-本地目录实时备份" class="headerlink" title="使用 lsyncd 本地目录实时备份"></a>使用 lsyncd 本地目录实时备份</h2><p>这一节实现的功能是，本地目录source实时同步到另一个目录target，而在source下有大量的文件，并且有部分目录和临时文件不需要同步。</p><h3 id="安装lsyncd"><a href="#安装lsyncd" class="headerlink" title="安装lsyncd"></a>安装lsyncd</h3><p>安装lsyncd极为简单，已经收录在ubuntu的官方镜像源里，直接通过apt-get install lsyncd就可以。<br>在Redhat系（我的环境是CentOS 6.2 x86_64 ），可以手动去下载 lsyncd-2.1.5-6.fc21.x86_64.rpm，但首先你得安装两个依赖yum install lua lua-devel。也可以通过在线安装，需要epel-release扩展包：</p><pre><code># rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm# yum install lsyncd</code></pre><p>源码编译安装</p><p>从源码编译安装可以使用最新版的lsyncd程序，但必须要相应的依赖库文件和编译工具：  </p><pre><code>yum install lua lua-devel asciidoc cmake。</code></pre><p>从 googlecode lsyncd 上下载的lsyncd-2.1.5.tar.gz，直接./configure、make &amp;&amp; make install就可以了。</p><p>从github上下载<a href="https://github.com/axkibe/lsyncd/archive/master.zip" target="_blank" rel="noopener">lsyncd-master.zip</a> 的2.1.5版本使用的是 cmake 编译工具，无法./configure：</p><blockquote><p>uzip lsyncd-master.zip<br>cd lsyncd-master<br>cmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncd-2.1.5<br>make &amp;&amp; make install  </p></blockquote><p>我这个版本编译时有个小bug，如果按照INSTALL在build目录中make，会提示：</p><blockquote><p>[100%] Generating doc/lsyncd.1<br>Updating the manpage<br>a2x: failed: source file not found: doc/lsyncd.1.txt<br>make[2]: <strong><em> [doc/lsyncd.1] Error 1<br>make[1]: </em></strong> [CMakeFiles/manpage.dir/all] Error 2<br>make: *** [all] Error 2  </p></blockquote><p>解决办法是要么直接在解压目录下cmake，不要mkdir build，要么在CMakeList.txt中搜索doc字符串，在前面加上${PROJECT_SOURCE_DIR}。</p><h3 id="lsyncd-conf"><a href="#lsyncd-conf" class="headerlink" title="lsyncd.conf"></a>lsyncd.conf</h3><p>下面都是在编译安装的情况下操作。</p><h4 id="lsyncd同步配置"><a href="#lsyncd同步配置" class="headerlink" title="lsyncd同步配置"></a>lsyncd同步配置</h4><pre><code>cd /usr/local/lsyncd-2.1.5mkdir etc varvim etc/lsyncd.confsettings {      logfile      =&quot;/usr/local/lsyncd-2.1.5/var/  lsyncd.log&quot;,      statusFile   =&quot;/usr/local/lsyncd-2.1.5/var/  lsyncd.status&quot;,      inotifyMode  = &quot;CloseWrite&quot;,      maxProcesses = 7,      -- nodaemon =true,      }  sync {     default.rsync,     source    = &quot;/tmp/src&quot;,    target    = &quot;/tmp/dest&quot;,     -- excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;,     rsync     = {          binary    = &quot;/usr/bin/rsync&quot;,          archive   = true,          compress  = true,          verbose   = true          }      }  </code></pre><p>到这启动 lsycnd 就可以完成实时同步了，默认的许多参数可以满足绝大部分需求，非常简单。</p><h4 id="lsyncd-conf配置选项说明"><a href="#lsyncd-conf配置选项说明" class="headerlink" title="lsyncd.conf配置选项说明"></a>lsyncd.conf配置选项说明</h4><p>settings</p><p>里面是全局设置，–开头表示注释，下面是几个常用选项说明：</p><blockquote><p>logfile 定义日志文件<br>stausFile 定义状态文件<br>nodaemon=true 表示不启用守护模式，默认<br>statusInterval 将lsyncd的状态写入上面的statusFile的间隔，默认10秒<br>inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify<br>maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而&gt;maxProcesses = 8，则最大能看到有8个rysnc进程<br>maxDelays 累计到多少所监控的事件激活一次同步，即使后面的delay延迟时间还未到  </p></blockquote><p>sync</p><p>里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式：</p><blockquote><blockquote><p>default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程；<br>default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份；<br>default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证  </p></blockquote></blockquote><blockquote><p>source 同步的源目录，使用绝对路径。  </p><blockquote><p>target 定义目的地址.对应不同的模式有几种写法：<br>/tmp/dest ：本地目录同步，可用于direct和rsync模式<br>172.29.88.223:/tmp/dest ：同步到远程服务器目录，可用于rsync和rsyncssh模式，拼接的命令类似于/usr/bin/rsync -ltsd –delete –include-from=- –exclude=* SOURCE TARGET，剩下的就是rsync的内容了，比如指定username，免密码同步<br>172.29.88.223::module ：同步到远程服务器目录，用于rsync模式</p></blockquote><p>三种模式的示例会在后面给出。<br>init 这是一个优化选项，当init = false，只同步进程启动以后发生改动事件的文件，原有的目录即使有差异也不会同步。默认是true<br>delay 累计事件，等待rsync同步延时时间，默认15秒（最大累计到1000个不可合并的事件）。也就是15s内监控目录下发生的改动，会累积到一次rsync同步，避免过于频繁的同步。（可合并的意思是，15s内两次修改了同一文件，最后只同步最新的文件）<br>excludeFrom 排除选项，后面指定排除的列表文件，如excludeFrom = “/etc/lsyncd.exclude”，如果是简单的排除，可以使用exclude = LIST。  </p><blockquote><p>这里的排除规则写法与原生rsync有点不同，更为简单：<br>监控路径里的任何部分匹配到一个文本，都会被排除，例如/bin/foo/bar可以匹配规则foo<br>如果规则以斜线/开头，则从头开始要匹配全部<br>如果规则以/结尾，则要匹配监控路径的末尾<br>?匹配任何字符，但不包括/<br>*匹配0或多个字符，但不包括/<br>**匹配0或多个字符，可以是/<br>delete 为了保持target与souce完全同步，Lsyncd默认会delete = true来允许同步删除。它除了false，还有startup、running值。</p></blockquote></blockquote><p>rsync<br>（提示一下，delete和exclude本来都是rsync的选项，上面是配置在sync中的，我想这样做的原因是为了减少rsync的开销）</p><blockquote><p>bwlimit 限速，单位kb/s，与rsync相同（这么重要的选项在文档里竟然没有标出）<br>compress 压缩传输默认为true。在带宽与cpu负载之间权衡，本地目录同步可以考虑把它设为false<br>perms 默认保留文件权限。<br>其它rsync的选项  </p></blockquote><p>其它还有rsyncssh模式独有的配置项，如host、targetdir、rsync_path、password_file，见后文示例。rsyncOps={“-avz”,”–delete”}这样的写法在2.1.*版本已经不支持。</p><p>lsyncd.conf可以有多个sync，各自的source，各自的target，各自的模式，互不影响。</p><h3 id="启动lsyncd"><a href="#启动lsyncd" class="headerlink" title="启动lsyncd"></a>启动lsyncd</h3><p>使用命令加载配置文件，启动守护进程，自动同步目录操作。</p><pre><code>lsyncd -log Exec /usr/local/lsyncd-2.1.5/etc/lsyncd.conf</code></pre><h3 id="lsyncd-conf其它模式示例"><a href="#lsyncd-conf其它模式示例" class="headerlink" title="lsyncd.conf其它模式示例"></a>lsyncd.conf其它模式示例</h3><p>以下配置本人都已经过验证可行，必须根据实际需要裁剪配置：</p><pre><code>settings {logfile =&quot;/usr/local/lsyncd-2.1.5/var/lsyncd.log&quot;,statusFile =&quot;/usr/local/lsyncd-2.1.5/var/lsyncd.status&quot;,inotifyMode = &quot;CloseWrite&quot;,maxProcesses = 8,}-- I. 本地目录同步，direct：cp/rm/mv。 适用：500+万文件，变动不大sync {    default.direct,    source    = &quot;/tmp/src&quot;,    target    = &quot;/tmp/dest&quot;,    delay = 1    maxProcesses = 1    }-- II. 本地目录同步，rsync模式：rsyncsync {    default.rsync,    source    = &quot;/tmp/src&quot;,    target    = &quot;/tmp/dest1&quot;,    excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;,    rsync     = {        binary = &quot;/usr/bin/rsync&quot;,        archive = true,        compress = true,        bwlimit   = 2000        }     }-- III. 远程目录同步，rsync模式 + rsyncd daemonsync {    default.rsync,    source    = &quot;/tmp/src&quot;,    target    = &quot;syncuser@172.29.88.223::module1&quot;,    delete=&quot;running&quot;,    exclude = { &quot;.*&quot;, &quot;.tmp&quot; },    delay = 30,  init = false,    rsync     = {        binary = &quot;/usr/bin/rsync&quot;,        archive = true,       compress = true,       verbose   = true,        password_file = &quot;/etc/rsyncd.d/rsync.pwd&quot;,     _extra    = {&quot;--bwlimit=200&quot;}            }       }-- IV. 远程目录同步，rsync模式 + ssh shellsync {   default.rsync,    source    = &quot;/tmp/src&quot;,    target    = &quot;172.29.88.223:/tmp/dest&quot;,     -- target    = &quot;root@172.29.88.223:/remote/dest&quot;,  -- 上面target，注意如果是普通用户，必须拥有写权限  maxDelays = 5,  delay = 30,  -- init = true,  rsync     = {    binary = &quot;/usr/bin/rsync&quot;,    archive = true,    compress = true,    bwlimit   = 2000    -- rsh = &quot;/usr/bin/ssh -p 22 -o StrictHostKeyChecking=no&quot;    -- 如果要指定其它端口，请用上面的rsh    }  } -- V. 远程目录同步，rsync模式 + rsyncssh，效果与上面相同sync {    default.rsyncssh,    source    = &quot;/tmp/src2&quot;,    host      = &quot;172.29.88.223&quot;,    targetdir = &quot;/remote/dir&quot;,    excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;,    -- maxDelays = 5,    delay = 0,    -- init = false,    rsync    = {        binary = &quot;/usr/bin/rsync&quot;,        archive = true,        compress = true,         verbose   = true,      _extra = {&quot;--bwlimit=2000&quot;},        },    ssh      = {        port  =  1234        }    }</code></pre><p>上面的内容几乎涵盖了所有同步的模式，其中第III个要求像rsync一样配置rsyncd服务端，见本文开头。第IV、V配置ssh方式同步，达到的效果相同，但实际同步时你会发现每次同步都会提示输入ssh的密码，可以通过以下方法解决：</p><p>在远端被同步的服务器上开启ssh无密码登录，请注意用户身份：</p><pre><code>user$ ssh-keygen -t rsa一路回车...user$ cd ~/.sshuser$ cat id_rsa.pub &gt;&gt; authorized_keys</code></pre><p>把id_rsa私钥拷贝到执行lsyncd的机器上</p><pre><code>user$ chmod 600 ~/.ssh/id_rsa测试能否无密码登录user$ ssh user@172.29.88.223</code></pre><h2 id="lsyncd的其它功能"><a href="#lsyncd的其它功能" class="headerlink" title="lsyncd的其它功能"></a>lsyncd的其它功能</h2><p>lsyncd的功能不仅仅是同步，官方手册 <a href="https://axkibe.github.io/lsyncd/" target="_blank" rel="noopener">Lsyncd 2.1.x ‖ Layer 2 Config ‖ Advanced onAction</a> 高级功能提到，还可以监控某个目录下的文件，根据触发的事件自己定义要执行的命令，example是监控某个某个目录，只要是有jpg、gif、png格式的文件参数，就把它们转成pdf，然后同步到另一个目录。正好在我运维的一个项目中有这个需求，现在都是在java代码里转换，还容易出现异常，通过lsyncd可以代替这样的功能。但，门槛在于要会一点点lua语言（根据官方example还是可以写出来）。</p><p>另外偶然想到个问题，同时设置了maxDelays和delay，当监控目录一直没有文件变化了，也会发生同步操作，虽然没有可rsync的文件。</p><p>TO-DO：</p><p>其它同步工具：csync2，clsync，btsync，drdb 。</p><p>lsyncd双向同步：<a href="https://axkibe.github.io/lsyncd/" target="_blank" rel="noopener">GlusterFS</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;几大实时同步工具比较&quot;&gt;&lt;a href=&quot;#几大实时同步工具比较&quot; class=&quot;headerlink&quot; title=&quot;几大实时同步工具比较&quot;&gt;&lt;/a&gt;几大实时同步工具比较&lt;/h2&gt;
    
    </summary>
    
      <category term="lsync" scheme="http://datura.me/categories/lsync/"/>
    
    
      <category term="lsync" scheme="http://datura.me/tags/lsync/"/>
    
  </entry>
  
  <entry>
    <title>linux 下同步工具inotify + rsync 使用详解</title>
    <link href="http://datura.me/2017/09/13/linux_%E4%B8%8B%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7inotify_+_rsync_%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3/"/>
    <id>http://datura.me/2017/09/13/linux_下同步工具inotify_+_rsync_使用详解/</id>
    <published>2017-09-13T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.723Z</updated>
    
    <content type="html"><![CDATA[<h2 id="rsynv"><a href="#rsynv" class="headerlink" title="rsynv"></a>rsynv</h2><a id="more"></a><h3 id="什么是rsync"><a href="#什么是rsync" class="headerlink" title="什么是rsync"></a>什么是rsync</h3><p>rsync是一个远程数据同步工具，可以通过LAN/WAN快速同步多台主机之间的文件。它使用所谓的“Rsync演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。所以通常可以作为备份工具来使用。</p><p>运行Rsync server的机器也叫backup server，一个Rsync server可同时备份多个client的数据；也可以多个Rsync server备份一个client的数据。Rsync可以搭配ssh甚至使用daemon模式。Rsync server会打开一个873的服务通道（port），等待对方rsync连接。连接时，Rsync server会检查口令是否相符，若通过口令查核，则可以开始进行文件传输。第一次联通完成时，会把整份文件传输一次，下一次就只会传送两个文件之间不同的部分。</p><h4 id="基本特点："><a href="#基本特点：" class="headerlink" title="基本特点："></a>基本特点：</h4><p>1.可以镜像保存整个目录树和文件系统；</p><p>2.可以很容易做到保持原来文件的权限、时间、软硬连接等；</p><p>3.无需特殊权限即可安装；</p><p>4.优化的流程，文件传输效率高；</p><p>5.可以使用rcp，ssh等方式来传输文件，当然也可以通过直接的socket连接；</p><p>6.支持匿名传输。</p><h4 id="命令语法："><a href="#命令语法：" class="headerlink" title="命令语法："></a>命令语法：</h4><p>rsync的命令格式可以分为以下六种：</p><pre><code>rsync [OPTION]... SRC DESTrsync [OPTION]... SRC [USER@]HOST:DESTrsync [OPTION]... [USER@]HOST:SRC DESTrsync [OPTION]... [USER@]HOST::SRC DESTrsync [OPTION]... SRC [USER@]HOST::DESTrsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]</code></pre><p>对应于以上六种命令格式，我们可以总结rsync有两种不同工作模式：</p><blockquote><ol><li>shell模式：使用远程shell程序（如ssh或rsh）进行连接。当源路径或目的路径的主机名后面包含一个冒号分隔符是使用这种模式，rsync安装完成后可以使用了，无所谓启动。</li><li>daemon模式：使用TCP直接连接rsync daemon。当源路径的主机名后面包含两个冒号，或使用rsync：//URL时使用这种模式，无需远程shell，但必须在一台机器上启动rsync daemon，默认端口873，这里可以通过rsyn –daemon使用独立进程方式，或者通过xinetd超级进程来管理rsync后台进程。</li></ol></blockquote><p>当rsync作为daemon运行时。他需要一个用户身份。如果你希望启用chroot，则必须以root身份来运行daemon，监听端口，或设定文件属主；如果不启用chroot，也可以不使用root用户来运行daemon，但该用户必须对相应的模块拥有读写数据、日志和lock file的权限。当rsync以daemon模式运行时，他还需要一个配置文件–rsync.conf。修改这个配置后不必重启rsync daemon，因为每一次的client连接都会去重新读取该文件。</p><p>我们一般DEST远程服务器端称为rsync server，运行rsync命令的一端SRC称为client。</p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>rsync在Centos 6上是默认已经安装，如果没有则可以使用<br>    yum install rsync -y<br>服务端和客户端是同一个安装包。rsync命令帮助<br>    rsync -h</p><h2 id="同步测试"><a href="#同步测试" class="headerlink" title="同步测试"></a>同步测试</h2><h3 id="本机文件夹同步"><a href="#本机文件夹同步" class="headerlink" title="本机文件夹同步"></a>本机文件夹同步</h3><pre><code>rsync -auvrtzopgP --progress /root/ /tmp/rsync_bak/</code></pre><p>会看到从/root/传输到/tmp/rsync_bak/的列表和速率，在运行一次会看到dending incremental file list下没有复制的内容，可以在/root/下 touch 某一个文件在运行看到只同步了修改过的文件。</p><p>上面需要考虑以下问题：</p><blockquote><p>删除/root/下的文件不会同步删除/tmp/rsync_bak，除非加入–delete选项<br>文件访问时间等属性、读写等权限、文件内容等有任何变动，都会被认为修改<br>目标目录下如果文件比源目录还新，则不会同步<br>源路径的最后是否有斜杠有不同的含义：有斜杠，只是复制目录中的文件；没有斜杠的话，不但要复制目录中的文件，还要复制目录本身</p></blockquote><h3 id="同步到远程服务器"><a href="#同步到远程服务器" class="headerlink" title="同步到远程服务器"></a>同步到远程服务器</h3><p>在服务器间rsync传输文件，需要有一个是开着rsync的服务，而这一服务需要两个配置文件，说明当运行的用户和用户组，这个用户名和用户组在改变文件权限和相关内容的时候有用，否则有时候会出现提示权限问题。配置文件也说明了模块、模块化管理服务的安全性，每个模块的名称都是自己定义的，可以添加用户密码验证，也可以验证IP，设置目录是否可以写等，不同模块用于同步不同需求的目录。</p><h4 id="服务端的配置文件"><a href="#服务端的配置文件" class="headerlink" title="服务端的配置文件"></a>服务端的配置文件</h4><p>/etc/rsyncd.conf</p><blockquote><p>uid=root<br>gid=root<br>use chroot=no<br>max connections=10<br>timeout=600<br>strict modes=yes<br>port=873<br>pid file=/var/run/rsyncd.pid<br>lock file=/var/run/rsyncd.lock<br>log file=/var/log/rsyncd.log  </p></blockquote><blockquote><p>[module_test]<br>path=/tmp/rsync_bak2<br>comment=rsync test logs<br>auth users=sean<br>uid=test<br>gid=test<br>secrets file=/etc/rsyncd.secrets<br>read only=no<br>list=no<br>hosts allow=IP<br>hosts deny=0.0.0.0/32 </p></blockquote><p>这里配置soket方式传输文件，端口873，[module_test]开始定义一个模块，指定要同步的目录（接收）path ，授权用户，密码文件，允许那台服务器IP同步（发送）等。</p><p>经测试，上述配置文件每行后面不能使用#来注释</p><p>/etc/rsyncd.secrets</p><blockquote><p>test:test</p></blockquote><p>一行一个用户，用户名：密码。请注意这里的用户名和密码与操作系统的用户名密码无关，可以随意指定，与/etc/rsyncd.conf中的auth users对应。</p><p>修改权限：<br>    chmod 600 /etc/rsyncd.d/rsync_server.pwd</p><h4 id="服务器启动rsync后台服务"><a href="#服务器启动rsync后台服务" class="headerlink" title="服务器启动rsync后台服务"></a>服务器启动rsync后台服务</h4><p>修改 /etc/xinetd.d/rsync 文件，disable 改为no</p><blockquote><p>service rsync<br>{<br>   disable = no<br>   flags       = IPv6<br>   socket_type     = stream<br>   wait            = no<br>   user            = root<br>   server          = /usr/bin/rsync<br>   server_args     = –daemon<br>   log_on_failure  += USERID<br>}  </p></blockquote><p>执行service xinetd restart会一起重启rsync后台进程，默认使用配置文件/etc/rsyncd.conf。也可以使用/usr/bin/rsync –daemon –config=/etc/rsyncd.conf。</p><p>为了以防rsync写入过多的无用日志到/var/log/message（容易塞满从而错过重要的信息），建议注释掉/etc/xinetd.conf的success：</p><pre><code># log_on_success  = PID HOST DURATION EXIT</code></pre><p>如果使用了防火墙，要添加允许IP到873端口的规则。</p><pre><code># iptables -A INPUT -p tcp -m state --state NEW  -m tcp --dport 873 -j ACCEPT# iptables -L  查看一下防火墙是不是打开了 873端口# netstat -anp|grep 873</code></pre><p>建议关闭selinux，可能会由于强访问控制导致同步报错。</p><h4 id="客户端测试同步"><a href="#客户端测试同步" class="headerlink" title="客户端测试同步"></a>客户端测试同步</h4><p>单向同步时，客户端只需要一个包含密码的文件。<br>/etc/rsync_client.pwd：</p><blockquote><p>   test  </p></blockquote><pre><code>chmod 600 /etc/rsync_client.pwd</code></pre><p>命令：<br>将本地/root/目录同步到远程172.29.88.223的/tmp/rsync_bak2目录（module_test指定）：  </p><pre><code>/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd /root/ sean@172.29.88.223::module_test </code></pre><p>当然你也可以将远程的/tmp/rsync_bak2目录同步到本地目录/root/tmp：</p><pre><code>/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd sean@172.29.88.223::module_test /root/ </code></pre><p>从上面两个命令可以看到，其实这里的服务器与客户端的概念是很模糊的，rsync daemon都运行在远程172.29.88.223上，第一条命令是本地主动推送目录到远程，远程服务器是用来备份的；第二条命令是本地主动向远程索取文件，本地服务器用来备份，也可以认为是本地服务器恢复的一个过程。</p><h3 id="rsync不足"><a href="#rsync不足" class="headerlink" title="rsync不足"></a>rsync不足</h3><p>与传统的cp、tar备份方式相比，rsync具有安全性高、备份迅速、支持增量备份等优点，通过rsync可以解决对实时性要求不高的数据备份需求，例如定期的备份文件服务器数据到远端服务器，对本地磁盘定期做数据镜像等。</p><p>随着应用系统规模的不断扩大，对数据的安全性和可靠性也提出的更好的要求，rsync在高端业务系统中也逐渐暴露出了很多不足，首先，rsync同步数据时，需要扫描所有文件后进行比对，进行差量传输。如果文件数量达到了百万甚至千万量级，扫描所有文件将是非常耗时的。而且正在发生变化的往往是其中很少的一部分，这是非常低效的方式。其次，rsync不能实时的去监测、同步数据，虽然它可以通过crontab方式进行触发同步，但是两次触发动作一定会有时间差，这样就导致了服务端和客户端数据可能出现不一致，无法在应用故障时完全的恢复数据。基于以上原因，rsync+inotify组合出现了！</p><h2 id="inotify-tools"><a href="#inotify-tools" class="headerlink" title="inotify-tools"></a>inotify-tools</h2><h3 id="什么是inotify"><a href="#什么是inotify" class="headerlink" title="什么是inotify"></a>什么是inotify</h3><p>inotify是一种强大的、细粒度的、异步的文件系统事件监控机制，Linux内核从2.6.13开始引入，允许监控程序打开一个独立文件描述符，并针对事件集监控一个或者多个文件，例如打开、关闭、移动/重命名、删除、创建或者改变属性。</p><p>CentOS6自然已经支持：</p><p>使用ll /proc/sys/fs/inotify命令，是否有以下三条信息输出，如果没有表示不支持。</p><blockquote><p>total 0<br>-rw-r–r– 1 root root 0 Dec 11 15:23 max_queued_events<br>-rw-r–r– 1 root root 0 Dec 11 15:23 max_user_instances<br>-rw-r–r– 1 root root 0 Dec 11 15:23 max_user_watches</p></blockquote><p>1./proc/sys/fs/inotify/max_queued_evnets表示调用inotify_init时分配给inotify instance中可排队的event的数目的最大值，超出这个值的事件被丢弃，但会触发IN_Q_OVERFLOW事件。</p><p>2./proc/sys/fs/inotify/max_user_instances表示每一个real user ID可创建的inotify instatnces的数量上限。</p><p>3./proc/sys/fs/inotify/max_user_watches表示每个inotify instatnces可监控的最大目录数量。如果监控的文件数目巨大，需要根据情况，适当增加此值的大小。</p><p>inotify-tools：</p><p>inotify-tools是为linux下inotify文件监控工具提供的一套C的开发接口库函数，同时还提供了一系列的命令行工具，这些工具可以用来监控文件系统的事件。 inotify-tools是用c编写的，除了要求内核支持inotify外，不依赖于其他。inotify-tools提供两种工具，一是inotifywait，它是用来监控文件或目录的变化，二是inotifywatch，它是用来统计文件系统访问的次数。</p><p>下载inotify-tools-3.14-1.el6.x86_64.rpm，通过rpm包安装：</p><pre><code># rpm -ivh /apps/crm/soft_src/inotify-tools-3.14-1.el6.x86_64.rpm warning: /apps/crm/soft_src/inotify-tools-3.14-1.el6.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 4026433f: NOKEY  Preparing...                ########################################### [100%]1:inotify-tools          ########################################### [100%]# rpm -qa|grep inotifyinotify-tools-3.14-1.el5.x86_64</code></pre><h3 id="inotifywait使用示例"><a href="#inotifywait使用示例" class="headerlink" title="inotifywait使用示例"></a>inotifywait使用示例</h3><p>监控/root/tmp目录文件的变化：</p><pre><code>/usr/bin/inotifywait -mrq --timefmt &apos;%Y/%m/%d-%H:%M:%S&apos; --format &apos;%T %w %f&apos; -e modify,delete,create,move,attrib /root/tmp/</code></pre><p>上面的命令表示，持续监听/root/tmp目录及其子目录的文件变化，监听事件包括文件被修改、删除、创建、移动、属性更改，显示到屏幕。执行完上面的命令后，在/root/tmp下创建或修改文件都会有信息输出：</p><pre><code>2014/12/11-15:40:04 /root/tmp/ new.txt2014/12/11-15:40:22 /root/tmp/ .new.txt.swp2014/12/11-15:40:22 /root/tmp/ .new.txt.swx2014/12/11-15:40:22 /root/tmp/ .new.txt.swx2014/12/11-15:40:22 /root/tmp/ .new.txt.swp2014/12/11-15:40:22 /root/tmp/ .new.txt.swp2014/12/11-15:40:23 /root/tmp/ .new.txt.swp2014/12/11-15:40:31 /root/tmp/ .new.txt.swp2014/12/11-15:40:32 /root/tmp/ 49132014/12/11-15:40:32 /root/tmp/ 49132014/12/11-15:40:32 /root/tmp/ 49132014/12/11-15:40:32 /root/tmp/ new.txt2014/12/11-15:40:32 /root/tmp/ new.txt~2014/12/11-15:40:32 /root/tmp/ new.txt...</code></pre><h2 id="rsync组合inotify-tools完成实时同步"><a href="#rsync组合inotify-tools完成实时同步" class="headerlink" title="rsync组合inotify-tools完成实时同步"></a>rsync组合inotify-tools完成实时同步</h2><p>这一步的核心其实就是在客户端创建一个脚本rsync.sh，适用inotifywait监控本地目录的变化，触发rsync将变化的文件传输到远程备份服务器上。为了更接近实战，我们要求一部分子目录不同步，如/root/tmp/log和临时文件。</p><h3 id="创建排除在外不同步的文件列表"><a href="#创建排除在外不同步的文件列表" class="headerlink" title="创建排除在外不同步的文件列表"></a>创建排除在外不同步的文件列表</h3><p>排除不需要同步的文件或目录有两种做法，第一种是inotify监控整个目录，在rsync中加入排除选项，简单；第二种是inotify排除部分不监控的目录，同时rsync中也要加入排除选项，可以减少不必要的网络带宽和CPU消耗。我们选择第二种。</p><h4 id="inotifywait排除"><a href="#inotifywait排除" class="headerlink" title="inotifywait排除"></a>inotifywait排除</h4><p>这个操作在客户端进行，假设/tmp/src/mail/2014/以及/tmp/src/mail/2015/cache/目录下的所有文件不用同步，所以不需要监控，/tmp/src/下的其他文件和目录都同步。（其实对于打开的临时文件，可以不监听modify时间而改成监听close_write）</p><p>inotifywait排除监控目录有–exclude <pattern>和–fromfile <file>两种格式，并且可以同时使用，但主要前者可以用正则，而后者只能是具体的目录或文件。</file></pattern></p><pre><code># vi /etc/inotify_exclude.lst：/tmp/src/pdf@/tmp/src/2014</code></pre><p>使用fromfile格式只能用绝对路径，不能使用诸如*正则表达式去匹配，@表示排除。</p><p>如果要排除的格式比较复杂，必须使用正则，那只能在inotifywait中加入选项，如–exclude ‘(.<em>/</em>.log|.<em>/</em>.swp)$|^/tmp/src/mail/(2014|201.<em>/cache.</em>)’，表示排除/tmp/src/mail/以下的2014目录，和所有201*目录下的带cache的文件或目录，以及/tmp/src目录下所有的以.log或.swp结尾的文件。</p><h4 id="rsync排除"><a href="#rsync排除" class="headerlink" title="rsync排除"></a>rsync排除</h4><p>使用inotifywait排除监控目录的情况下，必须同时使用rsync排除对应的目录，否则只要有触发同步操作，必然会导致不该同步的目录也会同步。与inotifywait类似，rsync的同步也有–exclude和–exclude-from两种写法。</p><p>个人还是习惯将要排除同步的目录卸载单独的文件列表里，便于管理。使用–include-from=FILE时，排除文件列表用绝对路径，但FILE里面的内容请用相对路径，如：</p><p>/etc/rsyncd.d/rsync_exclude.lst</p><blockquote><p>mail/2014/<br>mail/201<em>/201</em>/201<em>/.??</em><br>mail??<em><br>src/</em>.html<em><br>src/js/<br>src/ext3/<br>src/2014/20140[1-9]/<br>src/201</em>/201<em>/201</em>/.??<em><br>membermail/<br>membermail??</em><br>membermail/201<em>/201</em>/201<em>/.??</em></p></blockquote><p>排除同步的内容包括，mail下的2014目录，类似2015/201501/20150101/下的临时或隐藏文件，等</p><h3 id="客户端同步到远程的脚本rsync-sh"><a href="#客户端同步到远程的脚本rsync-sh" class="headerlink" title="客户端同步到远程的脚本rsync.sh"></a>客户端同步到远程的脚本rsync.sh</h3><p>下面是一个完整的同步脚本，请根据需要进行裁剪，rsync.sh：</p><pre><code>current_date=$(date +%Y%m%d_%H%M%S)source_path=/tmp/src/log_file=/var/log/rsync_client.log#rsyncrsync_server=172.29.88.223rsync_user=seanrsync_pwd=/etc/rsync_client.pwdrsync_module=module_testINOTIFY_EXCLUDE=&apos;(.*/*\.log|.*/*\.swp)$|^/tmp/src/mail/(2014|20.*/.*che.*)&apos;RSYNC_EXCLUDE=&apos;/etc/rsyncd.d/rsync_exclude.lst&apos;#rsync client pwd checkif [ ! -e ${rsync_pwd} ];thenecho -e &quot;rsync client passwod file ${rsync_pwd} does not exist!&quot;exit 0fi#inotify_functioninotify_fun(){/usr/bin/inotifywait -mrq --timefmt &apos;%Y/%m/%d-%H:%M:%S&apos; --format &apos;%T %w %f&apos; \      --exclude ${INOTIFY_EXCLUDE}  -e modify,delete,create,move,attrib ${source_path} \      | while read file  do      /usr/bin/rsync -auvrtzopgP --exclude-from=${RSYNC_EXCLUDE} --progress --bwlimit=200 --password-file=${rsync_pwd} ${source_path} ${rsync_user}@${rsync_server}::${rsync_module}   done}#inotify loginotify_fun &gt;&gt; ${log_file} 2&gt;&amp;1 &amp;</code></pre><p>–bwlimit=200用于限制传输速率最大200kb，因为在实际应用中发现如果不做速率限制，会导致巨大的CPU消耗。</p><p>在客户端运行脚本# ./rsync.sh即可实时同步目录。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;rsynv&quot;&gt;&lt;a href=&quot;#rsynv&quot; class=&quot;headerlink&quot; title=&quot;rsynv&quot;&gt;&lt;/a&gt;rsynv&lt;/h2&gt;
    
    </summary>
    
      <category term="rsync" scheme="http://datura.me/categories/rsync/"/>
    
    
      <category term="rsync" scheme="http://datura.me/tags/rsync/"/>
    
  </entry>
  
  <entry>
    <title>centos 7 部署 gitlab</title>
    <link href="http://datura.me/2017/09/08/gitlab%E5%AE%89%E8%A3%85/"/>
    <id>http://datura.me/2017/09/08/gitlab安装/</id>
    <published>2017-09-08T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.722Z</updated>
    
    <content type="html"><![CDATA[<h2 id="gitlab的安装搭建"><a href="#gitlab的安装搭建" class="headerlink" title="gitlab的安装搭建"></a>gitlab的安装搭建</h2><a id="more"></a><h3 id="安装基础环境包"><a href="#安装基础环境包" class="headerlink" title="安装基础环境包"></a>安装基础环境包</h3><pre><code>yum -y install curl policycoreutils openssh-server openssh-clients</code></pre><h3 id="启动sshd"><a href="#启动sshd" class="headerlink" title="启动sshd"></a>启动sshd</h3><pre><code>systemctl enable sshdsystemctl start sshd</code></pre><h3 id="安装postfix"><a href="#安装postfix" class="headerlink" title="安装postfix"></a>安装postfix</h3><pre><code>yum -y install postfixsystemctl enable postfixsystemctl start postfix</code></pre><h3 id="添加防火墙规则"><a href="#添加防火墙规则" class="headerlink" title="添加防火墙规则"></a>添加防火墙规则</h3><pre><code>firewall-cmd --permanent --add-service=httpsystemctl reload firewalld</code></pre><p>or<br>    yum install firewalld<br>    systemctl unmadk firewalld</p><h3 id="下载并安装软件包"><a href="#下载并安装软件包" class="headerlink" title="下载并安装软件包"></a>下载并安装软件包</h3><pre><code>curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bashyum install gitlab-ce</code></pre><p>如遇到time out，请更换成国内源<br>    vim /etc/yum.repos.d/gitlab-ce.repo</p><blockquote><p>[gitlab-ce]<br>name=gitlab-ce<br>baseurl=<a href="http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7" target="_blank" rel="noopener">http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7</a><br>repo_gpgcheck=0<br>gp0gcheck=0<br>enabled=1<br>gpgkey=<a href="https://packages.gitlab.com/gpg.key" target="_blank" rel="noopener">https://packages.gitlab.com/gpg.key</a></p></blockquote><pre><code>yum makecacheyum install gitlab-ce -y</code></pre><p>or 下载相应版本gitlab的rpm包</p><pre><code>https://packages.gitlab.com/gitlab/gitlab-ce/    </code></pre><p>安装完毕后</p><pre><code>gitlab-ctl reconfigure </code></pre><blockquote><p>gitlab: GitLab should be reachable at <a href="http://iZ2851te7e5Z" target="_blank" rel="noopener">http://iZ2851te7e5Z</a><br>gitlab: Otherwise configure GitLab for your system by editing /etc/gitlab/gitlab.rb file<br>gitlab: And running reconfigure again.<br>gitlab:<br>gitlab: For a comprehensive list of configuration options please see the Omnibus GitLab readme<br>gitlab: <a href="https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md" target="_blank" rel="noopener">https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md</a><br>gitlab:<br>It looks like GitLab has not been configured yet; skipping the upgrade script.<br>  验证中      : gitlab-ce-8.7.6-ce.0.el7.x86_64                                                                                             1/1<br>已安装:<br>  gitlab-ce.x86_64 0:8.7.6-ce.0.el7<br>完毕！</p></blockquote><h3 id="配置并启动gitlab"><a href="#配置并启动gitlab" class="headerlink" title="配置并启动gitlab"></a>配置并启动gitlab</h3><p>如果遇到</p><blockquote><p>安装GitLab出现ruby_block[supervise_redis_sleep] action run</p></blockquote><p>那么需要运行</p><pre><code>systemctl restart gitlab-runsvdirgitlab-ctl reconfigure</code></pre><h3 id="默认账号密码是"><a href="#默认账号密码是" class="headerlink" title="默认账号密码是"></a>默认账号密码是</h3><pre><code>Username: rootPassword: 5iveL!fe</code></pre><p>测试地址（默认80端口）<br>    <a href="http://127.0.0.1/" target="_blank" rel="noopener">http://127.0.0.1/</a></p><h2 id="gitlab的备份"><a href="#gitlab的备份" class="headerlink" title="gitlab的备份"></a>gitlab的备份</h2><h3 id="备份命令"><a href="#备份命令" class="headerlink" title="备份命令"></a>备份命令</h3><pre><code>gitlab-rake gitlab:backup:create</code></pre><p>默认的备份目录为： /var/opt/gitlab/backups  备份文件名类似： 时间戳_gitlab_backup.tar</p><p>如要修改备份目录：<br>    vim /etc/gitlab/gitlab.rd<br>    gitlab_rails[‘backup_path’] = ‘/mnt/gitlab_backups’</p><h3 id="gitlab数据的恢复或还原"><a href="#gitlab数据的恢复或还原" class="headerlink" title="gitlab数据的恢复或还原"></a>gitlab数据的恢复或还原</h3><p>提示：gitlab数据的恢复或者迁移成功的前提–两台服务器的gitlab的版本必须相同，若不同侧可能迁移或者恢复失败  </p><blockquote><p>将备份文件放在gitlab的默认备份目录<br>比如/var/opt/gitlab/backups下的1504693308_gitlab_backup.tar     </p></blockquote><p>设置自动备份</p><pre><code>0 2 * * * /opt/gitlab/bin/gitlab-rake gitlab:backup:create</code></pre><p>恢复或者还原  </p><p>停服务</p><pre><code>gitlab-ctl stop unicorngitlab-ctl stop sidekiq</code></pre><p>恢复数据</p><pre><code>gitlab-rake gitlab:backup:restore BACKUP=1504693308</code></pre><p>BACKUP后面跟的是备份文件的时间戳，比如恢复备份文件1504693308_gitlab_backup.tar</p><p>恢复完启动服务</p><pre><code>gitlab-ctl start</code></pre><h2 id="gitlab-nginx的修改"><a href="#gitlab-nginx的修改" class="headerlink" title="gitlab nginx的修改"></a>gitlab nginx的修改</h2><p>配置文件 /var/opt/gitlab/nginx/conf/gitlab-http.conf。这个文件是gitlab内置的nginx的配置文件，里面可以影响到nginx真实监听端口。</p><pre><code>server {    listen *:80;    server_name ip    server_tokens off; ##Don&apos;t show the nginx version number, a security best practice         }</code></pre><p>修改完成后，重启下就可以了<br>    gitlab-ctl restart</p><h2 id="汉化"><a href="#汉化" class="headerlink" title="汉化"></a>汉化</h2><h3 id="查看自己gitlab的版本号"><a href="#查看自己gitlab的版本号" class="headerlink" title="查看自己gitlab的版本号"></a>查看自己gitlab的版本号</h3><pre><code>cat /opt/gitlab/embedded/service/gitlab-rails/VERSION9.3.5</code></pre><p>当前版本为v9.3.5,并确认汉化版本库是否包含该版本的汉化标签(-zh结尾),也就是是否包含 v9.3.5-zh</p><h3 id="下载汉化包并汉化"><a href="#下载汉化包并汉化" class="headerlink" title="下载汉化包并汉化"></a>下载汉化包并汉化</h3><p>克隆汉化版本库，此处用了好久的时间，拉取这个分支，没有更好的办法，可以自行百度一下Git慢的解决方式</p><pre><code>git clone https://gitlab.com/xhang/gitlab.git</code></pre><p>如果已经克隆过，则进行更新</p><pre><code>git fetch</code></pre><p>比较汉化标签和原标签，导出 patch 用的 diff 文件.进入刚才的目录git clone 的目录</p><pre><code>cd gitlabgit diff v9.3.5 v9.3.5-zh &gt; ../9.3.5-zh.diff</code></pre><p>上传9.3.5-zh.diff文件到服务器停止 gitlab</p><pre><code>gitlab-ctl stoppatch -d /opt/gitlab/embedded/service/gitlab-rails -p1 &lt; ../9.3.6-zh.diff</code></pre><blockquote><p>这里path 如果也出现 command not found 说明path安装包没有安装，然后在运行前边的代码就可以了<br>yum -y install patch </p></blockquote><p>重启gitlab即可.</p><pre><code>gitlab-ctl start</code></pre><p>执行重新配置命令</p><pre><code>gitlab-ctl reconfigure</code></pre><h2 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h2><h3 id="关闭gitlab服务"><a href="#关闭gitlab服务" class="headerlink" title="关闭gitlab服务"></a>关闭gitlab服务</h3><pre><code>gitlab-ctl stop unicorngitlab-ctl stop sidekiqgitlab-ctl stop nginx</code></pre><h3 id="备份gitlab"><a href="#备份gitlab" class="headerlink" title="备份gitlab"></a>备份gitlab</h3><pre><code>gitlab-rake gitlab:backup:create</code></pre><h3 id="下载gitlab的RPM包并进行升级"><a href="#下载gitlab的RPM包并进行升级" class="headerlink" title="下载gitlab的RPM包并进行升级"></a>下载gitlab的RPM包并进行升级</h3><pre><code>curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bashyum update gitlab-ce</code></pre><p>或者直接上官网下载相应gitlab的版本所对应的软件包（<a href="https://packages.gitlab.com/gitlab/gitlab-ce/" target="_blank" rel="noopener">https://packages.gitlab.com/gitlab/gitlab-ce/</a>）</p><pre><code>yum install gitlab-ce-8.8.3-ce.0.el7.x86_64</code></pre><h3 id="启动并查看gitlab的版本信息"><a href="#启动并查看gitlab的版本信息" class="headerlink" title="启动并查看gitlab的版本信息"></a>启动并查看gitlab的版本信息</h3><pre><code>gitlab-ctl reconfiguregitlab-ctl restarthead -1 /opt/gitlab/version-manifest.txtcat /opt/gitlab/embedded/service/gitlab-rails/VERSION</code></pre><h3 id="可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务"><a href="#可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务" class="headerlink" title="可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务"></a>可以更换gitlab自带的nginx，使用自行编译好的nginx来管理gitlab服务</h3><pre><code>vim /etc/gitlab/gitlab.rd</code></pre><blockquote><p>设置nginx为dalse，关闭自带nginx<br>nginx[‘enable’] = false<br>检查默认nginx配置文件，并迁移至新nginx服务。<br>/var/opt/gitlab/nginx/conf/nginx.conf  #nginx配置文件，包含gitlab-http.conf文件<br>/var/ope/gitlab/nginx/conf/gitlab-http.conf #gitlab核心nginx配置文件</p></blockquote><p>重启nginx、gitlab服务</p><pre><code>gitlab-ctl reconfiguresystemctl restart nginx</code></pre><p>访问报502。原因是nginx用户无法访问gitlab用户的socket文件。重启gitlab需要重新授权</p><pre><code>chmod -R o+x /var/opt/gitlab/gitlab-railsgitlab-ctl restart</code></pre><h2 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h2><p>前提：必须在Gitlab运行状态下才能卸载</p><pre><code>gitlab-ctl uninstallrpm -e gitlab-ce</code></pre><p>在卸载gitlab然后再次安装执行gitlab-ctl reconfigure的时候往往会出现:ruby_block[supervise_redis_sleep] action run,会一直卡无法往下进行！<br>解决方案：  </p><p>按住CTRL+C强制结束  </p><p>运行:  </p><pre><code>systemctl restart gitlab-runsvdirgitlab-ctl reconfigure</code></pre><h2 id="报错解决"><a href="#报错解决" class="headerlink" title="报错解决"></a>报错解决</h2><h3 id="迁移后页面500错误"><a href="#迁移后页面500错误" class="headerlink" title="迁移后页面500错误"></a>迁移后页面500错误</h3><p>如果遇到迁移项目后web页面点击项目报500错误，查看相关日志如下</p><pre><code>==&gt; /var/log/gitlab/gitlab-rails/production.log &lt;==  Started GET &quot;/ops/install_php&quot; for 127.0.0.1 at   2017-09-13 10:32:45 +0800  Processing by ProjectsController#show as HTML     Parameters: {&quot;namespace_id&quot;=&gt;&quot;ops&quot;,  &quot;id&quot;=&gt;&quot;install_php&quot;}  Completed 500 Internal Server Error in 36ms (ActiveRecord: 2.2ms)  OpenSSL::Cipher::CipherError (bad decrypt):    app/models/project.rb:383:in `import_url&apos;  app/models/project.rb:413:in `external_import?&apos;  app/models/project.rb:405:in `import?&apos;  app/models/project.rb:421:in `import_in_progress?&apos;  app/controllers/projects_controller.rb:93:in `show&apos;  lib/gitlab/middleware/go.rb:16:in `call&apos;</code></pre><p>可得知是OpenSSL解密出现了问题，经调查后发现<br>这个是gitlab数据迁移的时候一个缺陷</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>1.覆盖原来gitlab的db_key_base到新的gitlab</p><p>db_key_base位置在/etc/gitlab/gitlab-secrets.json</p><p>2.EE版本执行</p><pre><code>sudo gitlab-rails runner &quot;Project.where(mirror: false).where.not(import_url: nil).each { |p| p.import_data.destroy if p.import_data }&quot;</code></pre><p>3.CE版本执行</p><pre><code>sudo gitlab-rails runner &quot;Project.where.not(import_url: nil).each { |p| p.import_data.destroy if p.import_data }&quot;</code></pre><h3 id="备机web界面项目地址显示主机名问题"><a href="#备机web界面项目地址显示主机名问题" class="headerlink" title="备机web界面项目地址显示主机名问题"></a>备机web界面项目地址显示主机名问题</h3><pre><code>vim /var/opt/gitlab/gitlab-rails/etc/gitlab.yml</code></pre><p>修改host项</p><blockquote><p>由host: localhost改成<br>host: <strong>**</strong></p></blockquote><p>gitlab重启即可</p><pre><code>gitlab-ctl restart</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;gitlab的安装搭建&quot;&gt;&lt;a href=&quot;#gitlab的安装搭建&quot; class=&quot;headerlink&quot; title=&quot;gitlab的安装搭建&quot;&gt;&lt;/a&gt;gitlab的安装搭建&lt;/h2&gt;
    
    </summary>
    
      <category term="git" scheme="http://datura.me/categories/git/"/>
    
    
      <category term="git" scheme="http://datura.me/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>centos 7 部署 open-falcon 0.2.1</title>
    <link href="http://datura.me/2017/08/31/open-falcon%E5%AE%89%E8%A3%85/"/>
    <id>http://datura.me/2017/08/31/open-falcon安装/</id>
    <published>2017-08-31T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.724Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><h3 id="更换阿里yum"><a href="#更换阿里yum" class="headerlink" title="更换阿里yum"></a>更换阿里yum</h3><a id="more"></a><p> 步骤：<br>1）下载wget  </p><pre><code>yum install -y wget</code></pre><p>2）备份默认的yum  </p><pre><code>mv /etc/yum.repos.d /etc/yum.repos.d.backup</code></pre><p>3）设置新的yum目录  </p><pre><code>mkdir /etc/yum.repos.d  </code></pre><p>4）下载阿里yum配置到该目录中   </p><pre><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</code></pre><p>5）重建缓存  </p><pre><code>yum clean all  yum makecache  </code></pre><p>6）升级所有包（改变软件设置和系统设置，系统版本内核都升级，故需要几分钟耐心等待）  </p><pre><code>yum update -y  </code></pre><h3 id="安装vim"><a href="#安装vim" class="headerlink" title="安装vim"></a>安装vim</h3><pre><code>yum install -y vim  </code></pre><h3 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h3><pre><code>yum install -y git  </code></pre><p>安装结束后安全起见，确认是否满足官方要求的Git &gt;= 1.7.5  </p><pre><code>git version</code></pre><h3 id="安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）"><a href="#安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）" class="headerlink" title="安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）"></a>安装go语言环境（因为官方yum和阿里yum都没有go的安装包，故只能通过fedora的epel仓库来安装）</h3><pre><code>yum install -y epel-releaseyum install golang -y</code></pre><p>安装结束后安全起见，确认是否满足官方要求的Go &gt;= 1.6  </p><pre><code>go version</code></pre><h3 id="安装redis"><a href="#安装redis" class="headerlink" title="安装redis"></a>安装redis</h3><p>由于部署go时已经安装了epel，故直接执行下面的安装命令（如果没有装epel，会提示No package redis available，也就是没有安装包可用，因为官方yum和阿里yum都没有redis，故只能通过fedora的epel仓库来安装）  </p><pre><code>yum install redis -y</code></pre><p>启动redis  </p><pre><code>systemctl start redis  </code></pre><p>设置redis开机启动   </p><pre><code>systemctl enable redis</code></pre><p>可以用下面的语句查看redis是否开启  </p><pre><code>systemctl status redis  </code></pre><h3 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h3><p> 步骤：  </p><p>1）下载repo源</p><pre><code>wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm  </code></pre><p>2）安装该rpm包（安装这个包后，会获得两个mysql的yum repo源：/etc/yum.repos.d/mysql-community.repo，/etc/yum.repos.d/mysql-community-source.repo）  </p><pre><code>rpm -ivh mysql-community-release-el7-5.noarch.rpm  </code></pre><p>3）安装mysql  </p><pre><code>yum install mysql-server -y  </code></pre><p>4）启动mysql  </p><pre><code>systemctl start mysql  </code></pre><p>可以用下面的语句查看mysql是否开启  </p><pre><code>systemctl status mysql  </code></pre><h3 id="设置环境变量GOROOT和GOPATH"><a href="#设置环境变量GOROOT和GOPATH" class="headerlink" title="设置环境变量GOROOT和GOPATH"></a>设置环境变量GOROOT和GOPATH</h3><pre><code>export GOROOT=/usr/lib/golangexport GOPATH=/home  </code></pre><h3 id="将open-falcon的源码从github上get下来"><a href="#将open-falcon的源码从github上get下来" class="headerlink" title="将open-falcon的源码从github上get下来"></a>将open-falcon的源码从github上get下来</h3><p>步骤：</p><p>1）创建GOPATH下的一个本地的路径  </p><pre><code>mkdir -p $GOPATH/src/github.com/open-falcon  </code></pre><p>2）进入该路径  </p><pre><code>cd $GOPATH/src/github.com/open-falcon  </code></pre><p>3）将源码get到本地  </p><pre><code>git clone https://github.com/open-falcon/falcon-plus.git</code></pre><h3 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h3><pre><code>cd $GOPATH/src/github.com/open-falcon/falcon-plus/scripts/mysql/db_schema/mysql -h 127.0.0.1 -u root -p &lt; 1_uic-db-schema.sqlmysql -h 127.0.0.1 -u root -p &lt; 2_portal-db-schema.sqlmysql -h 127.0.0.1 -u root -p &lt; 3_dashboard-db-schema.sqlmysql -h 127.0.0.1 -u root -p &lt; 4_graph-db-schema.sqlmysql -h 127.0.0.1 -u root -p &lt; 5_alarms-db-schema.sql</code></pre><p>再运行“mysql -h………………”时会提示“Enter password”，如果mysql的root没有设置密码，回车即可。</p><h3 id="编译源码并打包"><a href="#编译源码并打包" class="headerlink" title="编译源码并打包"></a>编译源码并打包</h3><p>步骤：  </p><p>1）进入本地源码路径下  </p><pre><code>cd $GOPATH/src/github.com/open-falcon/falcon-plus/</code></pre><p>2）使用go get获取rrdtool工具包（make过程卡壳的一个点）  </p><pre><code>go get github.com/open-falcon/rrdlite</code></pre><p>这一步是官方教程没有提到的内容，如果不获取该工具包make的时候会报错  </p><p>3）编译所有模块  </p><pre><code>make all</code></pre><p> 4）打包</p><pre><code>make pack  </code></pre><p>在$GOPATH/src/github.com/open-falcon/falcon-plus/目录下就多了刚才的压缩包“open-falcon-v0.2.0.tar.gz”。</p><h3 id="官方提供的安装包"><a href="#官方提供的安装包" class="headerlink" title="官方提供的安装包"></a>官方提供的安装包</h3><p><a href="https://book.open-falcon.org/zh_0_2/quick_install/prepare.html中官方有提供编译包，如果编译过程不顺利可以直接下载编译包。" target="_blank" rel="noopener">https://book.open-falcon.org/zh_0_2/quick_install/prepare.html中官方有提供编译包，如果编译过程不顺利可以直接下载编译包。</a></p><h2 id="部署后端"><a href="#部署后端" class="headerlink" title="部署后端"></a>部署后端</h2><h3 id="创建工作目录"><a href="#创建工作目录" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><pre><code>export WORKSPACE=/home/workmkdir -p $WORKSPACE</code></pre><h3 id="解压二进制包（包名根据实际进行修改）"><a href="#解压二进制包（包名根据实际进行修改）" class="headerlink" title="解压二进制包（包名根据实际进行修改）"></a>解压二进制包（包名根据实际进行修改）</h3><p>由于我是根据本教程编译源码获得的压缩包，故需要切换到“$GOPATH/src/github.com/open-falcon/falcon-plus/”路径下。</p><p>包名由于make pack的时候就是open-falcon-v0.2.0.tar.gz，具体根据实际情况。</p><pre><code>cd $GOPATH/src/github.com/open-falcon/falcon-plus/tar -xzvf open-falcon-v0.2.0.tar.gz -C $WORKSPACE</code></pre><h3 id="修改配置文件cfg-json"><a href="#修改配置文件cfg-json" class="headerlink" title="修改配置文件cfg.json"></a>修改配置文件cfg.json</h3><p>猜测部分模块依赖连接数据库，因为如果不修改配置文件，aggregator模块会出现无法启动，graph、hbs、nodata、api、alarm模块会出现开启不报错但是状态为开启失败的情况。（个人认为这块的设计值得作为open-falcon优化的一个点，连接本机mysql如果失败是可以收到错误提示的，第一时间有报错提示总比什么都不显示或显示开启但实际开启失败强，如果别人服务都不知道怎么开起来，系统功能再强大有多少人硬着头皮部署下去而不是选择换个系统试试呢）    </p><p>如果需要每个模块都能正常启动，需要将上面模块的cfg.json的数据库信息进行修改。根据本教程的配置，需要修改配置文件所在的目录：   </p><p>模块    配置文件所在路径  </p><p>aggregator        /home/work/aggregator/config/cfg.json<br>graph             /home/work/graph/config/cfg.json<br>hbs                /home/work/hbs/config/cfg.json<br>nodata          /home/work/nodata/config/cfg.json<br>api                /home/work/api/config/cfg.json<br>alarm           /home/work/alarm/config/cfg.json  </p><p>1）修改aggregator的配置文件  </p><pre><code>vim /home/work/aggregator/config/cfg.json</code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。   </p><p>2）修改graph的配置文件  </p><pre><code>vim /home/work/graph/config/cfg.json    </code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  </p><p>3）修改hbs的配置文件</p><pre><code>vim /home/work/hbs/config/cfg.json  </code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  </p><p>4）修改nodata的配置文件  </p><pre><code>vim /home/work/nodata/config/cfg.json  </code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。  </p><p>5）修改api的配置文件  </p><pre><code>vim /home/work/api/config/cfg.json  </code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。</p><p>6）修改alarm的配置文件  </p><pre><code>vim /home/work/alarm/config/cfg.json  </code></pre><p>mysql的root密码为空，则去掉“password”，若不为空，则用root密码替换“password”。   </p><h3 id="启动后端模块"><a href="#启动后端模块" class="headerlink" title="启动后端模块"></a>启动后端模块</h3><pre><code>cd $WORKSPACE./open-falcon start  </code></pre><p>可以用下面的命令检查各个模块的启动情况  </p><pre><code>./open-falcon check  </code></pre><p>更多命令的用法（命令的例子是启动agent模块）</p><pre><code>./open-falcon [start|stop|restart|check|monitor|reload] module./open-falcon start agent./open-falcon check    falcon-graph         UP           53007      falcon-hbs         UP           53014    falcon-judge         UP           53020 falcon-transfer         UP           53026   falcon-nodata         UP           53032falcon-aggregator         UP           53038    falcon-agent         UP           53044  falcon-gateway         UP           53050      falcon-api         UP           53056    falcon-alarm         UP           53063For debugging , You can check $WorkDir/$moduleName/log/logs/xxx.log  </code></pre><h2 id="部署前端"><a href="#部署前端" class="headerlink" title="部署前端"></a>部署前端</h2><h3 id="创建工作目录-1"><a href="#创建工作目录-1" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><pre><code>export FRONTSPACE=/home/front/open-falconmkdir -p $FRONTSPACE</code></pre><h3 id="获取前端代码"><a href="#获取前端代码" class="headerlink" title="获取前端代码"></a>获取前端代码</h3><pre><code>cd $FRONTSPACEgit clone https://github.com/open-falcon/dashboard.git</code></pre><h3 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h3><pre><code>yum install -y python-virtualenvyum install -y python-develyum install -y openldap-develyum install -y mysql-develyum groupinstall &quot;Development tools&quot; -ycd $FRONTSPACE/dashboard/virtualenv ./env./env/bin/pip install -r pip_requirements.txt</code></pre><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><p>根据本次记录的配置，dashboard的配置文件在/home/front/open-falcon/dashboard/rrd/config.py，需要根据实际情况对内部配置进行修改。  </p><p>由于前端后台搭在一台虚拟机里，且暂时不接入LDAP，且数据库root的密码为空，故先不修改配置文件。</p><h3 id="开启8081端口"><a href="#开启8081端口" class="headerlink" title="开启8081端口"></a>开启8081端口</h3><p>1）防火墙添加8081端口永久开放</p><pre><code>firewall-cmd --add-port=8081/tcp --permanent    </code></pre><p>2）重新载入防火墙配置 </p><pre><code>firewall-cmd --reload</code></pre><h3 id="在生产环境启动"><a href="#在生产环境启动" class="headerlink" title="在生产环境启动"></a>在生产环境启动</h3><pre><code>bash control start</code></pre><p>由于虚拟机ip配置为192.168.3.1，故在浏览器中输入192.168.3.1:8081后跳转。</p><h3 id="以开发者模式启动"><a href="#以开发者模式启动" class="headerlink" title="以开发者模式启动"></a>以开发者模式启动</h3><pre><code>./env/bin/python wsgi.py</code></pre><h2 id="安装agent端"><a href="#安装agent端" class="headerlink" title="安装agent端"></a>安装agent端</h2><h3 id="创建agent安装目录"><a href="#创建agent安装目录" class="headerlink" title="创建agent安装目录"></a>创建agent安装目录</h3><pre><code>mkdir -p $GOPATH/src/github.com/open-falconcd $GOPATH/src/github.com/open-falcon</code></pre><h3 id="从git上下载agent分支"><a href="#从git上下载agent分支" class="headerlink" title="从git上下载agent分支"></a>从git上下载agent分支</h3><pre><code>git clone https://github.com/open-falcon/agent.git</code></pre><h3 id="源码编译安装启动"><a href="#源码编译安装启动" class="headerlink" title="源码编译安装启动"></a>源码编译安装启动</h3><pre><code>cd agentgo get ./..../control build./control start./control pack</code></pre><p>最后一步会pack出一个tar.gz的安装包，拿着这个包去部署服务即可。需要注意的是在源码编译时：</p><p>1、需要主机配置GOPATH环境变量（一般可以配置为用户家家目录）；</p><p>2、需要主机可以连接外网，通过go get下载相关源码包。</p><p>3、编译pack 出的包，在其他agent主机上部署时，无需连接外网 ，pack出的包，可以类似的理解为由c源代码编译后得出的二进制文件。</p><h3 id="配置说明"><a href="#配置说明" class="headerlink" title="配置说明"></a>配置说明</h3><p>配置文件必须叫cfg.json，可以基于cfg.example.json修改，默认该文件并不存在，通过./control start时自动会从cfg.example.json复制一份为cfg.json 。</p><blockquote><p>{<br>    “debug”: true,<br>    “hostname”: “”,<br>    “ip”: “”,<br>    “plugin”: {<br>        “enabled”: false, # 默认不开启插件机制<br>        “dir”: “./plugin”,<br>        “git”: “<a href="https://coding.net/ulricqin/plugin.git&quot;" target="_blank" rel="noopener">https://coding.net/ulricqin/plugin.git&quot;</a>,<br>        “logs”: “./logs”<br>    },<br>    “heartbeat”: {<br>        “enabled”: true, # 此处enabled要设置为true<br>        “addr”: “127.0.0.1:6030”, # hbs的地址，端口是hbs的rpc端口<br>        “interval”: 60,<br>        “timeout”: 1000<br>    },<br>    “transfer”: {<br>        “enabled”: true, # 此处enabled要设置为true<br>        “addr”: “127.0.0.1:8433”, # transfer的地址，端口是transfer的rpc端口<br>        “interval”: 60,<br>        “timeout”: 1000<br>    },<br>    “http”: {<br>        “enabled”: true,<br>        “listen”: “:1988”<br>    },<br>    “collector”: {<br>        “ifacePrefix”: [“eth”, “em”] # 默认配置只会采集网卡名称前缀是eth、em的网卡流量，配置为空就会采集所有的，lo的也会采集。可以从/proc/net/dev看到各个网卡的流量信息<br>    },<br>    “ignore”: { # 默认采集了200多个metric，可以通过ignore设置为不采集<br>        “cpu.busy”: true,<br>        “mem.swapfree”: true<br>    }<br>}  </p></blockquote><h3 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h3><pre><code>./control start 启动进程./control stop 停止进程./control restart 重启进程./control status 查看进程状态./control tail 用tail -f的方式查看var/app.log</code></pre><p>验证 </p><p>看var目录下的log是否正常，或者浏览器访问其1988端口。另外agent提供了一个–check参数，可以检查agent是否可以正常跑在当前机器上。  </p><pre><code>./falcon-agent --check</code></pre><p>打url  <a href="http://IP:1988可以查看相关监控信息。" target="_blank" rel="noopener">http://IP:1988可以查看相关监控信息。</a>  </p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;headerlink&quot; title=&quot;环境准备&quot;&gt;&lt;/a&gt;环境准备&lt;/h2&gt;&lt;h3 id=&quot;更换阿里yum&quot;&gt;&lt;a href=&quot;#更换阿里yum&quot; class=&quot;headerlink&quot; title=&quot;更换阿里yum&quot;&gt;&lt;/a&gt;更换阿里yum&lt;/h3&gt;
    
    </summary>
    
      <category term="open-falcon" scheme="http://datura.me/categories/open-falcon/"/>
    
    
      <category term="open-falcon" scheme="http://datura.me/tags/open-falcon/"/>
    
  </entry>
  
  <entry>
    <title>Python笔记</title>
    <link href="http://datura.me/2017/07/05/Python(%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B)%E8%AF%A6%E8%A7%A3/"/>
    <id>http://datura.me/2017/07/05/Python(基础数据类型)详解/</id>
    <published>2017-07-05T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.722Z</updated>
    
    <content type="html"><![CDATA[<h2 id="str类"><a href="#str类" class="headerlink" title="str类"></a>str类</h2><a id="more"></a><pre><code>class str(basestring):  &quot;&quot;&quot;  str(object=&apos;&apos;) -&gt; string  Return a nice string representation of the object.  If the argument is a string, the return value is the same object.  &quot;&quot;&quot;  def capitalize(self):          &quot;&quot;&quot; 首字母变大写 &quot;&quot;&quot;        &quot;&quot;&quot;        S.capitalize() -&gt; string        Return a copy of the string S with only its first character        capitalized.        &quot;&quot;&quot;        return &quot;&quot;  def center(self, width, fillchar=None):          &quot;&quot;&quot; 内容居中，width：总长度；fillchar：空白处填充内容，默认无 &quot;&quot;&quot;        &quot;&quot;&quot;        S.center(width[, fillchar]) -&gt; string        Return S centered in a string of length width. Padding is        done using the specified fill character (default is a space)        &quot;&quot;&quot;        return &quot;&quot;  def count(self, sub, start=None, end=None):          &quot;&quot;&quot; 子序列个数 &quot;&quot;&quot;        &quot;&quot;&quot;        S.count(sub[, start[, end]]) -&gt; int        Return the number of non-overlapping occurrences of substring sub in        string S[start:end].  Optional arguments start and end are interpreted        as in slice notation.        &quot;&quot;&quot;        return 0  def decode(self, encoding=None, errors=None):          &quot;&quot;&quot; 解码 &quot;&quot;&quot;        &quot;&quot;&quot;        S.decode([encoding[,errors]]) -&gt; object        Decodes S using the codec registered for encoding. encoding defaults        to the default encoding. errors may be given to set a different error        handling scheme. Default is &apos;strict&apos; meaning that encoding errors raise        a UnicodeDecodeError. Other possible values are &apos;ignore&apos; and &apos;replace&apos;        as well as any other name registered with codecs.register_error that is        able to handle UnicodeDecodeErrors.        &quot;&quot;&quot;        return object()  def encode(self, encoding=None, errors=None):          &quot;&quot;&quot; 编码，针对unicode &quot;&quot;&quot;        &quot;&quot;&quot;        S.encode([encoding[,errors]]) -&gt; object        Encodes S using the codec registered for encoding. encoding defaults        to the default encoding. errors may be given to set a different error        handling scheme. Default is &apos;strict&apos; meaning that encoding errors raise        a UnicodeEncodeError. Other possible values are &apos;ignore&apos;, &apos;replace&apos; and        &apos;xmlcharrefreplace&apos; as well as any other name registered with        codecs.register_error that is able to handle UnicodeEncodeErrors.        &quot;&quot;&quot;        return object()  def endswith(self, suffix, start=None, end=None):          &quot;&quot;&quot; 是否以 xxx 结束 &quot;&quot;&quot;        &quot;&quot;&quot;        S.endswith(suffix[, start[, end]]) -&gt; bool        Return True if S ends with the specified suffix, False otherwise.        With optional start, test S beginning at that position.        With optional end, stop comparing S at that position.        suffix can also be a tuple of strings to try.        &quot;&quot;&quot;        return False   def expandtabs(self, tabsize=None):          &quot;&quot;&quot; 将tab转换成空格，默认一个tab转换成8个空格 &quot;&quot;&quot;        &quot;&quot;&quot;        S.expandtabs([tabsize]) -&gt; string        Return a copy of S where all tab characters are expanded using spaces.        If tabsize is not given, a tab size of 8 characters is assumed.        &quot;&quot;&quot;        return &quot;&quot;   def find(self, sub, start=None, end=None):          &quot;&quot;&quot; 寻找子序列位置，如果没找到，返回 -1 &quot;&quot;&quot;        &quot;&quot;&quot;        S.find(sub [,start [,end]]) -&gt; int        Return the lowest index in S where substring sub is found,        such that sub is contained within S[start:end].  Optional        arguments start and end are interpreted as in slice notation.        Return -1 on failure.        &quot;&quot;&quot;        return 0   def format(*args, **kwargs): # known special case of str.format        &quot;&quot;&quot; 字符串格式化，动态参数，将函数式编程时细说 &quot;&quot;&quot;        &quot;&quot;&quot;        S.format(*args, **kwargs) -&gt; string        Return a formatted version of S, using substitutions from args and kwargs.        The substitutions are identified by braces (&apos;{&apos; and &apos;}&apos;).        &quot;&quot;&quot;        pass   def index(self, sub, start=None, end=None):          &quot;&quot;&quot; 子序列位置，如果没找到，报错 &quot;&quot;&quot;        S.index(sub [,start [,end]]) -&gt; int        Like S.find() but raise ValueError when the substring is not found.        &quot;&quot;&quot;        return 0   def isalnum(self):          &quot;&quot;&quot; 是否是字母和数字 &quot;&quot;&quot;        &quot;&quot;&quot;        S.isalnum() -&gt; bool        Return True if all characters in S are alphanumeric        and there is at least one character in S, False otherwise.        &quot;&quot;&quot;        return False   def isalpha(self):          &quot;&quot;&quot; 是否是字母 &quot;&quot;&quot;        &quot;&quot;&quot;        S.isalpha() -&gt; bool        Return True if all characters in S are alphabetic        and there is at least one character in S, False otherwise.        &quot;&quot;&quot;        return False   def isdigit(self):          &quot;&quot;&quot; 是否是数字 &quot;&quot;&quot;        &quot;&quot;&quot;        S.isdigit() -&gt; bool        Return True if all characters in S are digits        and there is at least one character in S, False otherwise.        &quot;&quot;&quot;        return False   def islower(self):          &quot;&quot;&quot; 是否小写 &quot;&quot;&quot;        &quot;&quot;&quot;        S.islower() -&gt; bool        Return True if all cased characters in S are lowercase and there is        at least one cased character in S, False otherwise.        &quot;&quot;&quot;        return False   def isspace(self):          &quot;&quot;&quot;        S.isspace() -&gt; bool        Return True if all characters in S are whitespace        and there is at least one character in S, False otherwise.        &quot;&quot;&quot;        return False   def istitle(self):          &quot;&quot;&quot;        S.istitle() -&gt; bool        Return True if S is a titlecased string and there is at least one        character in S, i.e. uppercase characters may only follow uncased        characters and lowercase characters only cased ones. Return False        otherwise.        &quot;&quot;&quot;        return False   def isupper(self):          &quot;&quot;&quot;        S.isupper() -&gt; bool        Return True if all cased characters in S are uppercase and there is        at least one cased character in S, False otherwise.        &quot;&quot;&quot;        return False   def join(self, iterable):          &quot;&quot;&quot; 连接 &quot;&quot;&quot;        &quot;&quot;&quot;        S.join(iterable) -&gt; string        Return a string which is the concatenation of the strings in the        iterable.  The separator between elements is S.        &quot;&quot;&quot;        return &quot;&quot;   def ljust(self, width, fillchar=None):          &quot;&quot;&quot; 内容左对齐，右侧填充 &quot;&quot;&quot;        &quot;&quot;&quot;        S.ljust(width[, fillchar]) -&gt; string        Return S left-justified in a string of length width. Padding is        done using the specified fill character (default is a space).        &quot;&quot;&quot;        return &quot;&quot;   def lower(self):          &quot;&quot;&quot; 变小写 &quot;&quot;&quot;        &quot;&quot;&quot;        S.lower() -&gt; string        Return a copy of the string S converted to lowercase.        &quot;&quot;&quot;        return &quot;&quot;   def lstrip(self, chars=None):          &quot;&quot;&quot; 移除左侧空白 &quot;&quot;&quot;        &quot;&quot;&quot;        S.lstrip([chars]) -&gt; string or unicode        Return a copy of the string S with leading whitespace removed.        If chars is given and not None, remove characters in chars instead.        If chars is unicode, S will be converted to unicode before stripping        &quot;&quot;&quot;        return &quot;&quot;   def partition(self, sep):          &quot;&quot;&quot; 分割，前，中，后三部分 &quot;&quot;&quot;        &quot;&quot;&quot;        S.partition(sep) -&gt; (head, sep, tail)        Search for the separator sep in S, and return the part before it,        the separator itself, and the part after it.  If the separator is not        found, return S and two empty strings.        &quot;&quot;&quot;        pass   def replace(self, old, new, count=None):          &quot;&quot;&quot; 替换 &quot;&quot;&quot;        &quot;&quot;&quot;        S.replace(old, new[, count]) -&gt; string        Return a copy of string S with all occurrences of substring        old replaced by new.  If the optional argument count is        given, only the first count occurrences are replaced.        &quot;&quot;&quot;        return &quot;&quot;   def rfind(self, sub, start=None, end=None):          &quot;&quot;&quot;        S.rfind(sub [,start [,end]]) -&gt; int        Return the highest index in S where substring sub is found,        such that sub is contained within S[start:end].  Optional        arguments start and end are interpreted as in slice notation.        Return -1 on failure.        &quot;&quot;&quot;        return 0   def rindex(self, sub, start=None, end=None):          &quot;&quot;&quot;        S.rindex(sub [,start [,end]]) -&gt; int        Like S.rfind() but raise ValueError when the substring is not found.        &quot;&quot;&quot;        return 0   def rjust(self, width, fillchar=None):          &quot;&quot;&quot;        S.rjust(width[, fillchar]) -&gt; string        Return S right-justified in a string of length width. Padding is        done using the specified fill character (default is a space)        &quot;&quot;&quot;        return &quot;&quot;   def rpartition(self, sep):          &quot;&quot;&quot;        S.rpartition(sep) -&gt; (head, sep, tail)        Search for the separator sep in S, starting at the end of S, and return        the part before it, the separator itself, and the part after it.  If the        separator is not found, return two empty strings and S.        &quot;&quot;&quot;        pass   def rsplit(self, sep=None, maxsplit=None):          &quot;&quot;&quot;        S.rsplit([sep [,maxsplit]]) -&gt; list of strings        Return a list of the words in the string S, using sep as the        delimiter string, starting at the end of the string and working        to the front.  If maxsplit is given, at most maxsplit splits are        done. If sep is not specified or is None, any whitespace string        is a separator.        &quot;&quot;&quot;        return []   def rstrip(self, chars=None):          &quot;&quot;&quot;        S.rstrip([chars]) -&gt; string or unicode        Return a copy of the string S with trailing whitespace removed.        If chars is given and not None, remove characters in chars instead.        If chars is unicode, S will be converted to unicode before stripping        &quot;&quot;&quot;        return &quot;&quot;   def split(self, sep=None, maxsplit=None):          &quot;&quot;&quot; 分割， maxsplit最多分割几次 &quot;&quot;&quot;        &quot;&quot;&quot;        S.split([sep [,maxsplit]]) -&gt; list of strings        Return a list of the words in the string S, using sep as the        delimiter string.  If maxsplit is given, at most maxsplit        splits are done. If sep is not specified or is None, any        whitespace string is a separator and empty strings are removed        from the result.        &quot;&quot;&quot;        return []   def splitlines(self, keepends=False):          &quot;&quot;&quot; 根据换行分割 &quot;&quot;&quot;        &quot;&quot;&quot;        S.splitlines(keepends=False) -&gt; list of strings        Return a list of the lines in S, breaking at line boundaries.        Line breaks are not included in the resulting list unless keepends        is given and true.        &quot;&quot;&quot;        return []   def startswith(self, prefix, start=None, end=None):          &quot;&quot;&quot; 是否起始 &quot;&quot;&quot;        &quot;&quot;&quot;        S.startswith(prefix[, start[, end]]) -&gt; bool        Return True if S starts with the specified prefix, False otherwise.        With optional start, test S beginning at that position.        With optional end, stop comparing S at that position.        prefix can also be a tuple of strings to try.        &quot;&quot;&quot;        return False   def strip(self, chars=None):          &quot;&quot;&quot; 移除两段空白 &quot;&quot;&quot;        &quot;&quot;&quot;        S.strip([chars]) -&gt; string or unicode        Return a copy of the string S with leading and trailing        whitespace removed.        If chars is given and not None, remove characters in chars instead.        If chars is unicode, S will be converted to unicode before stripping        &quot;&quot;&quot;        return &quot;&quot;   def swapcase(self):          &quot;&quot;&quot; 大写变小写，小写变大写 &quot;&quot;&quot;        &quot;&quot;&quot;        S.swapcase() -&gt; string        Return a copy of the string S with uppercase characters        converted to lowercase and vice versa.        &quot;&quot;&quot;        return &quot;&quot;   def title(self):          &quot;&quot;&quot;        S.title() -&gt; string        Return a titlecased version of S, i.e. words start with uppercase        characters, all remaining cased characters have lowercase.        &quot;&quot;&quot;        return &quot;&quot;   def translate(self, table, deletechars=None):          &quot;&quot;&quot;        转换，需要先做一个对应表，最后一个表示删除字符集合        intab = &quot;aeiou&quot;        outtab = &quot;12345&quot;        trantab = maketrans(intab, outtab)        str = &quot;this is string example....wow!!!&quot;        print str.translate(trantab, &apos;xm&apos;)        &quot;&quot;&quot;        &quot;&quot;&quot;        S.translate(table [,deletechars]) -&gt; string        Return a copy of the string S, where all characters occurring        in the optional argument deletechars are removed, and the        remaining characters have been mapped through the given        translation table, which must be a string of length 256 or None.        If the table argument is None, no translation is applied and        the operation simply removes the characters in deletechars.        &quot;&quot;&quot;        return &quot;&quot;   def upper(self):          &quot;&quot;&quot;        S.upper() -&gt; string        Return a copy of the string S converted to uppercase.        &quot;&quot;&quot;        return &quot;&quot;   def zfill(self, width):          &quot;&quot;&quot;方法返回指定长度的字符串，原字符串右对齐，前面填充0。&quot;&quot;&quot;        &quot;&quot;&quot;        S.zfill(width) -&gt; string        Pad a numeric string S with zeros on the left, to fill a field        of the specified width.  The string S is never truncated.        &quot;&quot;&quot;        return &quot;&quot;   def _formatter_field_name_split(self, *args, **kwargs): # real signature unknown        pass   def _formatter_parser(self, *args, **kwargs): # real signature unknown        pass   def __add__(self, y):          &quot;&quot;&quot; x.__add__(y) &lt;==&gt; x+y &quot;&quot;&quot;        pass   def __contains__(self, y):          &quot;&quot;&quot; x.__contains__(y) &lt;==&gt; y in x &quot;&quot;&quot;        pass   def __eq__(self, y):          &quot;&quot;&quot; x.__eq__(y) &lt;==&gt; x==y &quot;&quot;&quot;        pass   def __format__(self, format_spec):          &quot;&quot;&quot;        S.__format__(format_spec) -&gt; string        Return a formatted version of S as described by format_spec.        &quot;&quot;&quot;        return &quot;&quot;   def __getattribute__(self, name):          &quot;&quot;&quot; x.__getattribute__(&apos;name&apos;) &lt;==&gt; x.name &quot;&quot;&quot;        pass   def __getitem__(self, y):          &quot;&quot;&quot; x.__getitem__(y) &lt;==&gt; x[y] &quot;&quot;&quot;        pass   def __getnewargs__(self, *args, **kwargs): # real signature unknown        pass   def __getslice__(self, i, j):          &quot;&quot;&quot;        x.__getslice__(i, j) &lt;==&gt; x[i:j]        Use of negative indices is not supported.        &quot;&quot;&quot;        pass   def __ge__(self, y):          &quot;&quot;&quot; x.__ge__(y) &lt;==&gt; x&gt;=y &quot;&quot;&quot;        pass   def __gt__(self, y):          &quot;&quot;&quot; x.__gt__(y) &lt;==&gt; x&gt;y &quot;&quot;&quot;        pass   def __hash__(self):          &quot;&quot;&quot; x.__hash__() &lt;==&gt; hash(x) &quot;&quot;&quot;        pass   def __init__(self, string=&apos;&apos;): # known special case of str.__init__        &quot;&quot;&quot;        str(object=&apos;&apos;) -&gt; string        Return a nice string representation of the object.        If the argument is a string, the return value is the same object.        # (copied from class doc)        &quot;&quot;&quot;        pass   def __len__(self):          &quot;&quot;&quot; x.__len__() &lt;==&gt; len(x) &quot;&quot;&quot;        pass   def __le__(self, y):          &quot;&quot;&quot; x.__le__(y) &lt;==&gt; x&lt;=y &quot;&quot;&quot;        pass   def __lt__(self, y):          &quot;&quot;&quot; x.__lt__(y) &lt;==&gt; x&lt;y &quot;&quot;&quot;        pass   def __mod__(self, y):          &quot;&quot;&quot; x.__mod__(y) &lt;==&gt; x%y &quot;&quot;&quot;        pass   def __mul__(self, n):          &quot;&quot;&quot; x.__mul__(n) &lt;==&gt; x*n &quot;&quot;&quot;        pass        @staticmethod # known case of __new__   def __new__(S, *more):          &quot;&quot;&quot; T.__new__(S, ...) -&gt; a new object with type S, a subtype of T &quot;&quot;&quot;        pass   def __ne__(self, y):          &quot;&quot;&quot; x.__ne__(y) &lt;==&gt; x!=y &quot;&quot;&quot;        pass   def __repr__(self):          &quot;&quot;&quot; x.__repr__() &lt;==&gt; repr(x) &quot;&quot;&quot;        pass   def __rmod__(self, y):          &quot;&quot;&quot; x.__rmod__(y) &lt;==&gt; y%x &quot;&quot;&quot;        pass   def __rmul__(self, n):          &quot;&quot;&quot; x.__rmul__(n) &lt;==&gt; n*x &quot;&quot;&quot;        pass   def __sizeof__(self):          &quot;&quot;&quot; S.__sizeof__() -&gt; size of S in memory, in bytes &quot;&quot;&quot;        pass   def __str__(self):          &quot;&quot;&quot; x.__str__() &lt;==&gt; str(x) &quot;&quot;&quot;        pass</code></pre><h2 id="int数字"><a href="#int数字" class="headerlink" title="int数字"></a>int数字</h2><pre><code>class int(object):    &quot;&quot;&quot;      int(x=0) -&gt; int or long     int(x, base=10) -&gt; int or long     Convert a number or string to an integer, or return 0 if no arguments     are given.  If x is floating point, the conversion truncates towards zero.     If x is outside the integer range, the function returns a long instead.     If x is not a number or if base is given, then x must be a string or     Unicode object representing an integer literal in the given base.  The     literal can be preceded by &apos;+&apos; or &apos;-&apos; and be surrounded by whitespace.     The base defaults to 10.  Valid bases are 0 and 2-36.  Base 0 means to     interpret the base from the string as an integer literal.     &gt;&gt;&gt; int(&apos;0b100&apos;, base=0)     4    &quot;&quot;&quot;   def bit_length(self):         &quot;&quot;&quot; 返回表示该数字的时占用的最少位数 &quot;&quot;&quot;        &quot;&quot;&quot;        int.bit_length() -&gt; int        Number of bits necessary to represent self in binary.        &gt;&gt;&gt; bin(37)        &apos;0b100101&apos;        &gt;&gt;&gt; (37).bit_length()        6        &quot;&quot;&quot;        return 0   def conjugate(self, *args, **kwargs): # real signature unknown        &quot;&quot;&quot; 返回该复数的共轭复数 &quot;&quot;&quot;        &quot;&quot;&quot; Returns self, the complex conjugate of any int. &quot;&quot;&quot;        pass   def __abs__(self):        &quot;&quot;&quot; 返回绝对值 &quot;&quot;&quot;        &quot;&quot;&quot; x.__abs__() &lt;==&gt; abs(x) &quot;&quot;&quot;        pass   def __add__(self, y):        &quot;&quot;&quot; x.__add__(y) &lt;==&gt; x+y &quot;&quot;&quot;        pass   def __and__(self, y):        &quot;&quot;&quot; x.__and__(y) &lt;==&gt; x&amp;y &quot;&quot;&quot;        pass   def __cmp__(self, y):         &quot;&quot;&quot; 比较两个数大小 &quot;&quot;&quot;        &quot;&quot;&quot; x.__cmp__(y) &lt;==&gt; cmp(x,y) &quot;&quot;&quot;        pass   def __coerce__(self, y):        &quot;&quot;&quot; 强制生成一个元组 &quot;&quot;&quot;         &quot;&quot;&quot; x.__coerce__(y) &lt;==&gt; coerce(x, y) &quot;&quot;&quot;        pass   def __divmod__(self, y):         &quot;&quot;&quot; 相除，得到商和余数组成的元组 &quot;&quot;&quot;         &quot;&quot;&quot; x.__divmod__(y) &lt;==&gt; divmod(x, y) &quot;&quot;&quot;        pass   def __div__(self, y):         &quot;&quot;&quot; x.__div__(y) &lt;==&gt; x/y &quot;&quot;&quot;        pass   def __float__(self):         &quot;&quot;&quot; 转换为浮点类型 &quot;&quot;&quot;         &quot;&quot;&quot; x.__float__() &lt;==&gt; float(x) &quot;&quot;&quot;        pass   def __floordiv__(self, y):         &quot;&quot;&quot; x.__floordiv__(y) &lt;==&gt; x//y &quot;&quot;&quot;        pass   def __format__(self, *args, **kwargs): # real signature unknown        pass   def __getattribute__(self, name):         &quot;&quot;&quot; x.__getattribute__(&apos;name&apos;) &lt;==&gt; x.name &quot;&quot;&quot;        pass   def __getnewargs__(self, *args, **kwargs): # real signature unknown        &quot;&quot;&quot; 内部调用 __new__方法或创建对象时传入参数使用 &quot;&quot;&quot;         pass   def __hash__(self):         &quot;&quot;&quot;如果对象object为哈希表类型，返回对象object的哈希值。哈希值为整数。在字典查找中，哈希值用于快速比较字典的键。两个数值如果相等，则哈希值也相等。&quot;&quot;&quot;        &quot;&quot;&quot; x.__hash__() &lt;==&gt; hash(x) &quot;&quot;&quot;        pass   def __hex__(self):         &quot;&quot;&quot; 返回当前数的 十六进制 表示 &quot;&quot;&quot;         &quot;&quot;&quot; x.__hex__() &lt;==&gt; hex(x) &quot;&quot;&quot;        pass   def __index__(self):         &quot;&quot;&quot; 用于切片，数字无意义 &quot;&quot;&quot;        &quot;&quot;&quot; x[y:z] &lt;==&gt; x[y.__index__():z.__index__()] &quot;&quot;&quot;        pass   def __init__(self, x, base=10): # known special case of int.__init__        &quot;&quot;&quot; 构造方法，执行 x = 123 或 x = int(10) 时，自动调用，暂时忽略 &quot;&quot;&quot;         &quot;&quot;&quot;        int(x=0) -&gt; int or long        int(x, base=10) -&gt; int or long        Convert a number or string to an integer, or return 0 if no arguments        are given.  If x is floating point, the conversion truncates towards zero.        If x is outside the integer range, the function returns a long instead.        If x is not a number or if base is given, then x must be a string or        Unicode object representing an integer literal in the given base.  The        literal can be preceded by &apos;+&apos; or &apos;-&apos; and be surrounded by whitespace.        The base defaults to 10.  Valid bases are 0 and 2-36.  Base 0 means to        interpret the base from the string as an integer literal.        &gt;&gt;&gt; int(&apos;0b100&apos;, base=0)        4        # (copied from class doc)        &quot;&quot;&quot;        pass   def __int__(self):         &quot;&quot;&quot; 转换为整数 &quot;&quot;&quot;         &quot;&quot;&quot; x.__int__() &lt;==&gt; int(x) &quot;&quot;&quot;        pass   def __invert__(self):         &quot;&quot;&quot; x.__invert__() &lt;==&gt; ~x &quot;&quot;&quot;        pass   def __long__(self):         &quot;&quot;&quot; 转换为长整数 &quot;&quot;&quot;         &quot;&quot;&quot; x.__long__() &lt;==&gt; long(x) &quot;&quot;&quot;        pass   def __lshift__(self, y):         &quot;&quot;&quot; x.__lshift__(y) &lt;==&gt; x&lt;&lt;y &quot;&quot;&quot;    pass   def __mod__(self, y):         &quot;&quot;&quot; x.__mod__(y) &lt;==&gt; x%y &quot;&quot;&quot;        pass   def __mul__(self, y):         &quot;&quot;&quot; x.__mul__(y) &lt;==&gt; x*y &quot;&quot;&quot;        pass   def __neg__(self):         &quot;&quot;&quot; x.__neg__() &lt;==&gt; -x &quot;&quot;&quot;        pass        @staticmethod # known case of __new__   def __new__(S, *more):         &quot;&quot;&quot; T.__new__(S, ...) -&gt; a new object with type S, a subtype of T &quot;&quot;&quot;        pass   def __nonzero__(self):         &quot;&quot;&quot; x.__nonzero__() &lt;==&gt; x != 0 &quot;&quot;&quot;        pass   def __oct__(self):         &quot;&quot;&quot; 返回改值的 八进制 表示 &quot;&quot;&quot;         &quot;&quot;&quot; x.__oct__() &lt;==&gt; oct(x) &quot;&quot;&quot;        pass   def __or__(self, y):         &quot;&quot;&quot; x.__or__(y) &lt;==&gt; x|y &quot;&quot;&quot;        pass   def __pos__(self):         &quot;&quot;&quot; x.__pos__() &lt;==&gt; +x &quot;&quot;&quot;        pass   def __pow__(self, y, z=None):         &quot;&quot;&quot; 幂，次方 &quot;&quot;&quot;         &quot;&quot;&quot; x.__pow__(y[, z]) &lt;==&gt; pow(x, y[, z]) &quot;&quot;&quot;        pass   def __radd__(self, y):         &quot;&quot;&quot; x.__radd__(y) &lt;==&gt; y+x &quot;&quot;&quot;        pass   def __rand__(self, y):         &quot;&quot;&quot; x.__rand__(y) &lt;==&gt; y&amp;x &quot;&quot;&quot;        pass   def __rdivmod__(self, y):         &quot;&quot;&quot; x.__rdivmod__(y) &lt;==&gt; divmod(y, x) &quot;&quot;&quot;        pass   def __rdiv__(self, y):         &quot;&quot;&quot; x.__rdiv__(y) &lt;==&gt; y/x &quot;&quot;&quot;        pass   def __repr__(self):         &quot;&quot;&quot;转化为解释器可读取的形式 &quot;&quot;&quot;        &quot;&quot;&quot; x.__repr__() &lt;==&gt; repr(x) &quot;&quot;&quot;        pass   def __str__(self):         &quot;&quot;&quot;转换为人阅读的形式，如果没有适于人阅读的解释形式的话，则返回解释器课阅读的形式&quot;&quot;&quot;        &quot;&quot;&quot; x.__str__() &lt;==&gt; str(x) &quot;&quot;&quot;        pass   def __rfloordiv__(self, y):         &quot;&quot;&quot; x.__rfloordiv__(y) &lt;==&gt; y//x &quot;&quot;&quot;        pass   def __rlshift__(self, y):         &quot;&quot;&quot; x.__rlshift__(y) &lt;==&gt; y&lt;&lt;x &quot;&quot;&quot;        pass   def __rmod__(self, y):         &quot;&quot;&quot; x.__rmod__(y) &lt;==&gt; y%x &quot;&quot;&quot;        pass   def __rmul__(self, y):         &quot;&quot;&quot; x.__rmul__(y) &lt;==&gt; y*x &quot;&quot;&quot;        pass   def __ror__(self, y):         &quot;&quot;&quot; x.__ror__(y) &lt;==&gt; y|x &quot;&quot;&quot;        pass   def __rpow__(self, x, z=None):         &quot;&quot;&quot; y.__rpow__(x[, z]) &lt;==&gt; pow(x, y[, z]) &quot;&quot;&quot;        pass   def __rrshift__(self, y):         &quot;&quot;&quot; x.__rrshift__(y) &lt;==&gt; y&gt;&gt;x &quot;&quot;&quot;        pass   def __rshift__(self, y):         &quot;&quot;&quot; x.__rshift__(y) &lt;==&gt; x&gt;&gt;y &quot;&quot;&quot;        pass   def __rsub__(self, y):         &quot;&quot;&quot; x.__rsub__(y) &lt;==&gt; y-x &quot;&quot;&quot;        pass   def __rtruediv__(self, y):         &quot;&quot;&quot; x.__rtruediv__(y) &lt;==&gt; y/x &quot;&quot;&quot;        pass   def __rxor__(self, y):         &quot;&quot;&quot; x.__rxor__(y) &lt;==&gt; y^x &quot;&quot;&quot;        pass   def __sub__(self, y):         &quot;&quot;&quot; x.__sub__(y) &lt;==&gt; x-y &quot;&quot;&quot;        pass   def __truediv__(self, y):         &quot;&quot;&quot; x.__truediv__(y) &lt;==&gt; x/y &quot;&quot;&quot;        pass   def __trunc__(self, *args, **kwargs):         &quot;&quot;&quot; 返回数值被截取为整形的值，在整形中无意义 &quot;&quot;&quot;        pass   def __xor__(self, y):         &quot;&quot;&quot; x.__xor__(y) &lt;==&gt; x^y &quot;&quot;&quot;        pass        denominator = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default        &quot;&quot;&quot; 分母 = 1 &quot;&quot;&quot;        &quot;&quot;&quot;the denominator of a rational number in lowest terms&quot;&quot;&quot;        imag = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default        &quot;&quot;&quot; 虚数，无意义 &quot;&quot;&quot;        &quot;&quot;&quot;the imaginary part of a complex number&quot;&quot;&quot;        numerator = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default        &quot;&quot;&quot; 分子 = 数字大小 &quot;&quot;&quot;        &quot;&quot;&quot;the numerator of a rational number in lowest terms&quot;&quot;&quot;        real = property(lambda self: object(), lambda self, v: None, lambda self: None)  # default        &quot;&quot;&quot; 实属，无意义 &quot;&quot;&quot;        &quot;&quot;&quot;the real part of a complex number&quot;&quot;&quot;</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;str类&quot;&gt;&lt;a href=&quot;#str类&quot; class=&quot;headerlink&quot; title=&quot;str类&quot;&gt;&lt;/a&gt;str类&lt;/h2&gt;
    
    </summary>
    
      <category term="python" scheme="http://datura.me/categories/python/"/>
    
    
      <category term="python" scheme="http://datura.me/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>linux开机启动顺序</title>
    <link href="http://datura.me/2017/06/28/linux%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8%E9%A1%BA%E5%BA%8F/"/>
    <id>http://datura.me/2017/06/28/linux开机启动顺序/</id>
    <published>2017-06-28T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.723Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://blog.chinaunix.net/attachment/201209/23/26495963_1348382510SRUx.png" alt="">  </p><h2 id="启动第一步－－加载BIOS"><a href="#启动第一步－－加载BIOS" class="headerlink" title="启动第一步－－加载BIOS"></a>启动第一步－－加载BIOS</h2><p>当你打开计算机电源，计算机会首先加载BIOS信息，BIOS信息是如此的重要，以至于计算机必须在最开始就找到它。这是因为BIOS中包含了CPU的相关信息、设备启动顺序信息、硬盘信息、内存信息、时钟信息、PnP特性等等。在此之后，计算机心里就有谱了，知道应该去读取哪个硬件设备了。  </p><a id="more"></a><h2 id="启动第二步－－读取MBR"><a href="#启动第二步－－读取MBR" class="headerlink" title="启动第二步－－读取MBR"></a>启动第二步－－读取MBR</h2><p>众所周知，硬盘上第0磁道第一个扇区被称为MBR，也就是Master Boot Record，即主引导记录，它的大小是512字节，别看地方不大，可里面却存放了预启动信息、分区表信息。<br>系统找到BIOS所指定的硬盘的MBR后，就会将其复制到0×7c00地址所在的物理内存中。其实被复制到物理内存的内容就是Boot Loader，而具体到你的电脑，那就是lilo或者grub了。    </p><h2 id="启动第三步－－Boot-Loader"><a href="#启动第三步－－Boot-Loader" class="headerlink" title="启动第三步－－Boot Loader"></a>启动第三步－－Boot Loader</h2><p>Boot Loader 就是在操作系统内核运行之前运行的一段小程序。通过这段小程序，我们可以初始化硬件设备、建立内存空间的映射图，从而将系统的软硬件环境带到一个合适的状态，以便为最终调用操作系统内核做好一切准备。<br>Boot Loader有若干种，其中Grub、Lilo和spfdisk是常见的Loader。<br>我们以Grub为例来讲解吧，毕竟用lilo和spfdisk的人并不多。<br>系统读取内存中的grub配置信息（一般为menu.lst或grub.lst），并依照此配置信息来启动不同的操作系统。  </p><h2 id="启动第四步－－加载内核"><a href="#启动第四步－－加载内核" class="headerlink" title="启动第四步－－加载内核"></a>启动第四步－－加载内核</h2><p>根据grub设定的内核映像所在路径，系统读取内存映像，并进行解压缩操作。此时，屏幕一般会输出“Uncompressing Linux”的提示。当解压缩内核完成后，屏幕输出“OK, booting the kernel”。<br>系统将解压后的内核放置在内存之中，并调用start_kernel()函数来启动一系列的初始化函数并初始化各种设备，完成Linux核心环境的建立。至此，Linux内核已经建立起来了，基于Linux的程序应该可以正常运行了。  </p><h2 id="启动第五步－－用户层init依据inittab文件来设定运行等级"><a href="#启动第五步－－用户层init依据inittab文件来设定运行等级" class="headerlink" title="启动第五步－－用户层init依据inittab文件来设定运行等级"></a>启动第五步－－用户层init依据inittab文件来设定运行等级</h2><p>内核被加载后，第一个运行的程序便是/sbin/init，该文件会读取/etc/inittab文件，并依据此文件来进行初始化工作。<br>其实/etc/inittab文件最主要的作用就是设定Linux的运行等级，其设定形式是“：id:5:initdefault:”，这就表明Linux需要运行在等级5上。Linux的运行等级设定如下：<br>0：关机<br>1：单用户模式<br>2：无网络支持的多用户模式<br>3：有网络支持的多用户模式<br>4：保留，未使用<br>5：有网络支持有X-Window支持的多用户模式<br>6：重新引导系统，即重启<br>关于/etc/inittab文件的学问，其实还有很多  </p><h2 id="启动第六步－－init进程执行rc-sysinit"><a href="#启动第六步－－init进程执行rc-sysinit" class="headerlink" title="启动第六步－－init进程执行rc.sysinit"></a>启动第六步－－init进程执行rc.sysinit</h2><p>在设定了运行等级后，Linux系统执行的第一个用户层文件就是/etc/rc.d/rc.sysinit脚本程序，它做的工作非常多，包括设定PATH、设定网络配置（/etc/sysconfig/network）、启动swap分区、设定/proc等等。如果你有兴趣，可以到/etc/rc.d中查看一下rc.sysinit文件，里面的脚本够你看几天的  </p><h2 id="启动第七步－－启动内核模块"><a href="#启动第七步－－启动内核模块" class="headerlink" title="启动第七步－－启动内核模块"></a>启动第七步－－启动内核模块</h2><p>具体是依据/etc/modules.conf文件或/etc/modules.d目录下的文件来装载内核模块。  </p><h2 id="启动第八步－－执行不同运行级别的脚本程序"><a href="#启动第八步－－执行不同运行级别的脚本程序" class="headerlink" title="启动第八步－－执行不同运行级别的脚本程序"></a>启动第八步－－执行不同运行级别的脚本程序</h2><p>根据运行级别的不同，系统会运行rc0.d到rc6.d中的相应的脚本程序，来完成相应的初始化工作和启动相应的服务。  </p><h2 id="启动第九步－－执行-etc-rc-d-rc-local"><a href="#启动第九步－－执行-etc-rc-d-rc-local" class="headerlink" title="启动第九步－－执行/etc/rc.d/rc.local"></a>启动第九步－－执行/etc/rc.d/rc.local</h2><p>你如果打开了此文件，里面有一句话，读过之后，你就会对此命令的作用一目了然：  </p><h1 id="This-script-will-be-executed-after-all-the-other-init-scripts"><a href="#This-script-will-be-executed-after-all-the-other-init-scripts" class="headerlink" title="This script will be executed after all the other init scripts."></a>This script will be executed <em>after</em> all the other init scripts.</h1><h1 id="You-can-put-your-own-initialization-stuff-in-here-if-you-don’t"><a href="#You-can-put-your-own-initialization-stuff-in-here-if-you-don’t" class="headerlink" title="You can put your own initialization stuff in here if you don’t"></a>You can put your own initialization stuff in here if you don’t</h1><h1 id="want-to-do-the-full-Sys-V-style-init-stuff"><a href="#want-to-do-the-full-Sys-V-style-init-stuff" class="headerlink" title="want to do the full Sys V style init stuff."></a>want to do the full Sys V style init stuff.</h1><p>rc.local就是在一切初始化工作后，Linux留给用户进行个性化的地方。你可以把你想设置和启动的东西放到这里。  </p><h2 id="启动第十步－－执行-bin-login程序，进入登录状态"><a href="#启动第十步－－执行-bin-login程序，进入登录状态" class="headerlink" title="启动第十步－－执行/bin/login程序，进入登录状态"></a>启动第十步－－执行/bin/login程序，进入登录状态</h2><p>此时，系统已经进入到了等待用户输入username和password的时候了，你已经可以用自己的帐号登入系统了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://blog.chinaunix.net/attachment/201209/23/26495963_1348382510SRUx.png&quot; alt=&quot;&quot;&gt;  &lt;/p&gt;
&lt;h2 id=&quot;启动第一步－－加载BIOS&quot;&gt;&lt;a href=&quot;#启动第一步－－加载BIOS&quot; class=&quot;headerlink&quot; title=&quot;启动第一步－－加载BIOS&quot;&gt;&lt;/a&gt;启动第一步－－加载BIOS&lt;/h2&gt;&lt;p&gt;当你打开计算机电源，计算机会首先加载BIOS信息，BIOS信息是如此的重要，以至于计算机必须在最开始就找到它。这是因为BIOS中包含了CPU的相关信息、设备启动顺序信息、硬盘信息、内存信息、时钟信息、PnP特性等等。在此之后，计算机心里就有谱了，知道应该去读取哪个硬件设备了。  &lt;/p&gt;
    
    </summary>
    
      <category term="linux" scheme="http://datura.me/categories/linux/"/>
    
    
      <category term="linux" scheme="http://datura.me/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>git使用说明详解</title>
    <link href="http://datura.me/2017/06/16/git%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/"/>
    <id>http://datura.me/2017/06/16/git使用说明/</id>
    <published>2017-06-16T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.723Z</updated>
    
    <content type="html"><![CDATA[<p>1.下载geekery.repo文件，具体操作如下：<br><a id="more"></a><br>找到存放yum文件的目录，命令如下：  </p><p>  <code>cd /etc/yum.repos.d/</code></p><blockquote><p> [geekery]<br>name = geekery repository<br>baseurl = <a href="http://geekery.altervista.org/geekery/el6/x86_64" target="_blank" rel="noopener">http://geekery.altervista.org/geekery/el6/x86_64</a><br><code>#mirrorlist = http://geekery.altervista.org/mirrors-geekery</code><br>enabled = 1<br>protect = 0<br>gpgkey = <a href="http://geekery.altervista.org/download.php?filename=GEEKERY-GPG-KEY" target="_blank" rel="noopener">http://geekery.altervista.org/download.php?filename=GEEKERY-GPG-KEY</a><br>gpgcheck = 1  </p></blockquote><p>2.下载rpmforge-release rpm包  </p><p>i386 <a href="http://apt.sw.be/redhat/el5/en/i386/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.i386.rpm" target="_blank" rel="noopener">http://apt.sw.be/redhat/el5/en/i386/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.i386.rpm</a><br>x86_64 <a href="http://apt.sw.be/redhat/el5/en/x86_64/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.x86_64.rpm" target="_blank" rel="noopener">http://apt.sw.be/redhat/el5/en/x86_64/RPMS.dag/rpmforge-release-0.3.6-1.el5.rf.x86_64.rpm</a></p><p><code>rpm -ivh rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm</code></p><p>3.下载epel-release rpm包，地址：<a href="http://rpm.pbone.net/，搜索epel-release，下载对应系统和适应的rmp包，之后执行安装命令如下：" target="_blank" rel="noopener">http://rpm.pbone.net/，搜索epel-release，下载对应系统和适应的rmp包，之后执行安装命令如下：</a>  </p><p><code>rpm -ivh epel-release-6-8.1.noarch.rpm</code>  </p><p>4.安装git<br><code>yum -y install git</code></p><p>5.git使用  </p><h2 id="配置git"><a href="#配置git" class="headerlink" title="配置git"></a>配置git</h2><p>   首先配置git信息（git使用者的用户名及邮箱）<br>   配置好这两项，用户就可以知道谁做了什么</p><p>   <code>git config --global user.name &quot;My Name&quot;</code><br>   <code>git config --global user.email myEmail@example.com</code>  </p><h2 id="创建一个新仓库"><a href="#创建一个新仓库" class="headerlink" title="创建一个新仓库"></a>创建一个新仓库</h2><p>git 会把所有文件以及历史记录保存在你的项目中，创建一个新的仓库，首先要去到项目路径，执行 git init。然后git会创建一个隐藏的文件夹.git，所有的信息都储存在其中。<br><code>cd Desktop/git_exercise/</code><br><code>git init</code><br>现在项目还什么都没有新建一个hello.txt文件试试</p><h2 id="检查状态"><a href="#检查状态" class="headerlink" title="检查状态"></a>检查状态</h2><p>git status 是另一个非常重要的命令，它会告诉我们创库的当前状态：是否为最新代码，有什么更新等等执行git status:<br><code>git status</code></p><blockquote><p> $ git status</p><p>On branch master</p><p>Initial commit</p><p>Untracked files:<br>  (use “git add …” to include in what will be committed)</p><p>  hello.txt<br>git  </p></blockquote><p>告诉我们，hello.txt尚未跟踪，这是因为这个文件是新的，git不知道是应该跟踪它的变动呢，还是直接忽略不管呢。为了跟踪我们的新文件，我们需要暂存它。</p><h2 id="暂存git"><a href="#暂存git" class="headerlink" title="暂存git"></a>暂存git</h2><p>git 有个概念叫 暂存区，你可以把它看成一块空白帆布，包裹着所有你可能会提交的变动。它一开始为空，你可以通过 git add 命令添加内容，并使用 git commit 提交。<br>这个例子中只有一个文件：  </p><p>提交hello.txt文件：<br><code>git add hello.txt</code>  </p><p>如果需要提交目录下的所有内容，可以这样：<br><code>git add -A</code>  </p><p>再次使用git status查看：<br><code>git status</code></p><blockquote><p>On branch master</p><p>Initial commit</p><p>Changes to be committed:<br>  (use “git rm –cached …” to unstage)</p><p>new file:   hello.txt</p></blockquote><p>我们的文件已经提交了。状态信息还会告诉我们暂存区文件发生了什么变动，不过这里我们提交的是一个全新文件。</p><h2 id="提交本地git分支"><a href="#提交本地git分支" class="headerlink" title="提交本地git分支"></a>提交本地git分支</h2><p>一次提交代表着我们的仓库到了一个交付状态，通常是完成了某一块小功能。它就像是一个快照，允许我们像使用时光机一样回到旧时光。<br>创建提交，需要我们提交东西到暂存区（git add），然后：  </p><blockquote><p>   <code>git commit -m &quot;Initial commit.&quot;</code><br>这就创建了一次提交，-m “Initial commit.”表示对这次提交的描述，建议使用有意义的描述性信息。<br>远端仓库<br>到目前为止，我们的操作都是在本地的，它存在于.git文件中。为了能够协同开发，我们需要把代码发布到远端仓库上。<br>1.链接远端仓库 - git remote add<br>为了能够上传到远端仓库，我们需要先建立起链接，这篇教程中，远端仓库的地址为：<a href="https://github.com/tutorialzine/awesome-project,但你应该自己在Github" target="_blank" rel="noopener">https://github.com/tutorialzine/awesome-project,但你应该自己在Github</a>,<br>BitBucket上搭建仓库，自己一步一步尝试。<br>添加测试用的远端仓库<br><code>git remote add origin https://github.com/tutorialzine/awesome-project.git</code><br>一个项目可以同时拥有好几个远端仓库为了能够区分，通常会起不同的名字。通常主远端仓库被称为origin。<br>2.上传到服务器 - git push<br>每次我们要提交代码到服务器上时，都会使用到git push。<br>git push命令会有两个参数，远端仓库的名字，以及分支的名字：<br><code>git push origin master</code></p><p>Counting objects: 3, done.<br>Writing objects: 100% (3/3), 212 bytes | 0 bytes/s, done.<br>Total 3 (delta 0), reused 0 (delta 0)<br>To <a href="https://github.com/tutorialzine/awesome-project.git" target="_blank" rel="noopener">https://github.com/tutorialzine/awesome-project.git</a>  </p><ul><li>[new branch]      master -master  </li></ul></blockquote><blockquote><p>取决于你使用的服务器，push过程你可能需要验证身份。如果没有出差错，现在使用浏览器去你的远端分支上看，hello.txt已经在那里等着你了。<br>3.克隆仓库 - git clone<br>放在Github上的开源项目，人们可以看到你的代码。可以使用 git clone进行下载到本地。<br><code>git clone https://github.com/tutorialzine/awesome-project.git</code><br>本地也会创建一个新的仓库，并自动将github上的分支设为远端分支。<br>4.从服务器上拉取代码 - git pull<br>如果你更新了代码到仓库上，其他人可以通过git pull命令拉取你的变动：<br><code>git pull origin master</code><br>From <a href="https://github.com/tutorialzine/awesome-project" target="_blank" rel="noopener">https://github.com/tutorialzine/awesome-project</a>  </p><ul><li>branch            master     -FETCH_HEAD<br>Already up-to-date.  </li></ul></blockquote><blockquote><p>因为暂时没有其他人提交，所有没有任何变动分支</p><p>branchs<br>当你在做一个新功能的时候，最好是在一个独立的区域上开发，通常称之为分支。分支之间相互独立，并且拥有自己的历史记录。这样做的原因是：<br>稳定版本的代码不会被破坏<br>不同的功能可以由不同开发者同时开发。<br>开发者可以专注于自己的分支，不用担心被其他人破坏了环境<br>在不确定之前，同一个特性可以拥有几个版本，便于比较<br>1.创建新分支 - git branch<br>每一个仓库的默认分支都叫master, 创建新分支可以这样：<br><code>git branch amazing_new_feature</code><br>创建了一个名为amazing_new_feature的新分支，它跟当前分支同一起点<br>2.切换分支 - git checkout<br>单独使用git branch，可以查看分支状态：<br><code>git branch</code><br>  amazing_new_feature  </p><ul><li><p>master  </p></li><li><p>号表示当前活跃分支为master，使用git checkout切换分支。<br>$ git checkout amazing_new_feature<br>3.合并分支 - git merge<br>我们的 amazing_new_feature 分支的任务是增加一个featuer.txt。我们来创建，添加到暂存区，提交。<br><code>git add feature.txt</code><br><code>git commit -m &quot;New feature complete.&quot;</code><br>新分支任务完成了，回到master分支<br><code>git checkout master</code><br>现在去查看文件，你会发现，之前创建的feature.txt文件不见了，因为master分支上并没有feature.txt。使用git merge 把 amazing_new_feature 分支合并到master上。<br><code>git merge amazing_new_feature</code><br>ok! 然后再把amazing_new_feature 分支删掉吧。<br><code>git branch -d amazing_new_feature</code>  </p></li></ul><p>高级<br>1.比对两个不同提交之间的差别<br>每次提交都有一个唯一id，查看所有提交和他们的id，可以使用 git log:<br><code>git log</code></p><p>commit ba25c0ff30e1b2f0259157b42b9f8f5d174d80d7<br>Author: Tutorialzine<br>Date:   Mon May 30 17:15:28 2016 +0300  </p><p>  New feature complete  </p><p>commit b10cc1238e355c02a044ef9f9860811ff605c9b4<br>Author: Tutorialzine<br>Date:   Mon May 30 16:30:04 2016 +0300  </p><p>   Added content to hello.txt  </p><p>commit 09bd8cc171d7084e78e4d118a2346b7487dca059<br>Author: Tutorialzine<br>Date:   Sat May 28 17:52:14 2016 +0300  </p><p>   Initial commit<br>id 很长，但是你并不需要复制整个字符串，前一小部分就够了。<br>查看某一次提交更新了什么，使用 git show:<br><code>git show b10cc123</code>  </p><p>commit b10cc1238e355c02a044ef9f9860811ff605c9b4<br>Author: Tutorialzine<br>Date:   Mon May 30 16:30:04 2016 +0300  </p><p>   Added content to hello.txt  </p><p>diff –git a/hello.txt b/hello.txt<br>index e69de29..b546a21 100644<br>— a/hello.txt<br>+++ b/hello.txt<br>@@ -0,0 +1 @@<br>+Nice weather today, isn’t it?<br>查看两次提交的不同，可以使用git diff [commit-from]..[commit-to] 语法：<br><code>git diff 09bd8cc..ba25c0ff</code>  </p><p>diff –git a/feature.txt b/feature.txt<br>new file mode 100644<br>index 0000000..e69de29<br>diff –git a/hello.txt b/hello.txt<br>index e69de29..b546a21 100644<br>— a/hello.txt<br>+++ b/hello.txt<br>@@ -0,0 +1 @@<br>+Nice weather today, isn’t it?<br>比较首次提交和最后一次提交，我们可以看到所有的更改。当然使用git difftool命令更加方便。<br>2.回滚某个文件到之前的版本<br>git 允许我们将某个特定的文件回滚到特定的提交，使用的也是 git checkout。<br>下面的例子，我们将hello.txt回滚到最初的状态，需要指定回滚到哪个提交，以及文件的全路径。<br><code>git checkout 09bd8cc1 hello.txt</code><br>3.回滚提交<br>如果你发现最新的一次提交完了加某个文件，你可以通过 git commit —amend来修复，它会把最新的提交打回暂存区，并尝试重新提交。<br>如果是更复杂的情况，比如不是最新的提交了。那你可以使用git revert。<br>最新的一次提交别名也叫HEAD。<br><code>git revert HEAD</code><br>其他提交可以使用id:<br><code>git revert b10cc123</code><br>混滚提交时，发生冲突是非常频繁的。当文件被后面的提交修改了以后，git不能正确回滚。<br>4.解决合并冲突<br>冲突经常出现在合并分支或者是拉去别人的代码。有些时候git能自动处理冲突，但大部分需要我们手动处理。<br>比如John 和 Tim 分别在各自的分支上写了两部分代码。<br>John 喜欢 for:<br>// Use a for loop to console.log contents.<br>for(var i=0; i&lt;arr.length;<br>i++) {<br>console.log(arr[i]);<br>}<br>Tim 喜欢 forEach:<br>// Use forEach to console.log contents.<br>arr.forEach(function(item)<br>{<br>console.log(item);<br>});<br>假设John 现在去拉取 Tim的代码:<br><code>git merge tim_branch</code>  </p><p>Auto-merging print_array.js<br>CONFLICT (content): Merge conflict in print_array.js<br>Automatic merge failed; fix conflicts and then commit the result.<br>这时候git并不知道如何解决冲突，因为他不知道John和Tim谁写得更好。<br>于是它就在代码中插入标记。<br>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD<br>// Use a for loop to console.log contents.<br>for(var i=0; i&lt;arr.length; i++) {<br>    console.log(arr[i]); } </p><p>=======<br>// Use forEach to console.log contents.<br>arr.forEach(function(item) {<br>    console.log(item);<br>});  </p><p>====<br>号上方是当前最新一次提交，下方是冲突的代码。我们需要解决这样的冲突，经过组委会成员讨论，一致认定，在座的各位都是垃圾！两个都不要。改成下面的代码。<br>// Not using for loop or forEach.<br>// Use Array.toString() to console.log contents.<br>console.log(arr.toString());<br>好了，再提交一下：<br><code>git add -A</code><br><code>git commit -m &quot;Array printing conflict resolved.&quot;</code><br>如果在大型项目中，这个过程可能容易出问题。你可以使用GUI 工具来帮助你。使用 git mergetool。<br>5.配置 .gitignore<br>大部分项目中，会有写文件，文件夹是我们不想提交的。为了防止一不小心提交，我们需要gitignore文件：<br>在项目根目录创建.gitignore文件<br>在文件中列出不需要提交的文件名，文件夹名，每个一行<br>.gitignore文件需要提交，就像普通文件一样<br>通常会被ignore的文件有：<br>log文件<br>task runner builds<br>node_modules等文件夹<br>IDEs生成的文件<br>个人笔记<br>例如：<br>*.log<br>build/<br>node_modules/<br>.idea/<br>my_notes.txt  </p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1.下载geekery.repo文件，具体操作如下：&lt;br&gt;
    
    </summary>
    
      <category term="git" scheme="http://datura.me/categories/git/"/>
    
    
      <category term="git" scheme="http://datura.me/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>用Kibana和logstash快速搭建实时日志查询、收集与分析系统</title>
    <link href="http://datura.me/2017/03/03/%E7%94%A8Kibana%E5%92%8Clogstash%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E5%AE%9E%E6%97%B6%E6%97%A5%E5%BF%97%E6%9F%A5%E8%AF%A2%E3%80%81%E6%94%B6%E9%9B%86%E4%B8%8E%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"/>
    <id>http://datura.me/2017/03/03/用Kibana和logstash快速搭建实时日志查询、收集与分析系统/</id>
    <published>2017-03-03T05:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.725Z</updated>
    
    <content type="html"><![CDATA[<p> Logstash是一个完全开源的工具，他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索），您可以使用它。说到搜索，logstash带有一个web界面，搜索和展示所有日志。<br>kibana 也是一个开源和免费的工具，他可以帮助您汇总、分析和搜索重要数据日志并提供友好的web界面。他可以为 Logstash 和 ElasticSearch 提供的日志分析的 Web 界面<br><a id="more"></a><br>说到这里，我们看看 kibana 和 logstash到底能为我们做些什么呢？下面是kibana的界面<br><img src="http://img1.51cto.com/attachment/201303/131035239.png" alt=""></p><p>简单来讲他具体的工作流程就是 logstash agent 监控并过滤日志，将过滤后的日志内容发给redis(这里的redis只处理队列不做存储)，logstash index将日志收集在一起交给<br>全文搜索服务ElasticSearch 可以用ElasticSearch进行自定义搜索 通过Kibana 来结合 自定义搜索进行页面展示，下图是 Kibana官网上的流程图<br><img src="http://img1.51cto.com/attachment/201303/131135111.png" alt=""></p><p>好了 让我们一步步的把这套环境搭建起来吧，先看看都需要安装什么软件包<br>ruby 运行Kibana 必须，<br>rubygems 安装ruby扩展必须<br>bundler 功能类似于yum<br>JDK 运行java程序必须<br>redis 用来处理日志队列<br>logstash 收集、过滤日志<br>ElasticSearch 全文搜索服务(logstash集成了一个)<br>kibana 页面展示<br>这里有三台服务器<br>192.168.233.128 logstash index，ElasticSearch，kibana，JDK<br>192.168.233.129 logstash agent，JDK<br>192.168.233.130 redis  </p><p>首先到 logstash index服务器上面，logstash分为 index和aget ，agent负责监控、过滤日志，index负责收集日志并将日志交给ElasticSearch 做搜索,此外 logstash 的收集方式分为 standalone 和 centralized。<br>standalone 是所有功能都在一个服务器上面，自发自收，centralized 就是集中收集，一台服务器接收所有shipper(个人理解就是logstash agent)的日志。<br>其实 logstash本身不分 什么 shipper 和 collector ，只不过就是配置文件不同而已，我们这次按照集中的方式来测试.</p><p>在 logstash index上安装基础的软件环境</p><pre><code>[192.168.233.128 root@nodec:~] # cd /soft/ [192.168.233.128 root@nodec:/soft] # wget http://down1.chinaunix.net/distfiles/jdk-6u13-dlj-linux-i586.bin 从oracle下载实在是太慢了，从CU下载会快一些，如果需要最新版本请访问这里 http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html [192.168.233.128 root@nodec:/soft] # sh jdk-6u13-dlj-linux-i586.bin 输入yes 便开始安装了 安装完成后设置一下 JAVA_HOME [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] # vim /etc/profile export JAVA_HOME=/usr/java export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$CLASSPATH 安装ruby 就比较简单了(Kibana需要ruby 1.8.7以上版本) [192.168.233.128 root@nodec:/soft] # yum install ruby rubygems ..... 安装内容省略 安装完成后用 rubygems 来安装bundler [192.168.233.128 root@nodec:/soft] # /usr/bin/gem install bundler ..... ok 这样基本的环境就已经有了，下面就是安装kibana 和 logstash 其实logstash 就是一个java脚本，不需要安装... 下载即用 [192.168.233.128 root@nodec:/soft] # wget http://logstash.objects.dreamhost.com/release/logstash-1.1.0-monolithic.jar 现在看看 这个脚本应该怎么去执行 [192.168.233.128 root@nodec:/soft] # java -jar /soft/logstash-1.1.0-monolithic.jar -h No such command &quot;-h&quot; Available commands:   -v   -V   --version   agent   web   test 显然没有 -h 参数，不过列出了能用的参数，但是logstash的参数可不止这些， java -jar /soft/logstash-1.1.0-monolithic.jar agent --help 这些是在agent模式下的命令参数 -f, --config CONFIGFILE Load the logstash config from a specific file, directory, or a wildcard. If given a directory or wildcard, config files will be read in order lexigraphically. -e CONFIGSTRING Use the given string as the configuration data. Same syntax as the config file. If not input is specified, &apos;stdin { type =&gt; stdin }&apos; is default. If no output is specified, &apos;stdout { debug =&gt; true }}&apos; is default. -w, --filterworks COUNT Run COUNT filter workers (default: 1) --watchdog-timeout TIMEOUT Set watchdog timeout value. -l, --log FILE Log to a given path. Default is to log to stdout -v Increase verbosity. There are multiple levels of verbosity available with &apos;-vv&apos; currently being the highest --pluginpath PLUGIN_PATH A colon-delimted path to find other logstash plugins in java -jar /soft/logstash-1.1.0-monolithic.jar web --help 下面的是在web界面的参数 --log FILE Log to a given path. Default is stdout. --address ADDRESS Address on which to start webserver. Default is 0.0.0.0. --port PORT Port on which to start webserver. Default is 9292. -B, --elasticsearch-bind-host ADDRESS Address on which to bind elastic search node. -b, --backend URL The backend URL to use. Default is elasticsearch:/// (assumes multicast discovery). You can specify elasticsearch://[host][:port]/[clustername] </code></pre><p>如果上面的这些命令都能执行正常的话就表示 logstash可以使用了，但要让他启动还需要一个配置文件</p><pre><code>[192.168.233.128 root@nodec:/soft] # vim redis.conf input {redis {   host =&gt; &apos;192.168.233.130&apos;   data_type =&gt; &apos;list&apos;   port =&gt; &quot;6379&quot;   key =&gt; &apos;logstash:redis&apos;   type =&gt; &apos;redis-input&apos;    }    }output { elasticsearch { embedded =&gt; true   }    } </code></pre><p>解释一下 logstash的配置文件由 input filter output 等几个基本的部分组成，顾名思义 input 就是在那收集数据，output就是输出到哪，filter代表一个过滤规则意思是什么内容<br>会被收集。<br>上面这段是让 logstash 去192.168.233.130 这个redis服务器上去收集日志 redis端口为6379，key是 logstash:redis 类型为 redis-input ，（注意:这几个值必须跟logstash agent的<br>output 所对应），收集完成后输出到 elasticsearch ,embedded =&gt; true 的意思是使用logstash 内嵌的 elasticsearch。如果有独立的elasticsearch服务器，需要将 这条改为<br>host =&gt; ‘elasticsearch的ip’ port =&gt; 端口<br>好了，这个简单的配置文件可以让logstash开始启动了  </p><pre><code>[192.168.233.128 root@nodec:/soft] # java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf -- web --backend elasticsearch:///?local &amp; [1] 5205 ...这里要等待约5秒钟... 为什么？去问开发者吧 [192.168.233.128 root@nodec:/soft] # I, [2013-03-19T03:23:10.749000 #5205]  INFO -- : Using beta plugin &apos;redis&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T03:23:10.732000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;redis&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} file:/soft/logstash-1.1.0-monolithic.jar!/gems/rack-1.3.4/lib/rack/backports/uri/common_192.rb:53 warning: already initialized constant WFKV_ Mizuno 0.5.0 (Jetty 8.0.y.z-SNAPSHOT) listening on 0.0.0.0:9292 解释一下 上面的命令 agent 代理模式 -f 指定配置文件 --web 其实是个分隔符等于又启动了一个命令，后面的参数就是开启一个web页面默认端口是9292,这个命令如果拆成两个就是这个样子 java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf &amp; java -jar /soft/logstash-1.1.0-monolithic.jar web --backend elasticsearch:///?local &amp; (其实如果用kibana来做web界面的话这一步完全可以省掉了)</code></pre><p>好了，看到9292 端口启动就代表 启动成功了，检查一下</p><pre><code>[192.168.233.128 root@nodec:/soft] # lsof -i:9292 COMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME java5205 root  465u  IPv4 130805   TCP *:armtechdaemon (LISTEN) 其实logstash还启动了一个端口9200，因为启动了内嵌的 elasticsearch，这个9200是 elasticsearch在监听 [192.168.233.128 root@nodec:/soft] # lsof -i:9200 COMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME java5205 root  160u  IPv4 130682   TCP *:wap-wsp (LISTEN) </code></pre><p>现在可以通过浏览器访问一下 <a href="http://192.168.233.128:9292" target="_blank" rel="noopener">http://192.168.233.128:9292</a> 看看logstash是的页面是个什么样子<br><img src="http://img1.51cto.com/attachment/201303/133957451.jpg" alt=""></p><p>现在还不能搜索因为现在还没有数据，其实这个时候 <a href="http://192.168.233.128:9200" target="_blank" rel="noopener">http://192.168.233.128:9200</a> 也是可以访问的，<br>很多开发自己写代码来调用elasticsearch 来实现他们自己的需要，这里就不多说了<br>192.168.233.128 这台logstash index的操作暂时告一段落，下面开始配置logstash的agent<br>登录到 服务器 192.168.233.129 安装基本软件包和logstash</p><pre><code>[192.168.233.129 root@noded:~] # cd /soft/ [192.168.233.129 root@noded:/soft] # wget http://down1.chinaunix.net/distfiles/jdk-6u13-dlj-linux-i586.bin [192.168.233.129 root@noded:/soft] # sh jdk-6u13-dlj-linux-i586.bin 设置 JAVA_HOME [192.168.233.129 root@noded:/soft] # vim /etc/profile export JAVA_HOME=/usr/java export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$CLASSPATH [192.168.233.129 root@noded:/soft] # yum install ruby 192.168.233.129 root@noded:/soft] # wget http://logstash.objects.dreamhost.com/release/logstash-1.1.0-monolithic.jar [192.168.233.129 root@noded:/soft] # vim redis.conf input { file { type =&gt; &quot;producer&quot; path =&gt; &quot;/soft/apache.log&quot; } file { type =&gt; &quot;php-log&quot; path =&gt; &quot;/soft/php.log&quot; } } filter {    grep {    match =&gt; [ &quot;@message&quot;, &quot;mysql|GET|error&quot; ] }    } output {   redis {   host =&gt; &apos;192.168.233.130&apos;   data_type =&gt; &apos;list&apos;   key =&gt; &apos;logstash:redis&apos;    }    } </code></pre><p>大概说一下这个配置文件 input 里的file就是要监视的文件了 这里我监视了两个文件，如果这两个文件有追加的内容就会通过下面的output设置发给 redis服务器<br>filter 里的grep 意思就是 grep…  后面这段就是 日志内容里面只要有匹配 mysql或GET或error的内容就会被过滤出来，发送到 logstash index<br>以上就是一个比较简单的配置文件了，让我们启动他</p><pre><code>[192.168.233.129 root@noded:/soft] # java -jar /soft/logstash-1.1.0-monolithic.jar agent -f /soft/redis.conf &amp; I, [2013-03-19T19:45:35.762000 #2721]  INFO -- : Using beta plugin &apos;file&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T19:45:35.752000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;file&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} I, [2013-03-19T19:45:35.778000 #2721]  INFO -- : Using beta plugin &apos;file&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T19:45:35.778000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;file&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} I, [2013-03-19T19:45:35.804000 #2721]  INFO -- : Using beta plugin &apos;grep&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T19:45:35.803000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;grep&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} I, [2013-03-19T19:45:35.854000 #2721]  INFO -- : Using beta plugin &apos;redis&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status  {&quot;timestamp&quot;:&quot;2013-03-19T19:45:35.853000 -0700&quot;,&quot;message&quot;:&quot;Using beta plugin &apos;redis&apos;. For more information about plugin statuses, see http://logstash.net/docs/1.1.0/plugin-status &quot;,&quot;level&quot;:&quot;info&quot;} </code></pre><p>只要没有 warning 和 error就算是正常启动了<br>启动之前请确定 192.168.233.130的 redis服务器已经启动，不然会报错<br>下面登录到 192.168.233.130 上看看 redis服务的状态</p><pre><code>[192.168.233.130 root@nodea:/data/redis/etc] # lsof -i:6379 COMMANDPID USER   FD   TYPE DEVICE SIZE NODE NAME redis-ser 2732 root4u  IPv4   7946   TCP *:6379 (LISTEN) redis-ser 2732 root5u  IPv4   7963   TCP localhost.localdomain:6379-&gt;localhost.localdomain:19214 (ESTABLISHED) java  2733 root9u  IPv4   7959   TCP localhost.localdomain:19214-&gt;localhost.localdomain:6379 (ESTABLISHED) 状态正常，端口处于监听状态，我用的是最简单的 配置， [192.168.233.130 root@nodea:/data/redis/etc] # vim redis.conf #this is the config file for redis pidfile /var/run/redis.pid port 6379 timeout 0 loglevel verbose logfile /data/redis/log/redis.log dbfilename dump.rdb dir /data/redis/db/ vm-swap-file /tmp/redis.swap activerehashing yes 启动命令如下 [192.168.233.130 root@nodea:/data/redis/etc] # redis-server /data/redis/etc/redis.conf &amp; </code></pre><p>下载安装就比较简单了</p><pre><code>[192.168.233.130 root@nodea:/soft] # wget http://redis.googlecode.com/files/redis-2.4.14.tar.gz [192.168.233.130 root@nodea:/data/redis/etc] # make –j24 [192.168.233.130 root@nodea:/data/redis/etc] # make install </code></pre><p>配置文件里的那几个路径要提前建好</p><p>最后我们回到 logstash agent 上面测试一下</p><pre><code>[192.168.233.129 root@noded:/soft] # echo GET12313 &gt;&gt; apache.log [192.168.233.129 root@noded:/soft] # echo errorabcd &gt;&gt; apache.log </code></pre><p>ok 到 <a href="http://192.168.233.128:9292" target="_blank" rel="noopener">http://192.168.233.128:9292</a> 去搜索一下 刚才的两个内容<br><img src="http://img1.51cto.com/attachment/201303/132952247.jpg" alt=""><br><img src="http://img1.51cto.com/attachment/201303/133019112.jpg" alt=""><br>嗯，就是这样了，我现在找个php的错误日志给他追加到php.log文件里 </p><pre><code>[192.168.233.129 root@noded:/soft]# cat php-error.log &gt;&gt; php.log</code></pre><p>在看看 logstash的页面 搜索一下 error</p><p><img src="http://img1.51cto.com/attachment/201303/202133777.jpg" alt=""><br>OK，最后就是 Kibana了 ，我把Kibana装在了 logstash index上面<br>下载地址为 <a href="http://kibana.org/intro.html" target="_blank" rel="noopener">http://kibana.org/intro.html</a></p><pre><code>[192.168.233.128 root@nodec:/soft] # tar xf Kibana-0.2.0.tar.gz [192.168.233.128 root@nodec:/soft] # cd Kibana-0.2.0 [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] # bundle install 直接安装就好了，非常简单，因为之前咱们已经安装好了 bundle 编辑配置文件，指定 elasticsearch 的位置 [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] # vim KibanaConfig.rb .....   Elasticsearch = &quot;localhost:9200&quot;   KibanaPort = 5601   KibanaHost = &apos;0.0.0.0&apos; ..... 主要是这几个参数 启动的话需要ruby [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] # /usr/bin/ruby kibana.rb &amp; [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] # == Sinatra/1.3.5 has taken the stage on 5601 for development with backup from Thin &gt;&gt; Thin web server (v1.5.0 codename Knife) &gt;&gt; Maximum connections set to 1024 &gt;&gt; Listening on 0.0.0.0:5601, CTRL+C to stop 如果ruby的东西都不缺的话，启动会很顺利，ok 现在看看5601端口的状态 [192.168.233.128 root@nodec:/soft/Kibana-0.2.0] # lsof -i:5601 COMMAND  PID USER   FD   TYPE DEVICE SIZE NODE NAME ruby3116 root5u  IPv4  28947   TCP *:esmagent (LISTEN) </code></pre><p>访问一下 试试看 <a href="http://192.168.233.128:5601" target="_blank" rel="noopener">http://192.168.233.128:5601</a> 尝试搜索一下php的错误日志，比如mysql<br><img src="http://img1.51cto.com/attachment/201303/133220759.jpg" alt=""><br>呵呵，要的就是这个效果，日志会实时的汇总到 logstash index 上供我们查询，当然这只是开始使用logstash的第一步而已，更多的高级功能可以看看官方文档<br><a href="http://logstash.net/docs/1.1.9/" target="_blank" rel="noopener">http://logstash.net/docs/1.1.9/</a><br>如果有问题大家可以一起探讨，我也是刚开始接触这个东东，收集日志是相当方便啊，据说还能跟nagios结合. 呵呵</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt; Logstash是一个完全开源的工具，他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索），您可以使用它。说到搜索，logstash带有一个web界面，搜索和展示所有日志。&lt;br&gt;kibana 也是一个开源和免费的工具，他可以帮助您汇总、分析和搜索重要数据日志并提供友好的web界面。他可以为 Logstash 和 ElasticSearch 提供的日志分析的 Web 界面&lt;br&gt;
    
    </summary>
    
      <category term="elk" scheme="http://datura.me/categories/elk/"/>
    
    
      <category term="elk" scheme="http://datura.me/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>tcpdump：理论、自动抓包及业务架构树的生成</title>
    <link href="http://datura.me/2017/03/02/tcpdump%EF%BC%9A%E7%90%86%E8%AE%BA%E3%80%81%E8%87%AA%E5%8A%A8%E6%8A%93%E5%8C%85%E5%8F%8A%E4%B8%9A%E5%8A%A1%E6%9E%B6%E6%9E%84%E6%A0%91%E7%9A%84%E7%94%9F%E6%88%90/"/>
    <id>http://datura.me/2017/03/02/tcpdump：理论、自动抓包及业务架构树的生成/</id>
    <published>2017-03-02T05:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.724Z</updated>
    
    <content type="html"><![CDATA[<p>###一、tcpdump基础</p><p>tcpdump是一个对网络数据包进行截获的包分析工具。</p><p>tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、端口等的过滤，并支持与、或、非逻辑语句协助过滤有效信息。<br><a id="more"></a><br>命令使用规则如下：</p><pre><code>tcpdump version 4.1-PRE-CVS_2016_05_10libpcap version 1.4.0Usage: tcpdump [-aAdDefhIJKlLnNOpqRStuUvxX] [ -B size ] [ -c count ]        [ -C file_size ] [ -E algo:secret ] [ -F file ] [ -G seconds ]        [ -i interface ] [ -j tstamptype ] [ -M secret ]        [ -Q|-P in|out|inout ]        [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ]        [ -W filecount ] [ -y datalinktype ] [ -z command ]        [ -Z user ] [ expression ]</code></pre><p>过滤方式有很多，可以依据所需设置过滤条件，较常用的三种：</p><p>####1、可以按host过滤，例如：</p><pre><code>tcpdump -i eth0 -n -X src host 172.17.198.10</code></pre><p>####2、可以按port过滤，例如：<br>    cpdump -i eth0 -n -X src host 172.17.198.10 and dst port 80</p><p>####3、可以按protocol过滤，例如：</p><pre><code>tcpdump -i eth0 -n -X src host 172.17.198.10 and dst port 80 and tcp</code></pre><p>下面来看一下tcpdump过滤规则的具体使用：</p><p>我们在服务器10.219.153.215上搭建了一个http服务用来作为服务端，10.19.66.62作为客户端客户端对其发起访问。我们使用前面提到的按host 10.19.66.62、port 80以及protocol tcp的组合条件来执行tcpdump。</p><pre><code>tcpdump -i eth0 -n  tcp port 80 and host 172.17.198.10[root@ssy-turn1 ~]# tcpdump -i eth0 -n  tcp port 80 and host 172.17.198.10tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes11:39:05.355344 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [S], seq 636850073, win 65160, options [mss 1460,sackOK,TS val 2335946898 ecr 3699469428,nop,wscale 14], length 011:39:05.355397 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [S.], seq 4174661387, ack 636850074, win 65160, options [mss 1460,sackOK,TS val 3699486375 ecr 2335946898,nop,wscale 14], length 011:39:05.357024 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 011:39:05.357062 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [P.], seq 1:193, ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 19211:39:05.357071 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [.], ack 193, win 4, options [nop,nop,TS val 3699486376 ecr 2335946899], length 011:39:05.357403 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [P.], seq 1:765, ack 193, win 4, options [nop,nop,TS val 3699486377 ecr 2335946899], length 76411:39:05.357766 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 011:39:05.359151 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [F.], seq 193, ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 011:39:05.359329 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [F.], seq 765, ack 194, win 4, options [nop,nop,TS val 3699486379 ecr 2335946901], length 011:39:05.359613 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 766, win 4, options [nop,nop,TS val 2335946903 ecr 3699486379], length 0</code></pre><p>不同的协议类型有不同的数据包格式显示，以tcp包为例，通常tcpdump对tcp数据包的显示格式如下:</p><pre><code>src &gt; dst: flags data-seqno ack window urgent optionssrc ＞ dst：表明从源地址到目的地址flags：TCP包中的标志信息，S 是SYN标志,，F (FIN)，P (PUSH)，R (RST)，”.” (没有标记）data-seqno：是数据包中的数据的顺序号ack：是下次期望的顺序号window：是接收缓存的窗口大小urgent：表明数据包中是否有紧急指针options：选项</code></pre><p>执行抓包过程中输出的这八行数据其实包含了tcp三次握手和四次挥手的交互过程，详细分析下看看：</p><pre><code>11:39:05.355344 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [S], seq 636850073, win 65160, options [mss 1460,sackOK,TS val 2335946898 ecr 3699469428,nop,wscale 14], length 011:39:05.355397 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [S.], seq 4174661387, ack 636850074, win 65160, options [mss 1460,sackOK,TS val 3699486375 ecr 2335946898,nop,wscale 14], length 011:39:05.357024 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 011:39:05.357062 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [P.], seq 1:193, ack 1, win 4, options [nop,nop,TS val 2335946899 ecr 3699486375], length 19211:39:05.357071 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [.], ack 193, win 4, options [nop,nop,TS val 3699486376 ecr 2335946899], length 011:39:05.357403 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [P.], seq 1:765, ack 193, win 4, options [nop,nop,TS val 3699486377 ecr 2335946899], length 76411:39:05.357766 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 011:39:05.359151 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [F.], seq 193, ack 765, win 4, options [nop,nop,TS val 2335946901 ecr 3699486377], length 011:39:05.359329 IP 172.17.198.11.http &gt; 172.17.198.10.solaris-audit: Flags [F.], seq 765, ack 194, win 4, options [nop,nop,TS val 3699486379 ecr 2335946901], length 011:39:05.359613 IP 172.17.198.10.solaris-audit &gt; 172.17.198.11.http: Flags [.], ack 766, win 4, options [nop,nop,TS val 2335946903 ecr 3699486379], length 0</code></pre><p>第一至三行为建立链接的三次握手过程，包状态为：[S]、[S.]、[.]，第四至七行为传输数据的过程，包状态为[P.]、[.]；第八至十行为关闭链接的四次挥手过程（ack延迟发送未禁用，所以这里只看到三个包），包状态为[F.]、[F.]、[.]。  </p><p>####第一行：客户端10向服务器11发送了一个序号seq 636850073给服务端；</p><p>####第二行：服务端收到后将序号加一返回ack 636850074；</p><p>####第三行：客户端检查返回值正确，向服务端发ack 1，建立了链接；</p><p>####第四行和第七行：具体的数据交互，tcpdump命令-x可以显示出具体内容；</p><p>####第八行：客户端发一个序号seq 193，说明要断开链接；</p><p>####第九行：服务端在收到后序号加一返回ack 194，同意断开链接；</p><p>####第十行：客户端检查返回值正确，向服务端发ack，链接断开。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;###一、tcpdump基础&lt;/p&gt;
&lt;p&gt;tcpdump是一个对网络数据包进行截获的包分析工具。&lt;/p&gt;
&lt;p&gt;tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、端口等的过滤，并支持与、或、非逻辑语句协助过滤有效信息。&lt;br&gt;
    
    </summary>
    
      <category term="linux" scheme="http://datura.me/categories/linux/"/>
    
    
      <category term="tcpdump" scheme="http://datura.me/tags/tcpdump/"/>
    
  </entry>
  
  <entry>
    <title>Glances</title>
    <link href="http://datura.me/2017/02/28/Glances/"/>
    <id>http://datura.me/2017/02/28/Glances/</id>
    <published>2017-02-28T05:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.722Z</updated>
    
    <content type="html"><![CDATA[<p>top 命令是 Linux 下的一个实时任务管理器， 同时也是用于在 GNU/Linux 发行版中寻找系统性能方面的瓶颈，并帮助我们作出正确操作的常用系统监视工具。 她有着一个极为简洁的界面，并自带少量的可以帮助我们快速了解系统性能的实用选项。<br><a id="more"></a><br>但是，有些时候想要通过她寻找一个占用系统资源比较大的应用或进程可能会比较困难。 因为 top 命令本身并不会帮助我们高亮那些吃太多 CPU，内存，或者其他资源的程序。</p><p>为了达到这个目标，这里我们将介绍一款超牛逼的系统监视程序 —— Glances。 她可以自动高亮利用最高系统资源的程序，并为 Linux/Unix 服务器提供尽可能多的信息。</p><p>什么是 Glances？<br>Glances 是一个由 Python 编写，使用 psutil 库来从系统抓取信息的基于 curses 开发的跨平台命令行系统监视工具。 通过 Glances，我们可以监视 CPU，平均负载，内存，网络流量，磁盘 I/O，其他处理器 和 文件系统 空间的利用情况。</p><p>Glances 是一个用来监视 GNU/Linux 和 FreeBSD 操作系统的 GPL 授权的自由软件。</p><p>Glances 同时也提供了很多实用的选项。 其中我们能够在配置文件见到的一项主要的功能就是设置关键值及相应的标签 （careful[小心], warning[警告] 和 critical[严重]）， 然后她会自动帮我们用不同颜色标出系统达到某个瓶颈的信息。</p><p>Glances 主要功能<br>CPU 信息 （用户的相关应用, 系统核心程序和空闲程序）<br>总内存信息，包括了物理内存，交换空间和空闲内存等等<br>之前的 1 分钟、5 分钟和 15 分钟平均的 CPU 负载<br>网络链接的下行和上行速度<br>处理器总数，以及其活动状态<br>硬盘 I/O 相关（读写）速度详情<br>当前挂载设备的磁盘使用情况<br>高 CPU 和内存使用的进程名，和相关应用的位置<br>在底部显示当前日期和时间<br>将消耗最高系统资源的进程用红色标出<br>下面是一个 Glances 的使用截图：<br><img src="https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214404gen07qvynyj3vjzn.jpeg" alt=""><br>在 Linux/Unix 系统中安装 Glances<br>虽然这个工具的发布比较晚，但你仍然可以在 Red Hat 系的系统中通过 EPEL 软件源安装。在终端用下面的命令安装：</p><p>对于 RHEL/CentOS/Fedora 发行版  </p><pre><code># yum install -y glances  </code></pre><p>对于 Debian/Ubuntu/Linux Mint 发行版<br>    $ sudo apt-add-repository ppa:arnaud-hartmann/glances-stable<br>    $ sudo apt-get update<br>    $ sudo apt-get install glances<br>如何使用 Glances<br>首先，你需要在终端中输入以下命令  </p><pre><code># glances  </code></pre><p><img src="https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214413hgrs2ozqwarrwypo.jpeg" alt=""></p><p>按下 ‘q‘ （‘ESC‘ 和 ‘Ctrl-C‘ 也可以） 退出 Glances 终端。 这里是从 CentOS 6.5 截取的另一张截图：<br><img src="https://dn-linuxcn.qbox.me/data/attachment/album/201403/31/214419xaiwmtwwaawo2oya.jpeg" alt=""><br>Glances 的默认刷新频率是 1 （秒），但是你可以通过在终端指定参数来手动定义其刷新频率  </p><pre><code># glances -t 2   </code></pre><p>Glances 中颜色的含义<br>Glances 会用一下几种颜色来代表状态：</p><p>绿色：OK（一切正常）<br>蓝色：CAREFUL（需要注意）<br>紫色：WARNING（警告）<br>红色：CRITICAL（严重）<br>阀值可以在配置文件中设置，一般阀值被默认设置为（careful=50、warning=70、critical=90）。</p><p>我们可以按照自己的需求在配置文件（默认在 /etc/glances/glances.conf）中自定义。</p><p>Glances 的选项<br>除了很多命令行选项之外，Glances 还提供了更多的可在其运行时开关输出信息选项的快捷键，下面是一些例子：</p><p>a – 对进程自动排序<br>c – 按 CPU 百分比对进程排序<br>m – 按内存百分比对进程排序<br>p – 按进程名字母顺序对进程排序<br>i – 按读写频率（I/O）对进程排序<br>d – 显示/隐藏磁盘 I/O 统计信息<br>f – 显示/隐藏文件系统统计信息<br>n – 显示/隐藏网络接口统计信息<br>s – 显示/隐藏传感器统计信息<br>y – 显示/隐藏硬盘温度统计信息<br>l – 显示/隐藏日志（log）<br>b – 切换网络 I/O 单位（Bytes/bits）<br>w – 删除警告日志<br>x – 删除警告和严重日志<br>1 – 切换全局 CPU 使用情况和每个 CPU 的使用情况<br>h – 显示/隐藏这个帮助画面<br>t – 以组合形式浏览网络 I/O<br>u – 以累计形式浏览网络 I/O<br>q – 退出（‘ESC‘ 和 ‘Ctrl&amp;C‘ 也可以）<br>远程使用 Glances<br>你甚至也可以通过 Glances 来监视远程系统。 要在远程系统使用 ‘glances’，需要在服务器运行 ‘glances -s’（-s 启动服务器/客户端模式）命令。  </p><pre><code># glances -s</code></pre><p>Define the password for the Glances server<br>Password:<br>Password (confirm):<br>Glances server is running on 0.0.0.0:61209<br>注意：当你执行了‘glances’命令后，她会让你为 Glances 服务器设置密码。</p><p>当你设置完毕，你将看到 “Glances server is running on 0.0.0.0:61209” （Glances 服务器正在 0.0.0.0 的 61209 端口运行）的消息。</p><p>当 Glances 服务器启动后，到本地执行下面的命令来指定服务器IP地址或主机名以链接。</p><p>注：这里的 ‘172.16.27.56’ 是我 Glances 服务器的 IP 地址。  </p><pre><code># glances -c -P 172.16.27.56    </code></pre><p>  下面是一些在使用服务器/客户端模式时必须知道的事情：  </p><ul><li>在服务器模式，你可以通过 <code>-B 地址</code> 来设置绑定地址，也可以通过 <code>-p 端口</code> 来绑定监听的 TCP 端口  </li><li>在客户端模式，你可以通过同样的 <code>-p 端口</code> 来指定服务器端口  </li><li>默认的绑定地址是 0.0.0.0，但这么做会监听所有网络接口的指定端口  </li><li>在服务器/客户端模式下，限制的阀值将由服务器的设置决定  </li><li>你也可以在命令行下用过 <code>-P 密码</code> 的方式来为服务器端设置一个密码<br>总结<br>Glances 对于大多用户而言是个在系统资源上提供过多信息的工具。但是如果你是一个想要仅从命令行就能快速获取系统整体状况的系统管理员，那这个工具绝对是你的必备利器。<br>请不要将 glances（本文中的工具）和 glance（一个 OpenStack 的工具）这两个包搞混了<br>Ubuntu 官方 Extra 源中的 glances 因为 python 库移动的问题导致无法正常使用 但可以通过建立软链接的方式临时修复：sudo ln -s /usr/lib/python2.7/dist-packages/glances /usr/share/pyshared/glances</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;top 命令是 Linux 下的一个实时任务管理器， 同时也是用于在 GNU/Linux 发行版中寻找系统性能方面的瓶颈，并帮助我们作出正确操作的常用系统监视工具。 她有着一个极为简洁的界面，并自带少量的可以帮助我们快速了解系统性能的实用选项。&lt;br&gt;
    
    </summary>
    
      <category term="Glances" scheme="http://datura.me/categories/Glances/"/>
    
    
      <category term="Glances" scheme="http://datura.me/tags/Glances/"/>
    
  </entry>
  
  <entry>
    <title>tsung使用说明</title>
    <link href="http://datura.me/2017/01/08/tsung%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3/"/>
    <id>http://datura.me/2017/01/08/tsung说明文档/</id>
    <published>2017-01-08T05:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.724Z</updated>
    
    <content type="html"><![CDATA[<p>1、tsung安装</p><p>tsung 一个非常优秀的压力测试工具，在8核32G机器上可以轻易的产生每秒10000个并发请求，且占用的资源很少，当前版本1.5.0<br><a id="more"></a><br>使用erlang开发，需要先安装erlang虚拟机。安装过程略</p><p>2、tsung使用<br>$ tsung -f ./tsung/tsung.xml sta</p><p>3、tusng.xml</p><p>下面是我自己的tsung.xml</p><pre><code>    &lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE tsung SYSTEM &quot;/usr/local/share/tsung/tsung-1.0.dtd&quot;&gt;&lt;!-- dumptraffic是调试模式，如果为true，就会打印详细的请求返回信息，一般设置为false， --&gt;&lt;tsung loglevel=&quot;notice&quot; dumptraffic=&quot;false&quot; version=&quot;1.0&quot;&gt;&lt;!-- tsung所在的服务器，maxusers就是tsung产生的最大用户数 --&gt;  &lt;clients&gt;&lt;client host=&quot;localhost&quot; use_controller_vm=&quot;true&quot;  maxusers=&quot;100000&quot; /&gt;  &lt;/clients&gt;&lt;!-- 被测服务器的ip和端口号，type一般设为tcp -&gt;  &lt;servers&gt;&lt;server host=&quot;@server&quot; port=&quot;@port&quot; type=&quot;tcp&quot;/&gt;  &lt;/servers&gt;&lt;!-- tsung产生的压力 --&gt;&lt;load&gt;&lt;!-- phase=&quot;1&quot; 第一阶段；duration：测试持续时间；unit：单位秒 --&gt;&lt;arrivalphase phase=&quot;1&quot; duration=&quot;@duration&quot; unit=&quot;second&quot;&gt;&lt;!-- maxnumber：最大用户数；arrivalrate：每秒新增用户数；unit：单位秒--&gt;  &lt;users maxnumber=&quot;@maxuser&quot; arrivalrate=&quot;@user&quot; unit=&quot;second&quot;/&gt;&lt;/arrivalphase&gt;  &lt;/load&gt;&lt;!-- 外部变量 --&gt;  &lt;options&gt;&lt;!-- 引入一个外部文件，类型为file_server，变量名为userfile，文件路径：/tmp/users--&gt;&lt;!-- 文件是以逗号分隔的csv文件 --&gt;&lt;option name=&quot;file_server&quot; id=&quot;userfile&quot; value=&quot;/tmp/users&quot;/&gt;  &lt;/options&gt;&lt;!-- 会话，每个用户都按照sessions中的配置发送请求 --&gt;  &lt;sessions&gt;&lt;!--probability=“100”:这个session的请求概率是100%，如果要同时测多个api，可以设置请求概率；请求类型为http --&gt;&lt;session name=&quot;test&quot; probability=&quot;100&quot; type=&quot;ts_http&quot;&gt;&lt;!-- 请求次数，to是最大请求数，如果设为100，就是每个用户请求100次 --&gt;  &lt;for from=&quot;1&quot; to=&quot;@loop&quot; incr=&quot;1&quot; var=&quot;counter&quot;&gt;&lt;!-- 解析前面引入的外部文件，以逗号做为分隔符，随机读取 --&gt;&lt;setdynvars sourcetype=&quot;file&quot; fileid=&quot;userfile&quot; delimiter=&quot;,&quot; order=&quot;random&quot;&gt;  &lt;var name=&quot;user_id&quot; /&gt;  &lt;var name=&quot;passwd&quot; /&gt;  &lt;var name=&quot;auth_token&quot; /&gt;&lt;/setdynvars&gt;&lt;!-- 返回随机小数，变量名为decimal，code中可以写erlang函数 --&gt;&lt;setdynvars sourcetype=&quot;eval&quot; code=&quot;fun({Pid,DynVars}) -&gt; random:uniform() end.&quot;&gt;  &lt;var name=&quot;decimal&quot; /&gt;&lt;/setdynvars&gt;&lt;!-- 返回随机数，从1到10000 --&gt;&lt;setdynvars sourcetype=&quot;random_number&quot; start=&quot;1&quot; end=&quot;10000&quot;&gt;   &lt;var name=&quot;int_1_10000&quot; /&gt;&lt;/setdynvars&gt;&lt;!-- 返回随机字符串，长度为10 --&gt;&lt;setdynvars sourcetype=&quot;random_string&quot; length=&quot;10&quot;&gt;   &lt;var name=&quot;string_10&quot; /&gt;&lt;/setdynvars&gt;&lt;!-- subst=&quot;true&quot;：如果在request中使用变量，需要设置subst --&gt;&lt;request subst=&quot;true&quot;&gt;&lt;!-- url：被测试的url；method：GET、POST等；contents：POST请求的参数 --&gt;  &lt;http url=&quot;@api&quot; method=&quot;@method&quot; contents=&quot;@contents&quot; version=&quot;1.1&quot;&gt;&lt;!-- http header，可以添加Authorization、Cookie等，注意变量的使用格式：%%_xxx%% --&gt;&lt;http_header name=&quot;Authorization&quot; value=&quot;111&quot;/&gt;&lt;http_header name=&quot;Cookie&quot; value=&quot;authToken=%%_auth_token%%; Path=/&quot;/&gt;&lt;!-- content-Type：POST请求参数的格式，如果是json格式可以这样写 --&gt;&lt;http_header name=&quot;Content-Type&quot; value=&quot;application/json&quot;/&gt;  &lt;/http&gt;&lt;/request&gt;&lt;!-- thinktime：两次请求之间的间隔时间，一般小于10s --&gt;&lt;thinktime value=&quot;1&quot;/&gt;  &lt;/for&gt;&lt;/session&gt;  &lt;/sessions&gt;&lt;/tsung&gt; </code></pre><p>如果被测接口需要登录跳转，可以指明跳转条件：   </p><pre><code>&lt;!-- if need login, http 302 will be return --&gt;&lt;request subst=&quot;true&quot;&gt;  &lt;dyn_variable name=&quot;redirect1&quot; re=&quot;Location: ((http|https)://.*)\r&quot;/&gt;  &lt;http url=&quot;@api&quot; method=&quot;@method&quot; contents=&quot;@contents&quot; version=&quot;1.1&quot;&gt;&lt;/http&gt;&lt;/request&gt;&lt;if var=&quot;redirect1&quot; neq=&quot;&quot;&gt;  &lt;request subst=&quot;true&quot;&gt;&lt;!-- 这里可以使用xpath提取页面中的元素值 --&gt;&lt;dyn_variable name=&quot;lt&quot; xpath=&quot;//input[@name=&apos;lt&apos;]/@value&quot;/&gt;&lt;dyn_variable name=&quot;s_uuid&quot; xpath=&quot;//input[@name=&apos;s_uuid&apos;]/@value&quot;/&gt;&lt;dyn_variable name=&quot;eventId&quot; xpath=&quot;//input[@name=&apos;_eventId&apos;]/@value&quot;/&gt;&lt;http url=&quot;%%_redirect1%%&quot; method=&quot;GET&quot;&gt;&lt;/http&gt;  &lt;/request&gt;  &lt;request subst=&quot;true&quot;&gt;&lt;dyn_variable name=&quot;redirect2&quot; re=&quot;Location: (http://.*)\r&quot;/&gt;&lt;http url=&quot;%%_redirect1%%&quot; method=&quot;POST&quot; contents=&quot;username=%%_username%%&amp;amp;password=%%_password%%&amp;amp;lt=%%_lt%%&amp;amp;s_uuid=%%_s_uuid%%&amp;amp;_eventId=%%_eventId%%&amp;amp;j_captcha_response=&apos;&apos;&quot;&gt;&lt;/http&gt;  &lt;/request&gt;  &lt;request subst=&quot;true&quot;&gt;&lt;dyn_variable name=&quot;redirect3&quot; re=&quot;Location: (http://.*)\r&quot;/&gt;&lt;http url=&quot;%%_redirect2%%&quot; method=&quot;GET&quot;&gt;&lt;/http&gt;  &lt;/request&gt;  &lt;request subst=&quot;true&quot;&gt;&lt;http url=&quot;%%_redirect3%%&quot; method=&quot;@method&quot; contents=&quot;@contents&quot;&gt;&lt;/http&gt;  &lt;/request&gt;&lt;/if&gt;</code></pre><p>4、通过shell控制tsung</p><p>如果每次使用tsung -f tsung.xml start运行tsung，那么每次修改测试接口或者压力改变都需要修改xml，非常麻烦，我写了一个shell脚本，替换上面的tsung.xml中以@开头的变量</p><pre><code>#!/bin/bashdefaultTestFile=&quot;$HOME/tsung_test.xml&quot;defaultUser=20defaultDuration=100# sdefaultThinktime=1defaultServer=&quot;tomcat1&quot;defaultPort=9000defaultApi=&quot;/test&quot;defaultMethod=&quot;POST&quot;defaultLoopCount=50defaultMaxuser=5000while [ $# -gt 0 ]; do  case &quot;$1&quot; in-f|--testFile)testFile=$2shift shift ;;-u|--user)user=$2shift shift ;;-d|--duration)duration=$2shift shift ;;-t|--thinktime)thinktime=$2shift shift ;;-s|--server)server=$2shift shift ;;-p|--port)port=$2shift shift ;;-a|--api)api=$2shift shift ;;-m|--method)method=$2shift shift ;;-l|--loopCount)loopCount=$2shift shift ;;-x|--maxuser)maxuser=$2shift shift ;;-h|--help)echo &quot;-f | --testFile: tsung test file xml,default $defaultTestFile&quot;echo &quot;-u | --user: user number per second, default $defaultUser&quot;echo &quot;-x | --maxuser: max user number, default $defaultMaxuser&quot;echo &quot;-d | --duration: times used to generate user,default $defaultDuration s&quot;echo &quot;-t | --thinktime: the inteval time between two request,default $defaultThinktime s&quot;echo &quot;-l | --loopCount: Each user&apos;s request number,default $defaultLoopCount&quot;echo &quot;-s | --server: play server,default $defaultServer&quot;echo &quot;-p | --port: play server http port,default $defaultPort&quot;echo &quot;-a | --api: api, default $defaultApi&quot;echo &quot;-m | --method: POST/GET,default $defaultMethod&quot;echo &quot;-h | --help: print this help&quot;shiftexit 1;;--)  shift  break  ;;*)  echo &quot;wrong input:$1,use -h or --help see how to use&quot; 1&gt;&amp;2  exit 1  ;;  esacdoneprocessName=&quot;tsung&quot;pid=`ps aux | grep $processName | grep -v grep | awk &apos;{print $2}&apos;`#convert from string to arraypid=($pid)if [ ${#pid[*]} -gt 3 ]; then  echo &quot;warning!!! a $processName process is running,please wait&quot;  exit 1fi#env#set default parameterstestFile=${testFile:=$defaultTestFile}user=${user:=$defaultUser}duration=${duration:=$defaultDuration}thinktime=${thinktime:=$defaultThinktime}server=${server:=$defaultServer}port=${port:=$defaultPort}api=${api:=$defaultApi}method=${method:=$defaultMethod}loopCount=${loopCount:=$defaultLoopCount}maxuser=${maxuser:=$defaultMaxuser}#key of params is nodname in tusng_test.xml filedeclare -A paramsparams=( \  [&quot;user&quot;]=$user \  [&quot;maxuser&quot;]=$maxuser \  [&quot;duration&quot;]=$duration \  [&quot;thinktime&quot;]=$thinktime \  [&quot;server&quot;]=$server \  [&quot;port&quot;]=$port \  [&quot;api&quot;]=$api \  [&quot;method&quot;]=$method \  [&quot;loopCount&quot;]=$loopCount \  )reportPath=&quot;$HOME/.tsung/log&quot;currentTest=`date +%Y%m%d-%H%M`reportPath=&quot;$reportPath/$currentTest&quot;mkdir -p $reportPath#deal with jmx filecp $testFile $reportPathcurrentTestFile=&quot;$reportPath/tsung_test.xml&quot;function replace(){  echo &quot;$1:$2&quot; | tee -a &quot;$reportPath/test.env&quot;  #change / to \/ for sed   local val=${2//\//\\\/}  sed -i &quot;s/@${1}/${val}/&quot; $currentTestFile}for key in ${!params[*]}do  replace $key ${params[$key]}done#start tsung tsung -f $currentTestFile start &amp;wait %1cd $reportPath/usr/local/lib/tsung/bin/tsung_stats.pl</code></pre><p>5、tsung结果分析</p><p>tsung生成的测试报告都放在$HOME/.tsung/log下，以日期加时间的方式命名，如：<code>.tsung/log/20150407-1951</code>，其中最重要的几张图是</p><ul><li>tsung产生的用户数曲线图 .tsung/log/20150407-1951/images/graphes-Users-simultaneous.png<br><img src="http://static.oschina.net/uploads/space/2015/0706/135050_sSxO_780347.png" alt=""></li></ul><p>Y轴代表每秒用户数，tsung每秒会产生一批用户，这个统计结果是每十秒统计一次，所有的图的起始位置显示的是0，其实是第一个10秒</p><ul><li><p>http接口响应数曲线图（TPS） .tsung/log/20150407-1951/images/graphes-HTTP_CODE-rate.png<br><img src="http://static.oschina.net/uploads/space/2015/0706/135106_dKTc_780347.png" alt=""></p><p>Y轴是每秒响应数，右上角的200是http状态码，如果有多个状态码，会有多条不同颜色的曲线。</p></li><li><p>http接口响应时间曲线图 .tsung/log/20150407-1951/images/graphes-Perfs-mean.png</p></li></ul><p><img src="http://static.oschina.net/uploads/space/2015/0706/135120_sPqf_780347.png" alt=""></p><p>  Y轴是接口响应时间，单位是毫秒，request的线代表请求响应总耗时，connect的线代表tcp链接建立的时间。</p><p>6、主要统计信息<br>Tsung统计数据是平均每十秒重置一次，所以这里的响应时间（连接、请求、页面、会话）是指每十秒的平均响应时间；<br>connect： 表示 每个连接持续时间；<br>Hightest 10sec mean    连接最长持续时间<br>Lowest 10sec mean    连接最短持续时间<br>Highest rate     每秒最高建立连接速率<br>Mean    平均每个连接持续时间<br>Count    总连接数<br>page： 表示 每个请求集合的响应时间,（一个页面表示一组没有被thinktime间隔的请求）<br>request： 表示 每个请求的响应时间；<br>Hightest 10sec mean    请求最长响应时间<br>Lowest 10sec mean    请求最短响应时间<br>Highest rate     请求最快发送速率<br>Mean    平均每个请求响应时间<br>Count    总请求数<br>session： 表示 每个用户会话持续时间；<br>Hightest 10sec mean    会话最长持续时间<br>Lowest 10sec mean    会话最短持续时间<br>Highest rate     每秒最高进行会话速率<br>Mean    平均每个会话持续时间<br>Count    总会话数  </p><p>7、数据流量统计<br>size_rcv: 表示 响应请求数据量<br>size_sent:表示 发送请求数据量<br>Hightest rate    每秒最高 响应/发送 请求数据量<br>Total     响应/发送 请求总数据量  </p><p>8、计数统计<br>connected    表示会话开始且尚未结束，并且已建立连接的最大用户数<br>finished_user_count    表示已经完成会话的最大用户数<br>users    表示会话开始且尚未结束的最大用户数<br>users_count    表示Tsung总共生成的用户总数  </p><p>9、错误统计<br>Error_abort_max_conn_retries    重新尝试连接错误<br>Error_connect_timeout    连接超时错误<br>Error_connect_nxdomain    不存在的域错误<br>Error_unknown    位置错误  </p><p>Highest rate     发生错误最高速率<br>Total number    发生该错误总个数  </p><p>10、http返回状态码统计<br>200：表示客户端请求已成功响应<br>Highest rate    状态码返回最高速率<br>Total number    返回状态码的总个数  </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1、tsung安装&lt;/p&gt;
&lt;p&gt;tsung 一个非常优秀的压力测试工具，在8核32G机器上可以轻易的产生每秒10000个并发请求，且占用的资源很少，当前版本1.5.0&lt;br&gt;
    
    </summary>
    
      <category term="tsung" scheme="http://datura.me/categories/tsung/"/>
    
    
      <category term="tsung" scheme="http://datura.me/tags/tsung/"/>
    
  </entry>
  
  <entry>
    <title>yum仓库搭建之RPM包制作</title>
    <link href="http://datura.me/2016/11/05/yum%E4%BB%93%E5%BA%93%E6%90%AD%E5%BB%BA%E4%B9%8BRPM%E5%8C%85%E5%88%B6%E4%BD%9C/"/>
    <id>http://datura.me/2016/11/05/yum仓库搭建之RPM包制作/</id>
    <published>2016-11-05T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.724Z</updated>
    
    <content type="html"><![CDATA[<p> 常见的软件安装方式有以下几种<br>1.yum安装，可自动解决依赖，但不能自定义软件安装位置<br>2.编译安装，可指定安装路径，指定装模块，但编译参数冗长，且耗时较长，不能解决依赖问题。<br><a id="more"></a><br>3.rpm安装，安装速度较快，但不能自动解决依赖，尤其是遇到需要的依赖包较多时，特别费时。<br>本文主要介绍利用fpm工具制作个性化的rpm包，后期可放到yum仓库中，直接用yum安装。<br>【fpm介绍】<br>项目地址：<a href="https://github.com/jordansissel/fpm" target="_blank" rel="noopener">https://github.com/jordansissel/fpm</a><br>作者把这个fpm称作Effing Package Management，翻译过来就是该死的包管理器，粗暴一点就是去他妈的包管理器。Ubuntu及CentOS的包管理及安装方式完全不同，要想同时掌握这两种平台下的软件包安装方法是很困难的，为了不再遭受这痛苦，fpm便应运而生了。fpm是由jordansissel于2011年开发的一套打包工具，可快速度地将你安装好的程序目录或包打包为rpm及deb等结尾软件包。与传统的打包工具(rpmbuild、dh_make)相比，制作起来更加简单、方便、快捷。<br>【fpm安装】<br>1.安装ruby及gcc    </p><pre><code>yum install ruby-devel gcc  </code></pre><p>2.安装fpm    </p><pre><code>gem install fpm  </code></pre><p>3.fpm打包<br>语法格式  </p><pre><code>fpm -s &lt;source type&gt; -t &lt;target type&gt; [options]  </code></pre><p>其中源类型主要有：dir、gem、rpm、python等，目标类型主要有rpm,deb,puppet,solaris等。<br>-s指定输入的包类型<br>-t指定输出包的类型<br>-n, –name指定输出的包名<br>-v, –version指定版本号，默认为1.0<br>-d, –depends指定依赖包，可重复多次出现，通常以”-d ‘name’ or -d ‘name &gt; version’”的形式展现。<br>-f, –force强制输出，会覆盖掉旧包<br>-p, –package OUTPUT 指定输出目录<br>【打包实例】<br>定制cron初始化rpm包    </p><pre><code>$fpm -s dir -t rpm -a noarch -p /root/ -n cron-init-script -v 1.0 /var/spool/cron/  no value for epoch is set, defaulting to nil {:level=&gt;:warn}  no value for epoch is set, defaulting to nil {:level=&gt;:warn}  Created package {:path=&gt;&quot;/root/cron-init-script-1.0-1.noarch.rpm&quot;}  $ll /root/cron-init-script-1.0-1.noarch.rpm   -rw-r--r-- 1 root root 1693 Nov  2 22:24 /root/cron-init-script-1.0-1.noarch.rpm  </code></pre><p>在客户端yum安装cron-init-script  </p><pre><code>yum install cron-init-scipt</code></pre><p>【升级RPM包】<br>1.编辑cron任务  </p><pre><code>$crontab -l  */5 * * * * /usr/sbin/ntpdate pool.ntp.org &gt;/dev/null 2&gt;&amp;1  */10 * * * * /usr/sbin/ntpdate 1.pool.ntp.org &gt;/dev/null 2&gt;&amp;1  </code></pre><p>2.重新生成包</p><pre><code>fpm -s dir -t rpm -a noarch -p /tools/fpm/ -n cron-init-script -v 1.1 /var/spool/cron/</code></pre><p>yum仓库搭建之RPM包制作<br>3.传到yum仓库  </p><pre><code>$cp cron-init-script-1.1-1.noarch.rpm /application/yum/centos6.6/x86_64/ </code></pre><p>4.更新yum仓库索引  </p><pre><code>$createrepo --update /application/yum/centos6.6/x86_64/Spawning worker 0 with 1 pkgs  Workers Finished  Gathering worker results  Saving Primary metadata  Saving file lists metadata  Saving other metadata  Generating sqlite DBs  Sqlite DBs complete  </code></pre><p>5.客户端清空yum缓存    </p><pre><code>###yum clean all  Loaded plugins: fastestmirror, security  Cleaning repos: oldboy  Cleaning up Everything   Cleaning up list of fastest mirrors  </code></pre><p>6.查找cron包  </p><pre><code># yum list |grep cron-init  cron-init-script.noarch 1.0-1  @oldboy#前面的@表示已经安装过，保留下来的信息   cron-init-script.noarch 1.1-1  oldboy   </code></pre><p>7.更新cron包  </p><pre><code># crontab -l  */5 * * * * /usr/sbin/ntpdate pool.ntp.org &gt;/dev/null 2&gt;&amp;1  # yum update cron-init-script  Is this ok [y/N]: y  Running Transaction    Updating  : cron-init-script-1.1-1.noarch1/2     Cleanup: cron-init-script-1.0-1.noarch2/2     Verifying  : cron-init-script-1.1-1.noarch1/2     Verifying  : cron-init-script-1.0-1.noarch2/2  Updated:    cron-init-script.noarch 0:1.1-1 Complete!  # crontab -l  */5 * * * * /usr/sbin/ntpdate pool.ntp.org &gt;/dev/null 2&gt;&amp;1  */10 * * * * /usr/sbin/ntpdate 1.pool.ntp.org &gt;/dev/null 2&gt;&amp;1  </code></pre><p>cron任务已更新。  </p><pre><code>fpm -f -s dir -t rpm -n easemob-sersync-ssy -v 2.5.4_64bit  --iteration 1.el6.centos -a native \  -C /tmp/easemob-serync \  --vendor &apos;sam@easemob.com&apos; \  --description &apos;Ejabberd packager by easemob.com&apos; \  --url &apos;https://github.com/easemob/serync/&apos; \  --rpm-user easemob \  --rpm-group easemob \  --verbose \  --epoch 20160616  createrepo /data/apps/data/nginx/yum/ssy/ssy201606/x86_64/6/easemob-ssy/packages/</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt; 常见的软件安装方式有以下几种&lt;br&gt;1.yum安装，可自动解决依赖，但不能自定义软件安装位置&lt;br&gt;2.编译安装，可指定安装路径，指定装模块，但编译参数冗长，且耗时较长，不能解决依赖问题。&lt;br&gt;
    
    </summary>
    
      <category term="rpm" scheme="http://datura.me/categories/rpm/"/>
    
    
      <category term="rpm" scheme="http://datura.me/tags/rpm/"/>
    
  </entry>
  
  <entry>
    <title>tcpdump抓包命令详解</title>
    <link href="http://datura.me/2016/11/03/tcpdump%E6%8A%93%E5%8C%85%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
    <id>http://datura.me/2016/11/03/tcpdump抓包命令详解/</id>
    <published>2016-11-03T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.724Z</updated>
    
    <content type="html"><![CDATA[<p>TCPdump抓包命令<br>tcpdump是一个用于截取网络分组，并输出分组内容的工具。tcpdump凭借强大的功能和灵活的截取策略，使其成为类UNIX系统下用于网络分析和问题排查的首选工具。<br>tcpdump提供了源代码，公开了接口，因此具备很强的可扩展性，对于网络维护和入侵者都是非常有用的工具。tcpdump存在于基本的Linux系统中，由于它需要将网络界面设置为混杂模式，普通用户不能正常执行，但具备root权限的用户可以直接执行它来获取网络上的信息。因此系统中存在网络分析工具主要不是对本机安全的威胁，而是对网络上的其他计算机的安全存在威胁。<br><a id="more"></a><br>一、概述<br>顾名思义，tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。<br>引用</p><h1 id="tcpdump-vv"><a href="#tcpdump-vv" class="headerlink" title="tcpdump -vv"></a>tcpdump -vv</h1><p>tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes<br>11:53:21.444591 IP (tos 0x10, ttl 64, id 19324, offset 0, flags [DF], proto 6, length: 92) asptest.localdomain.ssh &gt; 192.168.228.244.1858: P 3962132600:3962132652(52) ack 2726525936 win 1266<br>asptest.localdomain.1077 &gt; 192.168.228.153.domain: [bad udp cksum 166e!] 325+ PTR? 244.228.168.192.in-addr.arpa. (46)<br>11:53:21.446929 IP (tos 0x0, ttl 64, id 42911, offset 0, flags [DF], proto 17, length: 151) 192.168.228.153.domain &gt; asptest.localdomain.1077: 325 NXDomain q: PTR? 244.228.168.192.in-addr.arpa. 0/1/0 ns: 168.192.in-addr.arpa. (123)<br>11:53:21.447408 IP (tos 0x10, ttl 64, id 19328, offset 0, flags [DF], proto 6, length: 172) asptest.localdomain.ssh &gt; 192.168.228.244.1858: P 168:300(132) ack 1 win 1266<br>347 packets captured<br>1474 packets received by filter<br>745 packets dropped by kernel<br>不带参数的tcpdump会收集网络中所有的信息包头，数据量巨大，必须过滤。</p><p>二、选项介绍<br>引用<br>-A 以ASCII格式打印出所有分组，并将链路层的头最小化。<br>-c 在收到指定的数量的分组后，tcpdump就会停止。<br>-C 在将一个原始分组写入文件之前，检查文件当前的大小是否超过了参数file_size 中指定的大小。如果超过了指定大小，则关闭当前文件，然后在打开一个新的文件。参数 file_size 的单位是兆字节（是1,000,000字节，而不是1,048,576字节）。<br>-d 将匹配信息包的代码以人们能够理解的汇编格式给出。<br>-dd 将匹配信息包的代码以C语言程序段的格式给出。<br>-ddd 将匹配信息包的代码以十进制的形式给出。<br>-D 打印出系统中所有可以用tcpdump截包的网络接口。<br>-e 在输出行打印出数据链路层的头部信息。<br>-E 用spi@ipaddr algo:secret解密那些以addr作为地址，并且包含了安全参数索引值spi的IPsec ESP分组。<br>-f 将外部的Internet地址以数字的形式打印出来。<br>-F 从指定的文件中读取表达式，忽略命令行中给出的表达式。<br>-i 指定监听的网络接口。<br>-l 使标准输出变为缓冲行形式，可以把数据导出到文件。<br>-L 列出网络接口的已知数据链路。<br>-m 从文件module中导入SMI MIB模块定义。该参数可以被使用多次，以导入多个MIB模块。<br>-M 如果tcp报文中存在TCP-MD5选项，则需要用secret作为共享的验证码用于验证TCP-MD5选选项摘要（详情可参考RFC 2385）。<br>-b 在数据-链路层上选择协议，包括ip、arp、rarp、ipx都是这一层的。<br>-n 不把网络地址转换成名字。<br>-nn 不进行端口名称的转换。<br>-N 不输出主机名中的域名部分。例如，‘nic.ddn.mil‘只输出’nic‘。<br>-t 在输出的每一行不打印时间戳。<br>-O 不运行分组分组匹配（packet-matching）代码优化程序。<br>-P 不将网络接口设置成混杂模式。<br>-q 快速输出。只输出较少的协议信息。<br>-r 从指定的文件中读取包(这些包一般通过-w选项产生)。<br>-S 将tcp的序列号以绝对值形式输出，而不是相对值。<br>-s 从每个分组中读取最开始的snaplen个字节，而不是默认的68个字节。<br>-T 将监听到的包直接解释为指定的类型的报文，常见的类型有rpc远程过程调用）和snmp（简单网络管理协议；）。<br>-t 不在每一行中输出时间戳。<br>-tt 在每一行中输出非格式化的时间戳。<br>-ttt 输出本行和前面一行之间的时间差。<br>-tttt 在每一行中输出由date处理的默认格式的时间戳。<br>-u 输出未解码的NFS句柄。<br>-v 输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息。<br>-vv 输出详细的报文信息。<br>-w 直接将分组写入文件中，而不是不分析并打印出来。</p><p>三、tcpdump的表达式介绍<br>表达式是一个正则表达式，tcpdump利用它作为过滤报文的条件，如果一个报文满足表 达式的条件，则这个报文将会被捕获。如果没有给出任何条件，则网络上所有的信息包 将会被截获。<br>在表达式中一般如下几种类型的关键字：<br>引用<br>第一种是关于类型的关键字，主要包括host，net，port，例如 host 210.27.48.2， 指明 210.27.48.2是一台主机，net 202.0.0.0指明202.0.0.0是一个网络地址，port 23 指明端口号是23。如果没有指定类型，缺省的类型是host。<br>第二种是确定传输方向的关键字，主要包括src，dst，dst or src，dst and src， 这些关键字指明了传输的方向。举例说明，src 210.27.48.2 ，指明ip包中源地址是 210.27.48.2 ， dst net 202.0.0.0 指明目的网络地址是202.0.0.0。如果没有指明 方向关键字，则缺省是src or dst关键字。<br>第三种是协议的关键字，主要包括fddi，ip，arp，rarp，tcp，udp等类型。Fddi指明是在FDDI (分布式光纤数据接口网络)上的特定的网络协议，实际上它是”ether”的别名，fddi和ether 具有类似的源地址和目的地址，所以可以将fddi协议包当作ether的包进行处理和分析。 其他的几个关键字就是指明了监听的包的协议内容。如果没有指定任何协议，则tcpdump 将会 监听所有协议的信息包。<br>除了这三种类型的关键字之外，其他重要的关键字如下：gateway， broadcast，less， greater， 还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘， 与运算是’and’，’&amp;&amp;’;或运算是’or’ ，’&#124;&#124;’； 这些关键字可以组合起来构成强大的组合条件来满足人们的需要。<br>四、输出结果介绍<br>下面我们介绍几种典型的tcpdump命令的输出信息<br>(1) 数据链路层头信息<br>使用命令： </p><p>#tcpdump –e host ICE<br>ICE 是一台装有linux的主机。它的MAC地址是0：90：27：58：AF：1A H219是一台装有Solaris的SUN工作站。它的MAC地址是8：0：20：79：5B：46； 上一条命令的输出结果如下所示：<br>引用<br>21:50:12.847509 eth0 &lt; 8:0:20:79:5b:46 0:90:27:58:af:1a ip 60: h219.33357 &gt; ICE. telne t 0:0(0) ack 22535 win 8760 (DF)<br>21：50：12是显示的时间， 847509是ID号，eth0 &lt;表示从网络接口eth0接收该分组， eth0 &gt;表示从网络接口设备发送分组， 8:0:20:79:5b:46是主机H219的MAC地址， 它表明是从源地址H219发来的分组. 0:90:27:58:af:1a是主机ICE的MAC地址， 表示该分组的目的地址是ICE。 ip 是表明该分组是IP分组，60 是分组的长度， h219.33357 &gt; ICE. telnet 表明该分组是从主机H219的33357端口发往主机ICE的 TELNET(23)端口。 ack 22535 表明对序列号是222535的包进行响应。 win 8760表明发 送窗口的大小是8760。<br>(2) ARP包的tcpdump输出信息<br>使用命令： </p><p>#tcpdump arp<br>得到的输出结果是：<br>引用<br>22:32:42.802509 eth0 &gt; arp who-has route tell ICE (0:90:27:58:af:1a)<br>22:32:42.802902 eth0 &lt; arp reply route is-at 0:90:27:12:10:66 (0:90:27:58:af:1a)<br>22:32:42是时间戳， 802509是ID号， eth0 &gt;表明从主机发出该分组，arp表明是ARP请求包， who-has route tell ICE表明是主机ICE请求主机route的MAC地址。 0:90:27:58:af:1a是主机 ICE的MAC地址。<br>(3) TCP包的输出信息<br>用tcpdump捕获的TCP包的一般输出信息是：<br>引用<br>src &gt; dst: flags data-seqno ack window urgent options<br>src &gt; dst:表明从源地址到目的地址， flags是TCP报文中的标志信息，S 是SYN标志， F (FIN)， P (PUSH) ， R (RST) “.” (没有标记); data-seqno是报文中的数据 的顺序号， ack是下次期望的顺序号， window是接收缓存的窗口大小， urgent表明 报文中是否有紧急指针。 Options是选项。<br>(4) UDP包的输出信息<br>用tcpdump捕获的UDP包的一般输出信息是：<br>引用<br>route.port1 &gt; ICE.port2: udp lenth<br>UDP十分简单，上面的输出行表明从主机route的port1端口发出的一个UDP报文 到主机ICE的port2端口，类型是UDP， 包的长度是lenth。<br>五、举例<br>(1) 想要截获所有210.27.48.1 的主机收到的和发出的所有的分组： </p><p>#tcpdump host 210.27.48.1<br>(2) 想要截获主机210.27.48.1 和主机210.27.48.2或210.27.48.3的通信，使用命令（注意：括号前的反斜杠是必须的）： </p><p>#tcpdump host 210.27.48.1 and 210.27.48.2or210.27.48.3<br>(3) 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令： </p><p>#tcpdump ip host 210.27.48.1 and ! 210.27.48.2<br>(4) 如果想要获取主机192.168.228.246接收或发出的ssh包，并且不转换主机名使用如下命令： </p><p>#tcpdump -nn -n src host 192.168.228.246 and port 22 and tcp<br>(5) 获取主机192.168.228.246接收或发出的ssh包，并把mac地址也一同显示：</p><h1 id="tcpdump-e-src-host-192-168-228-246-and-port-22-and-tcp-n-nn"><a href="#tcpdump-e-src-host-192-168-228-246-and-port-22-and-tcp-n-nn" class="headerlink" title="tcpdump -e src host 192.168.228.246 and port 22 and tcp -n -nn"></a>tcpdump -e src host 192.168.228.246 and port 22 and tcp -n -nn</h1><p>(6) 过滤的是源主机为192.168.0.1与目的网络为192.168.0.0的报头：<br>tcpdump src host 192.168.0.1 and dst net 192.168.0.0/24<br>(7) 过滤源主机物理地址为XXX的报头：<br>tcpdump ether src 00:50:04:BA:9B and dst……<br>（为什么ether src后面没有host或者net？物理地址当然不可能有网络喽）。<br>(8) 过滤源主机192.168.0.1和目的端口不是telnet的报头，并导入到tes.t.txt文件中：<br>Tcpdump src host 192.168.0.1 and dst port not telnet -l &gt; test.txt<br>ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型。<br>tcpdump采用命令行方式，它的命令格式为：<br>tcpdump [-nn] [-i 接口] [-w 储存档名] [-c 次数] [-Ae]<br>                        [-qX] [-r 文件] [所欲捕获的数据内容]<br>参数：<br>-nn，直接以 IP 及 Port Number 显示，而非主机名与服务名称。<br>-i，后面接要「监听」的网络接口，例如 eth0, lo, ppp0 等等的接口。<br>-w，如果你要将监听所得的数据包数据储存下来，用这个参数就对了。后面接文件名。<br>-c，监听的数据包数，如果没有这个参数， tcpdump 会持续不断的监听，<br>     直到用户输入 [ctrl]-c 为止。<br>-A，数据包的内容以 ASCII 显示，通常用来捉取 WWW 的网页数据包资料。<br>-e，使用资料连接层 (OSI 第二层) 的 MAC 数据包数据来显示。<br>-q，仅列出较为简短的数据包信息，每一行的内容比较精简。<br>-X，可以列出十六进制 (hex) 以及 ASCII 的数据包内容，对于监听数据包内容很有用。<br>-r，从后面接的文件将数据包数据读出来。那个「文件」是已经存在的文件，<br>     并且这个「文件」是由 -w 所制作出来的。<br>所欲捕获的数据内容：我们可以专门针对某些通信协议或者是 IP 来源进行数据包捕获。<br>     那就可以简化输出的结果，并取得最有用的信息。常见的表示方法有。<br>    ‘host foo’, ‘host 127.0.0.1’ ：针对单台主机来进行数据包捕获。<br>     ‘net 192.168’ ：针对某个网段来进行数据包的捕获。<br>     ‘src host 127.0.0.1’ ‘dst net 192.168’：同时加上来源(src)或目标(dst)限制。<br>     ‘tcp port 21’：还可以针对通信协议检测，如tcp、udp、arp、ether 等。<br>     除了这三种类型的关键字之外，其他重要的关键字如下：gateway, broadcast,less,<br>greater,还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘, 与运算是’and’,’&amp;&amp;’;或运算 是’o<br>r’ ,’||’；</p><p>范例一：以 IP 与 Port Number 捉下 eth0 这个网卡上的数据包，持续 3 秒<br>[root@linux ~]# tcpdump -i eth0 -nn<br>tcpdump: verbose output suppressed, use -v or -vv for full protocol decode<br>listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes<br>01:33:40.41 IP 192.168.1.100.22 &gt; 192.168.1.11.1190: P 116:232(116) ack 1 win<br>9648<br>01:33:40.41 IP 192.168.1.100.22 &gt; 192.168.1.11.1190: P 232:364(132) ack 1 win<br>9648<br>&lt;==按下 [ctrl]-c 之后结束<br>6680 packets captured              &lt;==捉取下来的数据包数量<br>14250 packets received by filter   &lt;==由过滤所得的总数据包数量<br>7512 packets dropped by kernel     &lt;==被核心所丢弃的数据包<br>至于那个在范例一所产生的输出中，我们可以大概区分为几个字段，现以范例一当中那行特殊字体行来说明一下：<br>· 01:33:40.41：这个是此数据包被捕获的时间，“时:分:秒”的单位。<br>· IP：通过的通信协议是IP。<br>· 192.168.1.100.22&gt;：传送端是192.168.1.100这个IP，而传送的Port Number为22，那个大于（&gt;）的符号指的是数据包的传输方向。<br>· 192.168.1.11.1190：接收端的IP是192.168.1.11，且该主机开启port 1190来接收。<br>· P 116:232(116)：这个数据包带有PUSH的数据传输标志，且传输的数据为整体数据的116~232 Byte，所以这个数据包带有116 Bytes的数据量。<br>· ack 1 win 9648：ACK与Window size的相关资料。<br>最简单的说法，就是该数据包是由192.168.1.100传到192.168.1.11，通过的port是由22到1190，且带有116 Bytes的数据量，使用的是PUSH的标记，而不是SYN之类的主动联机标志。<br>接下来，在一个网络状态很忙的主机上面，你想要取得某台主机对你联机的数据包数据时，使用tcpdump配合管线命令与正则表达式也可以，不过，毕竟不好捕获。我们可以通过tcpdump的表达式功能，就能够轻易地将所需要的数据独立的取出来。在上面的范例一当中，我们仅针对eth0做监听，所以整个eth0接口上面的数据都会被显示到屏幕上，但这样不好分析，可以简化吗？例如，只取出port 21的联机数据包，可以这样做：<br>[root@linux ~]# tcpdump -i eth0 -nn port 21<br>tcpdump: verbose output suppressed, use -v or -vv for full protocol decode<br>listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes<br>01:54:37.96 IP 192.168.1.11.1240 &gt; 192.168.1.100.21:. ack 1 win 65535<br>01:54:37.96 IP 192.168.1.100.21 &gt; 192.168.1.11.1240:P 1:21(20) ack 1 win 5840<br>01:54:38.12 IP 192.168.1.11.1240 &gt; 192.168.1.100.21:. ack 21 win 65515<br>01:54:42.79 IP 192.168.1.11.1240 &gt; 192.168.1.100.21:P 1:17(16) ack 21 win 65515<br>01:54:42.79 IP 192.168.1.100.21 &gt; 192.168.1.11.1240: . ack 17 win 5840<br>01:54:42.79 IP 192.168.1.100.21 &gt; 192.168.1.11.1240: P 21:55(34) ack 17 win 5840<br>看！这样就仅取出port 21的信息，如果仔细看的话，你会发现数据包的传递都是双向的，Client端发出请求而Server端则予以响应，所以，当然是有去有回了。而我们也就可以经过这个数据包的流向来了解到数据包运动的过程了。例如：<br>· 我们先在一个终端机窗口输入“tcpdump-i lo-nn”的监听。<br>· 再另开一个终端机窗口来对本机（127.0.0.1）登录“ssh localhost”，那么输出的结果会是如何？<br>[root@linux ~]# tcpdump -i lo -nn<br> 1 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode<br> 2 listening on lo, link-type EN10MB (Ethernet), capture size 96 bytes<br> 3 11:02:54.253777 IP 127.0.0.1.32936 &gt;<br>127.0.0.1.22: S 933696132:933696132(0)<br>   win 32767<br> 4 11:02:54.253831 IP 127.0.0.1.22 &gt; 127.0.0.1.32936:<br>S 920046702:920046702(0)<br>   ack 933696133 win 32767<br> 5 11:02:54.253871 IP 127.0.0.1.32936 &gt; 127.0.0.1.22: . ack 1 win 8192<br> 6 11:02:54.272124 IP 127.0.0.1.22 &gt; 127.0.0.1.32936:<br>P 1:23(22) ack 1 win 8192 </p><p> 7 11:02:54.272375 IP 127.0.0.1.32936 &gt; 127.0.0.1.22: . ack 23 win 8192<br>代码显示的头两行是tcpdump的基本说明，然后：<br>· 第3行显示的是来自Client端带有SYN主动联机的数据包。<br>· 第4行显示的是来自Server端，除了响应Client端之外（ACK），还带有SYN主动联机的标志。<br>· 第5行则显示Client端响应Server确定联机建立（ACK）。<br>· 第6行以后则开始进入数据传输的步骤。<br>从第3~5行的流程来看，熟不熟悉啊？没错。那就是3次握手的基础流程，有趣吧。不过tcpdump之所以被称为黑客软件之一远不止上面介绍的功能。上面介绍的功能可以用来作为我们主机的数据包联机与传输的流程分析，这将有助于我们了解到数据包的运作，同时了解到主机的防火墙设置规则是否有需要修订的地方。<br>还有更神奇的用法。当我们使用tcpdump在Router上面监听明文的传输数据时，例如FTP传输协议，你觉得会发生什么问题呢？我们先在主机端执行“tcpdump -i lo port 21 -nn –X”，然后再以FTP登录本机，并输入账号与密码，结果你就可以发现如下的状况：<br>[root@linux ~]# tcpdump -i lo -nn -X ‘port 21’<br>    0x0000:  4500 0048 2a28 4000 4006 1286 7f00 0001  E..H*(@.@…….<br>    0x0010:  7f00 0001 0015 80ab 8355 2149 835c d825  ………U!I..%<br>    0x0020:  8018 2000 fe3c 0000 0101 080a 0e2e 0b67  …..&lt;………g<br>    0x0030:  0e2e 0b61 3232 3020 2876 7346 5450 6420  …a220.(vsFTPd.<br>    0x0040:  322e 302e 3129 0d0a                      2.0.1)..</p><pre><code>0x0000:  4510 0041 d34b 4000 4006 6959 7f00 0001  E..A.K@.@.iY....0x0010:  7f00 0001 80ab 0015 835c d825 8355 215d  .........\.%.U!]0x0020:  8018 2000 fe35 0000 0101 080a 0e2e 1b37  .....5.........70x0030:  0e2e 0b67 5553 4552 2064 6d74 7361 690d  ...gUSER.dmtsai.0x0040:  0a                                       .0x0000:  4510 004a d34f 4000 4006 694c 7f00 0001  E..J.O@.@.iL....0x0010:  7f00 0001 80ab 0015 835c d832 8355 217f  .........\.2.U!.0x0020:  8018 2000 fe3e 0000 0101 080a 0e2e 3227  .....&gt;........2&apos;0x0030:  0e2e 1b38 5041 5353 206d 7970 6173 7377  ...8PASS.mypassw0x0040:  6f72 6469 7379 6f75 0d0a                 ordisyou..</code></pre><p>上面的输出结果已经被简化过了，你需要自行在你的输出结果中搜索相关的字符串才行。从上面输出结果的特殊字体中，我们可以发现该FTP软件使用的是 vsFTPd，并且用户输入dmtsai这个账号名称，且密码是mypasswordisyou。如果使用的是明文方式来传输你的网络数据呢？<br>另外你得了解，为了让网络接口可以让tcpdump监听，所以执行tcpdump时网络接口会启动在“混杂模式（promiscuous）”，所以你会在 /var/log/messages里面看到很多的警告信息，通知你说你的网卡被设置成为混杂模式。别担心，那是正常的。至于更多的应用，请参考man tcpdump了。</p><p>例题：如何使用tcpdump监听来自eth0适配卡且通信协议为port 22，目标来源为192.168.1.100的数据包资料？<br>答：tcpdump -i eth0 -nn ‘port 22 and src host 192.168.1.100’。</p><p>##############例子2#######################################</p><p>普通情况下，直接启动tcpdump将监视第一个网络界面上所有流过的数据包。</p><h1 id="tcpdump"><a href="#tcpdump" class="headerlink" title="tcpdump"></a>tcpdump</h1><p>tcpdump: listening on fxp0<br>11:58:47.873028 202.102.245.40.netbios-ns &gt; 202.102.245.127.netbios-ns: udp 50<br>11:58:47.974331 0:10:7b:8:3a:56 &gt; 1:80:c2:0:0:0 802.1d ui/C len=43<br>0000 0000 0080 0000 1007 cf08 0900 0000<br>0e80 0000 902b 4695 0980 8701 0014 0002<br>000f 0000 902b 4695 0008 00<br>11:58:48.373134 0:0:e8:5b:6d:85 &gt; Broadcast sap e0 ui/C len=97<br>ffff 0060 0004 ffff ffff ffff ffff ffff<br>0452 ffff ffff 0000 e85b 6d85 4008 0002<br>0640 4d41 5354 4552 5f57 4542 0000 0000<br>0000 00<br>使用-i参数指定tcpdump监听的网络界面，这在计算机具有多个网络界面时非常有用，<br>使用-c参数指定要监听的数据包数量，<br>使用-w参数指定将监听到的数据包写入文件中保存<br>A想要截获所有210.27.48.1 的主机收到的和发出的所有的数据包：</p><p>#tcpdump host 210.27.48.1<br>B想要截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信，使用命令：（在命令行中适用　　　括号时，一定要</p><p>#tcpdump host 210.27.48.1 and \ (210.27.48.2 or 210.27.48.3 )<br>C如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：</p><p>#tcpdump ip host 210.27.48.1 and ! 210.27.48.2<br>D如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令：</p><p>#tcpdump tcp port 23 host 210.27.48.1<br>E 对本机的udp 123 端口进行监视 123 为ntp的服务端口</p><h1 id="tcpdump-udp-port-123"><a href="#tcpdump-udp-port-123" class="headerlink" title="tcpdump udp port 123"></a>tcpdump udp port 123</h1><p>F 系统将只对名为hostname的主机的通信数据包进行监视。主机名可以是本地主机，也可以是网络上的任何一台计算机。下面的命令可以读取主机hostname发送的所有数据：</p><p>#tcpdump -i eth0 src host hostname<br>G 下面的命令可以监视所有送到主机hostname的数据包：</p><p>#tcpdump -i eth0 dst host hostname<br>H 我们还可以监视通过指定网关的数据包：</p><p>#tcpdump -i eth0 gateway Gatewayname<br>I 如果你还想监视编址到指定端口的TCP或UDP数据包，那么执行以下命令：</p><p>#tcpdump -i eth0 host hostname and port 80<br>J 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包<br>，使用命令：</p><p>#tcpdump ip host 210.27.48.1 and ! 210.27.48.2<br>K 想要截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信，使用命令<br>：（在命令行中适用　　　括号时，一定要</p><p>#tcpdump host 210.27.48.1 and \ (210.27.48.2 or 210.27.48.3 )<br>L 如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：</p><p>#tcpdump ip host 210.27.48.1 and ! 210.27.48.2<br>M 如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令：</p><p>#tcpdump tcp port 23 host 210.27.48.1<br>第三种是协议的关键字，主要包括fddi,ip ,arp,rarp,tcp,udp等类型<br>除了这三种类型的关键字之外，其他重要的关键字如下：gateway, broadcast,less,<br>greater,还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘, 与运算是‘and‘,‘&amp;&amp;‘;或运算 是‘o<br>r‘ ,‘||‘；<br>第二种是确定传输方向的关键字，主要包括src , dst ,dst or src, dst and src ,<br>如果我们只需要列出送到80端口的数据包，用dst port；如果我们只希望看到返回80端口的数据包，用src port。</p><p>#tcpdump –i eth0 host hostname and dst port 80 目的端口是80<br>或者</p><p>#tcpdump –i eth0 host hostname and src port 80 源端口是80 一般是提供http的服务的主机<br>如果条件很多的话 要在条件之前加and 或 or 或 not</p><p>#tcpdump -i eth0 host ! 211.161.223.70 and ! 211.161.223.71 and dst port 80<br>如果在ethernet 使用混杂模式 系统的日志将会记录<br>May 7 20:03:46 localhost kernel: eth0: Promiscuous mode enabled.<br>May 7 20:03:46 localhost kernel: device eth0 entered promiscuous mode<br>May 7 20:03:57 localhost kernel: device eth0 left promiscuous mode<br>tcpdump对截获的数据并没有进行彻底解码，数据包内的大部分内容是使用十六进制的形式直接打印输出的。显然这不利于分析网络故障，通常的解决办法是先使用带-w参数的tcpdump 截获数据并保存到文件中，然后再使用其他程序进行解码分析。当然也应该定义过滤规则，以避免捕获的数据包填满整个硬盘。<br>除了过滤语句，还有一个很重要的参数，也就是说，如果这个参数不设置正确，会导致包数据的丢失！<br>它就是-s 参数，snaplen, 也就是数据包的截取长度，仔细看man就会明白的！默认截取长度为60个字节，但一般ethernet MTU都是1500字节。所以，要抓取大于60字节的包时，使用默认参数就会导致包数据丢失！<br>只要使用-s 0就可以按包长，截取数据！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;TCPdump抓包命令&lt;br&gt;tcpdump是一个用于截取网络分组，并输出分组内容的工具。tcpdump凭借强大的功能和灵活的截取策略，使其成为类UNIX系统下用于网络分析和问题排查的首选工具。&lt;br&gt;tcpdump提供了源代码，公开了接口，因此具备很强的可扩展性，对于网络维护和入侵者都是非常有用的工具。tcpdump存在于基本的Linux系统中，由于它需要将网络界面设置为混杂模式，普通用户不能正常执行，但具备root权限的用户可以直接执行它来获取网络上的信息。因此系统中存在网络分析工具主要不是对本机安全的威胁，而是对网络上的其他计算机的安全存在威胁。&lt;br&gt;
    
    </summary>
    
      <category term="linux" scheme="http://datura.me/categories/linux/"/>
    
    
      <category term="tcpdum" scheme="http://datura.me/tags/tcpdum/"/>
    
  </entry>
  
  <entry>
    <title>mtr命令详解</title>
    <link href="http://datura.me/2016/11/03/mtr%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
    <id>http://datura.me/2016/11/03/mtr命令详解/</id>
    <published>2016-11-03T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.724Z</updated>
    
    <content type="html"><![CDATA[<p>一般在windows 来判断网络连通性用ping 和tracert,ping的话可以来判断丢包率，tracert可以用来跟踪路由，在Linux中有一个更好的网络连通性判断工具，它可以结合ping nslookup tracert 来判断网络的相关特性,这个命令就是mtr<br><a id="more"></a><br>    [<a href="mailto:root@10.10.90.97" target="_blank" rel="noopener">root@10.10.90.97</a> ~]# mtr -h<br>    usage: mtr [-hvrctglspni46] [–help] [–version] [–report]<br>    [–report-cycles=COUNT] [–curses] [–gtk]<br>    [–raw] [–split] [–no-dns] [–address interface]<br>    [–psize=bytes/-s bytes]<br>        [–interval=SECONDS] HOSTNAME [PACKETSIZE]</p><pre><code>mtr -h 提供帮助命令mtr -v 显示mtr的版本信息mtr -r 已报告模式显示[root@10.10.90.97 ~]# mtr -r 202.108.33.94FOCUS9097 Snt: 10 Loss% Last Avg Best Wrst StDev220.181.61.252 0.0% 6.8 3.3 1.8 7.4 2.2220.181.17.217 0.0% 0.4 0.5 0.4 0.7 0.1220.181.16.17 0.0% 0.6 0.5 0.5 0.6 0.0202.97.53.14 10.0% 0.7 0.7 0.7 0.8 0.0219.158.35.1 0.0% 0.8 0.8 0.8 0.9 0.0219.158.5.81 0.0% 1.2 1.3 1.2 1.6 0.1123.126.0.138 0.0% 1.2 1.1 1.1 1.3 0.161.148.153.126 0.0% 1.9 10.5 1.5 89.9 27.961.148.143.22 0.0% 1.5 1.6 1.5 1.7 0.0210.74.178.198 0.0% 1.6 1.6 1.5 1.9 0.1202.108.33.94 0.0% 1.5 1.5 1.4 1.5 0.0</code></pre><p>报告说明：<br>第一列:显示的是IP地址和本机域名，这点和tracert很像<br>第二列:snt:10 设置每秒发送数据包的数量，默认值是10 可以通过参数 -c来指定。</p><pre><code>[root@10.10.90.97 ~]# mtr -r -c 15 202.108.33.94FOCUS9097 Snt: 15 Loss% Last Avg Best Wrst StDev220.181.61.252 0.0% 1.9 3.4 1.8 12.9 3.1220.181.17.217 0.0% 0.5 0.5 0.4 0.8 0.1220.181.16.17 0.0% 0.5 0.6 0.5 2.3 0.5202.97.53.14 0.0% 0.7 0.7 0.7 0.7 0.0219.158.35.1 0.0% 0.9 0.8 0.8 0.9 0.0219.158.5.81 0.0% 1.3 2.8 1.2 22.8 5.5123.126.0.138 0.0% 1.1 1.1 1.1 1.2 0.061.148.153.126 0.0% 13.8 7.4 1.6 60.4 15.561.148.143.22 0.0% 1.7 1.6 1.5 1.8 0.1210.74.178.198 0.0% 1.6 1.6 1.4 1.7 0.1202.108.33.94 0.0% 1.5 1.5 1.4 1.7 0.1</code></pre><p>其中-c的说明是：–report-cycles COUNT</p><p>第三列:是显示的每个对应IP的丢包率<br>第四列:显示的最近一次的返回时延<br>第五列:是平均值 这个应该是发送ping包的平均时延<br>第六列:是最好或者说时延最短的<br>第七列:是最差或者说时延最常的<br>第八列:是标准偏差<br>接下来接着说相关参数：</p><pre><code>mtr -s 用来指定ping数据包的大小mtr -n no-dns不对IP地址做域名解析mtr -a 来设置发送数据包的IP地址 这个对一个主机由多个IP地址是有用的mtr -i 使用这个参数来设置ICMP返回之间的要求默认是1秒mtr -4 IPv4mtr -6 IPv6</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一般在windows 来判断网络连通性用ping 和tracert,ping的话可以来判断丢包率，tracert可以用来跟踪路由，在Linux中有一个更好的网络连通性判断工具，它可以结合ping nslookup tracert 来判断网络的相关特性,这个命令就是mtr&lt;br&gt;
    
    </summary>
    
      <category term="mtr" scheme="http://datura.me/categories/mtr/"/>
    
    
      <category term="mtr" scheme="http://datura.me/tags/mtr/"/>
    
  </entry>
  
  <entry>
    <title>路由跟踪指令traceroute</title>
    <link href="http://datura.me/2016/11/03/linux%20traceroute%20%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
    <id>http://datura.me/2016/11/03/linux traceroute 命令详解/</id>
    <published>2016-11-03T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.723Z</updated>
    
    <content type="html"><![CDATA[<p>通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的<br><a id="more"></a><br>linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。<br>在大多数情况下，我们会在linux主机系统下，直接执行命令行：traceroute hostname<br>而在Windows系统下是执行tracert的命令： tracert hostname<br>1.命令格式：<br>traceroute[参数][主机]<br>2.命令功能：<br>traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。<br>具体参数格式：traceroute [-dFlnrvx][-f&lt;存活数值&gt;][-g&lt;网关&gt;…][-i&lt;网络界面&gt;][-m&lt;存活数值&gt;][-p&lt;通信端口&gt;][-s&lt;来源地址&gt;][-t&lt;服务类型&gt;][-w&lt;超时秒数&gt;][主机名称或IP地址][数据包大小]<br>3.命令参数：<br>-d 使用Socket层级的排错功能。<br>-f 设置第一个检测数据包的存活数值TTL的大小。<br>-F 设置勿离断位。<br>-g 设置来源路由网关，最多可设置8个。<br>-i 使用指定的网络界面送出数据包。<br>-I 使用ICMP回应取代UDP资料信息。<br>-m 设置检测数据包的最大存活数值TTL的大小。<br>-n 直接使用IP地址而非主机名称。<br>-p 设置UDP传输协议的通信端口。<br>-r 忽略普通的Routing Table，直接将数据包送到远端主机上。<br>-s 设置本地主机送出数据包的IP地址。<br>-t 设置检测数据包的TOS数值。<br>-v 详细显示指令的执行过程。<br>-w 设置等待远端主机回报的时间。<br>-x 开启或关闭数据包的正确性检验。<br>4.使用实例：<br>实例1：traceroute 用法简单、最常用的用法<br>命令：traceroute <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>输出：</p><p>复制代码<br>代码如下:</p><p>[root@localhost ~]# traceroute <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>traceroute to <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>1 192.168.74.2 (192.168.74.2) 2.606 ms 2.771 ms 2.950 ms<br>2 211.151.56.57 (211.151.56.57) 0.596 ms 0.598 ms 0.591 ms<br>3 211.151.227.206 (211.151.227.206) 0.546 ms 0.544 ms 0.538 ms<br>4 210.77.139.145 (210.77.139.145) 0.710 ms 0.748 ms 0.801 ms<br>5 202.106.42.101 (202.106.42.101) 6.759 ms 6.945 ms 7.107 ms<br>6 61.148.154.97 (61.148.154.97) 718.908 ms <em> bt-228-025.bta.net.cn (202.106.228.25) 5.177 ms<br>7 124.65.58.213 (124.65.58.213) 4.343 ms 4.336 ms 4.367 ms<br>8 202.106.35.190 (202.106.35.190) 1.795 ms 61.148.156.138 (61.148.156.138) 1.899 ms 1.951 ms<br>9 </em> <em> </em><br>30 <em> </em> *<br>[root@localhost ~]#<br>说明：<br>记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 <a href="http://www.58.com" target="_blank" rel="noopener">www.58.com</a> ，表示向每个网关发送4个数据包。<br>有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。<br>有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。<br>如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。<br>实例2：跳数设置<br>命令：traceroute -m 10 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>输出：</p><p>复制代码<br>代码如下:</p><p>[root@localhost ~]# traceroute -m 10 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>traceroute to <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> (61.135.169.105), 10 hops max, 40 byte packets<br>1 192.168.74.2 (192.168.74.2) 1.534 ms 1.775 ms 1.961 ms<br>2 211.151.56.1 (211.151.56.1) 0.508 ms 0.514 ms 0.507 ms<br>3 211.151.227.206 (211.151.227.206) 0.571 ms 0.558 ms 0.550 ms<br>4 210.77.139.145 (210.77.139.145) 0.708 ms 0.729 ms 0.785 ms<br>5 202.106.42.101 (202.106.42.101) 7.978 ms 8.155 ms 8.311 ms<br>6 bt-228-037.bta.net.cn (202.106.228.37) 772.460 ms bt-228-025.bta.net.cn (202.106.228.25) 2.152 ms 61.148.154.97 (61.148.154.97) 772.107 ms<br>7 124.65.58.221 (124.65.58.221) 4.875 ms 61.148.146.29 (61.148.146.29) 2.124 ms 124.65.58.221 (124.65.58.221) 4.854 ms<br>8 123.126.6.198 (123.126.6.198) 2.944 ms 61.148.156.6 (61.148.156.6) 3.505 ms 123.126.6.198 (123.126.6.198) 2.885 ms<br>9 <em> </em> <em><br>10 </em> <em> </em><br>[root@localhost ~]#</p><p>实例3：显示IP地址，不查主机名<br>命令：traceroute -n <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>输出：</p><p>复制代码<br>代码如下:</p><p>[root@localhost ~]# traceroute -n <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>traceroute to <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>1 211.151.74.2 5.430 ms 5.636 ms 5.802 ms<br>2 211.151.56.57 0.627 ms 0.625 ms 0.617 ms<br>3 211.151.227.206 0.575 ms 0.584 ms 0.576 ms<br>4 210.77.139.145 0.703 ms 0.754 ms 0.806 ms<br>5 202.106.42.101 23.683 ms 23.869 ms 23.998 ms<br>6 202.106.228.37 247.101 ms <em> </em><br>7 61.148.146.29 5.256 ms 124.65.58.213 4.386 ms 4.373 ms<br>8 202.106.35.190 1.610 ms 61.148.156.138 1.786 ms 61.148.3.34 2.089 ms<br>9 <em> </em> <em><br>30 </em> <em> </em><br>[root@localhost ~]# traceroute <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>traceroute to <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>1 211.151.74.2 (211.151.74.2) 4.671 ms 4.865 ms 5.055 ms<br>2 211.151.56.57 (211.151.56.57) 0.619 ms 0.618 ms 0.612 ms<br>3 211.151.227.206 (211.151.227.206) 0.620 ms 0.642 ms 0.636 ms<br>4 210.77.139.145 (210.77.139.145) 0.720 ms 0.772 ms 0.816 ms<br>5 202.106.42.101 (202.106.42.101) 7.667 ms 7.910 ms 8.012 ms<br>6 bt-228-025.bta.net.cn (202.106.228.25) 2.965 ms 2.440 ms 61.148.154.97 (61.148.154.97) 431.337 ms<br>7 124.65.58.213 (124.65.58.213) 5.134 ms 5.124 ms 5.044 ms<br>8 202.106.35.190 (202.106.35.190) 1.917 ms 2.052 ms 2.059 ms<br>9 <em> </em> <em><br>30 </em> <em> </em><br>[root@localhost ~]#<br>实例4：探测包使用的基本UDP端口设置6888<br>命令：traceroute -p 6888 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>输出：</p><p>复制代码<br>代码如下:</p><p>[root@localhost ~]# traceroute -p 6888 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>traceroute to <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> (220.181.111.147), 30 hops max, 40 byte packets<br>1 211.151.74.2 (211.151.74.2) 4.927 ms 5.121 ms 5.298 ms<br>2 211.151.56.1 (211.151.56.1) 0.500 ms 0.499 ms 0.509 ms<br>3 211.151.224.90 (211.151.224.90) 0.637 ms 0.631 ms 0.641 ms<br>4 <em> </em> <em><br>5 220.181.70.98 (220.181.70.98) 5.050 ms 5.313 ms 5.596 ms<br>6 220.181.17.94 (220.181.17.94) 1.665 ms !X </em> *<br>[root@localhost ~]#<br>实例5：把探测包的个数设置为值4<br>命令：traceroute -q 4 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>输出：</p><p>复制代码<br>代码如下:</p><p>[root@localhost ~]# traceroute -q 4 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>traceroute to <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>1 211.151.74.2 (211.151.74.2) 40.633 ms 40.819 ms 41.004 ms 41.188 ms<br>2 211.151.56.57 (211.151.56.57) 0.637 ms 0.633 ms 0.627 ms 0.619 ms<br>3 211.151.227.206 (211.151.227.206) 0.505 ms 0.580 ms 0.571 ms 0.569 ms<br>4 210.77.139.145 (210.77.139.145) 0.753 ms 0.800 ms 0.853 ms 0.904 ms<br>5 202.106.42.101 (202.106.42.101) 7.449 ms 7.543 ms 7.738 ms 7.893 ms<br>6 61.148.154.97 (61.148.154.97) 316.817 ms bt-228-025.bta.net.cn (202.106.228.25) 3.695 ms 3.672 ms <em><br>7 124.65.58.213 (124.65.58.213) 3.056 ms 2.993 ms 2.960 ms 61.148.146.29 (61.148.146.29) 2.837 ms<br>8 61.148.3.34 (61.148.3.34) 2.179 ms 2.295 ms 2.442 ms 202.106.35.190 (202.106.35.190) 7.136 ms<br>9 </em> <em> </em> <em><br>30 </em> <em> </em> *<br>[root@localhost ~]# </p><p>实例6：绕过正常的路由表，直接发送到网络相连的主机<br>命令：traceroute -r <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>输出：</p><p>复制代码<br>代码如下:</p><p>[root@localhost ~]# traceroute -r <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>traceroute to <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> (61.135.169.125), 30 hops max, 40 byte packets<br>connect: 网络不可达<br>[root@localhost ~]#<br>实例7：把对外发探测包的等待响应时间设置为3秒<br>命令：traceroute -w 3 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>输出：</p><p>复制代码<br>代码如下:</p><p>[root@localhost ~]# traceroute -w 3 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>traceroute to <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> (61.135.169.105), 30 hops max, 40 byte packets<br>1 211.151.74.2 (211.151.74.2) 2.306 ms 2.469 ms 2.650 ms<br>2 211.151.56.1 (211.151.56.1) 0.621 ms 0.613 ms 0.603 ms<br>3 211.151.227.206 (211.151.227.206) 0.557 ms 0.560 ms 0.552 ms<br>4 210.77.139.145 (210.77.139.145) 0.708 ms 0.761 ms 0.817 ms<br>5 202.106.42.101 (202.106.42.101) 7.520 ms 7.774 ms 7.902 ms<br>6 bt-228-025.bta.net.cn (202.106.228.25) 2.890 ms 2.369 ms 61.148.154.97 (61.148.154.97) 471.961 ms<br>7 124.65.58.221 (124.65.58.221) 4.490 ms 4.483 ms 4.472 ms<br>8 123.126.6.198 (123.126.6.198) 2.948 ms 61.148.156.6 (61.148.156.6) 7.688 ms 7.756 ms<br>9 <em> </em> <em><br>30 </em> <em> </em><br>[root@localhost ~]# </p><p>Traceroute的工作原理：<br>Traceroute最简单的基本用法是：traceroute hostname<br>Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器…… traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？<br>Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。<br>Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。<br>windows之tracert:<br>格式：<br>tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name<br>参数说明：<br>tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name<br>该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间 (TLS) 过期的报文并且对 tracert 无效。<br>参数：<br>-d 指定不对计算机名解析地址。<br>-h maximum_hops 指定查找目标的跳转的最大数目。<br>-jcomputer-list 指定在 computer-list 中松散源路由。<br>-w timeout 等待由 timeout 对每个应答指定的毫秒数。<br>target_name 目标计算机的名称。<br>实例：</p><p>复制代码<br>代码如下:</p><p>C:\Users\Administrator&gt;tracert <a href="http://www.58.com" target="_blank" rel="noopener">www.58.com</a><br>Tracing route to <a href="http://www.58.com" target="_blank" rel="noopener">www.58.com</a> [221.187.111.30]<br>over a maximum of 30 hops:<br>1 1 ms 1 ms 1 ms 10.58.156.1<br>2 1 ms &lt;1 ms &lt;1 ms 10.10.10.1<br>3 1 ms 1 ms 1 ms 211.103.193.129<br>4 2 ms 2 ms 2 ms 10.255.109.129<br>5 1 ms 1 ms 3 ms 124.205.98.205<br>6 2 ms 2 ms 2 ms 124.205.98.253<br>7 2 ms 6 ms 1 ms 202.99.1.125<br>8 5 ms 6 ms 5 ms 118.186.0.113<br>9 207 ms <em> </em> 118.186.0.106<br>10 8 ms 6 ms 11 ms 124.238.226.201<br>11 6 ms 7 ms 6 ms 219.148.19.177<br>12 12 ms 12 ms 16 ms 219.148.18.117<br>13 14 ms 17 ms 16 ms 219.148.19.125<br>14 13 ms 13 ms 12 ms 202.97.80.113<br>15 <em> </em> <em> Request timed out.<br>16 12 ms 12 ms 17 ms bj141-147-82.bjtelecom.net [219.141.147.82]<br>17 13 ms 13 ms 12 ms 202.97.48.2<br>18 </em> <em> </em> Request timed out.<br>19 14 ms 14 ms 12 ms 221.187.224.85<br>20 15 ms 13 ms 12 ms 221.187.104.2<br>21 <em> </em> * Request timed out.<br>22 15 ms 17 ms 18 ms 221.187.111.30<br>Trace complete.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>路由跟踪指令traceroute</title>
    <link href="http://datura.me/2016/11/03/linux_traceroute_%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
    <id>http://datura.me/2016/11/03/linux_traceroute_命令详解/</id>
    <published>2016-11-03T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.723Z</updated>
    
    <content type="html"><![CDATA[<p>通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的<br><a id="more"></a><br>linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。<br>在大多数情况下，我们会在linux主机系统下，直接执行命令行：traceroute hostname<br>而在Windows系统下是执行tracert的命令： tracert hostname  </p><p>###1.命令格式：</p><pre><code>traceroute[参数][主机]</code></pre><p>###2.命令功能：<br>traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。<br>具体参数格式：<br>traceroute [-dFlnrvx][-f&lt;存活数值&gt;][-g&lt;网关&gt;…][-i&lt;网络界面&gt;][-m&lt;存活数值&gt;][-p&lt;通信端口&gt;][-s&lt;来源地址&gt;][-t&lt;服务类型&gt;][-w&lt;超时秒数&gt;][主机名称或IP地址][数据包大小]  </p><p>###3.命令参数：<br>    -d 使用Socket层级的排错功能。<br>    -f 设置第一个检测数据包的存活数值TTL的大小。<br>    -F 设置勿离断位。<br>    -g 设置来源路由网关，最多可设置8个。<br>    -i 使用指定的网络界面送出数据包。<br>    -I 使用ICMP回应取代UDP资料信息。<br>    -m 设置检测数据包的最大存活数值TTL的大小。<br>    -n 直接使用IP地址而非主机名称。<br>    -p 设置UDP传输协议的通信端口。<br>    -r 忽略普通的Routing Table，直接将数据包送到远端主机上。<br>    -s 设置本地主机送出数据包的IP地址。<br>    -t 设置检测数据包的TOS数值。<br>    -v 详细显示指令的执行过程。<br>    -w 设置等待远端主机回报的时间。<br>    -x 开启或关闭数据包的正确性检验。  </p><p>###4.使用实例：<br>实例1：traceroute 用法简单、最常用的用法<br>命令：traceroute <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>输出：</p><p>复制代码<br>代码如下:</p><pre><code>[root@localhost ~]# traceroute www.baidu.com  traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets  1 192.168.74.2 (192.168.74.2) 2.606 ms 2.771 ms 2.950 ms2 211.151.56.57 (211.151.56.57) 0.596 ms 0.598 ms 0.591 ms3 211.151.227.206 (211.151.227.206) 0.546 ms 0.544 ms 0.538 ms4 210.77.139.145 (210.77.139.145) 0.710 ms 0.748 ms 0.801 ms5 202.106.42.101 (202.106.42.101) 6.759 ms 6.945 ms 7.107 ms6 61.148.154.97 (61.148.154.97) 718.908 ms * bt-228-025.bta.net.cn (202.106.228.25) 5.177 ms7 124.65.58.213 (124.65.58.213) 4.343 ms 4.336 ms 4.367 ms8 202.106.35.190 (202.106.35.190) 1.795 ms 61.148.156.138 (61.148.156.138) 1.899 ms 1.951 ms9 * * *30 * * *[root@localhost ~]# 说明：  记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。      有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。</code></pre><p>实例2：跳数设置<br>    命令：traceroute -m 10 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>    输出：</p><pre><code>复制代码代码如下:[root@localhost ~]# traceroute -m 10 www.baidu.comtraceroute to www.baidu.com (61.135.169.105), 10 hops max, 40 byte packets1 192.168.74.2 (192.168.74.2) 1.534 ms 1.775 ms 1.961 ms2 211.151.56.1 (211.151.56.1) 0.508 ms 0.514 ms 0.507 ms3 211.151.227.206 (211.151.227.206) 0.571 ms 0.558 ms 0.550 ms4 210.77.139.145 (210.77.139.145) 0.708 ms 0.729 ms 0.785 ms5 202.106.42.101 (202.106.42.101) 7.978 ms 8.155 ms 8.311 ms6 bt-228-037.bta.net.cn (202.106.228.37) 772.460 ms bt-228-025.bta.net.cn (202.106.228.25) 2.152 ms 61.148.154.97 (61.148.154.97) 772.107 ms7 124.65.58.221 (124.65.58.221) 4.875 ms 61.148.146.29 (61.148.146.29) 2.124 ms 124.65.58.221 (124.65.58.221) 4.854 ms8 123.126.6.198 (123.126.6.198) 2.944 ms 61.148.156.6 (61.148.156.6) 3.505 ms 123.126.6.198 (123.126.6.198) 2.885 ms9 * * *10 * * *[root@localhost ~]#</code></pre><p>实例3：显示IP地址，不查主机名<br>    命令：traceroute -n <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>    输出：</p><pre><code>复制代码代码如下:[root@localhost ~]# traceroute -n www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets1 211.151.74.2 5.430 ms 5.636 ms 5.802 ms2 211.151.56.57 0.627 ms 0.625 ms 0.617 ms3 211.151.227.206 0.575 ms 0.584 ms 0.576 ms4 210.77.139.145 0.703 ms 0.754 ms 0.806 ms5 202.106.42.101 23.683 ms 23.869 ms 23.998 ms6 202.106.228.37 247.101 ms * *7 61.148.146.29 5.256 ms 124.65.58.213 4.386 ms 4.373 ms8 202.106.35.190 1.610 ms 61.148.156.138 1.786 ms 61.148.3.34 2.089 ms9 * * *30 * * *[root@localhost ~]# traceroute www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets1 211.151.74.2 (211.151.74.2) 4.671 ms 4.865 ms 5.055 ms2 211.151.56.57 (211.151.56.57) 0.619 ms 0.618 ms 0.612 ms3 211.151.227.206 (211.151.227.206) 0.620 ms 0.642 ms 0.636 ms4 210.77.139.145 (210.77.139.145) 0.720 ms 0.772 ms 0.816 ms5 202.106.42.101 (202.106.42.101) 7.667 ms 7.910 ms 8.012 ms6 bt-228-025.bta.net.cn (202.106.228.25) 2.965 ms 2.440 ms 61.148.154.97 (61.148.154.97) 431.337 ms7 124.65.58.213 (124.65.58.213) 5.134 ms 5.124 ms 5.044 ms8 202.106.35.190 (202.106.35.190) 1.917 ms 2.052 ms 2.059 ms9 * * *30 * * *[root@localhost ~]# </code></pre><p>实例4：探测包使用的基本UDP端口设置6888<br>    命令：traceroute -p 6888 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>    输出：</p><pre><code>复制代码代码如下:[root@localhost ~]# traceroute -p 6888 www.baidu.comtraceroute to www.baidu.com (220.181.111.147), 30 hops max, 40 byte packets1 211.151.74.2 (211.151.74.2) 4.927 ms 5.121 ms 5.298 ms2 211.151.56.1 (211.151.56.1) 0.500 ms 0.499 ms 0.509 ms3 211.151.224.90 (211.151.224.90) 0.637 ms 0.631 ms 0.641 ms4 * * *5 220.181.70.98 (220.181.70.98) 5.050 ms 5.313 ms 5.596 ms6 220.181.17.94 (220.181.17.94) 1.665 ms !X * *[root@localhost ~]# </code></pre><p>实例5：把探测包的个数设置为值4<br>    命令：traceroute -q 4 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>    输出：</p><pre><code>复制代码代码如下:[root@localhost ~]# traceroute -q 4 www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets1 211.151.74.2 (211.151.74.2) 40.633 ms 40.819 ms 41.004 ms 41.188 ms2 211.151.56.57 (211.151.56.57) 0.637 ms 0.633 ms 0.627 ms 0.619 ms3 211.151.227.206 (211.151.227.206) 0.505 ms 0.580 ms 0.571 ms 0.569 ms4 210.77.139.145 (210.77.139.145) 0.753 ms 0.800 ms 0.853 ms 0.904 ms5 202.106.42.101 (202.106.42.101) 7.449 ms 7.543 ms 7.738 ms 7.893 ms6 61.148.154.97 (61.148.154.97) 316.817 ms bt-228-025.bta.net.cn (202.106.228.25) 3.695 ms 3.672 ms *7 124.65.58.213 (124.65.58.213) 3.056 ms 2.993 ms 2.960 ms 61.148.146.29 (61.148.146.29) 2.837 ms8 61.148.3.34 (61.148.3.34) 2.179 ms 2.295 ms 2.442 ms 202.106.35.190 (202.106.35.190) 7.136 ms9 * * * *30 * * * *[root@localhost ~]# </code></pre><p>实例6：绕过正常的路由表，直接发送到网络相连的主机<br>    命令：traceroute -r <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>    输出：</p><pre><code>复制代码代码如下:[root@localhost ~]# traceroute -r www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packetsconnect: 网络不可达[root@localhost ~]# </code></pre><p>实例7：把对外发探测包的等待响应时间设置为3秒<br>    命令：traceroute -w 3 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>    输出：</p><pre><code>复制代码代码如下:[root@localhost ~]# traceroute -w 3 www.baidu.comtraceroute to www.baidu.com (61.135.169.105), 30 hops max, 40 byte packets1 211.151.74.2 (211.151.74.2) 2.306 ms 2.469 ms 2.650 ms2 211.151.56.1 (211.151.56.1) 0.621 ms 0.613 ms 0.603 ms3 211.151.227.206 (211.151.227.206) 0.557 ms 0.560 ms 0.552 ms4 210.77.139.145 (210.77.139.145) 0.708 ms 0.761 ms 0.817 ms5 202.106.42.101 (202.106.42.101) 7.520 ms 7.774 ms 7.902 ms6 bt-228-025.bta.net.cn (202.106.228.25) 2.890 ms 2.369 ms 61.148.154.97 (61.148.154.97) 471.961 ms7 124.65.58.221 (124.65.58.221) 4.490 ms 4.483 ms 4.472 ms8 123.126.6.198 (123.126.6.198) 2.948 ms 61.148.156.6 (61.148.156.6) 7.688 ms 7.756 ms9 * * *30 * * *[root@localhost ~]# </code></pre><p>###Traceroute的工作原理：<br>Traceroute最简单的基本用法是：traceroute hostname<br>Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器…… traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？<br>Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。<br>Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。<br>windows之tracert:<br>格式：  </p><pre><code>tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name  </code></pre><p>参数说明：  </p><pre><code>tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name  </code></pre><p>该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间     (TLS) 过期的报文并且对 tracert 无效。  </p><pre><code>参数：  -d 指定不对计算机名解析地址。  -h maximum_hops 指定查找目标的跳转的最大数目。  -jcomputer-list 指定在 computer-list 中松散源路由。  -w timeout 等待由 timeout 对每个应答指定的毫秒数。  target_name 目标计算机的名称。  </code></pre><p>实例：  </p><p>复制代码<br>代码如下:  </p><pre><code>C:\Users\Administrator&gt;tracert www.58.comTracing route to www.58.com [221.187.111.30]over a maximum of 30 hops:1 1 ms 1 ms 1 ms 10.58.156.12 1 ms &lt;1 ms &lt;1 ms 10.10.10.13 1 ms 1 ms 1 ms 211.103.193.1294 2 ms 2 ms 2 ms 10.255.109.1295 1 ms 1 ms 3 ms 124.205.98.2056 2 ms 2 ms 2 ms 124.205.98.2537 2 ms 6 ms 1 ms 202.99.1.1258 5 ms 6 ms 5 ms 118.186.0.1139 207 ms * * 118.186.0.10610 8 ms 6 ms 11 ms 124.238.226.20111 6 ms 7 ms 6 ms 219.148.19.17712 12 ms 12 ms 16 ms 219.148.18.11713 14 ms 17 ms 16 ms 219.148.19.12514 13 ms 13 ms 12 ms 202.97.80.11315 * * * Request timed out.16 12 ms 12 ms 17 ms bj141-147-82.bjtelecom.net [219.141.147.82]17 13 ms 13 ms 12 ms 202.97.48.218 * * * Request timed out.19 14 ms 14 ms 12 ms 221.187.224.8520 15 ms 13 ms 12 ms 221.187.104.221 * * * Request timed out.22 15 ms 17 ms 18 ms 221.187.111.30Trace complete.</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的&lt;br&gt;
    
    </summary>
    
      <category term="linux" scheme="http://datura.me/categories/linux/"/>
    
    
      <category term="traceroute" scheme="http://datura.me/tags/traceroute/"/>
    
  </entry>
  
  <entry>
    <title>linux 命令rsync+crontab实现自动同步</title>
    <link href="http://datura.me/2016/10/05/linux_%E5%91%BD%E4%BB%A4rsync+crontab%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E5%90%8C%E6%AD%A5/"/>
    <id>http://datura.me/2016/10/05/linux_命令rsync+crontab实现自动同步/</id>
    <published>2016-10-05T04:00:00.000Z</published>
    <updated>2018-12-18T03:58:18.723Z</updated>
    
    <content type="html"><![CDATA[<p>linux 命令rsync+crontab实现自动同步,这个技术现在已经用得很广泛了,比起第三方的软件要可靠好使,所以得到系统管理员的广泛应用;在此,我给大伙来分享一下;请指教.</p><p>首先,我们来了解一下这个命令:</p><p>rsync命令格式:rsync [option] 源路径 目标路径;<br><a id="more"></a><br>其中:  </p><p>[option]:  </p><pre><code>a:使用archive模式,等于-rlptgoD,即保持原有的文件权限;z:表示传输时压缩数据;v:显示到屏幕中;e:使用远程shell程序(可以使用rsh或ssh;--delete:精确保存副本,源主机删除的文件,目标主机也会同步删除;--include=PATTERN:不排除符合PATTERN的文件或目录;--exclude=PATTERN:排除所有符合PATTERN的文件或目录;--password-file:指定用于rsync服务器的用户验证密码;</code></pre><p>源路径和目标路径可以使用如下格式:</p><pre><code>rsync://[USER@]Host[:Port]/Path #--rsync服务器路径;[USER@]Host::Path   #--rsync服务器的另一种表示形式;[USER@]Host:Path#--远程路径;LocalPath   #--本地路径;</code></pre><p>知道上述命令的基本格式了吗?</p><p>下面我们来讲安装rsyn命令;</p><pre><code>[root@dbserver ~]#yum list rsync*Loaded plugins: fastestmirror, refresh-packagekit, securityLoading mirror speeds from cached hostfile * rpmforge: mirrors.neusoft.edu.cnInstalled Packagesrsync.i686  3.0.6-9.el6   @anaconda-CentOS-201207051201.i386/6.3[root@dbserver ~]#yum -y install rsync*</code></pre><p>前面是查看rsync RPM包,后面是安装rsync这个命令;</p><p>安装完后,我们便可以来配置rsync服务器与客服端了;</p><p>实例:</p><p>A服务器:192.168.1.213</p><p>B客户端:192.168.1.210</p><p>首先人们配置服务器,look,</p><p>在配置服务器之前要先生成密钥,ssh-keygen -t rsa,生成密钥如下:</p><pre><code>[root@masternagios .ssh]# lsid_rsa  id_rsa.pub[root@masternagios .ssh]#  scp id_rsa_pub root@192.168.1.210:/root/.ssh/authorized_keys</code></pre><p>在客户端也要如下操作:</p><pre><code>[root@masternagios .ssh]# ssh-keygen -t rsa[root@masternagios .ssh]# lsid_rsa  id_rsa.pub  authorized_keys(213的公钥)[root@masternagios.ssh]#scp id_rsa_pub root@192.168.1.213:/root/.ssh/authorized_keys</code></pre><p>这样两台机可以无密码SSH登陆,以便后面我们同步方便;当然,不要上述的操作也能实现;那么如下操作:</p><p>服务端:</p><pre><code>vi /etc/sery.pass  权限:600(chmod 600 /etc/sery.pass)root:123456</code></pre><p>客服端:</p><pre><code>vi /etc/sery_client.pass  权限:600(chmod 600 /etc/sery_client.pass)123456</code></pre><p>生成的这两件文件后面有用处的;</p><p>然后新建配置文件vi /etc/rsyncd.conf,内容如下图示:<br><img src="http://hiphotos.baidu.com/exp/pic/item/d872d695d143ad4b038f881c83025aafa50f060e.jpg" alt=""><br>解析如下:</p><pre><code>uid = root           #root用户访问(我这里用ROOT用户,也可以用其他新建的用户)gid = root           #root组用户访问use chroot = no      #不能使用chrootmax connections = 10  #最大连接数list = yes           #允许列出文件清单pid file = /var/run/rsyncd.pidlock file = /var/run/rsyncd.locklog file = /var/log/rsyncd.loghosts allow  = 192.168.1.2      #只允许这个主机访问</code></pre><p>   [data]                    #发布项(注意这个命名)</p><pre><code>path = /webapps/IDManage         #发布的路径ignore errorsread only = yes            #只读auth users = root                #认证用户为rootsecrets file = /etc/sery.pass    #密码文件</code></pre><p>然后我们来启动:</p><p>[root@masternagios ~]# rsync –daemon –config=/etc/rsyncd.conf</p><pre><code>[root@masternagios ~]# ps -ef |grep rsyncroot     21359     1  0 Aug24 ?        00:00:00 rsync --daemon --     config=/etc/rsyncd.confroot     24018 23885  0 10:38 pts/0    00:00:00 grep rsync[root@masternagios ~]#lsof -i:873COMMAND   PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAMErsync   21359 root    4u  IPv4 1558266      0t0  TCP *:rsync (LISTEN)rsync   21359 root    5u  IPv6 1558267      0t0  TCP *:rsync (LISTEN)</code></pre><p>然后在客户端测试:</p><pre><code>[root@dbserver ~]# telnet 192.168.1.213 873Trying 192.168.1.213...Connected to 192.168.1.213.Escape character is &apos;^]&apos;.@RSYNCD: 30.0^]telnet&gt; qConnection closed.</code></pre><p>说明网络端口开放,没有问题;通常在这配置时会发现一些问题,比如报错(111)–说明服务器端口未开启,就检查一下rsync服务有没有开启;</p><p>报错(1503)(1536)–说明无 [data] #发布项(注意这个命名),这里命令一定要对应上同步::[data];</p><p>我们再来把服务端rsync加自动启动;</p><pre><code>echo &quot;/usr/bin/rsync --daemon --config=/etc/rsyncd.conf&quot; &gt;&gt;/etc/rc.local</code></pre><p>配置客户端;</p><p>客户端只要安装rsync这个命令便可以实现,所以,我们来测试同步实现;</p><pre><code>[root@dbserver ~]#rsync -aSvH /webapps/IDManage/ root@192.168.1.213::data --password-file=/etc/sery_client.pass</code></pre><p>可以看到:<br><img src="http://hiphotos.baidu.com/exp/pic/item/346bd85c10385343bd094ffd9213b07ec88088ed.jpg" alt=""><br>命令执行成功;说明服务端与客户端都没有问题;</p><p>如何自实rsync客户端自动与rsync服务器端同步呢?这里我们用到计划任务命令:crontab;</p><p>首先,我们来做一个shell脚本,</p><pre><code>[root@dbserver ~]#vi /tmp/rsyncd.sh#!/bin/bashrsync -aSvH /webapps/IDManage/ root@192.168.1.213::data --password-file=/etc/sery_client.passwq!   ##保存退出[root@dbserver ~]#crontab -e*/5 * * * * sh /tmp/rsyncd.sh #第5分钟执行一次同步;wq!   ##保存退出</code></pre><p>看了,到此分享linux 命令rsync+crontab实现自动同步,已经结束;总结一点:rsync命令格式一定要知道:rsync [option] 源路径目标路径,目标路径的格式有几种,大家只要记得一两种便可以了;</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;linux 命令rsync+crontab实现自动同步,这个技术现在已经用得很广泛了,比起第三方的软件要可靠好使,所以得到系统管理员的广泛应用;在此,我给大伙来分享一下;请指教.&lt;/p&gt;
&lt;p&gt;首先,我们来了解一下这个命令:&lt;/p&gt;
&lt;p&gt;rsync命令格式:rsync [option] 源路径 目标路径;&lt;br&gt;
    
    </summary>
    
      <category term="rsync" scheme="http://datura.me/categories/rsync/"/>
    
    
      <category term="rsync" scheme="http://datura.me/tags/rsync/"/>
    
  </entry>
  
</feed>
